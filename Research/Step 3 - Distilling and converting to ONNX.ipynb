{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98b2c15-46b2-4b0f-9069-68cfe40d8dc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conversion to ONNX\n",
    "ONNX is a different format for running machine learning models. The ONNX format is much faster on CPU, sometimes 5 times as fast as PyTorch!\n",
    "\n",
    "While the EAWSW model is designed to be small, accurate and accessible, for some people it's still too much to run...\n",
    "\n",
    "Hosting the model as a free service for players is an option. An ONNX version of the model allows us to host the model on CPU yet have faster response times! Given that the model is made in a time with chip shortage, running on hardware I already have inside a server is efficient, scalable and cheaper.\n",
    "\n",
    "An important note is that ONNX doesn't execute logic by itself, and you have to do that yourself, `onnx_model_manager.py` intends to deal with this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "916b7a9d-8687-4c2f-8278-6f83d9fabbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_utils import train_model, split_data, split_branches, get_model, set_pretrained_model_dropout, get_dataset\n",
    "from config import Config\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import onnx\n",
    "import logging\n",
    "from onnx_model_manager import OnnxModelManager\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "import os\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from model_manager import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c6b87e8-66eb-4779-89a5-a8d7aad4376f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying config files from huggingface (needed for conversion)... WARNING: this assumes the structure of the model isn't changed!\n",
      "Cloning into 'gpt-neo-125M'...\n",
      "remote: Enumerating objects: 44, done.\u001b[K\n",
      "remote: Total 44 (delta 0), reused 0 (delta 0), pack-reused 44\u001b[K\n",
      "Unpacking objects: 100% (44/44), 543.14 KiB | 1.23 MiB/s, done.\n",
      "Using framework PyTorch: 1.10.1+cu113\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:555: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert batch_size > 0, \"batch_size has to be defined and > 0\"\n",
      "Validating ONNX model...\n",
      "\t-[✓] ONNX model output names match reference model ({'logits'})\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[✓] (2, 8, 50257) matches (2, 8, 50257)\n",
      "\t\t-[✓] all values close (atol: 0.001)\n",
      "All good, model saved at: models/awsw_onnx/model.onnx\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = os.path.join(\"models\", \"awsw_main\")\n",
    "saved_model_onnx_path = os.path.join(\"models\", \"awsw_onnx\")\n",
    "if not os.path.exists(os.path.join(saved_model_path, \"special_tokens_map.json\")):\n",
    "    print(\"Copying config files from huggingface (needed for conversion)... WARNING: this assumes the structure of the model isn't changed!\")\n",
    "    !cd $saved_model_path && git clone https://huggingface.co/$Config.base_model_name\n",
    "    !cp -n $saved_model_path/$Config.base_model_basename/* $saved_model_path\n",
    "    !rm -rf $saved_model_path/$Config.base_model_basename\n",
    "if not os.path.exists(os.path.join(saved_model_onnx_path, \"model.onnx\")):\n",
    "    !python3 -m transformers.onnx --model=$saved_model_path --feature=causal-lm --atol=1e-03 $saved_model_onnx_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3fe1e14-e2a5-4fa9-a331-ae156a8967e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore MatMul due to non constant B: /[MatMul_102]\n",
      "Ignore MatMul due to non constant B: /[MatMul_133]\n",
      "Ignore MatMul due to non constant B: /[MatMul_235]\n",
      "Ignore MatMul due to non constant B: /[MatMul_266]\n",
      "Ignore MatMul due to non constant B: /[MatMul_368]\n",
      "Ignore MatMul due to non constant B: /[MatMul_399]\n",
      "Ignore MatMul due to non constant B: /[MatMul_501]\n",
      "Ignore MatMul due to non constant B: /[MatMul_532]\n",
      "Ignore MatMul due to non constant B: /[MatMul_634]\n",
      "Ignore MatMul due to non constant B: /[MatMul_665]\n",
      "Ignore MatMul due to non constant B: /[MatMul_767]\n",
      "Ignore MatMul due to non constant B: /[MatMul_798]\n",
      "Ignore MatMul due to non constant B: /[MatMul_900]\n",
      "Ignore MatMul due to non constant B: /[MatMul_931]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1033]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1064]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1166]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1197]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1299]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1330]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1432]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1463]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1565]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1596]\n"
     ]
    }
   ],
   "source": [
    "def optimize_onnx():\n",
    "    model_quant = os.path.join(saved_model_onnx_path, \"model_quant.onnx\")\n",
    "    if not os.path.exists(model_quant):\n",
    "        model_fp32 = os.path.join(saved_model_onnx_path, \"model.onnx\")\n",
    "        model_opt = os.path.join(saved_model_onnx_path, \"model-opt.onnx\")\n",
    "        quantized_model = quantize_dynamic(model_fp32, model_quant, weight_type = QuantType.QInt8)\n",
    "        #!rm $model_opt\n",
    "optimize_onnx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b3ae8b2-8518-4071-9e7b-bfdd52087a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = 'cpu'\n",
    "device = torch.device(device_name)\n",
    "\n",
    "onnx_model_manager = OnnxModelManager(os.path.join(saved_model_onnx_path, \"model-opt.onnx\"))\n",
    "onnx_model_manager_quant = OnnxModelManager(os.path.join(saved_model_onnx_path, \"model_quant.onnx\"))\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model_manager = ModelManager(model=model, tokenizer=tokenizer, device=device)\n",
    "print(f\"Pretrained model loaded on {device_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed6291ed-7153-4904-826b-fb64f88fdaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX: In my dreams, I'm a dragon.\"<p><msg>c \"I see.\"<|endoftext|>\n",
      "ONNX (Quantized): In my dreams, I'm a dragon. My dreams, I'm a dragon. I'm a dragon. I'm a. My dreams, I'm a. And...\n",
      "\n",
      "And I'm a dragon, and I'm arian. My opponent.<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon. I'm a human with horns, wings, and tails, and I can feel the hunger that comes from hearing those stories.\"<d><scn>hallway<msg>Rz \"You can't be serious? You don't have to explain it to them.\"<p><msg>c \"But you do.\"<d><scn>hallway<msg>Rz \"If I didn't have the opportunity, I certainly would.\"<p><msg>c \"It's not as if you have to explain it to them.\"<p>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon.\"<p><msg></p><d>\"<d><scn>o2<msg>Ad \"Oh. I see.\"<p><msg>c \"I see.\"<p><msg>c \"I see.\"<p><msg>c \"I see.\"<p><msg>c \"I see you, [d]kay.\"<p><msg>c \"I see ya.\"<p><msg>c \"leave\"<d><scn>park1<msg>m \"Oh, Park1<msg>Ip \"Oh\n",
      "ONNX (Quantized): In my dreams, I'm a dragon. My dreams, I'm a dragon. My dreams, I'm a dragon. My dreams, I'm a\n",
      "\n",
      "And I'm a\n",
      "\n",
      "And I'm arian, arian.\n",
      "\n",
      "#agles and blue\n",
      "\n",
      "And I'm arian\n",
      "\n",
      "And I'm arian\n",
      "\n",
      "And I'm<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon.\"<d><scn>black<msg>Ry \"...\"<d><scn>black<msg>Ry \"...\"<d><scn>black<msg>Ry \"...\"<d><scn>black<msg>Ry \"...\"<d><scn>black<msg>Ry \"Hey, [player_name].\"<p><msg>c \"I know you're alluding to the mythological parts, but I'm not exactly the only one making that case.\"<p><msg>c \"I'm not\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prompt = \"In my dreams, I'm a dragon\"\n",
    "for i in range(2):\n",
    "    print(\"ONNX:\", onnx_model_manager.say_raw(prompt, do_sample=True))\n",
    "    print(\"ONNX (Quantized):\", onnx_model_manager_quant.say_raw(prompt, do_sample=True))\n",
    "    print(\"PyTorch:\", model_manager.say_raw(prompt, 50, 0.7))\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9396c5-9837-4c77-9011-1ac48b711286",
   "metadata": {
    "id": "unxN7nYd2gOM",
    "tags": []
   },
   "source": [
    "# Testing\n",
    "\n",
    "We created a few past (for context) + present prompts (player input) and see the different reactions. This way, we can test the models across different iterations.\n",
    "The first test involves a old prompt to compare the pre-trained model with the one trained on AWSW. Did it manage to store it's data well? Is it able to write down things that have nothing to do with AWSW? (So we know we didn't overfit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225c3279-83c5-4d81-b333-5d9450ad1a62",
   "metadata": {},
   "source": [
    "**This test generates boring and repetetive** replies! It's because we use no good sampling algorithm, but it does give us a indication of what the model has learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01cf23db-6013-4ff4-8a4f-effddd883295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: How are you?\n",
      "[Pytorch] Reply: park2<msg>Ry \"I'm alright. I just wanted to talk to you about something.\"<p><msg>c \"I was with Katsuharu today\"<d><scn>park2<msg>Ry \"Very nice\"<|endoftext|>\n",
      "\n",
      "[ONNX] Reply: park2<msg>Ry \"I'm alright. I just wanted to talk to you about something.\"<p><msg>c \"I was with Katsuharu today\"<d><scn>park2<msg>Ry \"Very nice\"<|endoftext|>\n",
      "\n",
      "[ONNX Quantized] Reply: <msg>office<msg<msg>d \"<p>cave\"<d><scn><d>cave<msg<msg>r \"<d><HER2>set<msg>Rey<skip><d><p<oje< damned>cave<><msg>Ad \"Begging for a nice and precious chance<d>Ad only...\"<p><msg>c \"Begging for not so\"<leave>rcast<msg>Ad \"I am not. IADers...]p<p>cxx<d>Ad\n",
      "\n",
      "----------\n",
      "Prompt: What do you think of Lorem?\n",
      "[Pytorch] Reply: park2<msg>Ad \"I think he is funny.\"<|endoftext|>\n",
      "\n",
      "[ONNX] Reply: park2<msg>Ad \"I think he is funny.\"<|endoftext|>\n",
      "\n",
      "[ONNX Quantized] Reply: <msg>Ad \"<p><msg>c \"\n",
      "<p> adore naomina\n",
      "<p> ad \"Not only is it its own, Adine the ad-taker, and I the only adore.\"<d><<|endoftext|>\n",
      "\n",
      "----------\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "[Pytorch] Reply: park2<msg>Ry \"I was with Katsuharu today\"<d><scn>park2<msg>Ry \"Very nice\"<|endoftext|>\n",
      "\n",
      "[ONNX] Reply: park2<msg>Ry \"I was with Katsuharu today\"<d><scn>park2<msg>Ry \"Very nice\"<|endoftext|>\n",
      "\n",
      "[ONNX Quantized] Reply: <msg>m<p<msg> adine:<msg>Ad \"beta. Adine. \"\n",
      "<paging<leave>cave<leave>ad \"<punch><msg>b\"<msg>Ad \"Adine<adine<t><t><closed\"<msg>Ad \"Adine\"<t> adine \"beta/If�cadinebeta\"<paging<adiread>cadine<paging<pad>cave<adineaptjeomiairopt<I>park<I>adineo<I\n",
      "\n",
      "----------\n",
      "Prompt: What will we do here?\n",
      "[Pytorch] Reply: cafe<msg>An \"I'll have to think about it. I don't know what will happen when I get back. I don't know if I can do this.\"<p><msg>c \"I don't know.\"<d><scn>cafe<msg>An \"I don't know. I don't know what will happen.\"<p><msg>c \"I don't\n",
      "\n",
      "[ONNX] Reply: cafe<msg>An \"I'll have to think about it. I don't know what will happen when I get back. I don't know if I can do this.\"<p><msg>c \"I don't know.\"<d><scn>cafe<msg>An \"I don't know. I don't know what will happen.\"<p><msg>c \"I don't know. I don't know what will happen.\"<p><msg>c \"I don't know. I don't know what will happen.\"<p><msg>c \"I\n",
      "\n",
      "[ONNX Quantized] Reply: alley<msg>m<tjeaddress<t value>cafe<msg>Ad \"<p><msg>c \"I'm not sure what ails. I'm not sure how that's supposed to be\"<d>Ad \"Ad \"<cave\"<p><kj not sure if it's even going to be in not so\"<takes<\n",
      "<_cave>Adrian not sure if it is even not going to a point to by noticoad its own kiddingsal only<|endoftext|>\n",
      "\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    ('<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hello, [player_name].\"', \"How are you?\"),\n",
    "    ('<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"', \"What do you think of Lorem?\"),\n",
    "    ('<p><msg>m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('<p><msg>m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "for (past, prompt) in prompts:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    reply = model_manager.say(past, prompt)\n",
    "    print(f\"[Pytorch] Reply: {reply}\\n\")\n",
    "    reply = onnx_model_manager.say(past, prompt)\n",
    "    print(f\"[ONNX] Reply: {reply}\\n\")\n",
    "    reply = onnx_model_manager_quant.say(past, prompt)\n",
    "    print(f\"[ONNX Quantized] Reply: {reply}\\n\")\n",
    "    print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a9ea4d-a30f-4c1a-a1f6-d5badff70453",
   "metadata": {},
   "source": [
    "# Sampling test\n",
    "\n",
    "This is gonna be interesting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9216177f-f03b-4358-8b5c-7eb0dc663af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: How are you?\n",
      "[Pytorch] Reply: park2<msg>Ry \"Not bad, thanks for the flowers.\"<p><msg>c \"I was with Sebastian today\"<d><scn>park2<msg>Ry \"Very nice\"<|endoftext|>\n",
      "\n",
      "[ONNX] Reply: park2<msg>Ry \"Good. I was just leaving for a meeting today.\"<p><msg>c \"I was with Zhong today\"<d><scn>park2<msg>Ry \"Very nice!\"<|endoftext|>\n",
      "\n",
      "[ONNX Quantized] Reply: <msg>office<msg<msg>d \"<p>cave<HER2?is<msg>sad<HERna>c \"She looks like she is going to be at least at least being at least at least as soon as the [shendongle<ERT](she may be that) [# of notches]/loremapta\"<parms>cxx<msg>rtle<msg>c \"Ad \"I see that the ad is not so chosen and that its not even the best its notched[/possiblefights not only the<br><pad>\n",
      "\n",
      "----------\n",
      "Prompt: What do you think of Lorem?\n",
      "[Pytorch] Reply: park2<msg>Ad \"I think he is funny.\"<|endoftext|>\n",
      "\n",
      "[ONNX] Reply: park2<msg>Ad \"I like the fact that he is also a member of the police department. What a great opportunity.\"<p><msg>c \"What are you talking about?\"<d><scn>park2<msg>Ad \"What do you think of Lorem?\"<p><msg>c \"I think he's ugly. I think his face is ugly.\"<|endoftext|>\n",
      "\n",
      "[ONNX Quantized] Reply: <msg>Ad \"<vateful#1>Irey<msg>beta<�<msg> artz<msg \"Adine\"<d>Ad \"Melt<Adine>Ad \"<tbody<kore>Ad \"<ps>Ad \"<punch+1<p>Adriano[/urendad4lacialje]](#,adept+islamad#39andonlomadbeta)\"<d>Adine2<tities<Irey+2<Irey>Adlifeminster2<_Ad cyclist<_Ad cyclist2Adje<\n",
      "\n",
      "----------\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "[Pytorch] Reply: office<msg>Ad \"I walked back to the park, but you came in the other way, and then stopped me there.\"<p><msg>c \"What are you talking about?\"<d><scn>office<msg>Ad \"The entrance is completely hidden by the wall. We could've just gotten out and walked back in, but the door was a bit narrow.\"\n",
      "\n",
      "[ONNX] Reply: park2<msg>Ry \"It is a giant, ugly building with huge windows, and a whole lot more people live around here. I don't know how long it has, but I bet it is pretty big. I'm not sure if it even has a name.\"<p><msg>c \"I see. Well, I guess it is pretty much a town.\"<d><scn>park2<msg>Ry \"I see. Well, I guess it has a lot to do in the town, though.\"<p><msg>c \"What do you think of Kevin?\"<d\n",
      "\n",
      "[ONNX Quantized] Reply: <msg>m<p<msg> adine:<msg>Ad \"I see that Adine meets its end and ends in the end, not so that it makes it<p><msg>t \"<paging>Adine<msg>Ad \"Stop, Adine\"<d>Adine<T>Adine<T><\"<paging [punch]<|endoftext|>\n",
      "\n",
      "----------\n",
      "Prompt: What will we do here?\n",
      "[Pytorch] Reply: padx<msg>Br \"I'm not sure. I was with Anna today\"<d><scn>padx<msg>Sb \"She left after her arrival, but I managed to catch up with her before she left\"<|endoftext|>\n",
      "\n",
      "[ONNX] Reply: o2<msg>Br \"We'll have to be careful. We have a few tests to make, so I'm not sure what the results will be. But I'm not going to make any excuses.\"<p><msg>c \"goes to park1<msg>m \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "\n",
      "[ONNX Quantized] Reply: alna<msg>m<t.<|endoftext|>\n",
      "\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for (past, prompt) in prompts:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    reply = model_manager.say(past, prompt, top_k = 50, top_p = 0.7)\n",
    "    print(f\"[Pytorch] Reply: {reply}\\n\")\n",
    "    reply = onnx_model_manager.say(past, prompt, do_sample = True)\n",
    "    print(f\"[ONNX] Reply: {reply}\\n\")\n",
    "    reply = onnx_model_manager_quant.say(past, prompt, do_sample = True)\n",
    "    print(f\"[ONNX Quantized] Reply: {reply}\\n\")\n",
    "    print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c3f1c-91c0-4585-92b6-fab86678834c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RP test\n",
    "Testing out the injected roleplay actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba8b6dcd-9723-4832-994e-c39411df2507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pytorch] Visit Lorem -> loremapt<msg>Lo \"Oh, [player_name], I wasn't expecting visitors.\"<|endoftext|>\n",
      "[ONNX] Visit Lorem -> loremapt<msg>Lo \"Oh, really?\"<p><msg>c \"I was with Katsuhiko today\"<d><scn>loremapt<msg>Lo \"Very nice\"<|endoftext|>\n",
      "[ONNX Quantized] Visit Lorem -> <msg>m<p<msg>d \"M<d>Adine<t><msg>c: \"<d><p><msg>c \"Be posted\"<d><msg>Ad \"d>Adine<t>Adspace<d>Adspace<><p><c< borderline\"<d><d><<>oreapts<ERTfightersinemediated><td><IANNared<td><<p><3<^<p><actualjeckxx<Iadj><Iadj>ad<Iadj\n",
      "----------\n",
      "[Pytorch] Meet with Lorem -> park1<msg>Em \"Oh, [player_name], I wasn't expecting visitors.\"<|endoftext|>\n",
      "[ONNX] Meet with Lorem -> loremapt<msg>Lo \"Oh, I see.\"<p><msg>c \"I was talking with Lorem about it, and I told her that she should go back to her home town. If she doesn't want to come back, I can arrange to meet here, but I'm not sure what else I should be doing.\"<d><scn>loremapt<msg>Lo \"She should probably go now, though.\"<p><msg>c \"Alright.\"<d><scn>loremapt<msg>Lo \"I'm sorry if this is a misunderstanding\n",
      "[ONNX Quantized] Meet with Lorem -> on<msg>m<d>c<msg<msg<d>d \"m/p2>c \"<|endoftext|>\n",
      "----------\n",
      "[Pytorch] Visit Adine -> adineapt<msg>Ad \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "[ONNX] Visit Adine -> adineapt<msg>Ad \"Hey, [player_name]. I didn't expect you to arrive so late.\"<|endoftext|>\n",
      "[ONNX Quantized] Visit Adine -> (<msg> or not<d><msg>Ad \"Adine\"<d>Adine<t>Adine<t><msg>KER \"Adine\"<d>Adine<t><KERought<AD><t><msg>Ad \"Beachback<IREP<りipsity>Adip<IREP<OST><OSTADE>admitad, andjeeling<IAD not onlyalloweenin<Adine<ADneyadine notADay and that\\ thenudeom<...]<|endoftext|>\n",
      "----------\n",
      "[Pytorch] Fight -> black<msg>m \"I didn't hesitate and kicked Bryce right in the stomach\"<|endoftext|>\n",
      "[ONNX] Fight -> ecknaomiapt03<msg>m \"Naomi barely avoids me and quickly fell to the floor\"<|endoftext|>\n",
      "[ONNX Quantized] Fight -> f<msg>Ad \"<d><pSTv><msgappy<msg> na \"<p><d><c><msg>c \"Stop, na\"<d><msg>Ad \"Stop, not even an hour later\"<p><c><2<^p><c>Adhar<msg><msg>Ad \"Stop, na\"<t>Ad \"Bead\"<d>Adhar<^cave<p><^c�<msg>Ad \"Stopish<ERTIF^><^<p>Ad \"\n",
      "----------\n",
      "[Pytorch] Attack -> np2x<msg>m \"Maverick barely avoids my attack and fell, but managed to get up and quickly punch me in the face, a soaring pain quickly came over my face\"<|endoftext|>\n",
      "[ONNX] Attack -> black<msg>m \"Katsuharu dodges my attack and falls, but my weapon is still stuck. It's too late.\"<|endoftext|>\n",
      "[ONNX Quantized] Attack -> f<msg>Ad \"<p><q two<msg>c \"<p><msg>c \"Adar<p>Admitterate <d>Adipail< declined be<q>c \"<p>Adriano<KERA<KERvideos>c \"<msg>Ad \"KERney<ERT> \"<t martia_d\"<d>Ad \"<p> Lumpur not sotbeta ormo<tbody<adinecapati>c<_andAdje<_AdineadjeKERdOr<_<_AdPosted<_\n",
      "----------\n",
      "Lowercase test\n",
      "[Pytorch] visit Lorem -> loremapt<msg>Ip \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "[ONNX] visit Lorem -> loremapt<msg>Lo \"Hey, [player_name].\"<p><msg>c \"Hey [cave_lunar_player_name]!\"<p><msg>c \"I'm Lorema\"<d><scn>loremapt<msg>Lo \"Oh, [cave>Llure<msg>Iz \"Oh, [player_name]!\"<p><msg>d><scn>lorem3x<msg>Iz \"Oh, [player_name]!\"<p><msg>c><msg\n",
      "[ONNX Quantized] visit Lorem -> f<msg>Ad \"?<p><msg<qhyd>c<q><msg>Ad \"ISDA\"<d><scn<msg> naqo>adim:<p>Ad \"I see\"<d>Ad \"ISDA\"<d><d<scn.je#>Adje#<msg>orel<Sharp><msg>tb<0><msg<adje><msg<adje> \"IAd IAdIAd only needs to run its<br>o<IADS<IADS<Iad\n",
      "[Pytorch] visit lorem -> loremapt<msg>Lo \"Hey [player_name]!\"<|endoftext|>\n",
      "[ONNX] visit lorem -> loremapt<msg>Lo \"Hey!\"<|endoftext|>\n",
      "[ONNX Quantized] visit lorem -> on<msg><msg \"Adine<t>mike<msg> no-houghto<msg>c \"Adine<t>Adine<msg> na< hands/kick\"<|endoftext|>\n",
      "----------\n",
      "[Pytorch] meet with Lorem -> loremapt<msg>Lo \"Hey [player_name]!\"<|endoftext|>\n",
      "[ONNX] meet with Lorem -> loremapt<msg>Lo \"Oh, [player_of interest].\"<|endoftext|>\n",
      "[ONNX Quantized] meet with Lorem -> c<msg<msg> na \"came on to the end of the day.<d><c>|<peeps>c<msg>d< firm<3<msg>office<msg> na <d>cave<t><msg<office>d<msg<msg>office2<private-adj \"I see that the end of the day, and the end of the day that they are |<p><msg>c \"\n",
      "<p> ad only\n",
      "<msg<p>office not only the second or thatthereal: The same<p>\n",
      "<c\n",
      "[Pytorch] meet with lorem -> loremapt<msg>Lo \"Hey [player_name]! How are you?\"<|endoftext|>\n",
      "[ONNX] meet with lorem -> loremapt<msg>Lo \"Hey [player_name], I didn't expect you to arrive so soon. How's your job?\"<|endoftext|>\n",
      "[ONNX Quantized] meet with lorem -> on<msg>c \"<d><p>c \"meet\"\n",
      "<d> be meet<|endoftext|>\n",
      "----------\n",
      "[Pytorch] visit Adine -> adineapt<msg>Ad \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "[ONNX] visit Adine -> adineapt<msg>Ad \"Oh, [lm id = \"adine\"].\"<p><msg>c \"I was with Anna yesterday\"<d><scn>adineapt<msg>Ad \"Oh, [m former partner].\"<p><msg>c \"I'm not sure what this is all of these are. I just wanted to give you this. It's a list of the things I used to have together before we met, but I'm not sure what kind of relationship it would have been if I had been with you.\"<p><msg>c \"\n",
      "[ONNX Quantized] visit Adine -> <msg>Ad \"<p>c<msg>Adje<Td> \"<p><msg>c \"Stop at\"<d>Ad \"<p>Adine\"<d>Ad \"ore[/d value]<d>Adition<Takine>Adine \"Stop, not so soft<p>Ad \"Not so\"<p><msg<t<p>Ad \"Not even a good< signatureposting<Irey]<p>Ad \"Not evenAdine notAdbeck notAd notAd notad toAdderNotishapointAdbeck\n",
      "[Pytorch] visit adine -> adineapt<msg>Ad \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "[ONNX] visit adine -> adineapt<msg>Ad \"Oh, it's you! Thanks for having me! I love you!\"<p><msg>c \"Hey [name=\" +<d><scn>adineapt<msg>Nm \"Adine!\"<d><scn>adineapt<msg>Ad \"Thankyou so much for having me. You're such a nice person, I'm sure.\"<p><msg>c \"I was with Sebastian today\"<d><scn>adineapt<msg>Ad \"Very nice\"<|endoftext|>\n",
      "[ONNX Quantized] visit adine -> <msg>Ad \"Ad \"<p><msg>Ad \"<p>Ad \"<p><msg<msg>Ad \"<p> ad \"<pares not sure if it is even better for it's going to be\"<Aero\"beta><t>Ad \"Not sure if it's even not so, notjava adine not only lashing to notate\"<p><ikkadine not only is notbetaje that itsjeaddress is not only.<p>AdSharp not only is<p<IthrowawayAdardian<IamAdrianAd\n",
      "----------\n",
      "[Pytorch] fight -> o4<msg>m \"I didn't hesitate and kicked Sebastian right in the stomach\"<|endoftext|>\n",
      "[ONNX] fight -> black<msg>m \"I didn't hesitate and kickedniper\"<|endoftext|>\n",
      "[ONNX Quantized] fight -> on<msg>m.txt \"<p><msg> k.txt \"<p><msg> k. k. k. k. k. k.<p><msg>c \"peter\"<d><msg> \"<p>< supe \"><cave\"\n",
      "<p> adine kinespaks<v><pad>c \"<d><p><2<salad><p><msg>c \"seat\"<d><d><msg<d>cadinead<adine><t>\n",
      "[Pytorch] fight -> ecknaomiapt01<msg>m \"Naomi barely avoids my attack and fell, but managed to get up and quickly punch me in the face, a soaring pain quickly came over my face\"<|endoftext|>\n",
      "[ONNX] fight -> ecknaomiapt03<msg>m \"Oh, [playerpowergreaterfarend]!\"<|endoftext|>\n",
      "[ONNX Quantized] fight -> on<msg>m.txt \"<p><msg>c \"M. My face\"<d><scn>m.<d><d><scn>alm<msg>Ad \"<p><msg>c \"pairship\"<d><sk<_adine>c \"Melt\"<d>Adar<sk><d><d><scn>adine<HERnery<HERbye_setjeomian_in_p_<_msg<_p>Adje#2<msg>omdje+\n",
      "----------\n",
      "[Pytorch] attack -> ecknaomiapt03<msg>m \"I didn't hesitate and kicked Bryce right in the stomach\"<|endoftext|>\n",
      "[ONNX] attack -> o2<msg>m \"Adine dodger\"<d><scn>o2<msg>Ad \"I think we should come here, then.\"<|endoftext|>\n",
      "[ONNX Quantized] attack -> f.<p><msg>c \"\n",
      "<p><mb><msg>c, \"<d><scn><p><msg>c \"\n",
      "<d><# tipoff<leave>cafe<tbody>r<cap><msg<eat>(hey)<eat>d>Ad \"<eat>o@tak<AD>beta<t><# \"PLAYBACK<AD#>Ad {\"barelegged<OST><private>tbodyadbeta/Adchester_[/ad_#xx<t>legged>re[/ad_\n",
      "[Pytorch] attack -> black<msg>m \"I didn't hesitate and kicked Sebastian right in the stomach\"<|endoftext|>\n",
      "[ONNX] attack -> black<msg>m \"Naomi dodges my attack andtches my attack on the ground\"<|endoftext|>\n",
      "[ONNX Quantized] attack -> f.<p><msg>c \"\n",
      "<paging>c \"<d><msg>c \"\n",
      "<paging><paging><d>c<msg<msg> \\<d>c \"Adine<I><msg>Ad \"<d><She passed out>r<msg<tbody>Ad<d><o><private>jealpha<D><private>je#<private<t>adine[/private>d playoff[/private]/abhantagoster_paging_sk2_extra/<private<_\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "test_rps = [\n",
    "    \"Visit Lorem\",\n",
    "    \"Meet with Lorem\",\n",
    "    \"Visit Adine\",\n",
    "    \"Fight\",\n",
    "    \"Attack\"\n",
    "]\n",
    "\n",
    "for rp in test_rps:\n",
    "    print(f'[Pytorch] {rp} -> {model_manager.say(\"\", rp, top_k = 50, top_p = 0.7)}')\n",
    "    print(f'[ONNX] {rp} -> {onnx_model_manager.say(\"\", rp, do_sample = True)}')\n",
    "    print(f'[ONNX Quantized] {rp} -> {onnx_model_manager_quant.say(\"\", rp, do_sample = True)}')\n",
    "    print(\"-\" * 10)\n",
    "    \n",
    "print(\"Lowercase test\")\n",
    "\n",
    "for rp in test_rps:\n",
    "    rp = rp[0].lower() + rp[1:]\n",
    "    print(f'[Pytorch] {rp} -> {model_manager.say(\"\", rp, top_k = 50, top_p = 0.7)}')\n",
    "    print(f'[ONNX] {rp} -> {onnx_model_manager.say(\"\", rp, do_sample = True)}')\n",
    "    print(f'[ONNX Quantized] {rp} -> {onnx_model_manager_quant.say(\"\", rp, do_sample = True)}')\n",
    "    rp = rp.lower()\n",
    "    print(f'[Pytorch] {rp} -> {model_manager.say(\"\", rp, top_k = 50, top_p = 0.7)}')\n",
    "    print(f'[ONNX] {rp} -> {onnx_model_manager.say(\"\", rp, do_sample = True)}')\n",
    "    print(f'[ONNX Quantized] {rp} -> {onnx_model_manager_quant.say(\"\", rp, do_sample = True)}')\n",
    "    print(\"-\" * 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
