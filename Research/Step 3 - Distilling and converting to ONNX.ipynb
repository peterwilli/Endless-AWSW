{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98b2c15-46b2-4b0f-9069-68cfe40d8dc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conversion to ONNX\n",
    "ONNX is a different format for running machine learning models. The ONNX format is much faster on CPU, sometimes 5 times as fast as PyTorch!\n",
    "\n",
    "While the EAWSW model is designed to be small, accurate and accessible, for some people it's still too much to run...\n",
    "\n",
    "Hosting the model as a free service for players is an option. An ONNX version of the model allows us to host the model on CPU yet have faster response times! Given that the model is made in a time with chip shortage, running on hardware I already have inside a server is efficient, scalable and cheaper.\n",
    "\n",
    "An important note is that ONNX doesn't execute logic by itself, and you have to do that yourself, `onnx_model_manager.py` intends to deal with this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "916b7a9d-8687-4c2f-8278-6f83d9fabbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_utils import train_model, split_data, split_branches, get_model, set_pretrained_model_dropout, get_dataset, ModelSeeder\n",
    "from config import Config\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import onnx\n",
    "import logging\n",
    "from onnx_model_manager import OnnxModelManager\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "import os\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from model_manager import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c6b87e8-66eb-4779-89a5-a8d7aad4376f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying config files from huggingface (needed for conversion)... WARNING: this assumes the structure of the model isn't changed!\n",
      "Cloning into 'gpt-neo-125M'...\n",
      "remote: Enumerating objects: 44, done.\u001b[K\n",
      "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
      "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
      "remote: Total 44 (delta 20), reused 0 (delta 0)\u001b[K\n",
      "Unpacking objects: 100% (44/44), 543.14 KiB | 1.21 MiB/s, done.\n",
      "Using framework PyTorch: 1.10.1+cu113\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> True\n",
      "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:90: UserWarning: 'enable_onnx_checker' is deprecated and ignored. It will be removed in the next PyTorch release. To proceed despite ONNX checker failures, catch torch.onnx.ONNXCheckerError.\n",
      "  warnings.warn(\"'enable_onnx_checker' is deprecated and ignored. It will be removed in \"\n",
      "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:103: UserWarning: `use_external_data_format' is deprecated and ignored. Will be removed in next PyTorch release. The code will work as it is False if models are not larger than 2GB, Otherwise set to False because of size limits imposed by Protocol Buffers.\n",
      "  warnings.warn(\"`use_external_data_format' is deprecated and ignored. Will be removed in next \"\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:556: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert batch_size > 0, \"batch_size has to be defined and > 0\"\n",
      "Validating ONNX model...\n",
      "\t-[✓] ONNX model outputs' name match reference model ({'present.11.key', 'logits', 'present.0.key', 'present.7.value', 'present.8.key', 'present.3.key', 'present.7.key', 'present.0.value', 'present.5.value', 'present.9.key', 'present.1.value', 'present.6.key', 'present.4.key', 'present.6.value', 'present.5.key', 'present.2.value', 'present.11.value', 'present.2.key', 'present.1.key', 'present.9.value', 'present.4.value', 'present.8.value', 'present.10.key', 'present.3.value', 'present.10.value'})\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[✓] (2, 8, 50257) matches (2, 8, 50257)\n",
      "\t\t-[x] values not close enough (atol: 1e-05)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/transformers/onnx/__main__.py\", line 77, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/transformers/onnx/__main__.py\", line 70, in main\n",
      "    validate_model_outputs(onnx_config, tokenizer, model, args.output, onnx_outputs, args.atol)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/transformers/onnx/convert.py\", line 214, in validate_model_outputs\n",
      "    raise ValueError(\n",
      "ValueError: Outputs values doesn't match between reference model and ONNX exported model: Got max absolute difference of: 0.012689590454101562\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = os.path.join(\"models\", \"awsw_mixed\")\n",
    "saved_model_onnx_path = os.path.join(\"models\", \"awsw_onnx\")\n",
    "if not os.path.exists(os.path.join(saved_model_path, \"special_tokens_map.json\")):\n",
    "    print(\"Copying config files from huggingface (needed for conversion)... WARNING: this assumes the structure of the model isn't changed!\")\n",
    "    !cd $saved_model_path && git clone https://huggingface.co/EleutherAI/gpt-neo-125M\n",
    "    !cp -n $saved_model_path/gpt-neo-125M/* $saved_model_path\n",
    "    !rm -rf $saved_model_path/gpt-neo-125M\n",
    "if not os.path.exists(os.path.join(saved_model_onnx_path, \"model.onnx\")):\n",
    "    !python3 -m transformers.onnx --model=$saved_model_path --feature=causal-lm-with-past $saved_model_onnx_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3fe1e14-e2a5-4fa9-a331-ae156a8967e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_onnx():\n",
    "    model_quant = os.path.join(saved_model_onnx_path, \"model_quant.onnx\")\n",
    "    if not os.path.exists(model_quant):\n",
    "        model_fp32 = os.path.join(saved_model_onnx_path, \"model.onnx\")\n",
    "        model_opt = os.path.join(saved_model_onnx_path, \"model-opt.onnx\")\n",
    "        quantized_model = quantize_dynamic(model_fp32, model_quant, weight_type = QuantType.QInt8)\n",
    "        #!rm $model_opt\n",
    "optimize_onnx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b3ae8b2-8518-4071-9e7b-bfdd52087a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "\n",
    "onnx_model_manager = OnnxModelManager(os.path.join(saved_model_onnx_path, \"model-opt.onnx\"))\n",
    "onnx_model_manager_quant = OnnxModelManager(os.path.join(saved_model_onnx_path, \"model_quant.onnx\"))\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model_manager = ModelManager(model=model, tokenizer=tokenizer, device=device)\n",
    "print(f\"Pretrained model loaded on {device_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed6291ed-7153-4904-826b-fb64f88fdaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX: In my dreams, I'm a dragon. I can fly, but I can't swim. I've got a four-headed dragon, so I'm not sure if I can do that.\"<p><d>\"I can't swim, I'm afraid.\"<|endoftext|>\n",
      "ONNX (Quantized): In my dreams, I'm a dragon. I can see that.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon. I've dreamed of dragons before, and I'm not sure what I'm going to find out.\"<d><scn>o2<msg>I'm not sure if there is anything in particular that I could do to help, but I'm not taking any samples. I'm not taking any samples. I'm not sure what the world record holder for \"most human\" would be, but I'm not taking any samples. I'm not sure if there is anything in particular that could be useful to add to the archives or what they would like to see me do.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon. I can fly, but I can't swim. I've got a four-headed dragon, so I'm not sure if I can do that.\"<d><scn>beach<scn>beah<|endoftext|>\n",
      "ONNX (Quantized): In my dreams, I'm a dragon. I can see that.\"<br>I can see that. All of you are dragon species. All of us are sentient mammals. You are the one with the most skill in the human simulation community, and your species is the one that keeps all our knowledge alive.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon. I can see it in your face. You're a dragon, so I can see exactly how you look at me. I'm not sure what you're talking about.\"<d><scn>black<msg>Ry \"I'm talking about my family. I don't know if they'll ever get what they think they can get.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prompt = \"In my dreams, I'm a dragon\"\n",
    "for i in range(2):\n",
    "    print(\"ONNX:\", onnx_model_manager.say_raw(prompt, do_sample=True))\n",
    "    print(\"ONNX (Quantized):\", onnx_model_manager_quant.say_raw(prompt, do_sample=True))\n",
    "    print(\"PyTorch:\", model_manager.say_raw(prompt, 50, 0.7))\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9396c5-9837-4c77-9011-1ac48b711286",
   "metadata": {
    "id": "unxN7nYd2gOM",
    "tags": []
   },
   "source": [
    "# Testing\n",
    "\n",
    "We created a few past (for context) + present prompts (player input) and see the different reactions. This way, we can test the models across different iterations.\n",
    "The first test involves a old prompt to compare the pre-trained model with the one trained on AWSW. Did it manage to store it's data well? Is it able to write down things that have nothing to do with AWSW? (So we know we didn't overfit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225c3279-83c5-4d81-b333-5d9450ad1a62",
   "metadata": {},
   "source": [
    "**This test generates boring and repetetive** replies! It's because we use no good sampling algorithm, but it does give us a indication of what the model has learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01cf23db-6013-4ff4-8a4f-effddd883295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: How are you?\n",
      "[Pytorch] Reply: park2<msg>Ry \"I'm fine. I just have a few questions about the murder of your colleague.\"<d><scn>park2<msg>Ry \"I'm afraid so.\"<d><scn>park2<msg>Ry \"I'm afraid so, but I have to admit, I was kinda annoyed about the whole thing. I guess it showed.\"<\n",
      "\n",
      "[ONNX] Reply: park2<msg>Ry \"I'm fine. I just have a few questions about the murder of your colleague.\"<d><scn>park2<msg>Ry \"I'm afraid so.\"<d><scn>park2<msg>Ry \"I'm afraid so, but I have to admit, I was kinda annoyed about the whole thing. I guess it showed.\"<d><scn>park2<msg>Ry \"I'm not sure about that.\"<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hello, [player_\n",
      "\n",
      "[ONNX Quantized] Reply: park2<msg>Ry \"I'm fine. I'm just a little busy.\"<p><msg>c \"What about you, Ipsum?\"<d><scn>park2<msg>Ip \"I was just kidding.\"<p><msg>c \"I was just kidding.\"<d><scn>park2<msg>Ry \"I was just kidding. I was just kidding.\"<|endoftext|>\n",
      "\n",
      "----------\n",
      "Prompt: What do you think of Lorem?\n",
      "[Pytorch] Reply: park2<msg>Ad \"I think he's funny.\"<|endoftext|>\n",
      "\n",
      "[ONNX] Reply: park2<msg>Ad \"I think he's funny.\"<|endoftext|>\n",
      "\n",
      "[ONNX Quantized] Reply: park2<msg>Ad \"I think he's cute.\"<p><msg>c \"I like his personality.\"<d><scn>park2<msg>Ad \"It's not that easy to find. I'm not a fan of the old school uniform.\"<d><scn>park2<msg>Ad \"I see.\"<p><msg>c \"What about you, Adine?\"<d><scn>park2<msg>Ad \"I can't really say I have.\"<p><msg>c \"I was with Adine today\"<d><scn>\n",
      "\n",
      "----------\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "[Pytorch] Reply: o2<msg>Ad \"It's a game. I'm not sure what it means.\"<p><msg>c \"What do you think of Kevin?\"<d><scn>o2<msg>Ad \"I think he's cute.\"<|endoftext|>\n",
      "\n",
      "[ONNX] Reply: o2<msg>Ad \"It's a game. I'm not sure what it means.\"<p><msg>c \"What do you think of Kevin?\"<d><scn>o2<msg>Ad \"I think he's cute.\"<|endoftext|>\n",
      "\n",
      "[ONNX Quantized] Reply: Adine? Is that you?\"<p><msg>c \"What are you doing here?\"<d><scn>Adine? Are you sure?\"<p><msg>c \"I'm not sure, but I can tell you that no expense will be spared to make this a nice and simple evening.\"<d><scn>Adine? Are you sure?\"<p><msg>c \"I'm not sure, but I can tell you that no expense will be spared to make this a nice and simple evening.\"<d><scn>Adine? Are you sure?\"<p><msg>\n",
      "\n",
      "----------\n",
      "Prompt: What will we do here?\n",
      "[Pytorch] Reply: facin2<msg>An \"I don't know. I don't want to be rude, but I think it's better if we go our separate ways.\"<|endoftext|>\n",
      "\n",
      "[ONNX] Reply: facin2<msg>An \"I don't know. I don't want to be rude, but I think it's better if we go our separate ways.\"<|endoftext|>\n",
      "\n",
      "[ONNX Quantized] Reply: facin2<msg>An \"We'll see.\"<p><msg>c \"What are you talking about?\"<d><scn>facin2<msg>An \"I didn't want to be rude, but I was just curious about your decision to participate.\"<p><msg>c \"I didn't want to be rude, but I was just curious about your decision to participate.\"<d><scn>facin2<msg>An \"Why not?\"<p><msg>c \"I'm not sure, but I'll have to try.\"<d><scn>facin\n",
      "\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    ('<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hello, [player_name].\"', \"How are you?\"),\n",
    "    ('<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"', \"What do you think of Lorem?\"),\n",
    "    ('<p><msg>m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('<p><msg>m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "for (past, prompt) in prompts:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    reply = model_manager.say(past, prompt)\n",
    "    print(f\"[Pytorch] Reply: {reply}\\n\")\n",
    "    reply = onnx_model_manager.say(past, prompt)\n",
    "    print(f\"[ONNX] Reply: {reply}\\n\")\n",
    "    reply = onnx_model_manager_quant.say(past, prompt)\n",
    "    print(f\"[ONNX Quantized] Reply: {reply}\\n\")\n",
    "    print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a9ea4d-a30f-4c1a-a1f6-d5badff70453",
   "metadata": {},
   "source": [
    "# Sampling test\n",
    "\n",
    "This is gonna be interesting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9216177f-f03b-4358-8b5c-7eb0dc663af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: How are you?\n",
      "[Pytorch] Reply: park2<msg>Ry \"I'm fine. I'm just sad to leave you alone with me.\"<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hello, [player_name].\"<p><msg>c \"What are you talking about?\"<d><scn>park2<msg>Ry \"Do you consider\n",
      "\n",
      "[ONNX] Reply: park2<msg>Ry \"I'm good, really. Thanks for your help.\"<d><scn>park2<msg>Ry \"Likewise!\"<|endoftext|>\n",
      "\n",
      "[ONNX Quantized] Reply: park2<msg>Ry \"I'm not. What are you talking about?\"<|endoftext|>\n",
      "\n",
      "----------\n",
      "Prompt: What do you think of Lorem?\n",
      "[Pytorch] Reply: park2<msg>Ad \"I think he's funny.\"<|endoftext|>\n",
      "\n",
      "[ONNX] Reply: park2<msg>Ad \"I think he's cute.\"<|endoftext|>\n",
      "\n",
      "[ONNX Quantized] Reply: park2<msg>Ad \"Not really. I think he's good look.\"<|endoftext|>\n",
      "\n",
      "----------\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "[Pytorch] Reply: o2<msg>Ad \"It's a long story.\"<p><msg>c \"Go to Emera\"<d><scn>emeraroom<msg>Em \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "\n",
      "[ONNX] Reply: o2<msg>Ad \"It's some kind of joke I saw you do.\"<p><msg>c \"I was unsure. Maybe I should just leave now.\"<p><msg>c \"I'm not leaving, though. What are you going to do with this when you're gone?\"<d><scn>o2<msg>Ad \"We could call a few of the police. I'd like you to take charge of the investigation, but I've got a meeting with the head of the police right now. They must be worried.\"<p><msg>c \"What do we have for\n",
      "\n",
      "[ONNX Quantized] Reply: Adine? Is that you?\"<pmsg>c \"What is it?\"<|endoftext|>\n",
      "\n",
      "----------\n",
      "Prompt: What will we do here?\n",
      "[Pytorch] Reply: facin2<msg>An \"I don't know. I don't want to face her. I don't want to face her. I don't want to face her. I don't want to face her. I don't want to face her. I don't want to face her. I don't want to face her. I don't want to face her. I don't want to face her. I don't want to face\n",
      "\n",
      "[ONNX] Reply: facin2<msg>An \"First up is a small part of the machine: the hood. It's like a piece of paper with a black and white part.\"<p><msg>c \"What do you think of Bryce?\"<d><scn>facin2<msg>An \"I dont like him as much anymore. I think he's cute.\"<p><msg>c \"What about you, Anna?\"<d><scn>facin2<msg>An \"I dont like him as much as I did.\"<|endoftext|>\n",
      "\n",
      "[ONNX Quantized] Reply: facin2<msg>An \"We'll see what the end result of your experiments is.\"<p><msg>c \"go to maverit\"<d><scn>remyapt<msg>Mv \"Oh, you're in luck. I have a few questions on your part about the four-headed human, and I'll be of use.\"<d><scn>remyapt<msg>Mv \"You're right. I'm not sure how to say this.\"<d><scn>remyapt<msg>Mv \"Okay, I guess I'll just say\n",
      "\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for (past, prompt) in prompts:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    reply = model_manager.say(past, prompt, top_k = 50, top_p = 0.7)\n",
    "    print(f\"[Pytorch] Reply: {reply}\\n\")\n",
    "    reply = onnx_model_manager.say(past, prompt, do_sample = True)\n",
    "    print(f\"[ONNX] Reply: {reply}\\n\")\n",
    "    reply = onnx_model_manager_quant.say(past, prompt, do_sample = True)\n",
    "    print(f\"[ONNX Quantized] Reply: {reply}\\n\")\n",
    "    print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c3f1c-91c0-4585-92b6-fab86678834c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RP test\n",
    "Testing out the injected roleplay actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba8b6dcd-9723-4832-994e-c39411df2507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pytorch] Visit Lorem -> loremapt<msg>Lo \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "[ONNX] Visit Lorem -> loremapt<msg>Lo \"Oh. This is going pretty long. I'll have more than enough time to get this done when I'm done.\"<p><msg>c \"I'm not sure if it's worth it to ask you to take a seat.\"<d><scn>loremapt<msg>Lo \"Oh, right. I see.\"<d><scn>loremapt<msg>Lo \"I'm sorry, but I can't sell my body for an I am.\"<p><msg>c \"Hey, Lorem. What's the problem?\"<d><sc\n",
      "[ONNX Quantized] Visit Lorem -> loremapt<msg>Lo \"I thought it would show up as soon as it was supposed.\"<p><msg>c \"Then it should show you some proof.\"<d><scn>loremapt<msg>Lo \"No. If you can't prove it, you'll want a lawyer.\"<p><msg>c \"I'm not sure I have anything to offer.\"<d><scn>loremapt<msg>Lo \"I'll have a few things for you to do.\"<p><msg>c \"hello kreak\"<d><scn>loremapt\n",
      "----------\n",
      "[Pytorch] Meet with Lorem -> loremapt<msg>Lo \"Hey [player_name]!\"<|endoftext|>\n",
      "[ONNX] Meet with Lorem -> loremapt<msg>Lo \"Hey [player_name]!\"<|endoftext|>\n",
      "[ONNX Quantized] Meet with Lorem -> loremapt<msg>Lo \"Oh, I see.\"<d><scn>loremapt<msg>Lo \"I'm just saying that it's nice to have you on our side as well.\"<p><msg>c \"I'm serious.\"<d><scn>loremapt<msg>Lo \"Then no one can take your actions.\"<p><msg>c \"I'm sure we'll find out when it's all over.\"<d><scn>loremapt<msg>Lo \"And we'll figure that out.\"<|endoftext|>\n",
      "----------\n",
      "[Pytorch] Visit Adine -> adineapt<msg>Ad \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "[ONNX] Visit Adine -> adineapt<msg>Ad \"Hey [player_name]!\"<|endoftext|>\n",
      "[ONNX Quantized] Visit Adine -> adineapt<msg>Ad \"Hey [player_name]! What's up?\"<|endoftext|>\n",
      "----------\n",
      "[Pytorch] Fight Maverick -> o2<msg>Mv \"I didn't think he was going to let me win.\"<d><scn>o2<msg>Mv \"You know what happened out on the night? I saw you struggling through your bars. You fell to the ground, and you look kinda sad.\"<p><msg>c \"Fight Maverick\"<d><scn>o2<msg>Mv \"I didn't think he was going to let me win.\"<d><scn>o2<msg>\n",
      "[ONNX] Fight Maverick -> o2<msg>Mv \"I didn't think we had it in you.\"<d><scn>o2<msg>Mv \"I was trying. You're my guest after all.\"<d><scn>o2<msg>Mv \"I'll just go ahead and watch it over.\"<|endoftext|>\n",
      "[ONNX Quantized] Fight Maverick -> np2y<msg>m \"I wasn't sure what to think. She was just doing it for fun. I didn't want to get her to shut off a little, but it was too bad if she didn't want me to see her. I was going to try to get her to leave, but I was too late.\"<d><scn>np2y<msg>m \"I wasn't going to let her talk. I wasn't going to let you down, just like that...\"<d><scn>np2y<msg>m \"Then I was going to head back to the\n",
      "----------\n",
      "[Pytorch] Fight Adine -> adine<msg>Ad \"I think you're cute.\"<p><msg>c \"Adine? Is that you?\"<d><scn>adine<msg>Ad \"Hey, [player_name].\"<|endoftext|>\n",
      "[ONNX] Fight Adine -> cafe<msg>m \"She didn't hesitate and kicked Adine right in the stomach\"<|endoftext|>\n",
      "[ONNX Quantized] Fight Adine -> adineapt<msg>Ad \"I think you are cute.\"<p><msg>c \"go to mong\"<d><scn>park2<msg>Mv \"Hey [player_name].\"<|endoftext|>\n",
      "----------\n",
      "[Pytorch] Attack Adine -> o2<msg>Ad \"What's that?\"<|endoftext|>\n",
      "[ONNX] Attack Adine -> adineapt<msg>Ad \"Hey [player_name], what's going on?\"<|endoftext|>\n",
      "[ONNX Quantized] Attack Adine -> Adine? Is that you?\"<|endoftext|>\n",
      "----------\n",
      "Lowercase test\n",
      "[Pytorch] visit Lorem -> loremapt<msg>Lo \"Hey [player_name]!\"<|endoftext|>\n",
      "[ONNX] visit Lorem -> loremapt<msg>Lo \"Oh, you're in the way that I'm not allowed to visit you for too much longer. I'll be sure and I'm sure to let your gaze go.\"<p><msg>c \"visit mr\"<d><scn>mre<msg>Lo \"Hey, [player_name].\"<|endoftext|>\n",
      "[ONNX Quantized] visit Lorem -> loremapt<msg>Lo \"Oh. I see.\"<d><scn>loremapt<msg>Lo \"What are they? Are they fireworks or some kind of activity?\"<p><msg>c \"No, thanks not for the late night. I'm still going to spend the rest off of my regular wage.\"<d><scn>loremapt<msg>Lo \"I see. Well, that was interesting.\"<|endoftext|>\n",
      "[Pytorch] visit lorem -> loremapt<msg>Lo \"Oh, [player_name], I wasn't expecting visitors.\"<|endoftext|>\n",
      "[ONNX] visit lorem -> loremapt<msg>Lo \"Oh, I see. I'm not sure if I'll get a chance to find out what you've been up to since you came into office.\"<p><msg>c \"visit mvaugh\"<d><scn>loremapt<msg>Lo \"Oh, I see. I'm not even sure if this will be my first time.\"<p><msg>c \"Visit maverick\"<d><scn>park1<msg>Mv \"Oh. Well, I know I'm not as interested in the result as you would have,\n",
      "[ONNX Quantized] visit lorem -> loremapt<msg>Lo \"It was nice to see you again.\"<d><scn>loremapt<msg>Lo \"You're a good choice.\"<p><msg>c \"hello mn\"<d><scn>loremapt<msg>Mv \"Hey, you two. What canI bring you up to?\"<d><scn>loremapt<msg>m \"I'll take a look, but I'm pretty busy right now.\"<d><scn>loremapt<msg>Lo \"I have no idea, but maybe I should try.\"\n",
      "----------\n",
      "[Pytorch] meet with Lorem -> loremapt<msg>Lo \"Hey [player_name]! How are you?\"<|endoftext|>\n",
      "[ONNX] meet with Lorem -> loremapt<msg>Lo \"Hey, [player_name], I didn't expect you to show up.\"<p><msg>c \"Hey.\"<d><scn>loremapt<msg>Lo \"What are those? Seas?\"<p><msg>c \"Just a souvenir for when I get back home.\"<d><scn>loremapt<msg>Lo \"I see.\"<p><msg>c \"Meet with Adine\"<d><scn>adineapt<msg>Ad \"What's up over at our apartment?\"<p><msg>\n",
      "[ONNX Quantized] meet with Lorem -> loremapt<msg>Lo \"I'm not sure what you are talking About.\"<d><scn>loremapt<msg>Lo \"What is it, [p] or is there a video game you can play?\"<d><scn>loremapt<msg>Lo \"I like to think of it as a game. I like to try and make a good game. I like to try and make a good game. I've had few games before that I've played.\"<d><scn>loremapt<msg>Lo \"I like to hear it. It's good to\n",
      "[Pytorch] meet with lorem -> loremapt<msg>Lo \"Hey [player_name]! How are you?\"<|endoftext|>\n",
      "[ONNX] meet with lorem -> loremapt<msg>Lo \"Hey, Lore. I know you two don't usually get to meet, but we're here now.\"<p><msg>c \"What's up with that, anyway? I mean, can't you just go ahead and call your lawyer and tell her you're here to have fun?\"<d><scn>loremapt<msg>Lo \"Of course not! I'm sure you'll find that to be a very fulfilling compliment.\"<p><msg>c \"I'm sure of It.\"<p><msg>c \"hello maverick\"<d><sc\n",
      "[ONNX Quantized] meet with lorem -> loremapt<msg>Lo \"Oh, [player_name], can you see I'm still in the middle of all this. I'm sure you'll help me out.\"<p><msg>c \"meet with rez\"<d><scn>reza<msg>Rz \"Hey.\"<|endoftext|>\n",
      "----------\n",
      "[Pytorch] visit Adine -> adineapt<msg>Ad \"Hey [player_name]! How are you?\"<|endoftext|>\n",
      "[ONNX] visit Adine -> adineapt<msg>Ad \"Hey [player_name]!\"<|endoftext|>\n",
      "[ONNX Quantized] visit Adine -> adineapt<msg>Ad \"Oh, [player_name]! How are you?\"<|endoftext|>\n",
      "[Pytorch] visit adine -> adineapt<msg>Ad \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "[ONNX] visit adine -> adineapt<msg>Ad \"Oh. That's good.\"<|endoftext|>\n",
      "[ONNX Quantized] visit adine -> adineapt<msg>Ad \"Oh, [playtime], what are you doing here? You've been in our world for hours?\"<p><msg>c \"go home\"<d><scn>adineapt<msg>Ad \"Oh, I was just about done today, so maybe I can find a better one for you. Or do you need to be there all night?\"<p><msg>c \"Go home.\"<d><scn>adineapt<msg>Ad \"Come on. Wake up.\"<p><msg>c \"go home\"<d><scn\n",
      "----------\n",
      "[Pytorch] fight Maverick -> o2<msg>m \"Maverick aimed at the dragon, which he quickly dove behind the box with the generator for cover. Though the dragon was still out of the picture, Maverick aimed at the box where it had started. He quickly dove behind the box with the generator for cover, but Maverick aimed at the dragon. It quickly dove behind the box with the generator for cover, but Maverick aimed at the dragon. It quickly dove behind the box with the generator for cover, but Maverick aimed at the dragon. It quickly\n",
      "[ONNX] fight Maverick -> o2<msg>m \"Mv \"I didn't hesitate and kicked Maverick right in the stomach\"<|endoftext|>\n",
      "[ONNX Quantized] fight Maverick -> alley<msg>m \"He didn't hesitate to kill me, but then... I started to see a little of an edge of his profile.\"<d><scn>alley<msg>m \"And I realized that if I didn‒ look at a piece of paper, like this one, then it was probably time to start practicing. I didn't have time for this. I was about ready to go on a proper day of life.\"<d><scn>alley<msg>m \"I looked around for a suitable stone and soon found it. I put my hands on top of my chest\n",
      "[Pytorch] fight maverick -> black<msg>m \"I didn't hesitate and kicked him right in the stomach.\"<d><scn>black<msg>m \"He didn't want to go on a date with me, so I got up and left.\"<p><msg>c \"go to reza\"<d><scn>reza<msg>Rz \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "[ONNX] fight maverick -> black<msg>m \"I wasn’t sure what to say. I didn’t want to talk to the other side of town, and I didn’t want to face the situation like I did. I didn’t think the people of the town council would want to hear about this.\"<d><scn>black<msg>m \"I wasn’t sure what I expected out from being able to get out that easily.\"<d><scn>black<msg>m \"I wasn‘t surprised to see that they didn’t throw the first two shots,\n",
      "[ONNX Quantized] fight maverick -> black<msg>m \"I didn't hesitate and kicked the box with the stone. It flew forward and knocked the box over. I wasn't even sure how much better I could get at that speed. If I held the trigger, the box would spin out of control.\"<d><scn>black<msg>m \"I wasn't going to let that go.\"<d><scn>black<msg>m \"I quickly dove behind the box to get a better look, but as I did so, the box spun out of control and started to spin out, throwing my body forward and out of the way\n",
      "----------\n",
      "[Pytorch] fight Adine -> o2<msg>m \"I didn't hesitate and kicked Adine right in the stomach\"<|endoftext|>\n",
      "[ONNX] fight Adine -> adine<msg>m \"I didn’t think he was going to get much easier.\"<d><scn>adine<msg>m \"He didn't hesitate and kicked me right into the ground.\"<d><scn>adine<msg>m \"I wasn‘t sure if he was going to stop until I was sure.\"<d><scn>adine<msg>m \"I wasn‘t sure if he was going for a nice drink, but I was sure he was going to make a face. I didn\\' see Adine approach, but when she got\n",
      "[ONNX Quantized] fight Adine -> cafe<msg>m \"I didn \"fight\" the animal before and after you. You may have noticed that I didn't throw a particularly big time, but you can still make time for the fish. I'll try to be as quick or as soon.\"<d><scn>cafe<msg>Ad \"I'm not a big fish, so don's have a good point.\"<|endoftext|>\n",
      "[Pytorch] fight adine -> adine2<msg>m \"I didn't hesitate and kicked Adine right in the stomach.\"<d><scn>adine2<msg>Adine barely avoids my attack and fell, but managed to get up and quickly punch me in the stomach, which caused me to collapse on the ground.\"<d><scn>adine2<msg>Adine's stomach was a little soggy, but she was still as strong as ever.\"<p><msg>c \"fight adine\"<d><sc\n",
      "[ONNX] fight adine -> adine<msg>m \"Adine dodghed the question, and I didn't hesitate to get up and leave. When I got back to the department, I was met with a number and a sign of a police officer, not by the way but by the way.\"<|endoftext|>\n",
      "[ONNX Quantized] fight adine -> adineapt<msg>Ad \"I'm going to put a few more tests on you, then.\"<d><scn>adineapt<msg>Ad \"I'm not sure, let me try it...\"<d><scn>adineapt<msg>Ad \"I'm not sure, let me try it...\"<d><scn>adineapt<msg>Ad \"I'm sure it's not going so well for you, but I'll have to see what kind of tests you have.\"<p><msg>c \"Go to Kevin\"<d><scn>park3\n",
      "----------\n",
      "[Pytorch] attack Adine -> adine<msg>m \"Adine barely avoids my attack and fell, but managed to get up and quickly punch me in the face, a soaring pain quickly came over my face\"<|endoftext|>\n",
      "[ONNX] attack Adine -> adine<msg>m \"Adine barely avoids the attack, but managed a quick turn and got away safely.\"<d><scn>adine<msg>m \"Adine wasn’t moving at the moment. I looked at her face to see her blush, but it was gone.\"<d><scn>adine<msg>Adine was silent for a moment, then nodded.\"<p \"I see.\"<|endoftext|>\n",
      "[ONNX Quantized] attack Adine -> Adine? Is that you?\"<d><scn><msg>Adine<d><msg>Ad \"Hey, what's going on here?\"<p><msg><c \"I'm not sure, but I have to leave.\"<|endoftext|>\n",
      "[Pytorch] attack adine -> adine<msg>Ad \"Oh, you're not going to get away that easily.\"<p><msg>c \"attack adine\"<d><scn>adine<msg>Ad \"I'm not sure if I can do that.\"<p><msg>c \"attack adine\"<d><scn>adine<msg>Ad \"What do you think of Lorem?\"<p><msg>c \"I think he's cute.\"<p><msg>c \"attack adine\"<d\n",
      "[ONNX] attack adine -> adine<msg>Ad \"Oh, you've got Adine. Where's her?\"<|endoftext|>\n",
      "[ONNX Quantized] attack adine -> cafe<msg>Ad \"I think I'd like to see you try that again. It's only a small part.\"<|endoftext|>\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "test_rps = [\n",
    "    \"Visit Lorem\",\n",
    "    \"Meet with Lorem\",\n",
    "    \"Visit Adine\",\n",
    "    \"Fight Maverick\",\n",
    "    \"Fight Adine\",\n",
    "    \"Attack Adine\"\n",
    "]\n",
    "\n",
    "for rp in test_rps:\n",
    "    print(f'[Pytorch] {rp} -> {model_manager.say(\"\", rp, top_k = 50, top_p = 0.7)}')\n",
    "    print(f'[ONNX] {rp} -> {onnx_model_manager.say(\"\", rp, do_sample = True)}')\n",
    "    print(f'[ONNX Quantized] {rp} -> {onnx_model_manager_quant.say(\"\", rp, do_sample = True)}')\n",
    "    print(\"-\" * 10)\n",
    "    \n",
    "print(\"Lowercase test\")\n",
    "\n",
    "for rp in test_rps:\n",
    "    rp = rp[0].lower() + rp[1:]\n",
    "    print(f'[Pytorch] {rp} -> {model_manager.say(\"\", rp, top_k = 50, top_p = 0.7)}')\n",
    "    print(f'[ONNX] {rp} -> {onnx_model_manager.say(\"\", rp, do_sample = True)}')\n",
    "    print(f'[ONNX Quantized] {rp} -> {onnx_model_manager_quant.say(\"\", rp, do_sample = True)}')\n",
    "    rp = rp.lower()\n",
    "    print(f'[Pytorch] {rp} -> {model_manager.say(\"\", rp, top_k = 50, top_p = 0.7)}')\n",
    "    print(f'[ONNX] {rp} -> {onnx_model_manager.say(\"\", rp, do_sample = True)}')\n",
    "    print(f'[ONNX Quantized] {rp} -> {onnx_model_manager_quant.say(\"\", rp, do_sample = True)}')\n",
    "    print(\"-\" * 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
