{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da2dbfd-5b54-424f-8643-6482bd916f0c",
   "metadata": {},
   "source": [
    "# Overfitting\n",
    "\n",
    "... Normally? A bad thing! But for our case it's good...\n",
    "\n",
    "We use a new method to mix an overfitted model (our own) with a pretrained model (GPT-Neo-125M) and have them share eachothers traits. This way it's possible to finetune a model without having to retrain it. It's so fast it can be done in a second on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b97b376-9ac5-4c70-ba13-769649099a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_utils import train_model, split_data, split_branches, get_model, set_pretrained_model_dropout, get_dataset, ModelSeeder\n",
    "from config import Config\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import onnx\n",
    "import logging\n",
    "from onnx_model_manager import OnnxModelManager\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "import os\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from model_manager import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887d9f81-96c3-408f-bd1c-7b126becc4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use cuda:0 for training with seed: 970988852\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randint(0, 2 ** 32 - 1)\n",
    "seed = 970988852\n",
    "random.seed(seed)\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(f\"Will use {device_name} for training with seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e95113e-dfc1-40a9-a39b-5d56f3bf32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(os.path.join(Config.work_dir, \"awsw_story_input.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb65c62-47c6-4d36-bd1e-2adfef8ff1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'lr': 0.001,\n",
    "    \"warmup_factor\": 5,\n",
    "    'scheduler': 'cosine_schedule_with_warmup',\n",
    "    \"lr_end\": 2e-6,\n",
    "    \"power\": 0.6,\n",
    "    \"freeze_from_steps\": -1,\n",
    "    'to_freeze_count': 0,\n",
    "    \"seed\": seed,\n",
    "    \"num_epoch\": 250\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ffae5b-e197-4417-a4cd-e6befc6ee393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded empty model\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = os.path.join(\"models\", \"awsw_main\")\n",
    "if os.path.exists(os.path.join(saved_model_path, \"pytorch_model.bin\")):\n",
    "    tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "    model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "    print(\"Pretrained model loaded\")\n",
    "else:\n",
    "    model, tokenizer = get_model(\"EleutherAI/gpt-neo-125M\")\n",
    "    print(\"Loaded empty model\")\n",
    "model = model.to(device)\n",
    "# set_pretrained_model_dropout(model.transformer.h, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f3315-8f5d-4101-8e7e-2c0129204c94",
   "metadata": {},
   "source": [
    "# Test before training on a pretrained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f68c3f1-4c0a-41a2-a3fc-b8b3c36e418c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragon, a fighter, and a princess. I'm a dragon.\n",
      "\n",
      "In this book, I have been talking about my dream. It's about a dragon who was sent to save my world from a monster called the White Dragon. I'm not sure if it's a fairy or a dragon, but it's definitely a dragon. I'm thinking it's the dragon who's supposed to be guarding the dragon's lair.\n",
      "\n",
      "In the book, I also had the dragon's head. I know it's supposed to protect me from a dragon. But I can't find it in my dreams\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model_manager = ModelManager(model=model, tokenizer=tokenizer, device=device)\n",
    "def test_regular_sampler():\n",
    "    print(model_manager.say_raw(\"In my dreams, I'm a dragon\", 50, 0.7))\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f74aa-5030-4ffd-ad2f-ae013647975e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reviewing our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0974ac13-c420-4275-b34a-3816f580cb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feec9c6db40546dea6811692668ff7d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2616 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2318 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RP review!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2616 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2354 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2760 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2291 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you needed was...\"<p><msg>c \"(I don't think there's anything in here.)\"<p><msg>c \"(And who let this mess ever get to print? Sheesh.)\"<p><msg>c \"What do you think of Lorem?\"<d><scn>o<msg>Lo \"He is a bit interesting.\"<|endoftext|><p><msg>c \"I'm not here to help you. This is where it ends.\"<d><scn>black<msg>Rz \"What is your problem, [player_name]? You know about the comet,\n",
      "----------\n",
      "aying too far from him, as the sun had already departed for the day and the remaining light diminished by the minute.\"<p><msg>c \"Fight Remy\"<d><scn>np1n<msg>m \"Remy barely avoids my attack and fell, but managed to get up and quickly punch me in the face, a soaring pain quickly came over my face\"<|endoftext|><p><msg>c \"I just came by to give you this. I was already at the library, but Emera refused to let me drop it off there.\"<d><scn>office<msg>Ry \"I\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(tokenizer, path_train = os.path.join(Config.work_dir, \"data_train.txt\"))\n",
    "with open(\"data_train_sample.txt\", 'w') as f:\n",
    "    for i, item in enumerate(dataset['train']):\n",
    "        f.write(tokenizer.decode(item['input_ids']) + \"\\n\")\n",
    "        \n",
    "print(\"RP review!\")\n",
    "to_see_rp = [\n",
    "    'c \"Fight ',\n",
    "    'c \"What do you think of Lorem?'\n",
    "]\n",
    "for item in dataset['train']:\n",
    "    decoded = tokenizer.decode(item['input_ids'])\n",
    "    for rp in list(to_see_rp):\n",
    "        if rp in decoded: \n",
    "            print(decoded)\n",
    "            print(\"-\" * 10)\n",
    "            to_see_rp.remove(rp)\n",
    "            continue\n",
    "    if len(to_see_rp) == 0:\n",
    "        break\n",
    "# Clean up\n",
    "del to_see_rp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e9e10-b2eb-421a-9948-dc3590e1f46d",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Model is put in training mode and we begin training. The `train_results` will contain all data after training is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41750b03-f114-46c4-948e-637db79efe15",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] set freeze_part_layers: True (freezing 0 out of 160 layers.)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41718' max='41750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41718/41750 4:43:32 < 00:13, 2.45 it/s, Epoch 250/250]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>417</td>\n",
       "      <td>1.615700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>834</td>\n",
       "      <td>0.960200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1251</td>\n",
       "      <td>2.849300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1668</td>\n",
       "      <td>1.608100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2085</td>\n",
       "      <td>0.494400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2502</td>\n",
       "      <td>0.339000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2919</td>\n",
       "      <td>0.270600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3336</td>\n",
       "      <td>0.247200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3753</td>\n",
       "      <td>0.233800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4170</td>\n",
       "      <td>0.228400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4587</td>\n",
       "      <td>0.218100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5004</td>\n",
       "      <td>0.214700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5421</td>\n",
       "      <td>0.205400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5838</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6255</td>\n",
       "      <td>0.197200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6672</td>\n",
       "      <td>0.193500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7089</td>\n",
       "      <td>0.192300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7506</td>\n",
       "      <td>0.187800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7923</td>\n",
       "      <td>0.185400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8340</td>\n",
       "      <td>0.183900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8757</td>\n",
       "      <td>0.178500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9174</td>\n",
       "      <td>0.179000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9591</td>\n",
       "      <td>0.176200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10008</td>\n",
       "      <td>0.173800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10425</td>\n",
       "      <td>0.170400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10842</td>\n",
       "      <td>0.170800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11259</td>\n",
       "      <td>0.169400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11676</td>\n",
       "      <td>0.165600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12093</td>\n",
       "      <td>0.164600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12510</td>\n",
       "      <td>0.164600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12927</td>\n",
       "      <td>0.162400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13344</td>\n",
       "      <td>0.160100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13761</td>\n",
       "      <td>0.158800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14178</td>\n",
       "      <td>0.159100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14595</td>\n",
       "      <td>0.157400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15012</td>\n",
       "      <td>0.157700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15429</td>\n",
       "      <td>0.156100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15846</td>\n",
       "      <td>0.153800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16263</td>\n",
       "      <td>0.152000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16680</td>\n",
       "      <td>0.152200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17097</td>\n",
       "      <td>0.150800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17514</td>\n",
       "      <td>0.149600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17931</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18348</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18765</td>\n",
       "      <td>0.147300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19182</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19599</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20016</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20433</td>\n",
       "      <td>0.142400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20850</td>\n",
       "      <td>0.142600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21267</td>\n",
       "      <td>0.142600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21684</td>\n",
       "      <td>0.141200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22101</td>\n",
       "      <td>0.140900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22518</td>\n",
       "      <td>0.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22935</td>\n",
       "      <td>0.138300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23352</td>\n",
       "      <td>0.140100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23769</td>\n",
       "      <td>0.138300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24186</td>\n",
       "      <td>0.137200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24603</td>\n",
       "      <td>0.136500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25020</td>\n",
       "      <td>0.136300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25437</td>\n",
       "      <td>0.135600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25854</td>\n",
       "      <td>0.135200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26271</td>\n",
       "      <td>0.134300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26688</td>\n",
       "      <td>0.133800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27105</td>\n",
       "      <td>0.133900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27522</td>\n",
       "      <td>0.132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27939</td>\n",
       "      <td>0.131600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28356</td>\n",
       "      <td>0.132200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28773</td>\n",
       "      <td>0.131300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29190</td>\n",
       "      <td>0.131300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29607</td>\n",
       "      <td>0.129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30024</td>\n",
       "      <td>0.130300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30441</td>\n",
       "      <td>0.129800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30858</td>\n",
       "      <td>0.129700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31275</td>\n",
       "      <td>0.128100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31692</td>\n",
       "      <td>0.128100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32109</td>\n",
       "      <td>0.127500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32526</td>\n",
       "      <td>0.127100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32943</td>\n",
       "      <td>0.127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33360</td>\n",
       "      <td>0.126600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33777</td>\n",
       "      <td>0.126200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34194</td>\n",
       "      <td>0.125700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34611</td>\n",
       "      <td>0.126000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35028</td>\n",
       "      <td>0.125400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35445</td>\n",
       "      <td>0.124800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35862</td>\n",
       "      <td>0.125200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36279</td>\n",
       "      <td>0.124700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36696</td>\n",
       "      <td>0.124300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37113</td>\n",
       "      <td>0.124500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37530</td>\n",
       "      <td>0.124500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37947</td>\n",
       "      <td>0.124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38364</td>\n",
       "      <td>0.123800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38781</td>\n",
       "      <td>0.123300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39198</td>\n",
       "      <td>0.123100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39615</td>\n",
       "      <td>0.122800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40032</td>\n",
       "      <td>0.122500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40449</td>\n",
       "      <td>0.122200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40866</td>\n",
       "      <td>0.123300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41283</td>\n",
       "      <td>0.122900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41700</td>\n",
       "      <td>0.123100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results = {}\n",
    "model.train()\n",
    "train_model(model, tokenizer, dataset, config, train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c410a601-c5e4-4cc1-af2b-44a7378f3bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5b8085db20>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "fig.suptitle('Learning rate and loss')\n",
    "axs[0].plot(train_results['learning_rate_history'])\n",
    "axs[1].plot(train_results['loss_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "753228f0-b420-4b3d-bd69-53da7a87bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.save_pretrained(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30070cdb-23d0-4755-a517-2198a0454794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visit Lorem -> loremapt<msg>Lo \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "[sampled] Visit Lorem -> loremapt<msg>Lo \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "----------\n",
      "Meet with Lorem -> loremapt<msg>Lo \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "[sampled] Meet with Lorem -> loremapt<msg>Lo \"Oh, [player_name], I wasn't expecting visitors.\"<|endoftext|>\n",
      "----------\n",
      "Visit Adine -> adineapt<msg>Ad \"Hey [player_name]! How are you?\"<|endoftext|>\n",
      "[sampled] Visit Adine -> adineapt<msg>Ad \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "----------\n",
      "Fight Maverick -> park2<msg>m \"Maverick barely avoids my attack and fell, but managed to get up and quickly punch me in the face, a soaring pain quickly came over my face\"<|endoftext|>\n",
      "[sampled] Fight Maverick -> np1r<msg>m \"Maverick dodges my attack and comes rushing towards me\"<|endoftext|>\n",
      "----------\n",
      "Bite Adine -> o2<msg>Ad \"Wtf you think you doing?\"<|endoftext|>\n",
      "[sampled] Bite Adine -> adineapt<msg>Ad \"Think you can hurt me?\"<|endoftext|>\n",
      "----------\n",
      "Attack Adine -> adineapt<msg>m \"Adine dodges my attack and comes rushing towards me\"<|endoftext|>\n",
      "[sampled] Attack Adine -> np2x<msg>m \"Adine barely avoids my attack and fell, but managed to get up and quickly punch me in the face, a soaring pain quickly came over my face\"<|endoftext|>\n",
      "----------\n",
      "Lowercase test\n",
      "visit Lorem -> loremapt<msg>Lo \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "visit lorem -> loremapt<msg>Lo \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "----------\n",
      "meet with Lorem -> loremapt<msg>Lo \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "meet with lorem -> loremapt<msg>Lo \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "----------\n",
      "visit Adine -> adineapt<msg>Ad \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "visit adine -> adineapt<msg>Ad \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "----------\n",
      "fight Maverick -> park2<msg>m \"Maverick barely avoids my attack and fell, but managed to get up and quickly punch me in the face, a soaring pain quickly came over my face\"<|endoftext|>\n",
      "fight maverick -> park2<msg>m \"Maverick barely avoids my attack and fell, but managed to get up and quickly punch me in the face, a soaring pain quickly came over my face\"<|endoftext|>\n",
      "----------\n",
      "bite Adine -> o2<msg>Ad \"Wtf you think you doing?\"<|endoftext|>\n",
      "bite adine -> adineapt<msg>Ad \"Wtf you think you doing?\"<|endoftext|>\n",
      "----------\n",
      "attack Adine -> adineapt<msg>m \"Adine barely avoids my attack and fell, but managed to get up and quickly punch me in the face, a soaring pain quickly came over my face\"<|endoftext|>\n",
      "attack adine -> adineapt<msg>m \"Adine barely avoids my attack and fell, but managed to get up and quickly punch me in the face, a soaring pain quickly came over my face\"<|endoftext|>\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "test_rps = [\n",
    "    \"Visit Lorem\",\n",
    "    \"Meet with Lorem\",\n",
    "    \"Visit Adine\",\n",
    "    \"Fight Maverick\",\n",
    "    \"Bite Adine\",\n",
    "    \"Attack Adine\"\n",
    "]\n",
    "\n",
    "for rp in test_rps:\n",
    "    print(f'{rp} -> {model_manager.say(\"\", rp)}')\n",
    "    print(f'[sampled] {rp} -> {model_manager.say(\"\", rp, top_k = 50, top_p = 0.7)}')\n",
    "    print(\"-\" * 10)\n",
    "    \n",
    "print(\"Lowercase test\")\n",
    "\n",
    "for rp in test_rps:\n",
    "    rp = rp[0].lower() + rp[1:]\n",
    "    print(f'{rp} -> {model_manager.say(\"\", rp)}')\n",
    "    rp = rp.lower()\n",
    "    print(f'{rp} -> {model_manager.say(\"\", rp)}')\n",
    "    print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5946f900-c221-48a9-8436-c0051890bcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm not sure, exactly. It's probably some kind of vegetable blend.\"<p><msg>c \"I see. What kind of meat is commonly eaten around here, anyway?\"<d><scn>black<msg>Ry \"Aurochs meat. Are you familiar with that animal?\"<|endoftext|>\n",
      "Reply [sampled]: park2<msg>Ry \"I'm not sure, exactly. It's probably some kind of vegetable blend.\"<p><msg>c \"I see. What kind of meat is commonly eaten around here, anyway?\"<d><scn>black<msg>Ry \"Aurochs meat. Are you familiar with that animal?\"<|endoftext|>\n",
      "----------\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"I think he is funny.\"<|endoftext|>\n",
      "Reply [sampled]: park2<msg>Ad \"I think he is good looking.\"<|endoftext|>\n",
      "----------\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: adineapt<msg>Ad \"Well, I'm not going to tell you. Do you want me to put it on or not?\"<|endoftext|>\n",
      "Reply [sampled]: adineapt<msg>Ad \"Well, I'm not going to tell you. Do you want me to put it on or not?\"<|endoftext|>\n",
      "----------\n",
      "Prompt: What will we do here?\n",
      "Reply: facin2<msg>An \"I don't know where you are going, but I think I need a coffee or five. You can tag along if you like.\"<p><msg>c \"I think I'd rather not.\"<d><scn>facin2<msg>An \"Suit yourself.\"<d><scn>facin2<msg>n \"Whatever the reason, I decided not to join her\n",
      "Reply [sampled]: facin2<msg>An \"I don't know where you are going, but I think I need a coffee or five. You can tag along if you like.\"<p><msg>c \"I think I'd rather not.\"<d><scn>facin2<msg>An \"Suit yourself.\"<d><scn>facin2<msg>n \"Whatever the reason, I decided not to join her\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    ('<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hello, [player_name].\"', \"How are you?\"),\n",
    "    ('<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"', \"What do you think of Lorem?\"),\n",
    "    ('<p><msg>m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('<p><msg>m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "def prompt_test(model_manager, do_sample_test = True):\n",
    "    for (past, prompt) in prompts:\n",
    "        print(f\"Prompt: {prompt}\")\n",
    "        reply = model_manager.say(past, prompt)\n",
    "        print(f\"Reply: {reply}\")\n",
    "        if do_sample_test:\n",
    "            reply = model_manager.say(past, prompt, top_k = 50, top_p = 0.7)\n",
    "            print(f\"Reply [sampled]: {reply}\")\n",
    "        print(\"-\" * 10)\n",
    "        \n",
    "prompt_test(model_manager)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
