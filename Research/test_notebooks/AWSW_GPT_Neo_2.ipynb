{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-11-15T03:52:23.862863Z",
     "iopub.status.busy": "2021-11-15T03:52:23.862372Z",
     "iopub.status.idle": "2021-11-15T03:52:24.067817Z",
     "shell.execute_reply": "2021-11-15T03:52:24.067108Z"
    },
    "id": "2TJ-BqFtQ86M",
    "outputId": "f41c5626-6827-4d90-f0a9-8a11c01a366d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 15 03:52:23 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.63.01    Driver Version: 470.63.01    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| N/A   59C    P3    38W /  N/A |   1469MiB / 16125MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-11-15T03:52:24.072717Z",
     "iopub.status.busy": "2021-11-15T03:52:24.072225Z",
     "iopub.status.idle": "2021-11-15T03:52:25.869329Z",
     "shell.execute_reply": "2021-11-15T03:52:25.868783Z"
    },
    "id": "oR9S63qiQt2b",
    "outputId": "b1303393-4c18-4510-da76-59e5f2590db8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/awsw-dev/.local/lib/python3.8/site-packages (4.12.3)\r\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (1.15.1)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.26.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/awsw-dev/.local/lib/python3.8/site-packages (from transformers) (0.1.2)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.0.12)\r\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers) (0.0.45)\r\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.10.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2021.8.28)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (5.4.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.62.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.2)\r\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.4)\r\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (5.0.0)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (2.0.2)\r\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.12.2)\r\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2021.8.1)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.2)\r\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2021.5.30)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.6)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.0.4)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\r\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.0.1)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.16.0)\r\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (8.0.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (2.4.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2021.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.1)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (5.2.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.2.0)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.7.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (21.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T03:52:25.876153Z",
     "iopub.status.busy": "2021-11-15T03:52:25.875591Z",
     "iopub.status.idle": "2021-11-15T03:52:27.295690Z",
     "shell.execute_reply": "2021-11-15T03:52:27.295304Z"
    },
    "id": "GhhigZYMRK6N"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "from random import randrange\n",
    "import multiprocessing\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config, GPT2LMHeadModel, GPTNeoForCausalLM\n",
    "from transformers import AdamW, get_cosine_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup, get_polynomial_decay_schedule_with_warmup\n",
    "from transformers import Trainer, TrainingArguments, TrainerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T03:52:27.301042Z",
     "iopub.status.busy": "2021-11-15T03:52:27.300256Z",
     "iopub.status.idle": "2021-11-15T03:52:27.302400Z",
     "shell.execute_reply": "2021-11-15T03:52:27.302722Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '9994' # modify if RuntimeError: Address already in use\n",
    "os.environ['RANK'] = \"0\"\n",
    "os.environ['LOCAL_RANK'] = \"0\"\n",
    "os.environ['WORLD_SIZE'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-11-15T03:52:27.325778Z",
     "iopub.status.busy": "2021-11-15T03:52:27.325153Z",
     "iopub.status.idle": "2021-11-15T03:52:27.327567Z",
     "shell.execute_reply": "2021-11-15T03:52:27.327899Z"
    },
    "id": "MTduRlf-RQJa",
    "outputId": "296dba31-0af6-422c-eea8-f5c1130a5daf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use cuda:0 for training with seed: 1920244490\n"
     ]
    }
   ],
   "source": [
    "seed = random.randint(0, 2 ** 32 - 1)\n",
    "random.seed(seed)\n",
    "block_size = 64\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(f\"Will use {device_name} for training with seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278,
     "referenced_widgets": [
      "641f6e8a671d4dfe9da34c7685520767",
      "c7eb14f1388e42f29fbac8eef195fede",
      "40b7d134ba7b40299f6bd16b1e781d09",
      "13e5a9ab53bc4e1d8c3c7905ebd05ddf",
      "bc3c9b957d93490c8f9773e7050fd4ef",
      "e702472021334098b47210f9f1395f21",
      "8ed62e486a664d1f83fee6f21cb4585d",
      "ad42520b822e4454947f5d466424c8ca",
      "917d4196cdd14970b7965652f3b950a2",
      "3d72f5178e404d8c948ef13fc81a2bb8",
      "0ae32803eeaf436ab66cb3da9ff5439d",
      "5f28c40531fc4f43b4b62fd04912100c",
      "3c7dd63eb62d44598666166a87c0ff88",
      "7ed9d2386d57488c890d1ec712d1bef0",
      "da3c1240d6a94f3c9ff9ec0545675446",
      "cc7c2ac1006b4b109f302d7d26e3a578",
      "9bb4dcdb6f434d8b8cc95ef80f2ffe00",
      "5af83a55a73b4f3481a7559951ebdf08",
      "c4384ee96a1a4ae4bc8b46fa640b9058",
      "5f2bf3aebfd64baf94df39964208af4c",
      "307da63f10ad4ae5ae5e7e387d176d39",
      "8a282a2414874cb588a386e1444951dd",
      "659e0ad7f39c4cdbbdc1345c07a2e3f4",
      "1481fbbc74544c4888c0d6f88d8b3c9d",
      "54b833977b424c25a690d1bfe5d8c3f1",
      "8bfab1db231a4ff1975775f81f8a84f1",
      "3af5019cfacf4afc8a15a14d9a121ea8",
      "0ac398931b04418cbd3d227b9c634883",
      "7789164b5ee245b3a537d9d61dae038f",
      "8abd99000df0453e86bc458be29a10c7",
      "7db95c969d94465aaffbe9139f0f2a90",
      "d21de377e9074df083556c68e7d7cdbb",
      "3a0ada2f620a40aaa6c33fcea7a0bb91",
      "38bc8c5a2a3447e7942e2058c35d5e5b",
      "79170285a49a450494f0bfbe6cb4788e",
      "9813f2bda5ce4ab6887683fe63d0629e",
      "5c6ca36359bb4a1982c599f6a3f23b9f",
      "6e2cfa054082449e942297afd2f50f73",
      "5f3133f5c7254c248dad8e75534ea920",
      "eef06f8bc02749f4b04af47d92eb91b2",
      "2c60d924ee7b4fad984e2072973c3af3",
      "c1132ffe6c684c7ebeb3f285a101536b",
      "aa2a21546de1463f88a7feb8b697f9d3",
      "0abba2f64b4a43abadb38d461a5c7f42",
      "f43e9d4fa52c48c087ffeef399bfbed6",
      "4f1eafd9553b4bd5b396bba8f3896a22",
      "bbd5e6b14d864c1eb6a4d9c4247fb520",
      "29b2e68155a947e0aca0760c7e8e4afa",
      "fa1b29c48993478f9c2be4877ec675fc",
      "e4a6b2af572e44eda537e74847c58709",
      "8110f29e7b134607b38b29fad32ab1a1",
      "470ba5ce89ee4927a9be685adbc08675",
      "d10fbe074d4b42c9a8a6522252ef016f",
      "5af59ca6be4a427c8f83a906bbb6ce93",
      "17c9592d03324c4797abc812044e7500",
      "f6153c2ce07b4f4097a2a0486fb896ac",
      "3daedb3b85264408a8821ee2e480b356",
      "b2ce0d43567b4cc09e1f5571ee25263c",
      "c3a28b9889cd40e2ac0b9860e7f3932b",
      "99e992b8d4564ddd9c7634ac7663053a",
      "ae627a7820d4450a97b47d63dd5fbd92",
      "56a8c3c144404bd793e29a023032a09f",
      "2a9348d6cd674898ac4c9a303a254f26",
      "bafebeb0fba04d148ae3adf44171e0fe",
      "a8e19067a3ad411cad1aba489d390516",
      "6cf4e15a56fc4ac188609b806f11afcd"
     ]
    },
    "execution": {
     "iopub.execute_input": "2021-11-15T03:52:27.335798Z",
     "iopub.status.busy": "2021-11-15T03:52:27.334974Z",
     "iopub.status.idle": "2021-11-15T03:52:36.421941Z",
     "shell.execute_reply": "2021-11-15T03:52:36.421455Z"
    },
    "id": "QSVYD7o_eL2o",
    "outputId": "4f570825-b314-421b-b1ee-07449f7787f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading empty, pre-trained model with 76 parameters.\n",
      "Model attached to cuda:0\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(\"/opt/awsw\"):\n",
    "  # In case we run this locally (in Docker)\n",
    "  work_dir = os.path.join(\"/opt\", \"awsw\")\n",
    "else:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  work_dir = os.path.join(\"/content\", \"drive\", \"MyDrive\", \"endless_awsw\")\n",
    "\n",
    "models_dir = os.path.join(work_dir, \"models_5\")\n",
    "\n",
    "if not os.path.isdir(models_dir):\n",
    "    pathlib.Path(models_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "#tokenizer = GPT2Tokenizer.from_pretrained('EleutherAI/gpt-neo-125M', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n",
    "#model = GPTNeoForCausalLM.from_pretrained('EleutherAI/gpt-neo-125M', pad_token_id = tokenizer.pad_token_id, bos_token_id=tokenizer.bos_token_id, eos_token_id=tokenizer.eos_token_id)\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained('EleutherAI/gpt-neo-1.3B', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n",
    "#model = GPTNeoForCausalLM.from_pretrained('EleutherAI/gpt-neo-1.3B', pad_token_id = tokenizer.pad_token_id, bos_token_id=tokenizer.bos_token_id, eos_token_id=tokenizer.eos_token_id)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n",
    "model = GPT2LMHeadModel.from_pretrained('distilgpt2', pad_token_id = tokenizer.pad_token_id, bos_token_id=tokenizer.bos_token_id, eos_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "named_parameters = list(model.named_parameters())\n",
    "\n",
    "# Freeze a part\n",
    "for name, param in named_parameters[:-20]:\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.config.attention_dropout = 0.01\n",
    "model.config.embed_dropout = 0.01\n",
    "print(f\"Loading empty, pre-trained model with {len(named_parameters)} parameters.\")\n",
    "\n",
    "model.to(device)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(f\"Model attached to {device_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMEavxJ32gOH"
   },
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-11-15T03:52:36.518979Z",
     "iopub.status.busy": "2021-11-15T03:52:36.484110Z",
     "iopub.status.idle": "2021-11-15T03:52:36.522295Z",
     "shell.execute_reply": "2021-11-15T03:52:36.521542Z"
    },
    "id": "OzWBTuEj2gOJ",
    "outputId": "0668db46-b7fd-4806-e90e-a898d2a6b77b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_lines: \n",
      "train_lines: PlayerReply c \"Hey, Remy!\" DragonReply Ry \"Hello, [player_name].\"\n",
      "PlayerReply c \"Is there any particular reason why you wanted to meet here?\" DragonReply Ry \"I enjoy Tatsu Park is all. Have you been here before?\"\n",
      "PlayerReply c \"Can't say I have.\" PlayerReply c \"A few times.\" PlayerReply c \"Once or twice.\" DragonReply Ry \"I see.\" DragonReply Ry \"Well, what do you think of it?\"\n",
      "PlayerReply c \"It's pretty idyllic.\" DragonReply Ry smile \"It is. I like it a lot here.\"\n",
      "PlayerReply c \"It's pretty romantic.\" DragonReply Ry shy \"You think so?\"\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(work_dir, \"awsw_story_input.txt\")) as f:\n",
    "    data = f.read()\n",
    "lines = data.split(\"\\n\")\n",
    "player_dragon_pairs = {}\n",
    "last_player_talk = []\n",
    "closed_player_talk = False\n",
    "re_player_talk = re.compile(r'c \"(.*?)\"')\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    line_split = line.split(\" \")\n",
    "    if len(line_split) <= 1:\n",
    "        continue\n",
    "    \n",
    "    if line_split[0] == \"c\":\n",
    "        if closed_player_talk:\n",
    "            closed_player_talk = False\n",
    "            last_player_talk = []\n",
    "        last_player_talk.append(re.sub(re_player_talk, r\"\\1\", line))\n",
    "    else:\n",
    "        if not closed_player_talk:\n",
    "            last_player_talk = json.dumps(last_player_talk)\n",
    "            if not last_player_talk in player_dragon_pairs:\n",
    "                player_dragon_pairs[last_player_talk] = []\n",
    "            closed_player_talk = True\n",
    "            \n",
    "        line = \"DragonReply \" + line\n",
    "        if last_player_talk is not None:\n",
    "            player_dragon_pairs[last_player_talk].append(line)\n",
    "    \n",
    "train_lines = []\n",
    "eval_lines = []\n",
    "eval_per_character = 0\n",
    "\n",
    "for player_line_str in player_dragon_pairs.keys():\n",
    "    player_lines = json.loads(player_line_str)\n",
    "    dragon_lines = player_dragon_pairs[player_line_str]\n",
    "    compiled_line = \" \".join([f'PlayerReply c \"{player_line}\"' for player_line in player_lines]) + \" \" + \" \".join(dragon_lines)\n",
    "    train_lines.append(compiled_line)\n",
    "    \n",
    "test_bucket = {}\n",
    "for l in train_lines:\n",
    "    l_split = l.split(\" \")\n",
    "    character = None\n",
    "    for i, ls in enumerate(l_split):\n",
    "        if ls == \"DragonReply\":\n",
    "            character = l_split[i + 1]\n",
    "            break\n",
    "    if not character in test_bucket:\n",
    "        test_bucket[character] = []\n",
    "    test_bucket[character].append(l)\n",
    "    \n",
    "for i in range(eval_per_character):\n",
    "    for character in test_bucket.keys():\n",
    "        random_line = test_bucket[character][randrange(len(test_bucket[character]))]\n",
    "        eval_lines.append(random_line)\n",
    "        for i2, t in enumerate(train_lines):\n",
    "            if t == random_line:\n",
    "                del train_lines[i2]\n",
    "                break\n",
    "    \n",
    "joined_eval_lines = \"\\n\".join(eval_lines[:5])\n",
    "print(f\"eval_lines: {joined_eval_lines}\")\n",
    "joined_train_lines = \"\\n\".join(train_lines[:5])\n",
    "print(f\"train_lines: {joined_train_lines}\")\n",
    "\n",
    "random.shuffle(train_lines)\n",
    "\n",
    "if not os.path.isfile(os.path.join(work_dir, \"data_train.txt\")):\n",
    "    with open(os.path.join(work_dir, \"data_train.txt\"), \"w\") as f:\n",
    "        for l in train_lines:\n",
    "            f.write(l + \"\\n\")\n",
    "            \n",
    "if not os.path.isfile(os.path.join(work_dir, \"data_test.txt\")):\n",
    "    with open(os.path.join(work_dir, \"data_test.txt\"), \"w\") as f:\n",
    "        for l in eval_lines:\n",
    "            f.write(l + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220,
     "referenced_widgets": [
      "a04e889a56e94ce9812a0e7d89d4d4f4",
      "3c2d0014295e47f9a07de8d4e36e7ba4",
      "76286c1e442541e0a6cb2d7cbbc9cc8f",
      "dcad41ec160e448b83d85c907a48facb",
      "27f2d980cb774902a82c0ad2545f549a",
      "131ce893dc784733b42f384b419145db",
      "607ee5c0b54042f3919d0588d66e31c1",
      "b2373342cb4942569088a5b20186795a",
      "11475ac58a594c6db1641401b1cc0d13",
      "f6625c167f7b4aa4bbecf2129e07c068",
      "ef9e25d7100e4e9ba064e938bd8157ea",
      "7bb369ca60f94acc99a4ee8e8f8fd261",
      "bc20a41ccda14aeeb72014b80a5ec53a",
      "c6ff5b9114424dbfafcbc3b3ab887af5",
      "1153397efee1426cac848341c0b88785",
      "37672ae801de4f42a9f6f49cc33fb88e",
      "8528f9fbbc504a44b9670a760256192d",
      "406b2f47896446a187725d4a1aa926f8",
      "cb33a87e718546f3a33b7deea817de56",
      "eeb54e278e184bc5aabf0283f1b276ff",
      "809a3780924641b8ace57e9141b0167f",
      "b805525a58804750ae56dad7e43ecb0e",
      "906b9daf9437432c81546f35256c7232",
      "0ce77d162a014a2fa17628ef8fe20846",
      "3fed2802cbab4a90a5b3d5a8c9bc8974",
      "a146d5c5588944368242c519984cbccc",
      "28d30b2eecf04ae6835cf4c35648dcfc",
      "65c48ca18ea14cf9bccbaa2495c2f120",
      "5067025a37bb42318ae93216b3205b17",
      "d18658b25f6f47778b984d0bf35be999",
      "6ade1603ab664b9f9d5ce44014bc5305",
      "fd91a671eeb7431d90d86b44beb276bd",
      "df0a544035814e1ca11d6191c10a5b62",
      "23a62f16d8de4f3ab9fa64ada07d1e35",
      "d50f5db4d1a1430caecace0510c1a24e",
      "d36395d1dcad4ead98f7f4756b8dbd37",
      "2cf737292a8343f5965c3eb0ace01875",
      "9ba5d1e5fab74947a328842b5105a28e",
      "073bc138772048729e04017123149e80",
      "ab0ce277776d4d218bf97fff5acc8e28",
      "b404b600842a4fc4b2b66c6b015235d6",
      "06dd02ec048945e5bf6b17d2b5558fb2",
      "437e050108fd46e1ba0f35674fa7314f",
      "a5725e8dc8104756bcba16b2c886a27f",
      "a31733df07ed4bb485d518b64634acfb",
      "1a2fe039b81a42c496ba363b2000bc41",
      "3f271f4469cf4796b92a78eba64c30b3",
      "fd200bcd96354e36b32ca82660eb0ef2",
      "33f9747c1f474c1790c7c293c853fad5",
      "e10acb8e2c8240409a19c61499576afd",
      "cc3c5e1ef5974710a06c1eab3d90cfb1",
      "6eda966317484df2a47fa0c4f2a0370c",
      "0cd6ff104b484203adda9e8414fd80fa",
      "c5a11599f37c4077a4ab0daec124a78c",
      "6cd8593a13f54c138c9adf5ec85f2d97"
     ]
    },
    "execution": {
     "iopub.execute_input": "2021-11-15T03:52:36.538102Z",
     "iopub.status.busy": "2021-11-15T03:52:36.537459Z",
     "iopub.status.idle": "2021-11-15T03:52:53.703882Z",
     "shell.execute_reply": "2021-11-15T03:52:53.704449Z"
    },
    "id": "pWeL2qWd2gOK",
    "outputId": "efdd650f-d95e-47a9-ad2f-396593bb779e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef2b65a9340445796f6deb5202fe179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('text', data_files={'train': os.path.join(work_dir, \"data_train.txt\"), 'test': os.path.join(work_dir, \"data_test.txt\")})\n",
    "\n",
    "class AWSWDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, dataset, dataset_type, do_shuffle=False):\n",
    "        self.current_dataset = dataset\n",
    "        self.dataset_type = dataset_type\n",
    "        self.do_shuffle = do_shuffle\n",
    "        self.shuffled_datasets = []\n",
    "        self.current_idx = 0\n",
    "        for i in range(1):\n",
    "            self.current_dataset = self.current_dataset.shuffle()\n",
    "            mapped_dataset = self.current_dataset.map(\n",
    "                group_texts,\n",
    "                batched=True,\n",
    "                batch_size=dataset_batch_size,\n",
    "                num_proc=dataset_map_cores\n",
    "            )\n",
    "            self.shuffled_datasets.append(mapped_dataset)\n",
    "        \n",
    "    def approx_len(self):\n",
    "        return len(self.shuffled_datasets[0][self.dataset_type])\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.current_idx = (self.current_idx + 1) % len(self.shuffled_datasets)\n",
    "        return iter(self.shuffled_datasets[self.current_idx][self.dataset_type])\n",
    "    \n",
    "def encode(batch):\n",
    "    result = []\n",
    "    attention_mask = []\n",
    "    for item in batch['text']:\n",
    "        #tokens = [tokenizer.bos_token_id] + tokenizer.encode(item) + [tokenizer.eos_token_id]\n",
    "        #tokens = tokenizer.encode(item)\n",
    "        tokens = tokenizer.encode(item) + [tokenizer.eos_token_id]\n",
    "        result.append(tokens)\n",
    "        attention_mask.append([1] * len(tokens))\n",
    "    return {\n",
    "        'attention_mask': attention_mask,\n",
    "        'input_ids': result\n",
    "    }\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    #random_shift = random.randint(0, 64)\n",
    "    #concatenated_examples['input_ids'] = concatenated_examples['input_ids'][random_shift:]\n",
    "    #concatenated_examples['attention_mask'] = concatenated_examples['attention_mask'][random_shift:]\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # Pad the end\n",
    "    to_add = (math.ceil(total_length / block_size) * block_size) - total_length\n",
    "    if to_add > 0:\n",
    "        concatenated_examples['input_ids'] += [tokenizer.pad_token_id] * to_add\n",
    "        concatenated_examples['attention_mask'] += [0] * to_add\n",
    "        total_length += to_add\n",
    "    # Split by chunks of block_size.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "def map_dragon_reply_text(batch):\n",
    "    result = {'text': []}\n",
    "    for item in batch['text']:\n",
    "        item_split = item.split(\" \")\n",
    "        player_replies = []\n",
    "        dragon_replies = []\n",
    "        current_reply = []\n",
    "        handling_reply = None\n",
    "        for token in item_split:\n",
    "            if token == \"PlayerReply\":\n",
    "                if handling_reply is None:\n",
    "                    handling_reply = \"PlayerReply\"\n",
    "                else:\n",
    "                    if handling_reply == \"PlayerReply\":\n",
    "                        # We need to store the PlayerReply\n",
    "                        player_replies.append(\" \".join(current_reply))\n",
    "                        current_reply = []\n",
    "            elif token == \"DragonReply\":\n",
    "                if handling_reply == \"DragonReply\":\n",
    "                    # We need to store the DragonReply\n",
    "                    dragon_replies.append(\" \".join(current_reply))\n",
    "                    current_reply = []\n",
    "                    \n",
    "                if handling_reply == \"PlayerReply\":\n",
    "                    # We need to store the PlayerReply\n",
    "                    player_replies.append(\" \".join(current_reply))\n",
    "                    current_reply = []\n",
    "                    \n",
    "                handling_reply = \"DragonReply\"\n",
    "                current_reply = []\n",
    "                    \n",
    "            if handling_reply is not None:\n",
    "                current_reply.append(token)\n",
    "                \n",
    "        # There's always a dragon reply at the end.\n",
    "        dragon_replies.append(\" \".join(current_reply))\n",
    "        for player_idx in range(len(player_replies)):\n",
    "            for dragon_idx in range(len(dragon_replies)):\n",
    "                result['text'].append(player_replies[player_idx] + \" \" + dragon_replies[dragon_idx])\n",
    "                \n",
    "    return result\n",
    "\n",
    "dataset_map_cores = min(multiprocessing.cpu_count(), 10)\n",
    "dataset_batch_size = 1000\n",
    "\n",
    "dataset = dataset.map(\n",
    "    map_dragon_reply_text,\n",
    "    batched=True,\n",
    "    batch_size=dataset_batch_size,\n",
    "    num_proc=dataset_map_cores\n",
    ")\n",
    "\n",
    "dataset = dataset.map(\n",
    "    encode,\n",
    "    batched=True,\n",
    "    batch_size=dataset_batch_size,\n",
    "    remove_columns=[\"text\"],\n",
    "    num_proc=dataset_map_cores\n",
    ")\n",
    "\n",
    "dataset = dataset.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=dataset_batch_size,\n",
    "    num_proc=dataset_map_cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-11-15T03:52:53.710574Z",
     "iopub.status.busy": "2021-11-15T03:52:53.710107Z",
     "iopub.status.idle": "2021-11-15T03:52:53.711847Z",
     "shell.execute_reply": "2021-11-15T03:52:53.712326Z"
    },
    "id": "PhiZIfn02gOL",
    "outputId": "47e5768d-8b9d-4ea8-c5ac-cc392abba402"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_len: 8658 num_training_steps: 136 num_total_steps: 13600\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_len = len(dataset['train'])\n",
    "num_training_steps = math.ceil(train_len / batch_size)\n",
    "num_epoch = 100\n",
    "num_total_steps = num_training_steps * num_epoch\n",
    "num_warmup_steps = num_training_steps * 2\n",
    "print(f\"train_len: {train_len} num_training_steps: {num_training_steps} num_total_steps: {num_total_steps}\")\n",
    "def get_optimizer_and_scheduler(params):\n",
    "    optimizer = AdamW(params, lr=0.001)\n",
    "    #scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_total_steps)\n",
    "    #scheduler = get_polynomial_decay_schedule_with_warmup(optimizer, num_warmup_steps, num_total_steps, power=0.5, lr_end=1e-10)\n",
    "    scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, num_warmup_steps, num_total_steps, 4)\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T03:52:53.716855Z",
     "iopub.status.busy": "2021-11-15T03:52:53.716247Z",
     "iopub.status.idle": "2021-11-15T03:52:54.052800Z",
     "shell.execute_reply": "2021-11-15T03:52:54.052474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrs = []\n",
    "optimizer, scheduler = get_optimizer_and_scheduler([torch.tensor(0.1)])\n",
    "for i in range(num_total_steps):\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "plt.plot(lrs)\n",
    "plt.show()\n",
    "del lrs\n",
    "del optimizer\n",
    "del scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T03:52:54.057572Z",
     "iopub.status.busy": "2021-11-15T03:52:54.057096Z",
     "iopub.status.idle": "2021-11-15T03:52:54.195563Z",
     "shell.execute_reply": "2021-11-15T03:52:54.195138Z"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat <<'EOT' > ds_config_zero3.json\n",
    "{\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": \"auto\",\n",
    "            \"warmup_max_lr\": \"auto\",\n",
    "            \"warmup_num_steps\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 3,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": true\n",
    "        },\n",
    "        \"offload_param\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": true\n",
    "        },\n",
    "        \"overlap_comm\": true,\n",
    "        \"contiguous_gradients\": true,\n",
    "        \"sub_group_size\": 1e9,\n",
    "        \"reduce_bucket_size\": \"auto\",\n",
    "        \"stage3_prefetch_bucket_size\": \"auto\",\n",
    "        \"stage3_param_persistence_threshold\": \"auto\",\n",
    "        \"stage3_max_live_parameters\": 1e9,\n",
    "        \"stage3_max_reuse_distance\": 1e9,\n",
    "        \"stage3_gather_fp16_weights_on_model_save\": true\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 2000,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": false\n",
    "}\n",
    "EOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "execution": {
     "iopub.execute_input": "2021-11-15T03:52:54.203822Z",
     "iopub.status.busy": "2021-11-15T03:52:54.203429Z",
     "iopub.status.idle": "2021-11-15T04:42:05.634603Z",
     "shell.execute_reply": "2021-11-15T04:42:05.634071Z"
    },
    "id": "AdPIW0xSTpRY",
    "outputId": "01338ca7-7ed2-4d8e-dd7b-5c235e4c5e30"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 8658\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13600' max='13600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13600/13600 49:10, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>6.213000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.456000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.084400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.859600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.689100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.561000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.461000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.388500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.335500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.295400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.267900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.247800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.235400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.229500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.288500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.359200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.310300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.267000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>0.232300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.204400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>0.182600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.166200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5750</td>\n",
       "      <td>0.152100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.142000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6250</td>\n",
       "      <td>0.133700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.127700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6750</td>\n",
       "      <td>0.124800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.135200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7250</td>\n",
       "      <td>0.232700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.226700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7750</td>\n",
       "      <td>0.198100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.174800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8250</td>\n",
       "      <td>0.157300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.143300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8750</td>\n",
       "      <td>0.131100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.121800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9250</td>\n",
       "      <td>0.114500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.107600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9750</td>\n",
       "      <td>0.103100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.100300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10250</td>\n",
       "      <td>0.099600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.162100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10750</td>\n",
       "      <td>0.192500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.171900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11250</td>\n",
       "      <td>0.152900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.137200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11750</td>\n",
       "      <td>0.126500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.117000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12250</td>\n",
       "      <td>0.109800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12750</td>\n",
       "      <td>0.096200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.093000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13250</td>\n",
       "      <td>0.090400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.088700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-500\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-500/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-1000\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-1000/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-1500\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-1500/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-1500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-2000\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-2000/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-2000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-2500\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-2500/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-2500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-3000\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-3000/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-3000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-3500\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-3500/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-3500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-4000\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-4000/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-4000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-4500\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-4500/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-4500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-3500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-5000\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-5000/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-5000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-5500\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-5500/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-5500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-4500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-6000\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-6000/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-6000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-6500\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-6500/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-6500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-5500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-7000\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-7000/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-7000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-7500\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-7500/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-7500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-6500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-8000\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-8000/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-8000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-8500\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-8500/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-8500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-7500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-9000\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-9000/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-9000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-9500\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-9500/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-9500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-8500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-10000\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-10000/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-10000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-10500\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-10500/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-10500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-9500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-11000\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-11000/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-11000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-10000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-11500\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-11500/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-11500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-10500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-12000\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-12000/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-12000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-11000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-12500\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-12500/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-12500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-11500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-13000\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-13000/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-13000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-12000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_5/checkpoint-13500\n",
      "Configuration saved in /opt/awsw/models_5/checkpoint-13500/config.json\n",
      "Model weights saved in /opt/awsw/models_5/checkpoint-13500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_5/checkpoint-12500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class AWSWTrainer(Trainer):\n",
    "    def _get_train_sampler(self):\n",
    "        return None\n",
    "    \n",
    "class AWSWTrainerCallback(TrainerCallback):\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        learning_rate_history = [h['learning_rate'] for h in state.log_history if 'loss' in h]\n",
    "        loss_history = [h['loss'] for h in state.log_history if 'loss' in h]\n",
    "        fig, axs = plt.subplots(2)\n",
    "        fig.suptitle('Learning rate and loss')\n",
    "        axs[0].plot(learning_rate_history)\n",
    "        axs[1].plot(loss_history)\n",
    "        \n",
    "def train(model):\n",
    "    optimizer, scheduler = get_optimizer_and_scheduler(model.parameters())\n",
    "    training_args = TrainingArguments(\n",
    "        models_dir,\n",
    "        seed=seed,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=num_epoch,\n",
    "        save_total_limit=2,\n",
    "        save_steps=500,\n",
    "        logging_steps=250,\n",
    "        ddp_find_unused_parameters=False,\n",
    "        #deepspeed=\"ds_config_zero3.json\"\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model, \n",
    "        args=training_args, \n",
    "        train_dataset=dataset['train'],\n",
    "        optimizers=(optimizer, scheduler),\n",
    "        callbacks=[AWSWTrainerCallback]\n",
    "    )\n",
    "    checkpoint_dirs = [os.path.join(models_dir, d) for d in os.listdir(models_dir) if os.path.isdir(os.path.join(models_dir, d))]\n",
    "    if len(checkpoint_dirs) > 0:\n",
    "        latest_checkpoint = max(checkpoint_dirs, key=os.path.getmtime)\n",
    "        trainer.train(latest_checkpoint)\n",
    "    else:\n",
    "        trainer.train()\n",
    "\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unxN7nYd2gOM",
    "tags": []
   },
   "source": [
    "# Testing\n",
    "\n",
    "We created a few past (for context) + present prompts (player input) and see the different reactions. This way, we can test the models across different iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T04:42:05.642053Z",
     "iopub.status.busy": "2021-11-15T04:42:05.641364Z",
     "iopub.status.idle": "2021-11-15T04:42:06.032487Z",
     "shell.execute_reply": "2021-11-15T04:42:06.031981Z"
    },
    "id": "5UePGmLD2gON"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_dragon_reply(past, prompt, top_k=None, top_p=None):\n",
    "    model.eval()\n",
    "    prompt = f'{past} PlayerReply c \"{prompt}\" DragonReply'\n",
    "    generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "    generated = generated.to(device)\n",
    "\n",
    "    sample_outputs = model.generate(\n",
    "        generated, \n",
    "        do_sample=(top_k is not None and top_p is not None),\n",
    "        top_p=top_p,\n",
    "        top_k=top_k,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        max_length=block_size,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    return tokenizer.decode(sample_outputs[0], skip_special_tokens=False)[len(prompt):].strip()\n",
    "\n",
    "prompts = [\n",
    "    ('PlayerReply c \"Hey Remy!\" DragonReply Ry \"Hey!\"', \"How are you?\"),\n",
    "    ('PlayerReply c \"I was with Lorem today.\" DragonReply Ad \"That\\'s awesome. He\\'s a cute fellow.\"', \"What do you think of Lorem?\"),\n",
    "    ('DragonReply m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('DragonReply m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "# Set a fixed seed to make sure we get the same response every time.\n",
    "torch.manual_seed(80085)\n",
    "for (past, prompt) in prompts:\n",
    "    reply = generate_dragon_reply(past, prompt)\n",
    "    print(f\"Prompt: {prompt}\\nReply: {reply}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OZarUHg2gON"
   },
   "source": [
    "# Sampling test\n",
    "\n",
    "Which combination is the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T04:42:06.037871Z",
     "iopub.status.busy": "2021-11-15T04:42:06.037427Z",
     "iopub.status.idle": "2021-11-15T04:42:50.016702Z",
     "shell.execute_reply": "2021-11-15T04:42:50.017083Z"
    },
    "id": "bWoLzL9B2gON"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test 1 top_k: 99, top_p: 0.57] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 1 top_k: 99, top_p: 0.57] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 1 top_k: 99, top_p: 0.57] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I saw her on the coffee table and saw the message. That's something,\n",
      "\n",
      "[Test 1 top_k: 99, top_p: 0.57] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 2 top_k: 2, top_p: 0.97] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 2 top_k: 2, top_p: 0.97] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 2 top_k: 2, top_p: 0.97] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I saw her on the coffee table. I thought, why didn't I realize\n",
      "\n",
      "[Test 2 top_k: 2, top_p: 0.97] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, did you hear about this?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 3 top_k: 31, top_p: 0.31] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 3 top_k: 31, top_p: 0.31] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 3 top_k: 31, top_p: 0.31] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 3 top_k: 31, top_p: 0.31] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 4 top_k: 30, top_p: 0.44] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 4 top_k: 30, top_p: 0.44] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 4 top_k: 30, top_p: 0.44] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. It was the better plan. Better\n",
      "\n",
      "[Test 4 top_k: 30, top_p: 0.44] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 5 top_k: 50, top_p: 0.28] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 5 top_k: 50, top_p: 0.28] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 5 top_k: 50, top_p: 0.28] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 5 top_k: 50, top_p: 0.28] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 6 top_k: 6, top_p: 0.37] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 6 top_k: 6, top_p: 0.37] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 6 top_k: 6, top_p: 0.37] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 6 top_k: 6, top_p: 0.37] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 7 top_k: 10, top_p: 0.85] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 7 top_k: 10, top_p: 0.85] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 7 top_k: 10, top_p: 0.85] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to be recognized.\"<|endoftext|>\n",
      "\n",
      "[Test 7 top_k: 10, top_p: 0.85] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Let's see what it says about the portal, then.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 8 top_k: 50, top_p: 0.89] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 8 top_k: 50, top_p: 0.89] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 8 top_k: 50, top_p: 0.89] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to make it look myself, so I followed her from a\n",
      "\n",
      "[Test 8 top_k: 50, top_p: 0.89] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, did you hear about this?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 9 top_k: 88, top_p: 0.62] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 9 top_k: 88, top_p: 0.62] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 9 top_k: 88, top_p: 0.62] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I saw her on the coffee table and saw the message. That's something,\n",
      "\n",
      "[Test 9 top_k: 88, top_p: 0.62] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 10 top_k: 49, top_p: 0.58] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 10 top_k: 49, top_p: 0.58] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 10 top_k: 49, top_p: 0.58] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I saw her on the coffee table and saw the message. That's something,\n",
      "\n",
      "[Test 10 top_k: 49, top_p: 0.58] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 11 top_k: 75, top_p: 0.08] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 11 top_k: 75, top_p: 0.08] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 11 top_k: 75, top_p: 0.08] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 11 top_k: 75, top_p: 0.08] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 12 top_k: 28, top_p: 0.79] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 12 top_k: 28, top_p: 0.79] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 12 top_k: 28, top_p: 0.79] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to be recognized.\"<|endoftext|>\n",
      "\n",
      "[Test 12 top_k: 28, top_p: 0.79] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Let's see what it says about the portal, then.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 13 top_k: 48, top_p: 0.13] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 13 top_k: 48, top_p: 0.13] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 13 top_k: 48, top_p: 0.13] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 13 top_k: 48, top_p: 0.13] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 14 top_k: 77, top_p: 0.36] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 14 top_k: 77, top_p: 0.36] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 14 top_k: 77, top_p: 0.36] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 14 top_k: 77, top_p: 0.36] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 15 top_k: 15, top_p: 0.77] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 15 top_k: 15, top_p: 0.77] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 15 top_k: 15, top_p: 0.77] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I saw her on the coffee table and the stars. I was aware of the\n",
      "\n",
      "[Test 15 top_k: 15, top_p: 0.77] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, did you hear about this?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 16 top_k: 78, top_p: 0.65] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 16 top_k: 78, top_p: 0.65] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 16 top_k: 78, top_p: 0.65] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I saw her on the coffee table and saw the message. That's something,\n",
      "\n",
      "[Test 16 top_k: 78, top_p: 0.65] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 17 top_k: 91, top_p: 0.42] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 17 top_k: 91, top_p: 0.42] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 17 top_k: 91, top_p: 0.42] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. It was the better plan. Better\n",
      "\n",
      "[Test 17 top_k: 91, top_p: 0.42] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 18 top_k: 90, top_p: 0.21] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 18 top_k: 90, top_p: 0.21] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 18 top_k: 90, top_p: 0.21] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 18 top_k: 90, top_p: 0.21] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 19 top_k: 96, top_p: 0.54] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 19 top_k: 96, top_p: 0.54] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 19 top_k: 96, top_p: 0.54] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my friend here.\"<|endoftext|>\n",
      "\n",
      "[Test 19 top_k: 96, top_p: 0.54] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 20 top_k: 33, top_p: 0.77] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 20 top_k: 33, top_p: 0.77] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 20 top_k: 33, top_p: 0.77] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I saw her on the coffee table and the stars. I was aware of the\n",
      "\n",
      "[Test 20 top_k: 33, top_p: 0.77] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, did you hear about this?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 21 top_k: 21, top_p: 0.29] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 21 top_k: 21, top_p: 0.29] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 21 top_k: 21, top_p: 0.29] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 21 top_k: 21, top_p: 0.29] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 22 top_k: 62, top_p: 0.34] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 22 top_k: 62, top_p: 0.34] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 22 top_k: 62, top_p: 0.34] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 22 top_k: 62, top_p: 0.34] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 23 top_k: 70, top_p: 0.07] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 23 top_k: 70, top_p: 0.07] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 23 top_k: 70, top_p: 0.07] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 23 top_k: 70, top_p: 0.07] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 24 top_k: 64, top_p: 0.01] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 24 top_k: 64, top_p: 0.01] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 24 top_k: 64, top_p: 0.01] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 24 top_k: 64, top_p: 0.01] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 25 top_k: 63, top_p: 0.32] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 25 top_k: 63, top_p: 0.32] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 25 top_k: 63, top_p: 0.32] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 25 top_k: 63, top_p: 0.32] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 26 top_k: 8, top_p: 0.98] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 26 top_k: 8, top_p: 0.98] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 26 top_k: 8, top_p: 0.98] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to make it look myself, so I took the advice she\n",
      "\n",
      "[Test 26 top_k: 8, top_p: 0.98] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, did you hear about this?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 27 top_k: 88, top_p: 0.26] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 27 top_k: 88, top_p: 0.26] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 27 top_k: 88, top_p: 0.26] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 27 top_k: 88, top_p: 0.26] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 28 top_k: 26, top_p: 0.78] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 28 top_k: 26, top_p: 0.78] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 28 top_k: 26, top_p: 0.78] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to be recognized.\"<|endoftext|>\n",
      "\n",
      "[Test 28 top_k: 26, top_p: 0.78] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Let's see what it says about the portal, then.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 29 top_k: 34, top_p: 0.42] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 29 top_k: 34, top_p: 0.42] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 29 top_k: 34, top_p: 0.42] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. It was the better plan. Better\n",
      "\n",
      "[Test 29 top_k: 34, top_p: 0.42] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 30 top_k: 85, top_p: 0.08] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 30 top_k: 85, top_p: 0.08] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 30 top_k: 85, top_p: 0.08] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 30 top_k: 85, top_p: 0.08] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 31 top_k: 18, top_p: 0.83] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 31 top_k: 18, top_p: 0.83] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 31 top_k: 18, top_p: 0.83] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to be recognized.\"<|endoftext|>\n",
      "\n",
      "[Test 31 top_k: 18, top_p: 0.83] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Let's see what it says about the portal, then.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 32 top_k: 15, top_p: 0.37] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 32 top_k: 15, top_p: 0.37] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 32 top_k: 15, top_p: 0.37] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 32 top_k: 15, top_p: 0.37] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 33 top_k: 73, top_p: 0.42] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 33 top_k: 73, top_p: 0.42] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 33 top_k: 73, top_p: 0.42] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. It was the better plan. Better\n",
      "\n",
      "[Test 33 top_k: 73, top_p: 0.42] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 34 top_k: 24, top_p: 0.2] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 34 top_k: 24, top_p: 0.2] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 34 top_k: 24, top_p: 0.2] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 34 top_k: 24, top_p: 0.2] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 35 top_k: 16, top_p: 0.21] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 35 top_k: 16, top_p: 0.21] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 35 top_k: 16, top_p: 0.21] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 35 top_k: 16, top_p: 0.21] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 36 top_k: 57, top_p: 0.01] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 36 top_k: 57, top_p: 0.01] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 36 top_k: 57, top_p: 0.01] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 36 top_k: 57, top_p: 0.01] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 37 top_k: 85, top_p: 0.96] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 37 top_k: 85, top_p: 0.96] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 37 top_k: 85, top_p: 0.96] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to make it look myself, so I took the advice she\n",
      "\n",
      "[Test 37 top_k: 85, top_p: 0.96] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, did you hear about this?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 38 top_k: 71, top_p: 0.77] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 38 top_k: 71, top_p: 0.77] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 38 top_k: 71, top_p: 0.77] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to be recognized.\"<|endoftext|>\n",
      "\n",
      "[Test 38 top_k: 71, top_p: 0.77] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Let's see what it says about the portal, then.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 39 top_k: 55, top_p: 0.57] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 39 top_k: 55, top_p: 0.57] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 39 top_k: 55, top_p: 0.57] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I saw her on the coffee table and saw the message. That's something,\n",
      "\n",
      "[Test 39 top_k: 55, top_p: 0.57] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 40 top_k: 32, top_p: 0.09] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 40 top_k: 32, top_p: 0.09] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 40 top_k: 32, top_p: 0.09] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 40 top_k: 32, top_p: 0.09] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 41 top_k: 8, top_p: 0.8] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 41 top_k: 8, top_p: 0.8] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 41 top_k: 8, top_p: 0.8] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I saw her on the coffee table and saw the message. That's something,\n",
      "\n",
      "[Test 41 top_k: 8, top_p: 0.8] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, did you hear about this?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 42 top_k: 26, top_p: 0.17] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 42 top_k: 26, top_p: 0.17] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 42 top_k: 26, top_p: 0.17] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 42 top_k: 26, top_p: 0.17] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 43 top_k: 41, top_p: 0.31] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 43 top_k: 41, top_p: 0.31] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 43 top_k: 41, top_p: 0.31] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 43 top_k: 41, top_p: 0.31] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 44 top_k: 33, top_p: 0.95] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 44 top_k: 33, top_p: 0.95] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 44 top_k: 33, top_p: 0.95] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to make it look myself, so I took the advice she\n",
      "\n",
      "[Test 44 top_k: 33, top_p: 0.95] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, did you hear about this?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 45 top_k: 20, top_p: 0.19] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 45 top_k: 20, top_p: 0.19] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 45 top_k: 20, top_p: 0.19] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 45 top_k: 20, top_p: 0.19] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 46 top_k: 88, top_p: 0.75] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 46 top_k: 88, top_p: 0.75] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 46 top_k: 88, top_p: 0.75] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I saw her on the coffee table and saw the message. That's something,\n",
      "\n",
      "[Test 46 top_k: 88, top_p: 0.75] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, did you hear about this?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 47 top_k: 98, top_p: 0.86] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 47 top_k: 98, top_p: 0.86] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 47 top_k: 98, top_p: 0.86] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to be recognized.\"<|endoftext|>\n",
      "\n",
      "[Test 47 top_k: 98, top_p: 0.86] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Let's see what it says about the portal, then.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 48 top_k: 6, top_p: 0.98] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 48 top_k: 6, top_p: 0.98] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 48 top_k: 6, top_p: 0.98] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to make it look myself, so I took the advice she\n",
      "\n",
      "[Test 48 top_k: 6, top_p: 0.98] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, did you hear about this?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 49 top_k: 97, top_p: 0.38] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 49 top_k: 97, top_p: 0.38] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 49 top_k: 97, top_p: 0.38] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 49 top_k: 97, top_p: 0.38] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 50 top_k: 10, top_p: 0.32] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 50 top_k: 10, top_p: 0.32] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 50 top_k: 10, top_p: 0.32] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 50 top_k: 10, top_p: 0.32] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 51 top_k: 73, top_p: 0.36] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 51 top_k: 73, top_p: 0.36] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 51 top_k: 73, top_p: 0.36] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 51 top_k: 73, top_p: 0.36] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 52 top_k: 79, top_p: 0.81] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 52 top_k: 79, top_p: 0.81] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 52 top_k: 79, top_p: 0.81] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to be recognized.\"<|endoftext|>\n",
      "\n",
      "[Test 52 top_k: 79, top_p: 0.81] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Let's see what it says about the portal, then.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 53 top_k: 91, top_p: 0.45] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 53 top_k: 91, top_p: 0.45] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 53 top_k: 91, top_p: 0.45] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. It was the better plan. Better\n",
      "\n",
      "[Test 53 top_k: 91, top_p: 0.45] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 54 top_k: 70, top_p: 0.37] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 54 top_k: 70, top_p: 0.37] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 54 top_k: 70, top_p: 0.37] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 54 top_k: 70, top_p: 0.37] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 55 top_k: 45, top_p: 0.48] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 55 top_k: 45, top_p: 0.48] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 55 top_k: 45, top_p: 0.48] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. It was the better plan. Better\n",
      "\n",
      "[Test 55 top_k: 45, top_p: 0.48] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 56 top_k: 33, top_p: 0.82] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 56 top_k: 33, top_p: 0.82] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 56 top_k: 33, top_p: 0.82] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to be recognized.\"<|endoftext|>\n",
      "\n",
      "[Test 56 top_k: 33, top_p: 0.82] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Let's see what it says about the portal, then.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 57 top_k: 31, top_p: 0.09] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 57 top_k: 31, top_p: 0.09] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 57 top_k: 31, top_p: 0.09] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 57 top_k: 31, top_p: 0.09] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 58 top_k: 88, top_p: 0.01] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 58 top_k: 88, top_p: 0.01] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 58 top_k: 88, top_p: 0.01] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 58 top_k: 88, top_p: 0.01] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 59 top_k: 75, top_p: 0.15] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 59 top_k: 75, top_p: 0.15] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 59 top_k: 75, top_p: 0.15] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 59 top_k: 75, top_p: 0.15] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 60 top_k: 37, top_p: 0.23] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 60 top_k: 37, top_p: 0.23] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 60 top_k: 37, top_p: 0.23] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 60 top_k: 37, top_p: 0.23] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 61 top_k: 41, top_p: 0.96] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 61 top_k: 41, top_p: 0.96] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 61 top_k: 41, top_p: 0.96] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to make it look myself, so I took the advice she\n",
      "\n",
      "[Test 61 top_k: 41, top_p: 0.96] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, did you hear about this?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 62 top_k: 12, top_p: 0.3] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 62 top_k: 12, top_p: 0.3] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 62 top_k: 12, top_p: 0.3] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 62 top_k: 12, top_p: 0.3] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 63 top_k: 31, top_p: 0.34] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 63 top_k: 31, top_p: 0.34] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 63 top_k: 31, top_p: 0.34] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 63 top_k: 31, top_p: 0.34] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 64 top_k: 96, top_p: 0.48] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 64 top_k: 96, top_p: 0.48] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 64 top_k: 96, top_p: 0.48] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. It was the better plan. Better\n",
      "\n",
      "[Test 64 top_k: 96, top_p: 0.48] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 65 top_k: 71, top_p: 0.78] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 65 top_k: 71, top_p: 0.78] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 65 top_k: 71, top_p: 0.78] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to be recognized.\"<|endoftext|>\n",
      "\n",
      "[Test 65 top_k: 71, top_p: 0.78] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Let's see what it says about the portal, then.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 66 top_k: 58, top_p: 0.2] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 66 top_k: 58, top_p: 0.2] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 66 top_k: 58, top_p: 0.2] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 66 top_k: 58, top_p: 0.2] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 67 top_k: 44, top_p: 0.62] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 67 top_k: 44, top_p: 0.62] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 67 top_k: 44, top_p: 0.62] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I saw her on the coffee table and saw the message. That's something,\n",
      "\n",
      "[Test 67 top_k: 44, top_p: 0.62] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 68 top_k: 15, top_p: 0.61] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 68 top_k: 15, top_p: 0.61] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 68 top_k: 15, top_p: 0.61] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I saw her on the coffee table and saw the message. That's something,\n",
      "\n",
      "[Test 68 top_k: 15, top_p: 0.61] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 69 top_k: 28, top_p: 0.83] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 69 top_k: 28, top_p: 0.83] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 69 top_k: 28, top_p: 0.83] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to be recognized.\"<|endoftext|>\n",
      "\n",
      "[Test 69 top_k: 28, top_p: 0.83] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Let's see what it says about the portal, then.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 70 top_k: 51, top_p: 0.9] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 70 top_k: 51, top_p: 0.9] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 70 top_k: 51, top_p: 0.9] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to make it look myself, so I followed her from a\n",
      "\n",
      "[Test 70 top_k: 51, top_p: 0.9] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, did you hear about this?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 71 top_k: 50, top_p: 0.93] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 71 top_k: 50, top_p: 0.93] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 71 top_k: 50, top_p: 0.93] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to make it look myself, so I followed her from a\n",
      "\n",
      "[Test 71 top_k: 50, top_p: 0.93] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, did you hear about this?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 72 top_k: 85, top_p: 0.11] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 72 top_k: 85, top_p: 0.11] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 72 top_k: 85, top_p: 0.11] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 72 top_k: 85, top_p: 0.11] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 73 top_k: 18, top_p: 0.71] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 73 top_k: 18, top_p: 0.71] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 73 top_k: 18, top_p: 0.71] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I saw her on the coffee table and saw the message. That's something,\n",
      "\n",
      "[Test 73 top_k: 18, top_p: 0.71] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, did you hear about this?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 74 top_k: 30, top_p: 0.16] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 74 top_k: 30, top_p: 0.16] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 74 top_k: 30, top_p: 0.16] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 74 top_k: 30, top_p: 0.16] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 75 top_k: 85, top_p: 0.84] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 75 top_k: 85, top_p: 0.84] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 75 top_k: 85, top_p: 0.84] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to be recognized.\"<|endoftext|>\n",
      "\n",
      "[Test 75 top_k: 85, top_p: 0.84] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Let's see what it says about the portal, then.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 76 top_k: 61, top_p: 0.95] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 76 top_k: 61, top_p: 0.95] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 76 top_k: 61, top_p: 0.95] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to make it look myself, so I took the advice she\n",
      "\n",
      "[Test 76 top_k: 61, top_p: 0.95] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, did you hear about this?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 77 top_k: 66, top_p: 0.59] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 77 top_k: 66, top_p: 0.59] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 77 top_k: 66, top_p: 0.59] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I saw her on the coffee table and saw the message. That's something,\n",
      "\n",
      "[Test 77 top_k: 66, top_p: 0.59] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 78 top_k: 54, top_p: 0.92] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 78 top_k: 54, top_p: 0.92] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 78 top_k: 54, top_p: 0.92] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to make it look myself, so I followed her from a\n",
      "\n",
      "[Test 78 top_k: 54, top_p: 0.92] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, did you hear about this?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 79 top_k: 39, top_p: 0.76] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 79 top_k: 39, top_p: 0.76] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 79 top_k: 39, top_p: 0.76] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I saw her on the coffee table and the stars. I was aware of the\n",
      "\n",
      "[Test 79 top_k: 39, top_p: 0.76] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, did you hear about this?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 80 top_k: 30, top_p: 0.41] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 80 top_k: 30, top_p: 0.41] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 80 top_k: 30, top_p: 0.41] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. It was the better plan. Better\n",
      "\n",
      "[Test 80 top_k: 30, top_p: 0.41] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 81 top_k: 85, top_p: 0.18] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 81 top_k: 85, top_p: 0.18] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 81 top_k: 85, top_p: 0.18] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 81 top_k: 85, top_p: 0.18] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 82 top_k: 85, top_p: 0.17] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 82 top_k: 85, top_p: 0.17] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 82 top_k: 85, top_p: 0.17] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 82 top_k: 85, top_p: 0.17] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 83 top_k: 71, top_p: 0.91] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 83 top_k: 71, top_p: 0.91] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 83 top_k: 71, top_p: 0.91] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to make it look myself, so I followed her from a\n",
      "\n",
      "[Test 83 top_k: 71, top_p: 0.91] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, did you hear about this?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 84 top_k: 78, top_p: 0.7] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 84 top_k: 78, top_p: 0.7] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 84 top_k: 78, top_p: 0.7] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I saw her on the coffee table and saw the message. That's something,\n",
      "\n",
      "[Test 84 top_k: 78, top_p: 0.7] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, did you hear about this?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 85 top_k: 52, top_p: 0.83] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 85 top_k: 52, top_p: 0.83] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 85 top_k: 52, top_p: 0.83] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to be recognized.\"<|endoftext|>\n",
      "\n",
      "[Test 85 top_k: 52, top_p: 0.83] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Let's see what it says about the portal, then.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 86 top_k: 10, top_p: 0.86] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 86 top_k: 10, top_p: 0.86] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 86 top_k: 10, top_p: 0.86] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to be recognized.\"<|endoftext|>\n",
      "\n",
      "[Test 86 top_k: 10, top_p: 0.86] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Let's see what it says about the portal, then.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 87 top_k: 23, top_p: 0.41] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 87 top_k: 23, top_p: 0.41] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 87 top_k: 23, top_p: 0.41] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. It was the better plan. Better\n",
      "\n",
      "[Test 87 top_k: 23, top_p: 0.41] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 88 top_k: 27, top_p: 0.47] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 88 top_k: 27, top_p: 0.47] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 88 top_k: 27, top_p: 0.47] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. It was the better plan. Better\n",
      "\n",
      "[Test 88 top_k: 27, top_p: 0.47] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 89 top_k: 16, top_p: 0.59] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 89 top_k: 16, top_p: 0.59] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 89 top_k: 16, top_p: 0.59] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I saw her on the coffee table and saw the message. That's something,\n",
      "\n",
      "[Test 89 top_k: 16, top_p: 0.59] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 90 top_k: 86, top_p: 0.4] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 90 top_k: 86, top_p: 0.4] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 90 top_k: 86, top_p: 0.4] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 90 top_k: 86, top_p: 0.4] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 91 top_k: 44, top_p: 0.91] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 91 top_k: 44, top_p: 0.91] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ry \"Well, I'm glad to hear it.\"<|endoftext|>\n",
      "\n",
      "[Test 91 top_k: 44, top_p: 0.91] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. I didn't want to make it look myself, so I followed her from a\n",
      "\n",
      "[Test 91 top_k: 44, top_p: 0.91] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, did you hear about this?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 92 top_k: 34, top_p: 0.4] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 92 top_k: 34, top_p: 0.4] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 92 top_k: 34, top_p: 0.4] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 92 top_k: 34, top_p: 0.4] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 93 top_k: 57, top_p: 0.23] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 93 top_k: 57, top_p: 0.23] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 93 top_k: 57, top_p: 0.23] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 93 top_k: 57, top_p: 0.23] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 94 top_k: 69, top_p: 0.43] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 94 top_k: 69, top_p: 0.43] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 94 top_k: 69, top_p: 0.43] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. It was the better plan. Better\n",
      "\n",
      "[Test 94 top_k: 69, top_p: 0.43] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 95 top_k: 70, top_p: 0.46] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 95 top_k: 70, top_p: 0.46] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 95 top_k: 70, top_p: 0.46] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. It was the better plan. Better\n",
      "\n",
      "[Test 95 top_k: 70, top_p: 0.46] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 96 top_k: 57, top_p: 0.39] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 96 top_k: 57, top_p: 0.39] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 96 top_k: 57, top_p: 0.39] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 96 top_k: 57, top_p: 0.39] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 97 top_k: 84, top_p: 0.53] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 97 top_k: 84, top_p: 0.53] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 97 top_k: 84, top_p: 0.53] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my friend here.\"<|endoftext|>\n",
      "\n",
      "[Test 97 top_k: 84, top_p: 0.53] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 98 top_k: 59, top_p: 0.23] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 98 top_k: 59, top_p: 0.23] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 98 top_k: 59, top_p: 0.23] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 98 top_k: 59, top_p: 0.23] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 99 top_k: 78, top_p: 0.43] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 99 top_k: 78, top_p: 0.43] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 99 top_k: 78, top_p: 0.43] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. It was the better plan. Better\n",
      "\n",
      "[Test 99 top_k: 78, top_p: 0.43] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 100 top_k: 55, top_p: 0.06] -> Prompt: How are you?\n",
      "Reply: Ry shy \"I-I don't really like talking about myself.\"<|endoftext|>\n",
      "\n",
      "[Test 100 top_k: 55, top_p: 0.06] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"He was interrupted by a loud snore that came from under the table. When we looked down, I saw\n",
      "\n",
      "[Test 100 top_k: 55, top_p: 0.06] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad \"I just realized why I hadn't been able to identify her. She was my product. We were humans. We were vehicles. It was a\n",
      "\n",
      "[Test 100 top_k: 55, top_p: 0.06] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"By the way, who won?\"<|endoftext|>\n",
      "\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    torch.manual_seed(80085)\n",
    "    top_k = random.randint(0, 100)\n",
    "    top_p = round(random.uniform(0, 1), 2)\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = generate_dragon_reply(past, prompt, top_k = top_k, top_p = top_p)\n",
    "        print(f\"[Test {i + 1} top_k: {top_k}, top_p: {top_p}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T04:42:50.024460Z",
     "iopub.status.busy": "2021-11-15T04:42:50.023895Z",
     "iopub.status.idle": "2021-11-15T04:42:50.130804Z",
     "shell.execute_reply": "2021-11-15T04:42:50.130388Z"
    },
    "id": "FgM9Awn7acpG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What to say?\n"
     ]
    },
    {
     "ename": "StdinNotImplementedError",
     "evalue": "raw_input was called, but this frontend does not support input requests.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStdinNotImplementedError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6217/61523620.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What to say?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_reply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \"\"\"\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_stdin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m             raise StdinNotImplementedError(\n\u001b[0m\u001b[1;32m   1004\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             )\n",
      "\u001b[0;31mStdinNotImplementedError\u001b[0m: raw_input was called, but this frontend does not support input requests."
     ]
    }
   ],
   "source": [
    "def generate_reply(prompt):\n",
    "    model.eval()\n",
    "    prompt = f'PlayerReply c \"{prompt}\" DragonReply'\n",
    "    generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "    generated = generated.to(device)\n",
    "    print(prompt, generated)\n",
    "\n",
    "    sample_outputs = model.generate(\n",
    "        generated, \n",
    "        do_sample=True,   \n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        top_length = block_size,\n",
    "        top_p=0.95, \n",
    "        num_return_sequences=3\n",
    "    )\n",
    "\n",
    "    for i, sample_output in enumerate(sample_outputs):\n",
    "        print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=False)))\n",
    "\n",
    "print(\"What to say?\")\n",
    "print(generate_reply(input()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXKM4uLM2gOO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AWSW_GPT-Neo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0a924033dd794b5d8794c7b296e13a05": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0c47223f3f454549b5b3c58d6b361cec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_95c53ef74b99403eb3c0fc846810d65a",
       "placeholder": "​",
       "style": "IPY_MODEL_f6da99bc23c840e8a2f9487b15ff9cf8",
       "value": " 2/2 [00:00&lt;00:00, 103.97it/s]"
      }
     },
     "163a6a8782c548f496b440befc8bd403": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1adc8d773a034903b9e8c44ba363ed59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "62ce980543284a1e8860175d1d97b32a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6c8709b00b4a4e5fa6cc0a6ea96ddf5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0a924033dd794b5d8794c7b296e13a05",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_caa7a065e8564eea85bbaa14fd64bee5",
       "value": 2.0
      }
     },
     "95c53ef74b99403eb3c0fc846810d65a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c28ad431af4344f58db8010fe494cbfa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_163a6a8782c548f496b440befc8bd403",
       "placeholder": "​",
       "style": "IPY_MODEL_1adc8d773a034903b9e8c44ba363ed59",
       "value": "100%"
      }
     },
     "caa7a065e8564eea85bbaa14fd64bee5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "eef2b65a9340445796f6deb5202fe179": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c28ad431af4344f58db8010fe494cbfa",
        "IPY_MODEL_6c8709b00b4a4e5fa6cc0a6ea96ddf5c",
        "IPY_MODEL_0c47223f3f454549b5b3c58d6b361cec"
       ],
       "layout": "IPY_MODEL_62ce980543284a1e8860175d1d97b32a"
      }
     },
     "f6da99bc23c840e8a2f9487b15ff9cf8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
