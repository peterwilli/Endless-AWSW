{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-11-14T23:48:29.588878Z",
     "iopub.status.busy": "2021-11-14T23:48:29.588486Z",
     "iopub.status.idle": "2021-11-14T23:48:29.788872Z",
     "shell.execute_reply": "2021-11-14T23:48:29.788495Z"
    },
    "id": "2TJ-BqFtQ86M",
    "outputId": "f41c5626-6827-4d90-f0a9-8a11c01a366d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 14 23:48:29 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.63.01    Driver Version: 470.63.01    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "| N/A   54C    P8    21W /  N/A |    721MiB / 16125MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-11-14T23:48:29.795274Z",
     "iopub.status.busy": "2021-11-14T23:48:29.792679Z",
     "iopub.status.idle": "2021-11-14T23:48:31.620516Z",
     "shell.execute_reply": "2021-11-14T23:48:31.619864Z"
    },
    "id": "oR9S63qiQt2b",
    "outputId": "b1303393-4c18-4510-da76-59e5f2590db8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/awsw-dev/.local/lib/python3.8/site-packages (4.12.3)\r\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (1.15.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2021.8.28)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.26.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/awsw-dev/.local/lib/python3.8/site-packages (from transformers) (0.1.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.62.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.2)\r\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.10.3)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.0.12)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (5.4.1)\r\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers) (0.0.45)\r\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.12.2)\r\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2021.8.1)\r\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.0)\r\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.4)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.2)\r\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (5.0.0)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (2.0.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (2.4.7)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.6)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2021.5.30)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\r\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.0.1)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.16.0)\r\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (8.0.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.2.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (21.2.0)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.7.2)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (5.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2021.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T23:48:31.627404Z",
     "iopub.status.busy": "2021-11-14T23:48:31.626820Z",
     "iopub.status.idle": "2021-11-14T23:48:33.035208Z",
     "shell.execute_reply": "2021-11-14T23:48:33.034564Z"
    },
    "id": "GhhigZYMRK6N"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "from random import randrange\n",
    "import multiprocessing\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config, GPT2LMHeadModel, GPTNeoForCausalLM\n",
    "from transformers import AdamW, get_cosine_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup, get_polynomial_decay_schedule_with_warmup\n",
    "from transformers import Trainer, TrainingArguments, TrainerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T23:48:33.040228Z",
     "iopub.status.busy": "2021-11-14T23:48:33.039637Z",
     "iopub.status.idle": "2021-11-14T23:48:33.041957Z",
     "shell.execute_reply": "2021-11-14T23:48:33.041615Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '9994' # modify if RuntimeError: Address already in use\n",
    "os.environ['RANK'] = \"0\"\n",
    "os.environ['LOCAL_RANK'] = \"0\"\n",
    "os.environ['WORLD_SIZE'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-11-14T23:48:33.064575Z",
     "iopub.status.busy": "2021-11-14T23:48:33.064066Z",
     "iopub.status.idle": "2021-11-14T23:48:33.066633Z",
     "shell.execute_reply": "2021-11-14T23:48:33.066284Z"
    },
    "id": "MTduRlf-RQJa",
    "outputId": "296dba31-0af6-422c-eea8-f5c1130a5daf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use cuda:0 for training with seed: 2526821839\n"
     ]
    }
   ],
   "source": [
    "seed = random.randint(0, 2 ** 32 - 1)\n",
    "random.seed(seed)\n",
    "block_size = 64\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(f\"Will use {device_name} for training with seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278,
     "referenced_widgets": [
      "641f6e8a671d4dfe9da34c7685520767",
      "c7eb14f1388e42f29fbac8eef195fede",
      "40b7d134ba7b40299f6bd16b1e781d09",
      "13e5a9ab53bc4e1d8c3c7905ebd05ddf",
      "bc3c9b957d93490c8f9773e7050fd4ef",
      "e702472021334098b47210f9f1395f21",
      "8ed62e486a664d1f83fee6f21cb4585d",
      "ad42520b822e4454947f5d466424c8ca",
      "917d4196cdd14970b7965652f3b950a2",
      "3d72f5178e404d8c948ef13fc81a2bb8",
      "0ae32803eeaf436ab66cb3da9ff5439d",
      "5f28c40531fc4f43b4b62fd04912100c",
      "3c7dd63eb62d44598666166a87c0ff88",
      "7ed9d2386d57488c890d1ec712d1bef0",
      "da3c1240d6a94f3c9ff9ec0545675446",
      "cc7c2ac1006b4b109f302d7d26e3a578",
      "9bb4dcdb6f434d8b8cc95ef80f2ffe00",
      "5af83a55a73b4f3481a7559951ebdf08",
      "c4384ee96a1a4ae4bc8b46fa640b9058",
      "5f2bf3aebfd64baf94df39964208af4c",
      "307da63f10ad4ae5ae5e7e387d176d39",
      "8a282a2414874cb588a386e1444951dd",
      "659e0ad7f39c4cdbbdc1345c07a2e3f4",
      "1481fbbc74544c4888c0d6f88d8b3c9d",
      "54b833977b424c25a690d1bfe5d8c3f1",
      "8bfab1db231a4ff1975775f81f8a84f1",
      "3af5019cfacf4afc8a15a14d9a121ea8",
      "0ac398931b04418cbd3d227b9c634883",
      "7789164b5ee245b3a537d9d61dae038f",
      "8abd99000df0453e86bc458be29a10c7",
      "7db95c969d94465aaffbe9139f0f2a90",
      "d21de377e9074df083556c68e7d7cdbb",
      "3a0ada2f620a40aaa6c33fcea7a0bb91",
      "38bc8c5a2a3447e7942e2058c35d5e5b",
      "79170285a49a450494f0bfbe6cb4788e",
      "9813f2bda5ce4ab6887683fe63d0629e",
      "5c6ca36359bb4a1982c599f6a3f23b9f",
      "6e2cfa054082449e942297afd2f50f73",
      "5f3133f5c7254c248dad8e75534ea920",
      "eef06f8bc02749f4b04af47d92eb91b2",
      "2c60d924ee7b4fad984e2072973c3af3",
      "c1132ffe6c684c7ebeb3f285a101536b",
      "aa2a21546de1463f88a7feb8b697f9d3",
      "0abba2f64b4a43abadb38d461a5c7f42",
      "f43e9d4fa52c48c087ffeef399bfbed6",
      "4f1eafd9553b4bd5b396bba8f3896a22",
      "bbd5e6b14d864c1eb6a4d9c4247fb520",
      "29b2e68155a947e0aca0760c7e8e4afa",
      "fa1b29c48993478f9c2be4877ec675fc",
      "e4a6b2af572e44eda537e74847c58709",
      "8110f29e7b134607b38b29fad32ab1a1",
      "470ba5ce89ee4927a9be685adbc08675",
      "d10fbe074d4b42c9a8a6522252ef016f",
      "5af59ca6be4a427c8f83a906bbb6ce93",
      "17c9592d03324c4797abc812044e7500",
      "f6153c2ce07b4f4097a2a0486fb896ac",
      "3daedb3b85264408a8821ee2e480b356",
      "b2ce0d43567b4cc09e1f5571ee25263c",
      "c3a28b9889cd40e2ac0b9860e7f3932b",
      "99e992b8d4564ddd9c7634ac7663053a",
      "ae627a7820d4450a97b47d63dd5fbd92",
      "56a8c3c144404bd793e29a023032a09f",
      "2a9348d6cd674898ac4c9a303a254f26",
      "bafebeb0fba04d148ae3adf44171e0fe",
      "a8e19067a3ad411cad1aba489d390516",
      "6cf4e15a56fc4ac188609b806f11afcd"
     ]
    },
    "execution": {
     "iopub.execute_input": "2021-11-14T23:48:33.073855Z",
     "iopub.status.busy": "2021-11-14T23:48:33.073233Z",
     "iopub.status.idle": "2021-11-14T23:48:42.849431Z",
     "shell.execute_reply": "2021-11-14T23:48:42.848804Z"
    },
    "id": "QSVYD7o_eL2o",
    "outputId": "4f570825-b314-421b-b1ee-07449f7787f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading empty, pre-trained model with 76 parameters.\n",
      "Model attached to cuda:0\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(\"/opt/awsw\"):\n",
    "  # In case we run this locally (in Docker)\n",
    "  work_dir = os.path.join(\"/opt\", \"awsw\")\n",
    "else:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  work_dir = os.path.join(\"/content\", \"drive\", \"MyDrive\", \"endless_awsw\")\n",
    "\n",
    "models_dir = os.path.join(work_dir, \"models\")\n",
    "\n",
    "if not os.path.isdir(models_dir):\n",
    "    pathlib.Path(models_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "#tokenizer = GPT2Tokenizer.from_pretrained('EleutherAI/gpt-neo-125M', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n",
    "#model = GPTNeoForCausalLM.from_pretrained('EleutherAI/gpt-neo-125M', pad_token_id = tokenizer.pad_token_id, bos_token_id=tokenizer.bos_token_id, eos_token_id=tokenizer.eos_token_id)\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained('EleutherAI/gpt-neo-1.3B', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n",
    "#model = GPTNeoForCausalLM.from_pretrained('EleutherAI/gpt-neo-1.3B', pad_token_id = tokenizer.pad_token_id, bos_token_id=tokenizer.bos_token_id, eos_token_id=tokenizer.eos_token_id)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n",
    "model = GPT2LMHeadModel.from_pretrained('distilgpt2', pad_token_id = tokenizer.pad_token_id, bos_token_id=tokenizer.bos_token_id, eos_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "named_parameters = list(model.named_parameters())\n",
    "\n",
    "# Freeze a part\n",
    "for name, param in named_parameters[:-10]:\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.config.attention_dropout = 0.01\n",
    "model.config.embed_dropout = 0.01\n",
    "print(f\"Loading empty, pre-trained model with {len(named_parameters)} parameters.\")\n",
    "\n",
    "model.to(device)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(f\"Model attached to {device_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMEavxJ32gOH"
   },
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-11-14T23:48:42.944930Z",
     "iopub.status.busy": "2021-11-14T23:48:42.914003Z",
     "iopub.status.idle": "2021-11-14T23:48:42.954388Z",
     "shell.execute_reply": "2021-11-14T23:48:42.953772Z"
    },
    "id": "OzWBTuEj2gOJ",
    "outputId": "0668db46-b7fd-4806-e90e-a898d2a6b77b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_lines: \n",
      "train_lines: PlayerReply c \"Hey, Remy!\" DragonReply Ry \"Hello, [player_name].\"\n",
      "PlayerReply c \"Is there any particular reason why you wanted to meet here?\" DragonReply Ry \"I enjoy Tatsu Park is all. Have you been here before?\"\n",
      "PlayerReply c \"Can't say I have.\" PlayerReply c \"A few times.\" PlayerReply c \"Once or twice.\" DragonReply Ry \"I see.\" DragonReply Ry \"Well, what do you think of it?\"\n",
      "PlayerReply c \"It's pretty idyllic.\" DragonReply Ry smile \"It is. I like it a lot here.\"\n",
      "PlayerReply c \"It's pretty romantic.\" DragonReply Ry shy \"You think so?\"\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(work_dir, \"awsw_story_input.txt\")) as f:\n",
    "    data = f.read()\n",
    "lines = data.split(\"\\n\")\n",
    "player_dragon_pairs = {}\n",
    "last_player_talk = []\n",
    "closed_player_talk = False\n",
    "re_player_talk = re.compile(r'c \"(.*?)\"')\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    line_split = line.split(\" \")\n",
    "    if len(line_split) <= 1:\n",
    "        continue\n",
    "    \n",
    "    if line_split[0] == \"c\":\n",
    "        if closed_player_talk:\n",
    "            closed_player_talk = False\n",
    "            last_player_talk = []\n",
    "        last_player_talk.append(re.sub(re_player_talk, r\"\\1\", line))\n",
    "    else:\n",
    "        if not closed_player_talk:\n",
    "            last_player_talk = json.dumps(last_player_talk)\n",
    "            if not last_player_talk in player_dragon_pairs:\n",
    "                player_dragon_pairs[last_player_talk] = []\n",
    "            closed_player_talk = True\n",
    "            \n",
    "        line = \"DragonReply \" + line\n",
    "        if last_player_talk is not None:\n",
    "            player_dragon_pairs[last_player_talk].append(line)\n",
    "    \n",
    "train_lines = []\n",
    "eval_lines = []\n",
    "eval_per_character = 0\n",
    "\n",
    "for player_line_str in player_dragon_pairs.keys():\n",
    "    player_lines = json.loads(player_line_str)\n",
    "    dragon_lines = player_dragon_pairs[player_line_str]\n",
    "    compiled_line = \" \".join([f'PlayerReply c \"{player_line}\"' for player_line in player_lines]) + \" \" + \" \".join(dragon_lines)\n",
    "    train_lines.append(compiled_line)\n",
    "    \n",
    "test_bucket = {}\n",
    "for l in train_lines:\n",
    "    l_split = l.split(\" \")\n",
    "    character = None\n",
    "    for i, ls in enumerate(l_split):\n",
    "        if ls == \"DragonReply\":\n",
    "            character = l_split[i + 1]\n",
    "            break\n",
    "    if not character in test_bucket:\n",
    "        test_bucket[character] = []\n",
    "    test_bucket[character].append(l)\n",
    "    \n",
    "for i in range(eval_per_character):\n",
    "    for character in test_bucket.keys():\n",
    "        random_line = test_bucket[character][randrange(len(test_bucket[character]))]\n",
    "        eval_lines.append(random_line)\n",
    "        for i2, t in enumerate(train_lines):\n",
    "            if t == random_line:\n",
    "                del train_lines[i2]\n",
    "                break\n",
    "    \n",
    "joined_eval_lines = \"\\n\".join(eval_lines[:5])\n",
    "print(f\"eval_lines: {joined_eval_lines}\")\n",
    "joined_train_lines = \"\\n\".join(train_lines[:5])\n",
    "print(f\"train_lines: {joined_train_lines}\")\n",
    "\n",
    "random.shuffle(train_lines)\n",
    "\n",
    "if not os.path.isfile(os.path.join(work_dir, \"data_train.txt\")):\n",
    "    with open(os.path.join(work_dir, \"data_train.txt\"), \"w\") as f:\n",
    "        for l in train_lines:\n",
    "            f.write(l + \"\\n\")\n",
    "            \n",
    "if not os.path.isfile(os.path.join(work_dir, \"data_test.txt\")):\n",
    "    with open(os.path.join(work_dir, \"data_test.txt\"), \"w\") as f:\n",
    "        for l in eval_lines:\n",
    "            f.write(l + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220,
     "referenced_widgets": [
      "a04e889a56e94ce9812a0e7d89d4d4f4",
      "3c2d0014295e47f9a07de8d4e36e7ba4",
      "76286c1e442541e0a6cb2d7cbbc9cc8f",
      "dcad41ec160e448b83d85c907a48facb",
      "27f2d980cb774902a82c0ad2545f549a",
      "131ce893dc784733b42f384b419145db",
      "607ee5c0b54042f3919d0588d66e31c1",
      "b2373342cb4942569088a5b20186795a",
      "11475ac58a594c6db1641401b1cc0d13",
      "f6625c167f7b4aa4bbecf2129e07c068",
      "ef9e25d7100e4e9ba064e938bd8157ea",
      "7bb369ca60f94acc99a4ee8e8f8fd261",
      "bc20a41ccda14aeeb72014b80a5ec53a",
      "c6ff5b9114424dbfafcbc3b3ab887af5",
      "1153397efee1426cac848341c0b88785",
      "37672ae801de4f42a9f6f49cc33fb88e",
      "8528f9fbbc504a44b9670a760256192d",
      "406b2f47896446a187725d4a1aa926f8",
      "cb33a87e718546f3a33b7deea817de56",
      "eeb54e278e184bc5aabf0283f1b276ff",
      "809a3780924641b8ace57e9141b0167f",
      "b805525a58804750ae56dad7e43ecb0e",
      "906b9daf9437432c81546f35256c7232",
      "0ce77d162a014a2fa17628ef8fe20846",
      "3fed2802cbab4a90a5b3d5a8c9bc8974",
      "a146d5c5588944368242c519984cbccc",
      "28d30b2eecf04ae6835cf4c35648dcfc",
      "65c48ca18ea14cf9bccbaa2495c2f120",
      "5067025a37bb42318ae93216b3205b17",
      "d18658b25f6f47778b984d0bf35be999",
      "6ade1603ab664b9f9d5ce44014bc5305",
      "fd91a671eeb7431d90d86b44beb276bd",
      "df0a544035814e1ca11d6191c10a5b62",
      "23a62f16d8de4f3ab9fa64ada07d1e35",
      "d50f5db4d1a1430caecace0510c1a24e",
      "d36395d1dcad4ead98f7f4756b8dbd37",
      "2cf737292a8343f5965c3eb0ace01875",
      "9ba5d1e5fab74947a328842b5105a28e",
      "073bc138772048729e04017123149e80",
      "ab0ce277776d4d218bf97fff5acc8e28",
      "b404b600842a4fc4b2b66c6b015235d6",
      "06dd02ec048945e5bf6b17d2b5558fb2",
      "437e050108fd46e1ba0f35674fa7314f",
      "a5725e8dc8104756bcba16b2c886a27f",
      "a31733df07ed4bb485d518b64634acfb",
      "1a2fe039b81a42c496ba363b2000bc41",
      "3f271f4469cf4796b92a78eba64c30b3",
      "fd200bcd96354e36b32ca82660eb0ef2",
      "33f9747c1f474c1790c7c293c853fad5",
      "e10acb8e2c8240409a19c61499576afd",
      "cc3c5e1ef5974710a06c1eab3d90cfb1",
      "6eda966317484df2a47fa0c4f2a0370c",
      "0cd6ff104b484203adda9e8414fd80fa",
      "c5a11599f37c4077a4ab0daec124a78c",
      "6cd8593a13f54c138c9adf5ec85f2d97"
     ]
    },
    "execution": {
     "iopub.execute_input": "2021-11-14T23:48:42.970313Z",
     "iopub.status.busy": "2021-11-14T23:48:42.969637Z",
     "iopub.status.idle": "2021-11-14T23:49:00.603885Z",
     "shell.execute_reply": "2021-11-14T23:49:00.604425Z"
    },
    "id": "pWeL2qWd2gOK",
    "outputId": "efdd650f-d95e-47a9-ad2f-396593bb779e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa31ee10bcc442a59a6709b8cfc3a563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('text', data_files={'train': os.path.join(work_dir, \"data_train.txt\"), 'test': os.path.join(work_dir, \"data_test.txt\")})\n",
    "\n",
    "class AWSWDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, dataset, dataset_type, do_shuffle=False):\n",
    "        self.current_dataset = dataset\n",
    "        self.dataset_type = dataset_type\n",
    "        self.do_shuffle = do_shuffle\n",
    "        self.shuffled_datasets = []\n",
    "        self.current_idx = 0\n",
    "        for i in range(1):\n",
    "            self.current_dataset = self.current_dataset.shuffle()\n",
    "            mapped_dataset = self.current_dataset.map(\n",
    "                group_texts,\n",
    "                batched=True,\n",
    "                batch_size=dataset_batch_size,\n",
    "                num_proc=dataset_map_cores\n",
    "            )\n",
    "            self.shuffled_datasets.append(mapped_dataset)\n",
    "        \n",
    "    def approx_len(self):\n",
    "        return len(self.shuffled_datasets[0][self.dataset_type])\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.current_idx = (self.current_idx + 1) % len(self.shuffled_datasets)\n",
    "        return iter(self.shuffled_datasets[self.current_idx][self.dataset_type])\n",
    "    \n",
    "def encode(batch):\n",
    "    result = []\n",
    "    attention_mask = []\n",
    "    for item in batch['text']:\n",
    "        #tokens = [tokenizer.bos_token_id] + tokenizer.encode(item) + [tokenizer.eos_token_id]\n",
    "        #tokens = tokenizer.encode(item)\n",
    "        tokens = tokenizer.encode(item) + [tokenizer.eos_token_id]\n",
    "        result.append(tokens)\n",
    "        attention_mask.append([1] * len(tokens))\n",
    "    return {\n",
    "        'attention_mask': attention_mask,\n",
    "        'input_ids': result\n",
    "    }\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    #random_shift = random.randint(0, 64)\n",
    "    #concatenated_examples['input_ids'] = concatenated_examples['input_ids'][random_shift:]\n",
    "    #concatenated_examples['attention_mask'] = concatenated_examples['attention_mask'][random_shift:]\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # Pad the end\n",
    "    to_add = (math.ceil(total_length / block_size) * block_size) - total_length\n",
    "    if to_add > 0:\n",
    "        concatenated_examples['input_ids'] += [tokenizer.pad_token_id] * to_add\n",
    "        concatenated_examples['attention_mask'] += [0] * to_add\n",
    "        total_length += to_add\n",
    "    # Split by chunks of block_size.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "def map_dragon_reply_text(batch):\n",
    "    result = {'text': []}\n",
    "    for item in batch['text']:\n",
    "        item_split = item.split(\" \")\n",
    "        player_replies = []\n",
    "        dragon_replies = []\n",
    "        current_reply = []\n",
    "        handling_reply = None\n",
    "        for token in item_split:\n",
    "            if token == \"PlayerReply\":\n",
    "                if handling_reply is None:\n",
    "                    handling_reply = \"PlayerReply\"\n",
    "                else:\n",
    "                    if handling_reply == \"PlayerReply\":\n",
    "                        # We need to store the PlayerReply\n",
    "                        player_replies.append(\" \".join(current_reply))\n",
    "                        current_reply = []\n",
    "            elif token == \"DragonReply\":\n",
    "                if handling_reply == \"DragonReply\":\n",
    "                    # We need to store the DragonReply\n",
    "                    dragon_replies.append(\" \".join(current_reply))\n",
    "                    current_reply = []\n",
    "                    \n",
    "                if handling_reply == \"PlayerReply\":\n",
    "                    # We need to store the PlayerReply\n",
    "                    player_replies.append(\" \".join(current_reply))\n",
    "                    current_reply = []\n",
    "                    \n",
    "                handling_reply = \"DragonReply\"\n",
    "                current_reply = []\n",
    "                    \n",
    "            if handling_reply is not None:\n",
    "                current_reply.append(token)\n",
    "                \n",
    "        # There's always a dragon reply at the end.\n",
    "        dragon_replies.append(\" \".join(current_reply))\n",
    "        for player_idx in range(len(player_replies)):\n",
    "            for dragon_idx in range(len(dragon_replies)):\n",
    "                result['text'].append(player_replies[player_idx] + \" \" + dragon_replies[dragon_idx])\n",
    "                \n",
    "    return result\n",
    "\n",
    "dataset_map_cores = min(multiprocessing.cpu_count(), 10)\n",
    "dataset_batch_size = 1000\n",
    "\n",
    "dataset = dataset.map(\n",
    "    map_dragon_reply_text,\n",
    "    batched=True,\n",
    "    batch_size=dataset_batch_size,\n",
    "    num_proc=dataset_map_cores\n",
    ")\n",
    "\n",
    "dataset = dataset.map(\n",
    "    encode,\n",
    "    batched=True,\n",
    "    batch_size=dataset_batch_size,\n",
    "    remove_columns=[\"text\"],\n",
    "    num_proc=dataset_map_cores\n",
    ")\n",
    "\n",
    "dataset = dataset.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=dataset_batch_size,\n",
    "    num_proc=dataset_map_cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-11-14T23:49:00.610502Z",
     "iopub.status.busy": "2021-11-14T23:49:00.609888Z",
     "iopub.status.idle": "2021-11-14T23:49:00.611595Z",
     "shell.execute_reply": "2021-11-14T23:49:00.611874Z"
    },
    "id": "PhiZIfn02gOL",
    "outputId": "47e5768d-8b9d-4ea8-c5ac-cc392abba402"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_len: 8658 num_training_steps: 136 num_total_steps: 13600\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_len = len(dataset['train'])\n",
    "num_training_steps = math.ceil(train_len / batch_size)\n",
    "num_epoch = 100\n",
    "num_total_steps = num_training_steps * num_epoch\n",
    "num_warmup_steps = num_training_steps * 2\n",
    "print(f\"train_len: {train_len} num_training_steps: {num_training_steps} num_total_steps: {num_total_steps}\")\n",
    "def get_optimizer_and_scheduler(params):\n",
    "    optimizer = AdamW(params, lr=0.001)\n",
    "    #scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_total_steps)\n",
    "    #scheduler = get_polynomial_decay_schedule_with_warmup(optimizer, num_warmup_steps, num_total_steps, power=0.5, lr_end=1e-10)\n",
    "    scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, num_warmup_steps, num_total_steps, 4)\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T23:49:00.616648Z",
     "iopub.status.busy": "2021-11-14T23:49:00.616126Z",
     "iopub.status.idle": "2021-11-14T23:49:00.955694Z",
     "shell.execute_reply": "2021-11-14T23:49:00.955215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrs = []\n",
    "optimizer, scheduler = get_optimizer_and_scheduler([torch.tensor(0.1)])\n",
    "for i in range(num_total_steps):\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "plt.plot(lrs)\n",
    "plt.show()\n",
    "del lrs\n",
    "del optimizer\n",
    "del scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T23:49:01.034667Z",
     "iopub.status.busy": "2021-11-14T23:49:00.960308Z",
     "iopub.status.idle": "2021-11-14T23:49:01.116604Z",
     "shell.execute_reply": "2021-11-14T23:49:01.117068Z"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat <<'EOT' > ds_config_zero3.json\n",
    "{\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": \"auto\",\n",
    "            \"warmup_max_lr\": \"auto\",\n",
    "            \"warmup_num_steps\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 3,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": true\n",
    "        },\n",
    "        \"offload_param\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": true\n",
    "        },\n",
    "        \"overlap_comm\": true,\n",
    "        \"contiguous_gradients\": true,\n",
    "        \"sub_group_size\": 1e9,\n",
    "        \"reduce_bucket_size\": \"auto\",\n",
    "        \"stage3_prefetch_bucket_size\": \"auto\",\n",
    "        \"stage3_param_persistence_threshold\": \"auto\",\n",
    "        \"stage3_max_live_parameters\": 1e9,\n",
    "        \"stage3_max_reuse_distance\": 1e9,\n",
    "        \"stage3_gather_fp16_weights_on_model_save\": true\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 2000,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": false\n",
    "}\n",
    "EOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "execution": {
     "iopub.execute_input": "2021-11-14T23:49:01.125764Z",
     "iopub.status.busy": "2021-11-14T23:49:01.125258Z",
     "iopub.status.idle": "2021-11-15T00:36:51.225245Z",
     "shell.execute_reply": "2021-11-15T00:36:51.224907Z"
    },
    "id": "AdPIW0xSTpRY",
    "outputId": "01338ca7-7ed2-4d8e-dd7b-5c235e4c5e30"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 8658\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13600' max='13600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13600/13600 47:49, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>10.263600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.654000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.110200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.966800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.855900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.755300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.690100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.632000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.589300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.559300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.533500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.519200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.512200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.557400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.590500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.544200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.492200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>0.449200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.412700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>0.379500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5750</td>\n",
       "      <td>0.331000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.315500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6250</td>\n",
       "      <td>0.299900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.290400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6750</td>\n",
       "      <td>0.284900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.297400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7250</td>\n",
       "      <td>0.377300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.360700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7750</td>\n",
       "      <td>0.334600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.306900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8250</td>\n",
       "      <td>0.285900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.265700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8750</td>\n",
       "      <td>0.247300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.232300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9250</td>\n",
       "      <td>0.221300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.210300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9750</td>\n",
       "      <td>0.203200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.198300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10250</td>\n",
       "      <td>0.196600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.259900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10750</td>\n",
       "      <td>0.279000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.261400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11250</td>\n",
       "      <td>0.243600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.227800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11750</td>\n",
       "      <td>0.213600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.198900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12250</td>\n",
       "      <td>0.188200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.176600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12750</td>\n",
       "      <td>0.167000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.161500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13250</td>\n",
       "      <td>0.157900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.156800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /opt/awsw/models/checkpoint-500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-1000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-1000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-1500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-1500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-1500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-2000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-2000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-2000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-2500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-2500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-2500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-3000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-3000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-3000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-3500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-3500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-3500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-4000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-4000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-4000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-4500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-4500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-4500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-3500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-5000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-5000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-5000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-5500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-5500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-5500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-4500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-6000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-6000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-6000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-6500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-6500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-6500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-5500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-7000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-7000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-7000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-7500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-7500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-7500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-6500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-8000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-8000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-8000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-8500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-8500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-8500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-7500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-9000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-9000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-9000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-9500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-9500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-9500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-8500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-10000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-10000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-10000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-10500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-10500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-10500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-9500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-11000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-11000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-11000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-10000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-11500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-11500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-11500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-10500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-12000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-12000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-12000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-11000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-12500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-12500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-12500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-11500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-13000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-13000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-13000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-12000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-13500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-13500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-13500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-12500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class AWSWTrainer(Trainer):\n",
    "    def _get_train_sampler(self):\n",
    "        return None\n",
    "    \n",
    "class AWSWTrainerCallback(TrainerCallback):\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        learning_rate_history = [h['learning_rate'] for h in state.log_history if 'loss' in h]\n",
    "        loss_history = [h['loss'] for h in state.log_history if 'loss' in h]\n",
    "        fig, axs = plt.subplots(2)\n",
    "        fig.suptitle('Learning rate and loss')\n",
    "        axs[0].plot(learning_rate_history)\n",
    "        axs[1].plot(loss_history)\n",
    "        \n",
    "def train(model):\n",
    "    optimizer, scheduler = get_optimizer_and_scheduler(model.parameters())\n",
    "    training_args = TrainingArguments(\n",
    "        models_dir,\n",
    "        seed=seed,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=num_epoch,\n",
    "        save_total_limit=2,\n",
    "        save_steps=500,\n",
    "        logging_steps=250,\n",
    "        ddp_find_unused_parameters=False,\n",
    "        #deepspeed=\"ds_config_zero3.json\"\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model, \n",
    "        args=training_args, \n",
    "        train_dataset=dataset['train'],\n",
    "        optimizers=(optimizer, scheduler),\n",
    "        callbacks=[AWSWTrainerCallback]\n",
    "    )\n",
    "    checkpoint_dirs = [os.path.join(models_dir, d) for d in os.listdir(models_dir) if os.path.isdir(os.path.join(models_dir, d))]\n",
    "    if len(checkpoint_dirs) > 0:\n",
    "        latest_checkpoint = max(checkpoint_dirs, key=os.path.getmtime)\n",
    "        trainer.train(latest_checkpoint)\n",
    "    else:\n",
    "        trainer.train()\n",
    "\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unxN7nYd2gOM",
    "tags": []
   },
   "source": [
    "# Testing\n",
    "\n",
    "We created a few past (for context) + present prompts (player input) and see the different reactions. This way, we can test the models across different iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T00:36:51.232938Z",
     "iopub.status.busy": "2021-11-15T00:36:51.232257Z",
     "iopub.status.idle": "2021-11-15T00:36:51.645857Z",
     "shell.execute_reply": "2021-11-15T00:36:51.645321Z"
    },
    "id": "5UePGmLD2gON"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_dragon_reply(past, prompt, top_k=None, top_p=None):\n",
    "    model.eval()\n",
    "    prompt = f'{past} PlayerReply c \"{prompt}\" DragonReply'\n",
    "    generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "    generated = generated.to(device)\n",
    "\n",
    "    sample_outputs = model.generate(\n",
    "        generated, \n",
    "        do_sample=(top_k is not None and top_p is not None),\n",
    "        top_p=top_p,\n",
    "        top_k=top_k,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        max_length=block_size,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    return tokenizer.decode(sample_outputs[0], skip_special_tokens=False)[len(prompt):].strip()\n",
    "\n",
    "prompts = [\n",
    "    ('PlayerReply c \"Hey Remy!\" DragonReply Ry \"Hey!\"', \"How are you?\"),\n",
    "    ('PlayerReply c \"I was with Lorem today.\" DragonReply Ad \"That\\'s awesome. He\\'s a cute fellow.\"', \"What do you think of Lorem?\"),\n",
    "    ('DragonReply m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('DragonReply m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "# Set a fixed seed to make sure we get the same response every time.\n",
    "torch.manual_seed(80085)\n",
    "for (past, prompt) in prompts:\n",
    "    reply = generate_dragon_reply(past, prompt)\n",
    "    print(f\"Prompt: {prompt}\\nReply: {reply}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OZarUHg2gON"
   },
   "source": [
    "# Sampling test\n",
    "\n",
    "Which combination is the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T00:36:51.651718Z",
     "iopub.status.busy": "2021-11-15T00:36:51.651210Z",
     "iopub.status.idle": "2021-11-15T00:37:36.804049Z",
     "shell.execute_reply": "2021-11-15T00:37:36.803601Z"
    },
    "id": "bWoLzL9B2gON"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test 1 top_k: 95, top_p: 0.4] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 1 top_k: 95, top_p: 0.4] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get to the point where I just have to follow the same\n",
      "\n",
      "[Test 1 top_k: 95, top_p: 0.4] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 1 top_k: 95, top_p: 0.4] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Just wait until I get outside, then, shall we?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 2 top_k: 33, top_p: 0.97] -> Prompt: How are you?\n",
      "Reply: Ry smile \"I thought that should be everything.\"<|endoftext|>\n",
      "\n",
      "[Test 2 top_k: 33, top_p: 0.97] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you're curious.\"<|endoftext|>\n",
      "\n",
      "[Test 2 top_k: 33, top_p: 0.97] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 2 top_k: 33, top_p: 0.97] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"The Administrator turned to leave.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 3 top_k: 37, top_p: 0.25] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 3 top_k: 37, top_p: 0.25] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 3 top_k: 37, top_p: 0.25] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 3 top_k: 37, top_p: 0.25] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 4 top_k: 63, top_p: 0.73] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 4 top_k: 63, top_p: 0.73] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see if I can make a first impression of that.\"<|endoftext|>\n",
      "\n",
      "[Test 4 top_k: 63, top_p: 0.73] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 4 top_k: 63, top_p: 0.73] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at least I'll be able to check in on her.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 5 top_k: 40, top_p: 0.16] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 5 top_k: 40, top_p: 0.16] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 5 top_k: 40, top_p: 0.16] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 5 top_k: 40, top_p: 0.16] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 6 top_k: 7, top_p: 0.63] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 6 top_k: 7, top_p: 0.63] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see where I'll be.\"<|endoftext|>\n",
      "\n",
      "[Test 6 top_k: 7, top_p: 0.63] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 6 top_k: 7, top_p: 0.63] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Just wait until I get up and we're ready to go.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 7 top_k: 23, top_p: 0.97] -> Prompt: How are you?\n",
      "Reply: Ry smile \"I thought that should be everything.\"<|endoftext|>\n",
      "\n",
      "[Test 7 top_k: 23, top_p: 0.97] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you're curious.\"<|endoftext|>\n",
      "\n",
      "[Test 7 top_k: 23, top_p: 0.97] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 7 top_k: 23, top_p: 0.97] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"The Administrator turned to leave.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 8 top_k: 49, top_p: 0.29] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 8 top_k: 49, top_p: 0.29] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 8 top_k: 49, top_p: 0.29] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 8 top_k: 49, top_p: 0.29] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, we could look at the portal from the wrong angle.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 9 top_k: 62, top_p: 0.41] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 9 top_k: 62, top_p: 0.41] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get to the point where I just have to follow the same\n",
      "\n",
      "[Test 9 top_k: 62, top_p: 0.41] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 9 top_k: 62, top_p: 0.41] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Just wait until I get outside, then, shall we?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 10 top_k: 62, top_p: 0.91] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 10 top_k: 62, top_p: 0.91] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good time for everything. I'll see you next time, then.\"<|endoftext|>\n",
      "\n",
      "[Test 10 top_k: 62, top_p: 0.91] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 10 top_k: 62, top_p: 0.91] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, let's just sit down somewhere and wait.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 11 top_k: 100, top_p: 0.43] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 11 top_k: 100, top_p: 0.43] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get to the point where I just have to follow the same\n",
      "\n",
      "[Test 11 top_k: 100, top_p: 0.43] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 11 top_k: 100, top_p: 0.43] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Just wait until I get up and we're ready to go.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 12 top_k: 0, top_p: 0.85] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 12 top_k: 0, top_p: 0.85] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good time for everything. I'll see you next time, then.\"<|endoftext|>\n",
      "\n",
      "[Test 12 top_k: 0, top_p: 0.85] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 12 top_k: 0, top_p: 0.85] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, let's just all go inside.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 13 top_k: 66, top_p: 0.84] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 13 top_k: 66, top_p: 0.84] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see if I can make a first impression of that.\"<|endoftext|>\n",
      "\n",
      "[Test 13 top_k: 66, top_p: 0.84] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 13 top_k: 66, top_p: 0.84] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, what do you think?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 14 top_k: 46, top_p: 0.8] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 14 top_k: 46, top_p: 0.8] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see if I can make a first impression of that.\"<|endoftext|>\n",
      "\n",
      "[Test 14 top_k: 46, top_p: 0.8] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 14 top_k: 46, top_p: 0.8] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at least I'll be able to check in on her.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 15 top_k: 11, top_p: 0.52] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 15 top_k: 11, top_p: 0.52] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see where everything is.\"<|endoftext|>\n",
      "\n",
      "[Test 15 top_k: 11, top_p: 0.52] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 15 top_k: 11, top_p: 0.52] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, we could look at the portal from the wrong angle.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 16 top_k: 60, top_p: 0.66] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 16 top_k: 60, top_p: 0.66] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see where I'll be.\"<|endoftext|>\n",
      "\n",
      "[Test 16 top_k: 60, top_p: 0.66] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 16 top_k: 60, top_p: 0.66] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Just wait until I get up and we're ready to go.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 17 top_k: 24, top_p: 0.31] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 17 top_k: 24, top_p: 0.31] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 17 top_k: 24, top_p: 0.31] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 17 top_k: 24, top_p: 0.31] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, we could look at the portal from the wrong angle.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 18 top_k: 84, top_p: 0.13] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 18 top_k: 84, top_p: 0.13] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 18 top_k: 84, top_p: 0.13] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 18 top_k: 84, top_p: 0.13] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 19 top_k: 6, top_p: 0.24] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 19 top_k: 6, top_p: 0.24] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 19 top_k: 6, top_p: 0.24] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 19 top_k: 6, top_p: 0.24] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 20 top_k: 95, top_p: 0.58] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 20 top_k: 95, top_p: 0.58] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see where everything is.\"<|endoftext|>\n",
      "\n",
      "[Test 20 top_k: 95, top_p: 0.58] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 20 top_k: 95, top_p: 0.58] -> Prompt: What will we do here?\n",
      "Reply: Ad \"They aren't really my children, per se. I just take care of them.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 21 top_k: 81, top_p: 0.24] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 21 top_k: 81, top_p: 0.24] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 21 top_k: 81, top_p: 0.24] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 21 top_k: 81, top_p: 0.24] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 22 top_k: 27, top_p: 0.17] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 22 top_k: 27, top_p: 0.17] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 22 top_k: 27, top_p: 0.17] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 22 top_k: 27, top_p: 0.17] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 23 top_k: 37, top_p: 0.94] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 23 top_k: 37, top_p: 0.94] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good time for everything. I'll see you next time, then.\"<|endoftext|>\n",
      "\n",
      "[Test 23 top_k: 37, top_p: 0.94] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 23 top_k: 37, top_p: 0.94] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, let's just sit down somewhere and wait.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 24 top_k: 93, top_p: 0.24] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 24 top_k: 93, top_p: 0.24] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 24 top_k: 93, top_p: 0.24] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 24 top_k: 93, top_p: 0.24] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 25 top_k: 8, top_p: 0.74] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 25 top_k: 8, top_p: 0.74] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see if I can make a first impression of that.\"<|endoftext|>\n",
      "\n",
      "[Test 25 top_k: 8, top_p: 0.74] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 25 top_k: 8, top_p: 0.74] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at least I'll be able to check in on her.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 26 top_k: 87, top_p: 0.21] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 26 top_k: 87, top_p: 0.21] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 26 top_k: 87, top_p: 0.21] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 26 top_k: 87, top_p: 0.21] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 27 top_k: 92, top_p: 0.2] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 27 top_k: 92, top_p: 0.2] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 27 top_k: 92, top_p: 0.2] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 27 top_k: 92, top_p: 0.2] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 28 top_k: 63, top_p: 0.76] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 28 top_k: 63, top_p: 0.76] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see if I can make a first impression of that.\"<|endoftext|>\n",
      "\n",
      "[Test 28 top_k: 63, top_p: 0.76] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 28 top_k: 63, top_p: 0.76] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at least I'll be able to check in on her.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 29 top_k: 27, top_p: 0.1] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 29 top_k: 27, top_p: 0.1] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 29 top_k: 27, top_p: 0.1] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 29 top_k: 27, top_p: 0.1] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 30 top_k: 49, top_p: 0.09] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 30 top_k: 49, top_p: 0.09] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 30 top_k: 49, top_p: 0.09] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 30 top_k: 49, top_p: 0.09] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 31 top_k: 16, top_p: 0.7] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 31 top_k: 16, top_p: 0.7] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see if I can make a first impression of that.\"<|endoftext|>\n",
      "\n",
      "[Test 31 top_k: 16, top_p: 0.7] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 31 top_k: 16, top_p: 0.7] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 32 top_k: 21, top_p: 0.77] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 32 top_k: 21, top_p: 0.77] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see if I can make a first impression of that.\"<|endoftext|>\n",
      "\n",
      "[Test 32 top_k: 21, top_p: 0.77] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 32 top_k: 21, top_p: 0.77] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at least I'll be able to check in on her.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 33 top_k: 2, top_p: 0.83] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 33 top_k: 2, top_p: 0.83] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see if I can make a first impression of that.\"<|endoftext|>\n",
      "\n",
      "[Test 33 top_k: 2, top_p: 0.83] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 33 top_k: 2, top_p: 0.83] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at least I'll be able to check in on her.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 34 top_k: 85, top_p: 0.87] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 34 top_k: 85, top_p: 0.87] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good time for everything. I'll see you next time, then.\"<|endoftext|>\n",
      "\n",
      "[Test 34 top_k: 85, top_p: 0.87] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 34 top_k: 85, top_p: 0.87] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, let's just all go inside.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 35 top_k: 19, top_p: 0.34] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 35 top_k: 19, top_p: 0.34] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 35 top_k: 19, top_p: 0.34] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 35 top_k: 19, top_p: 0.34] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, we could look at the portal from the wrong angle.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 36 top_k: 99, top_p: 0.12] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 36 top_k: 99, top_p: 0.12] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 36 top_k: 99, top_p: 0.12] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 36 top_k: 99, top_p: 0.12] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 37 top_k: 55, top_p: 0.62] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 37 top_k: 55, top_p: 0.62] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see where I'll be.\"<|endoftext|>\n",
      "\n",
      "[Test 37 top_k: 55, top_p: 0.62] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 37 top_k: 55, top_p: 0.62] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Just wait until I get up and we're ready to go.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 38 top_k: 27, top_p: 0.29] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 38 top_k: 27, top_p: 0.29] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 38 top_k: 27, top_p: 0.29] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 38 top_k: 27, top_p: 0.29] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, we could look at the portal from the wrong angle.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 39 top_k: 53, top_p: 0.79] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 39 top_k: 53, top_p: 0.79] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see if I can make a first impression of that.\"<|endoftext|>\n",
      "\n",
      "[Test 39 top_k: 53, top_p: 0.79] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 39 top_k: 53, top_p: 0.79] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at least I'll be able to check in on her.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 40 top_k: 98, top_p: 0.46] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 40 top_k: 98, top_p: 0.46] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get to the point where I just have to follow the same\n",
      "\n",
      "[Test 40 top_k: 98, top_p: 0.46] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 40 top_k: 98, top_p: 0.46] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Just wait until I get up and we're ready to go.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 41 top_k: 25, top_p: 0.77] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 41 top_k: 25, top_p: 0.77] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see if I can make a first impression of that.\"<|endoftext|>\n",
      "\n",
      "[Test 41 top_k: 25, top_p: 0.77] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 41 top_k: 25, top_p: 0.77] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at least I'll be able to check in on her.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 42 top_k: 0, top_p: 0.22] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 42 top_k: 0, top_p: 0.22] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 42 top_k: 0, top_p: 0.22] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 42 top_k: 0, top_p: 0.22] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 43 top_k: 25, top_p: 0.13] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 43 top_k: 25, top_p: 0.13] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 43 top_k: 25, top_p: 0.13] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 43 top_k: 25, top_p: 0.13] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 44 top_k: 46, top_p: 0.03] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 44 top_k: 46, top_p: 0.03] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 44 top_k: 46, top_p: 0.03] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 44 top_k: 46, top_p: 0.03] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 45 top_k: 100, top_p: 0.02] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 45 top_k: 100, top_p: 0.02] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 45 top_k: 100, top_p: 0.02] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 45 top_k: 100, top_p: 0.02] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 46 top_k: 48, top_p: 0.82] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 46 top_k: 48, top_p: 0.82] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see if I can make a first impression of that.\"<|endoftext|>\n",
      "\n",
      "[Test 46 top_k: 48, top_p: 0.82] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 46 top_k: 48, top_p: 0.82] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, what do you think?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 47 top_k: 61, top_p: 0.76] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 47 top_k: 61, top_p: 0.76] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see if I can make a first impression of that.\"<|endoftext|>\n",
      "\n",
      "[Test 47 top_k: 61, top_p: 0.76] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 47 top_k: 61, top_p: 0.76] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at least I'll be able to check in on her.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 48 top_k: 56, top_p: 0.17] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 48 top_k: 56, top_p: 0.17] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 48 top_k: 56, top_p: 0.17] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 48 top_k: 56, top_p: 0.17] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 49 top_k: 65, top_p: 0.79] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 49 top_k: 65, top_p: 0.79] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see if I can make a first impression of that.\"<|endoftext|>\n",
      "\n",
      "[Test 49 top_k: 65, top_p: 0.79] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 49 top_k: 65, top_p: 0.79] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at least I'll be able to check in on her.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 50 top_k: 28, top_p: 0.88] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 50 top_k: 28, top_p: 0.88] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good time for everything. I'll see you next time, then.\"<|endoftext|>\n",
      "\n",
      "[Test 50 top_k: 28, top_p: 0.88] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 50 top_k: 28, top_p: 0.88] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, let's just all go inside.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 51 top_k: 77, top_p: 0.17] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 51 top_k: 77, top_p: 0.17] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 51 top_k: 77, top_p: 0.17] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 51 top_k: 77, top_p: 0.17] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 52 top_k: 100, top_p: 0.93] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 52 top_k: 100, top_p: 0.93] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good time for everything. I'll see you next time, then.\"<|endoftext|>\n",
      "\n",
      "[Test 52 top_k: 100, top_p: 0.93] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 52 top_k: 100, top_p: 0.93] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, let's just sit down somewhere and wait.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 53 top_k: 34, top_p: 0.48] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 53 top_k: 34, top_p: 0.48] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see where everything is.\"<|endoftext|>\n",
      "\n",
      "[Test 53 top_k: 34, top_p: 0.48] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 53 top_k: 34, top_p: 0.48] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, we could look at the portal from the wrong angle.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 54 top_k: 98, top_p: 0.83] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 54 top_k: 98, top_p: 0.83] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see if I can make a first impression of that.\"<|endoftext|>\n",
      "\n",
      "[Test 54 top_k: 98, top_p: 0.83] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 54 top_k: 98, top_p: 0.83] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, what do you think?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 55 top_k: 84, top_p: 0.2] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 55 top_k: 84, top_p: 0.2] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 55 top_k: 84, top_p: 0.2] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 55 top_k: 84, top_p: 0.2] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 56 top_k: 92, top_p: 0.95] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 56 top_k: 92, top_p: 0.95] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good time for everything. I'll see you next time, then.\"<|endoftext|>\n",
      "\n",
      "[Test 56 top_k: 92, top_p: 0.95] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 56 top_k: 92, top_p: 0.95] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, let's just sit down somewhere and wait.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 57 top_k: 88, top_p: 0.79] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 57 top_k: 88, top_p: 0.79] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see if I can make a first impression of that.\"<|endoftext|>\n",
      "\n",
      "[Test 57 top_k: 88, top_p: 0.79] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 57 top_k: 88, top_p: 0.79] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at least I'll be able to check in on her.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 58 top_k: 73, top_p: 0.36] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 58 top_k: 73, top_p: 0.36] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get to the point where I just have to follow the same\n",
      "\n",
      "[Test 58 top_k: 73, top_p: 0.36] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 58 top_k: 73, top_p: 0.36] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 59 top_k: 24, top_p: 0.69] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 59 top_k: 24, top_p: 0.69] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see if I can make a first impression of that.\"<|endoftext|>\n",
      "\n",
      "[Test 59 top_k: 24, top_p: 0.69] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 59 top_k: 24, top_p: 0.69] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 60 top_k: 41, top_p: 0.98] -> Prompt: How are you?\n",
      "Reply: Ry smile \"I thought that should be everything.\"<|endoftext|>\n",
      "\n",
      "[Test 60 top_k: 41, top_p: 0.98] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you're curious.\"<|endoftext|>\n",
      "\n",
      "[Test 60 top_k: 41, top_p: 0.98] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 60 top_k: 41, top_p: 0.98] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"The Administrator turned to leave.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 61 top_k: 33, top_p: 0.07] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 61 top_k: 33, top_p: 0.07] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 61 top_k: 33, top_p: 0.07] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 61 top_k: 33, top_p: 0.07] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 62 top_k: 19, top_p: 0.98] -> Prompt: How are you?\n",
      "Reply: Ry smile \"I thought that should be everything.\"<|endoftext|>\n",
      "\n",
      "[Test 62 top_k: 19, top_p: 0.98] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you're curious.\"<|endoftext|>\n",
      "\n",
      "[Test 62 top_k: 19, top_p: 0.98] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 62 top_k: 19, top_p: 0.98] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"The Administrator turned to leave.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 63 top_k: 5, top_p: 0.06] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 63 top_k: 5, top_p: 0.06] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 63 top_k: 5, top_p: 0.06] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 63 top_k: 5, top_p: 0.06] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 64 top_k: 28, top_p: 0.29] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 64 top_k: 28, top_p: 0.29] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 64 top_k: 28, top_p: 0.29] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 64 top_k: 28, top_p: 0.29] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, we could look at the portal from the wrong angle.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 65 top_k: 10, top_p: 0.08] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 65 top_k: 10, top_p: 0.08] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 65 top_k: 10, top_p: 0.08] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 65 top_k: 10, top_p: 0.08] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 66 top_k: 20, top_p: 0.42] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 66 top_k: 20, top_p: 0.42] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get to the point where I just have to follow the same\n",
      "\n",
      "[Test 66 top_k: 20, top_p: 0.42] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 66 top_k: 20, top_p: 0.42] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Just wait until I get up and we're ready to go.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 67 top_k: 59, top_p: 0.84] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 67 top_k: 59, top_p: 0.84] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see if I can make a first impression of that.\"<|endoftext|>\n",
      "\n",
      "[Test 67 top_k: 59, top_p: 0.84] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 67 top_k: 59, top_p: 0.84] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, what do you think?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 68 top_k: 100, top_p: 0.19] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 68 top_k: 100, top_p: 0.19] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 68 top_k: 100, top_p: 0.19] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 68 top_k: 100, top_p: 0.19] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 69 top_k: 7, top_p: 0.93] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 69 top_k: 7, top_p: 0.93] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good time for everything. I'll see you next time, then.\"<|endoftext|>\n",
      "\n",
      "[Test 69 top_k: 7, top_p: 0.93] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 69 top_k: 7, top_p: 0.93] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, let's just sit down somewhere and wait.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 70 top_k: 46, top_p: 0.68] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 70 top_k: 46, top_p: 0.68] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see where I'll be.\"<|endoftext|>\n",
      "\n",
      "[Test 70 top_k: 46, top_p: 0.68] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 70 top_k: 46, top_p: 0.68] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Just wait until I get up and we're ready to go.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 71 top_k: 57, top_p: 0.3] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 71 top_k: 57, top_p: 0.3] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 71 top_k: 57, top_p: 0.3] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 71 top_k: 57, top_p: 0.3] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, we could look at the portal from the wrong angle.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 72 top_k: 26, top_p: 0.6] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 72 top_k: 26, top_p: 0.6] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see where I'll be.\"<|endoftext|>\n",
      "\n",
      "[Test 72 top_k: 26, top_p: 0.6] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 72 top_k: 26, top_p: 0.6] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Just wait until I get up and we're ready to go.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 73 top_k: 67, top_p: 0.55] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 73 top_k: 67, top_p: 0.55] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see where everything is.\"<|endoftext|>\n",
      "\n",
      "[Test 73 top_k: 67, top_p: 0.55] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 73 top_k: 67, top_p: 0.55] -> Prompt: What will we do here?\n",
      "Reply: Ad \"They aren't really my children, per se. I just take care of them.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 74 top_k: 59, top_p: 0.17] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 74 top_k: 59, top_p: 0.17] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 74 top_k: 59, top_p: 0.17] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 74 top_k: 59, top_p: 0.17] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 75 top_k: 43, top_p: 0.16] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 75 top_k: 43, top_p: 0.16] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 75 top_k: 43, top_p: 0.16] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 75 top_k: 43, top_p: 0.16] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 76 top_k: 7, top_p: 0.85] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 76 top_k: 7, top_p: 0.85] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see if I can make a first impression of that.\"<|endoftext|>\n",
      "\n",
      "[Test 76 top_k: 7, top_p: 0.85] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 76 top_k: 7, top_p: 0.85] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at least I'll be able to check in on her.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 77 top_k: 85, top_p: 0.0] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 77 top_k: 85, top_p: 0.0] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 77 top_k: 85, top_p: 0.0] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 77 top_k: 85, top_p: 0.0] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 78 top_k: 69, top_p: 0.28] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 78 top_k: 69, top_p: 0.28] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 78 top_k: 69, top_p: 0.28] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 78 top_k: 69, top_p: 0.28] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 79 top_k: 100, top_p: 0.27] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 79 top_k: 100, top_p: 0.27] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 79 top_k: 100, top_p: 0.27] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 79 top_k: 100, top_p: 0.27] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 80 top_k: 52, top_p: 0.02] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 80 top_k: 52, top_p: 0.02] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 80 top_k: 52, top_p: 0.02] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 80 top_k: 52, top_p: 0.02] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 81 top_k: 51, top_p: 0.13] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 81 top_k: 51, top_p: 0.13] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 81 top_k: 51, top_p: 0.13] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 81 top_k: 51, top_p: 0.13] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 82 top_k: 33, top_p: 0.2] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 82 top_k: 33, top_p: 0.2] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 82 top_k: 33, top_p: 0.2] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 82 top_k: 33, top_p: 0.2] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 83 top_k: 7, top_p: 0.58] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 83 top_k: 7, top_p: 0.58] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see where everything is.\"<|endoftext|>\n",
      "\n",
      "[Test 83 top_k: 7, top_p: 0.58] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 83 top_k: 7, top_p: 0.58] -> Prompt: What will we do here?\n",
      "Reply: Ad \"They aren't really my children, per se. I just take care of them.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 84 top_k: 21, top_p: 0.16] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 84 top_k: 21, top_p: 0.16] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 84 top_k: 21, top_p: 0.16] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 84 top_k: 21, top_p: 0.16] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 85 top_k: 15, top_p: 0.09] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 85 top_k: 15, top_p: 0.09] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 85 top_k: 15, top_p: 0.09] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 85 top_k: 15, top_p: 0.09] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 86 top_k: 83, top_p: 0.76] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 86 top_k: 83, top_p: 0.76] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see if I can make a first impression of that.\"<|endoftext|>\n",
      "\n",
      "[Test 86 top_k: 83, top_p: 0.76] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 86 top_k: 83, top_p: 0.76] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at least I'll be able to check in on her.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 87 top_k: 97, top_p: 0.23] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 87 top_k: 97, top_p: 0.23] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 87 top_k: 97, top_p: 0.23] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 87 top_k: 97, top_p: 0.23] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 88 top_k: 48, top_p: 0.44] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 88 top_k: 48, top_p: 0.44] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get to the point where I just have to follow the same\n",
      "\n",
      "[Test 88 top_k: 48, top_p: 0.44] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 88 top_k: 48, top_p: 0.44] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Just wait until I get up and we're ready to go.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 89 top_k: 77, top_p: 0.96] -> Prompt: How are you?\n",
      "Reply: Ry smile \"I thought that should be everything.\"<|endoftext|>\n",
      "\n",
      "[Test 89 top_k: 77, top_p: 0.96] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you're curious.\"<|endoftext|>\n",
      "\n",
      "[Test 89 top_k: 77, top_p: 0.96] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 89 top_k: 77, top_p: 0.96] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"The Administrator turned to leave.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 90 top_k: 2, top_p: 0.14] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 90 top_k: 2, top_p: 0.14] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 90 top_k: 2, top_p: 0.14] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 90 top_k: 2, top_p: 0.14] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 91 top_k: 3, top_p: 0.15] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 91 top_k: 3, top_p: 0.15] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 91 top_k: 3, top_p: 0.15] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 91 top_k: 3, top_p: 0.15] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 92 top_k: 77, top_p: 0.96] -> Prompt: How are you?\n",
      "Reply: Ry smile \"I thought that should be everything.\"<|endoftext|>\n",
      "\n",
      "[Test 92 top_k: 77, top_p: 0.96] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you're curious.\"<|endoftext|>\n",
      "\n",
      "[Test 92 top_k: 77, top_p: 0.96] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 92 top_k: 77, top_p: 0.96] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"The Administrator turned to leave.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 93 top_k: 78, top_p: 0.65] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 93 top_k: 78, top_p: 0.65] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see where I'll be.\"<|endoftext|>\n",
      "\n",
      "[Test 93 top_k: 78, top_p: 0.65] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 93 top_k: 78, top_p: 0.65] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Just wait until I get up and we're ready to go.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 94 top_k: 9, top_p: 0.89] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 94 top_k: 9, top_p: 0.89] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good time for everything. I'll see you next time, then.\"<|endoftext|>\n",
      "\n",
      "[Test 94 top_k: 9, top_p: 0.89] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 94 top_k: 9, top_p: 0.89] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, let's just all go inside.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 95 top_k: 93, top_p: 0.86] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 95 top_k: 93, top_p: 0.86] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good time for everything. I'll see you next time, then.\"<|endoftext|>\n",
      "\n",
      "[Test 95 top_k: 93, top_p: 0.86] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 95 top_k: 93, top_p: 0.86] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, let's just all go inside.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 96 top_k: 67, top_p: 0.35] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 96 top_k: 67, top_p: 0.35] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get to the point where I just have to follow the same\n",
      "\n",
      "[Test 96 top_k: 67, top_p: 0.35] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 96 top_k: 67, top_p: 0.35] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 97 top_k: 21, top_p: 0.46] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 97 top_k: 21, top_p: 0.46] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get to the point where I just have to follow the same\n",
      "\n",
      "[Test 97 top_k: 21, top_p: 0.46] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 97 top_k: 21, top_p: 0.46] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Just wait until I get up and we're ready to go.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 98 top_k: 10, top_p: 0.37] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 98 top_k: 10, top_p: 0.37] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get to the point where I just have to follow the same\n",
      "\n",
      "[Test 98 top_k: 10, top_p: 0.37] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 98 top_k: 10, top_p: 0.37] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 99 top_k: 58, top_p: 0.6] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 99 top_k: 58, top_p: 0.6] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"That's certainly a good name. Let's see where I'll be.\"<|endoftext|>\n",
      "\n",
      "[Test 99 top_k: 58, top_p: 0.6] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 99 top_k: 58, top_p: 0.6] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Just wait until I get up and we're ready to go.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 100 top_k: 27, top_p: 0.06] -> Prompt: How are you?\n",
      "Reply: Ry \"Hey, [player_name].\"<|endoftext|>\n",
      "\n",
      "[Test 100 top_k: 27, top_p: 0.06] -> Prompt: What do you think of Lorem?\n",
      "Reply: Sb \"I suppose you'll be stuck with that until I get this number.\"<|endoftext|>\n",
      "\n",
      "[Test 100 top_k: 27, top_p: 0.06] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ka exhausted flip \"Yes, I will have to admit defeat on that front, but in hindsight, all successful ideas look like good ones.\"<|endoftext|>\n",
      "\n",
      "[Test 100 top_k: 27, top_p: 0.06] -> Prompt: What will we do here?\n",
      "Reply: Ad think b \"Well, at the very least, I hope you're ready, because of the fireworks we had going on.\"<|endoftext|>\n",
      "\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    torch.manual_seed(80085)\n",
    "    top_k = random.randint(0, 100)\n",
    "    top_p = round(random.uniform(0, 1), 2)\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = generate_dragon_reply(past, prompt, top_k = top_k, top_p = top_p)\n",
    "        print(f\"[Test {i + 1} top_k: {top_k}, top_p: {top_p}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T00:37:36.812496Z",
     "iopub.status.busy": "2021-11-15T00:37:36.812016Z",
     "iopub.status.idle": "2021-11-15T00:37:36.920953Z",
     "shell.execute_reply": "2021-11-15T00:37:36.920635Z"
    },
    "id": "FgM9Awn7acpG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What to say?\n"
     ]
    },
    {
     "ename": "StdinNotImplementedError",
     "evalue": "raw_input was called, but this frontend does not support input requests.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStdinNotImplementedError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5552/61523620.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What to say?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_reply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \"\"\"\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_stdin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m             raise StdinNotImplementedError(\n\u001b[0m\u001b[1;32m   1004\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             )\n",
      "\u001b[0;31mStdinNotImplementedError\u001b[0m: raw_input was called, but this frontend does not support input requests."
     ]
    }
   ],
   "source": [
    "def generate_reply(prompt):\n",
    "    model.eval()\n",
    "    prompt = f'PlayerReply c \"{prompt}\" DragonReply'\n",
    "    generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "    generated = generated.to(device)\n",
    "    print(prompt, generated)\n",
    "\n",
    "    sample_outputs = model.generate(\n",
    "        generated, \n",
    "        do_sample=True,   \n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        top_length = block_size,\n",
    "        top_p=0.95, \n",
    "        num_return_sequences=3\n",
    "    )\n",
    "\n",
    "    for i, sample_output in enumerate(sample_outputs):\n",
    "        print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=False)))\n",
    "\n",
    "print(\"What to say?\")\n",
    "print(generate_reply(input()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXKM4uLM2gOO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AWSW_GPT-Neo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "062ae380bf694354b24baaff72d10c4a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5a5fe877ce2b4ffc83315b247c3b1b99",
       "placeholder": "​",
       "style": "IPY_MODEL_69326db63df745d0b96604410fe5d606",
       "value": "100%"
      }
     },
     "2242da906f8745c781b1bf8ddfc583a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7fb92fc9d89a46c186c8793a2729cef9",
       "placeholder": "​",
       "style": "IPY_MODEL_4979266ac8d14185a1a6ca53109ca2f7",
       "value": " 2/2 [00:00&lt;00:00, 94.26it/s]"
      }
     },
     "3c033f7283f34fb3b41cabc9c52dd290": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4979266ac8d14185a1a6ca53109ca2f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "54a76f86e7034244a5092ba7041b3010": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a5fe877ce2b4ffc83315b247c3b1b99": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "69326db63df745d0b96604410fe5d606": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7fb92fc9d89a46c186c8793a2729cef9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e1256b21619b4666990d7050dd036c19": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e1e91ceb85f24475b27b7449bb941929": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_54a76f86e7034244a5092ba7041b3010",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e1256b21619b4666990d7050dd036c19",
       "value": 2.0
      }
     },
     "fa31ee10bcc442a59a6709b8cfc3a563": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_062ae380bf694354b24baaff72d10c4a",
        "IPY_MODEL_e1e91ceb85f24475b27b7449bb941929",
        "IPY_MODEL_2242da906f8745c781b1bf8ddfc583a4"
       ],
       "layout": "IPY_MODEL_3c033f7283f34fb3b41cabc9c52dd290"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
