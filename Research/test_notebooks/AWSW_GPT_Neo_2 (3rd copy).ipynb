{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-11-15T00:37:39.959234Z",
     "iopub.status.busy": "2021-11-15T00:37:39.958598Z",
     "iopub.status.idle": "2021-11-15T00:37:40.161321Z",
     "shell.execute_reply": "2021-11-15T00:37:40.160734Z"
    },
    "id": "2TJ-BqFtQ86M",
    "outputId": "f41c5626-6827-4d90-f0a9-8a11c01a366d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 15 00:37:40 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.63.01    Driver Version: 470.63.01    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| N/A   57C    P3    38W /  N/A |    848MiB / 16125MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-11-15T00:37:40.165856Z",
     "iopub.status.busy": "2021-11-15T00:37:40.165295Z",
     "iopub.status.idle": "2021-11-15T00:37:41.954860Z",
     "shell.execute_reply": "2021-11-15T00:37:41.954368Z"
    },
    "id": "oR9S63qiQt2b",
    "outputId": "b1303393-4c18-4510-da76-59e5f2590db8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/awsw-dev/.local/lib/python3.8/site-packages (4.12.3)\r\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (1.15.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/awsw-dev/.local/lib/python3.8/site-packages (from transformers) (0.1.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2021.8.28)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.0.12)\r\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers) (0.0.45)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.26.0)\r\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.10.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.62.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (5.4.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.0)\r\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.4)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (2.0.2)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.2)\r\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.12.2)\r\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.0)\r\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (5.0.0)\r\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2021.8.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\r\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.0.1)\r\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (8.0.1)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.16.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2021.5.30)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.2)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.6)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (2.4.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2021.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.7.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (21.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.2.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (5.2.0)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T00:37:41.961570Z",
     "iopub.status.busy": "2021-11-15T00:37:41.961035Z",
     "iopub.status.idle": "2021-11-15T00:37:43.364122Z",
     "shell.execute_reply": "2021-11-15T00:37:43.363725Z"
    },
    "id": "GhhigZYMRK6N"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "from random import randrange\n",
    "import multiprocessing\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config, GPT2LMHeadModel, GPTNeoForCausalLM\n",
    "from transformers import AdamW, get_cosine_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup, get_polynomial_decay_schedule_with_warmup\n",
    "from transformers import Trainer, TrainingArguments, TrainerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T00:37:43.369141Z",
     "iopub.status.busy": "2021-11-15T00:37:43.368710Z",
     "iopub.status.idle": "2021-11-15T00:37:43.370240Z",
     "shell.execute_reply": "2021-11-15T00:37:43.370562Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '9994' # modify if RuntimeError: Address already in use\n",
    "os.environ['RANK'] = \"0\"\n",
    "os.environ['LOCAL_RANK'] = \"0\"\n",
    "os.environ['WORLD_SIZE'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-11-15T00:37:43.393625Z",
     "iopub.status.busy": "2021-11-15T00:37:43.393142Z",
     "iopub.status.idle": "2021-11-15T00:37:43.394677Z",
     "shell.execute_reply": "2021-11-15T00:37:43.394953Z"
    },
    "id": "MTduRlf-RQJa",
    "outputId": "296dba31-0af6-422c-eea8-f5c1130a5daf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use cuda:0 for training with seed: 651582961\n"
     ]
    }
   ],
   "source": [
    "seed = random.randint(0, 2 ** 32 - 1)\n",
    "random.seed(seed)\n",
    "block_size = 64\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(f\"Will use {device_name} for training with seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278,
     "referenced_widgets": [
      "641f6e8a671d4dfe9da34c7685520767",
      "c7eb14f1388e42f29fbac8eef195fede",
      "40b7d134ba7b40299f6bd16b1e781d09",
      "13e5a9ab53bc4e1d8c3c7905ebd05ddf",
      "bc3c9b957d93490c8f9773e7050fd4ef",
      "e702472021334098b47210f9f1395f21",
      "8ed62e486a664d1f83fee6f21cb4585d",
      "ad42520b822e4454947f5d466424c8ca",
      "917d4196cdd14970b7965652f3b950a2",
      "3d72f5178e404d8c948ef13fc81a2bb8",
      "0ae32803eeaf436ab66cb3da9ff5439d",
      "5f28c40531fc4f43b4b62fd04912100c",
      "3c7dd63eb62d44598666166a87c0ff88",
      "7ed9d2386d57488c890d1ec712d1bef0",
      "da3c1240d6a94f3c9ff9ec0545675446",
      "cc7c2ac1006b4b109f302d7d26e3a578",
      "9bb4dcdb6f434d8b8cc95ef80f2ffe00",
      "5af83a55a73b4f3481a7559951ebdf08",
      "c4384ee96a1a4ae4bc8b46fa640b9058",
      "5f2bf3aebfd64baf94df39964208af4c",
      "307da63f10ad4ae5ae5e7e387d176d39",
      "8a282a2414874cb588a386e1444951dd",
      "659e0ad7f39c4cdbbdc1345c07a2e3f4",
      "1481fbbc74544c4888c0d6f88d8b3c9d",
      "54b833977b424c25a690d1bfe5d8c3f1",
      "8bfab1db231a4ff1975775f81f8a84f1",
      "3af5019cfacf4afc8a15a14d9a121ea8",
      "0ac398931b04418cbd3d227b9c634883",
      "7789164b5ee245b3a537d9d61dae038f",
      "8abd99000df0453e86bc458be29a10c7",
      "7db95c969d94465aaffbe9139f0f2a90",
      "d21de377e9074df083556c68e7d7cdbb",
      "3a0ada2f620a40aaa6c33fcea7a0bb91",
      "38bc8c5a2a3447e7942e2058c35d5e5b",
      "79170285a49a450494f0bfbe6cb4788e",
      "9813f2bda5ce4ab6887683fe63d0629e",
      "5c6ca36359bb4a1982c599f6a3f23b9f",
      "6e2cfa054082449e942297afd2f50f73",
      "5f3133f5c7254c248dad8e75534ea920",
      "eef06f8bc02749f4b04af47d92eb91b2",
      "2c60d924ee7b4fad984e2072973c3af3",
      "c1132ffe6c684c7ebeb3f285a101536b",
      "aa2a21546de1463f88a7feb8b697f9d3",
      "0abba2f64b4a43abadb38d461a5c7f42",
      "f43e9d4fa52c48c087ffeef399bfbed6",
      "4f1eafd9553b4bd5b396bba8f3896a22",
      "bbd5e6b14d864c1eb6a4d9c4247fb520",
      "29b2e68155a947e0aca0760c7e8e4afa",
      "fa1b29c48993478f9c2be4877ec675fc",
      "e4a6b2af572e44eda537e74847c58709",
      "8110f29e7b134607b38b29fad32ab1a1",
      "470ba5ce89ee4927a9be685adbc08675",
      "d10fbe074d4b42c9a8a6522252ef016f",
      "5af59ca6be4a427c8f83a906bbb6ce93",
      "17c9592d03324c4797abc812044e7500",
      "f6153c2ce07b4f4097a2a0486fb896ac",
      "3daedb3b85264408a8821ee2e480b356",
      "b2ce0d43567b4cc09e1f5571ee25263c",
      "c3a28b9889cd40e2ac0b9860e7f3932b",
      "99e992b8d4564ddd9c7634ac7663053a",
      "ae627a7820d4450a97b47d63dd5fbd92",
      "56a8c3c144404bd793e29a023032a09f",
      "2a9348d6cd674898ac4c9a303a254f26",
      "bafebeb0fba04d148ae3adf44171e0fe",
      "a8e19067a3ad411cad1aba489d390516",
      "6cf4e15a56fc4ac188609b806f11afcd"
     ]
    },
    "execution": {
     "iopub.execute_input": "2021-11-15T00:37:43.405395Z",
     "iopub.status.busy": "2021-11-15T00:37:43.401987Z",
     "iopub.status.idle": "2021-11-15T00:37:52.933377Z",
     "shell.execute_reply": "2021-11-15T00:37:52.932817Z"
    },
    "id": "QSVYD7o_eL2o",
    "outputId": "4f570825-b314-421b-b1ee-07449f7787f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading empty, pre-trained model with 160 parameters.\n",
      "Model attached to cuda:0\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(\"/opt/awsw\"):\n",
    "  # In case we run this locally (in Docker)\n",
    "  work_dir = os.path.join(\"/opt\", \"awsw\")\n",
    "else:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  work_dir = os.path.join(\"/content\", \"drive\", \"MyDrive\", \"endless_awsw\")\n",
    "\n",
    "models_dir = os.path.join(work_dir, \"models_4\")\n",
    "\n",
    "if not os.path.isdir(models_dir):\n",
    "    pathlib.Path(models_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "tokenizer = GPT2Tokenizer.from_pretrained('EleutherAI/gpt-neo-125M', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n",
    "model = GPTNeoForCausalLM.from_pretrained('EleutherAI/gpt-neo-125M', pad_token_id = tokenizer.pad_token_id, bos_token_id=tokenizer.bos_token_id, eos_token_id=tokenizer.eos_token_id)\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained('EleutherAI/gpt-neo-1.3B', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n",
    "#model = GPTNeoForCausalLM.from_pretrained('EleutherAI/gpt-neo-1.3B', pad_token_id = tokenizer.pad_token_id, bos_token_id=tokenizer.bos_token_id, eos_token_id=tokenizer.eos_token_id)\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n",
    "#model = GPT2LMHeadModel.from_pretrained('distilgpt2', pad_token_id = tokenizer.pad_token_id, bos_token_id=tokenizer.bos_token_id, eos_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "named_parameters = list(model.named_parameters())\n",
    "\n",
    "# Freeze a part\n",
    "for name, param in named_parameters[:-30]:\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.config.attention_dropout = 0.01\n",
    "model.config.embed_dropout = 0.01\n",
    "print(f\"Loading empty, pre-trained model with {len(named_parameters)} parameters.\")\n",
    "\n",
    "model.to(device)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(f\"Model attached to {device_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMEavxJ32gOH"
   },
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-11-15T00:37:52.944721Z",
     "iopub.status.busy": "2021-11-15T00:37:52.944229Z",
     "iopub.status.idle": "2021-11-15T00:37:53.039007Z",
     "shell.execute_reply": "2021-11-15T00:37:53.038570Z"
    },
    "id": "OzWBTuEj2gOJ",
    "outputId": "0668db46-b7fd-4806-e90e-a898d2a6b77b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_lines: \n",
      "train_lines: PlayerReply c \"Hey, Remy!\" DragonReply Ry \"Hello, [player_name].\"\n",
      "PlayerReply c \"Is there any particular reason why you wanted to meet here?\" DragonReply Ry \"I enjoy Tatsu Park is all. Have you been here before?\"\n",
      "PlayerReply c \"Can't say I have.\" PlayerReply c \"A few times.\" PlayerReply c \"Once or twice.\" DragonReply Ry \"I see.\" DragonReply Ry \"Well, what do you think of it?\"\n",
      "PlayerReply c \"It's pretty idyllic.\" DragonReply Ry smile \"It is. I like it a lot here.\"\n",
      "PlayerReply c \"It's pretty romantic.\" DragonReply Ry shy \"You think so?\"\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(work_dir, \"awsw_story_input.txt\")) as f:\n",
    "    data = f.read()\n",
    "lines = data.split(\"\\n\")\n",
    "player_dragon_pairs = {}\n",
    "last_player_talk = []\n",
    "closed_player_talk = False\n",
    "re_player_talk = re.compile(r'c \"(.*?)\"')\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    line_split = line.split(\" \")\n",
    "    if len(line_split) <= 1:\n",
    "        continue\n",
    "    \n",
    "    if line_split[0] == \"c\":\n",
    "        if closed_player_talk:\n",
    "            closed_player_talk = False\n",
    "            last_player_talk = []\n",
    "        last_player_talk.append(re.sub(re_player_talk, r\"\\1\", line))\n",
    "    else:\n",
    "        if not closed_player_talk:\n",
    "            last_player_talk = json.dumps(last_player_talk)\n",
    "            if not last_player_talk in player_dragon_pairs:\n",
    "                player_dragon_pairs[last_player_talk] = []\n",
    "            closed_player_talk = True\n",
    "            \n",
    "        line = \"DragonReply \" + line\n",
    "        if last_player_talk is not None:\n",
    "            player_dragon_pairs[last_player_talk].append(line)\n",
    "    \n",
    "train_lines = []\n",
    "eval_lines = []\n",
    "eval_per_character = 0\n",
    "\n",
    "for player_line_str in player_dragon_pairs.keys():\n",
    "    player_lines = json.loads(player_line_str)\n",
    "    dragon_lines = player_dragon_pairs[player_line_str]\n",
    "    compiled_line = \" \".join([f'PlayerReply c \"{player_line}\"' for player_line in player_lines]) + \" \" + \" \".join(dragon_lines)\n",
    "    train_lines.append(compiled_line)\n",
    "    \n",
    "test_bucket = {}\n",
    "for l in train_lines:\n",
    "    l_split = l.split(\" \")\n",
    "    character = None\n",
    "    for i, ls in enumerate(l_split):\n",
    "        if ls == \"DragonReply\":\n",
    "            character = l_split[i + 1]\n",
    "            break\n",
    "    if not character in test_bucket:\n",
    "        test_bucket[character] = []\n",
    "    test_bucket[character].append(l)\n",
    "    \n",
    "for i in range(eval_per_character):\n",
    "    for character in test_bucket.keys():\n",
    "        random_line = test_bucket[character][randrange(len(test_bucket[character]))]\n",
    "        eval_lines.append(random_line)\n",
    "        for i2, t in enumerate(train_lines):\n",
    "            if t == random_line:\n",
    "                del train_lines[i2]\n",
    "                break\n",
    "    \n",
    "joined_eval_lines = \"\\n\".join(eval_lines[:5])\n",
    "print(f\"eval_lines: {joined_eval_lines}\")\n",
    "joined_train_lines = \"\\n\".join(train_lines[:5])\n",
    "print(f\"train_lines: {joined_train_lines}\")\n",
    "\n",
    "random.shuffle(train_lines)\n",
    "\n",
    "if not os.path.isfile(os.path.join(work_dir, \"data_train.txt\")):\n",
    "    with open(os.path.join(work_dir, \"data_train.txt\"), \"w\") as f:\n",
    "        for l in train_lines:\n",
    "            f.write(l + \"\\n\")\n",
    "            \n",
    "if not os.path.isfile(os.path.join(work_dir, \"data_test.txt\")):\n",
    "    with open(os.path.join(work_dir, \"data_test.txt\"), \"w\") as f:\n",
    "        for l in eval_lines:\n",
    "            f.write(l + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220,
     "referenced_widgets": [
      "a04e889a56e94ce9812a0e7d89d4d4f4",
      "3c2d0014295e47f9a07de8d4e36e7ba4",
      "76286c1e442541e0a6cb2d7cbbc9cc8f",
      "dcad41ec160e448b83d85c907a48facb",
      "27f2d980cb774902a82c0ad2545f549a",
      "131ce893dc784733b42f384b419145db",
      "607ee5c0b54042f3919d0588d66e31c1",
      "b2373342cb4942569088a5b20186795a",
      "11475ac58a594c6db1641401b1cc0d13",
      "f6625c167f7b4aa4bbecf2129e07c068",
      "ef9e25d7100e4e9ba064e938bd8157ea",
      "7bb369ca60f94acc99a4ee8e8f8fd261",
      "bc20a41ccda14aeeb72014b80a5ec53a",
      "c6ff5b9114424dbfafcbc3b3ab887af5",
      "1153397efee1426cac848341c0b88785",
      "37672ae801de4f42a9f6f49cc33fb88e",
      "8528f9fbbc504a44b9670a760256192d",
      "406b2f47896446a187725d4a1aa926f8",
      "cb33a87e718546f3a33b7deea817de56",
      "eeb54e278e184bc5aabf0283f1b276ff",
      "809a3780924641b8ace57e9141b0167f",
      "b805525a58804750ae56dad7e43ecb0e",
      "906b9daf9437432c81546f35256c7232",
      "0ce77d162a014a2fa17628ef8fe20846",
      "3fed2802cbab4a90a5b3d5a8c9bc8974",
      "a146d5c5588944368242c519984cbccc",
      "28d30b2eecf04ae6835cf4c35648dcfc",
      "65c48ca18ea14cf9bccbaa2495c2f120",
      "5067025a37bb42318ae93216b3205b17",
      "d18658b25f6f47778b984d0bf35be999",
      "6ade1603ab664b9f9d5ce44014bc5305",
      "fd91a671eeb7431d90d86b44beb276bd",
      "df0a544035814e1ca11d6191c10a5b62",
      "23a62f16d8de4f3ab9fa64ada07d1e35",
      "d50f5db4d1a1430caecace0510c1a24e",
      "d36395d1dcad4ead98f7f4756b8dbd37",
      "2cf737292a8343f5965c3eb0ace01875",
      "9ba5d1e5fab74947a328842b5105a28e",
      "073bc138772048729e04017123149e80",
      "ab0ce277776d4d218bf97fff5acc8e28",
      "b404b600842a4fc4b2b66c6b015235d6",
      "06dd02ec048945e5bf6b17d2b5558fb2",
      "437e050108fd46e1ba0f35674fa7314f",
      "a5725e8dc8104756bcba16b2c886a27f",
      "a31733df07ed4bb485d518b64634acfb",
      "1a2fe039b81a42c496ba363b2000bc41",
      "3f271f4469cf4796b92a78eba64c30b3",
      "fd200bcd96354e36b32ca82660eb0ef2",
      "33f9747c1f474c1790c7c293c853fad5",
      "e10acb8e2c8240409a19c61499576afd",
      "cc3c5e1ef5974710a06c1eab3d90cfb1",
      "6eda966317484df2a47fa0c4f2a0370c",
      "0cd6ff104b484203adda9e8414fd80fa",
      "c5a11599f37c4077a4ab0daec124a78c",
      "6cd8593a13f54c138c9adf5ec85f2d97"
     ]
    },
    "execution": {
     "iopub.execute_input": "2021-11-15T00:37:53.055171Z",
     "iopub.status.busy": "2021-11-15T00:37:53.054623Z",
     "iopub.status.idle": "2021-11-15T00:38:10.167727Z",
     "shell.execute_reply": "2021-11-15T00:38:10.167248Z"
    },
    "id": "pWeL2qWd2gOK",
    "outputId": "efdd650f-d95e-47a9-ad2f-396593bb779e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725cba957cbb4fc585dce57cae3d9b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('text', data_files={'train': os.path.join(work_dir, \"data_train.txt\"), 'test': os.path.join(work_dir, \"data_test.txt\")})\n",
    "\n",
    "class AWSWDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, dataset, dataset_type, do_shuffle=False):\n",
    "        self.current_dataset = dataset\n",
    "        self.dataset_type = dataset_type\n",
    "        self.do_shuffle = do_shuffle\n",
    "        self.shuffled_datasets = []\n",
    "        self.current_idx = 0\n",
    "        for i in range(1):\n",
    "            self.current_dataset = self.current_dataset.shuffle()\n",
    "            mapped_dataset = self.current_dataset.map(\n",
    "                group_texts,\n",
    "                batched=True,\n",
    "                batch_size=dataset_batch_size,\n",
    "                num_proc=dataset_map_cores\n",
    "            )\n",
    "            self.shuffled_datasets.append(mapped_dataset)\n",
    "        \n",
    "    def approx_len(self):\n",
    "        return len(self.shuffled_datasets[0][self.dataset_type])\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.current_idx = (self.current_idx + 1) % len(self.shuffled_datasets)\n",
    "        return iter(self.shuffled_datasets[self.current_idx][self.dataset_type])\n",
    "    \n",
    "def encode(batch):\n",
    "    result = []\n",
    "    attention_mask = []\n",
    "    for item in batch['text']:\n",
    "        #tokens = [tokenizer.bos_token_id] + tokenizer.encode(item) + [tokenizer.eos_token_id]\n",
    "        #tokens = tokenizer.encode(item)\n",
    "        tokens = tokenizer.encode(item) + [tokenizer.eos_token_id]\n",
    "        result.append(tokens)\n",
    "        attention_mask.append([1] * len(tokens))\n",
    "    return {\n",
    "        'attention_mask': attention_mask,\n",
    "        'input_ids': result\n",
    "    }\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    #random_shift = random.randint(0, 64)\n",
    "    #concatenated_examples['input_ids'] = concatenated_examples['input_ids'][random_shift:]\n",
    "    #concatenated_examples['attention_mask'] = concatenated_examples['attention_mask'][random_shift:]\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # Pad the end\n",
    "    to_add = (math.ceil(total_length / block_size) * block_size) - total_length\n",
    "    if to_add > 0:\n",
    "        concatenated_examples['input_ids'] += [tokenizer.pad_token_id] * to_add\n",
    "        concatenated_examples['attention_mask'] += [0] * to_add\n",
    "        total_length += to_add\n",
    "    # Split by chunks of block_size.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "def map_dragon_reply_text(batch):\n",
    "    result = {'text': []}\n",
    "    for item in batch['text']:\n",
    "        item_split = item.split(\" \")\n",
    "        player_replies = []\n",
    "        dragon_replies = []\n",
    "        current_reply = []\n",
    "        handling_reply = None\n",
    "        for token in item_split:\n",
    "            if token == \"PlayerReply\":\n",
    "                if handling_reply is None:\n",
    "                    handling_reply = \"PlayerReply\"\n",
    "                else:\n",
    "                    if handling_reply == \"PlayerReply\":\n",
    "                        # We need to store the PlayerReply\n",
    "                        player_replies.append(\" \".join(current_reply))\n",
    "                        current_reply = []\n",
    "            elif token == \"DragonReply\":\n",
    "                if handling_reply == \"DragonReply\":\n",
    "                    # We need to store the DragonReply\n",
    "                    dragon_replies.append(\" \".join(current_reply))\n",
    "                    current_reply = []\n",
    "                    \n",
    "                if handling_reply == \"PlayerReply\":\n",
    "                    # We need to store the PlayerReply\n",
    "                    player_replies.append(\" \".join(current_reply))\n",
    "                    current_reply = []\n",
    "                    \n",
    "                handling_reply = \"DragonReply\"\n",
    "                current_reply = []\n",
    "                    \n",
    "            if handling_reply is not None:\n",
    "                current_reply.append(token)\n",
    "                \n",
    "        # There's always a dragon reply at the end.\n",
    "        dragon_replies.append(\" \".join(current_reply))\n",
    "        for player_idx in range(len(player_replies)):\n",
    "            for dragon_idx in range(len(dragon_replies)):\n",
    "                result['text'].append(player_replies[player_idx] + \" \" + dragon_replies[dragon_idx])\n",
    "                \n",
    "    return result\n",
    "\n",
    "dataset_map_cores = min(multiprocessing.cpu_count(), 10)\n",
    "dataset_batch_size = 1000\n",
    "\n",
    "dataset = dataset.map(\n",
    "    map_dragon_reply_text,\n",
    "    batched=True,\n",
    "    batch_size=dataset_batch_size,\n",
    "    num_proc=dataset_map_cores\n",
    ")\n",
    "\n",
    "dataset = dataset.map(\n",
    "    encode,\n",
    "    batched=True,\n",
    "    batch_size=dataset_batch_size,\n",
    "    remove_columns=[\"text\"],\n",
    "    num_proc=dataset_map_cores\n",
    ")\n",
    "\n",
    "dataset = dataset.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=dataset_batch_size,\n",
    "    num_proc=dataset_map_cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-11-15T00:38:10.173745Z",
     "iopub.status.busy": "2021-11-15T00:38:10.173253Z",
     "iopub.status.idle": "2021-11-15T00:38:10.176135Z",
     "shell.execute_reply": "2021-11-15T00:38:10.175601Z"
    },
    "id": "PhiZIfn02gOL",
    "outputId": "47e5768d-8b9d-4ea8-c5ac-cc392abba402"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_len: 8658 num_training_steps: 136 num_total_steps: 13600\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_len = len(dataset['train'])\n",
    "num_training_steps = math.ceil(train_len / batch_size)\n",
    "num_epoch = 100\n",
    "num_total_steps = num_training_steps * num_epoch\n",
    "num_warmup_steps = num_training_steps * 2\n",
    "print(f\"train_len: {train_len} num_training_steps: {num_training_steps} num_total_steps: {num_total_steps}\")\n",
    "def get_optimizer_and_scheduler(params):\n",
    "    optimizer = AdamW(params, lr=0.001)\n",
    "    #scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_total_steps)\n",
    "    #scheduler = get_polynomial_decay_schedule_with_warmup(optimizer, num_warmup_steps, num_total_steps, power=0.5, lr_end=1e-10)\n",
    "    scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, num_warmup_steps, num_total_steps, 4)\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T00:38:10.181193Z",
     "iopub.status.busy": "2021-11-15T00:38:10.180607Z",
     "iopub.status.idle": "2021-11-15T00:38:10.532227Z",
     "shell.execute_reply": "2021-11-15T00:38:10.532555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrs = []\n",
    "optimizer, scheduler = get_optimizer_and_scheduler([torch.tensor(0.1)])\n",
    "for i in range(num_total_steps):\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "plt.plot(lrs)\n",
    "plt.show()\n",
    "del lrs\n",
    "del optimizer\n",
    "del scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T00:38:10.609416Z",
     "iopub.status.busy": "2021-11-15T00:38:10.537304Z",
     "iopub.status.idle": "2021-11-15T00:38:10.690405Z",
     "shell.execute_reply": "2021-11-15T00:38:10.689816Z"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat <<'EOT' > ds_config_zero3.json\n",
    "{\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": \"auto\",\n",
    "            \"warmup_max_lr\": \"auto\",\n",
    "            \"warmup_num_steps\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 3,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": true\n",
    "        },\n",
    "        \"offload_param\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": true\n",
    "        },\n",
    "        \"overlap_comm\": true,\n",
    "        \"contiguous_gradients\": true,\n",
    "        \"sub_group_size\": 1e9,\n",
    "        \"reduce_bucket_size\": \"auto\",\n",
    "        \"stage3_prefetch_bucket_size\": \"auto\",\n",
    "        \"stage3_param_persistence_threshold\": \"auto\",\n",
    "        \"stage3_max_live_parameters\": 1e9,\n",
    "        \"stage3_max_reuse_distance\": 1e9,\n",
    "        \"stage3_gather_fp16_weights_on_model_save\": true\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 2000,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": false\n",
    "}\n",
    "EOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "execution": {
     "iopub.execute_input": "2021-11-15T00:38:10.698324Z",
     "iopub.status.busy": "2021-11-15T00:38:10.697757Z",
     "iopub.status.idle": "2021-11-15T01:48:46.693148Z",
     "shell.execute_reply": "2021-11-15T01:48:46.693515Z"
    },
    "id": "AdPIW0xSTpRY",
    "outputId": "01338ca7-7ed2-4d8e-dd7b-5c235e4c5e30"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 8658\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13600' max='13600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13600/13600 1:10:35, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.219000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.206100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.838400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.564100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.351200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.249200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.196500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.159300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.143600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.111700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.108500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.232800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.529800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>6.130800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>6.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>6.173100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>6.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>5.878800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>5.751900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5750</td>\n",
       "      <td>5.649300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>5.580100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6250</td>\n",
       "      <td>5.529900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>5.491600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6750</td>\n",
       "      <td>5.476700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>5.523300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7250</td>\n",
       "      <td>5.474500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>5.231400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7750</td>\n",
       "      <td>5.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>4.898300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8250</td>\n",
       "      <td>4.782100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>4.664100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8750</td>\n",
       "      <td>4.561300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>4.470200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9250</td>\n",
       "      <td>4.392100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>4.333000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9750</td>\n",
       "      <td>4.292000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>4.260500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10250</td>\n",
       "      <td>4.241400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>4.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10750</td>\n",
       "      <td>4.275500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>4.167600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11250</td>\n",
       "      <td>4.062100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>3.960300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11750</td>\n",
       "      <td>3.867700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>3.767600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12250</td>\n",
       "      <td>3.678800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>3.585500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12750</td>\n",
       "      <td>3.511500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>3.454400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13250</td>\n",
       "      <td>3.407600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>3.379200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-500\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-500/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-1000\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-1000/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-1500\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-1500/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-1500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-2000\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-2000/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-2000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-2500\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-2500/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-2500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-3000\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-3000/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-3000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-3500\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-3500/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-3500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-4000\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-4000/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-4000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-4500\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-4500/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-4500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-3500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-5000\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-5000/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-5000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-5500\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-5500/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-5500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-4500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-6000\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-6000/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-6000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-6500\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-6500/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-6500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-5500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-7000\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-7000/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-7000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-7500\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-7500/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-7500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-6500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-8000\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-8000/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-8000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-8500\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-8500/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-8500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-7500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-9000\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-9000/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-9000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-9500\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-9500/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-9500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-8500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-10000\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-10000/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-10000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-10500\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-10500/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-10500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-9500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-11000\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-11000/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-11000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-10000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-11500\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-11500/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-11500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-10500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-12000\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-12000/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-12000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-11000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-12500\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-12500/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-12500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-11500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-13000\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-13000/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-13000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-12000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models_4/checkpoint-13500\n",
      "Configuration saved in /opt/awsw/models_4/checkpoint-13500/config.json\n",
      "Model weights saved in /opt/awsw/models_4/checkpoint-13500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models_4/checkpoint-12500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class AWSWTrainer(Trainer):\n",
    "    def _get_train_sampler(self):\n",
    "        return None\n",
    "    \n",
    "class AWSWTrainerCallback(TrainerCallback):\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        learning_rate_history = [h['learning_rate'] for h in state.log_history if 'loss' in h]\n",
    "        loss_history = [h['loss'] for h in state.log_history if 'loss' in h]\n",
    "        fig, axs = plt.subplots(2)\n",
    "        fig.suptitle('Learning rate and loss')\n",
    "        axs[0].plot(learning_rate_history)\n",
    "        axs[1].plot(loss_history)\n",
    "        \n",
    "def train(model):\n",
    "    optimizer, scheduler = get_optimizer_and_scheduler(model.parameters())\n",
    "    training_args = TrainingArguments(\n",
    "        models_dir,\n",
    "        seed=seed,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=num_epoch,\n",
    "        save_total_limit=2,\n",
    "        save_steps=500,\n",
    "        logging_steps=250,\n",
    "        ddp_find_unused_parameters=False,\n",
    "        #deepspeed=\"ds_config_zero3.json\"\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model, \n",
    "        args=training_args, \n",
    "        train_dataset=dataset['train'],\n",
    "        optimizers=(optimizer, scheduler),\n",
    "        callbacks=[AWSWTrainerCallback]\n",
    "    )\n",
    "    checkpoint_dirs = [os.path.join(models_dir, d) for d in os.listdir(models_dir) if os.path.isdir(os.path.join(models_dir, d))]\n",
    "    if len(checkpoint_dirs) > 0:\n",
    "        latest_checkpoint = max(checkpoint_dirs, key=os.path.getmtime)\n",
    "        trainer.train(latest_checkpoint)\n",
    "    else:\n",
    "        trainer.train()\n",
    "\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unxN7nYd2gOM",
    "tags": []
   },
   "source": [
    "# Testing\n",
    "\n",
    "We created a few past (for context) + present prompts (player input) and see the different reactions. This way, we can test the models across different iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T01:48:46.701303Z",
     "iopub.status.busy": "2021-11-15T01:48:46.700341Z",
     "iopub.status.idle": "2021-11-15T01:48:47.384063Z",
     "shell.execute_reply": "2021-11-15T01:48:47.383607Z"
    },
    "id": "5UePGmLD2gON"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure you're.\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure you can really do, I'll see the warmth I'd be able to do you can't\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was a few seconds, but I was a few stacks of the portal, I was just know what I was a good, I was a\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: Br \"I'm not sure it's not sure it.\"<|endoftext|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_dragon_reply(past, prompt, top_k=None, top_p=None):\n",
    "    model.eval()\n",
    "    prompt = f'{past} PlayerReply c \"{prompt}\" DragonReply'\n",
    "    generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "    generated = generated.to(device)\n",
    "\n",
    "    sample_outputs = model.generate(\n",
    "        generated, \n",
    "        do_sample=(top_k is not None and top_p is not None),\n",
    "        top_p=top_p,\n",
    "        top_k=top_k,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        max_length=block_size,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    return tokenizer.decode(sample_outputs[0], skip_special_tokens=False)[len(prompt):].strip()\n",
    "\n",
    "prompts = [\n",
    "    ('PlayerReply c \"Hey Remy!\" DragonReply Ry \"Hey!\"', \"How are you?\"),\n",
    "    ('PlayerReply c \"I was with Lorem today.\" DragonReply Ad \"That\\'s awesome. He\\'s a cute fellow.\"', \"What do you think of Lorem?\"),\n",
    "    ('DragonReply m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('DragonReply m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "# Set a fixed seed to make sure we get the same response every time.\n",
    "torch.manual_seed(80085)\n",
    "for (past, prompt) in prompts:\n",
    "    reply = generate_dragon_reply(past, prompt)\n",
    "    print(f\"Prompt: {prompt}\\nReply: {reply}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OZarUHg2gON"
   },
   "source": [
    "# Sampling test\n",
    "\n",
    "Which combination is the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T01:48:47.390111Z",
     "iopub.status.busy": "2021-11-15T01:48:47.389592Z",
     "iopub.status.idle": "2021-11-15T01:49:56.627891Z",
     "shell.execute_reply": "2021-11-15T01:49:56.627475Z"
    },
    "id": "bWoLzL9B2gON"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test 1 top_k: 17, top_p: 0.52] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options, I'll have to be, I have to get it.\"<|endoftext|>\n",
      "\n",
      "[Test 1 top_k: 17, top_p: 0.52] -> Prompt: What do you think of Lorem?\n",
      "Reply: Br \"Well, I was, it's not a lot of the portal, I can't want to do, but I\n",
      "\n",
      "[Test 1 top_k: 17, top_p: 0.52] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m of our council's not it's just be all the time.\"<|endoftext|>\n",
      "\n",
      "[Test 1 top_k: 17, top_p: 0.52] -> Prompt: What will we do here?\n",
      "Reply: Ad \"I don't need to get.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 2 top_k: 39, top_p: 0.62] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about this one, then.\"<|endoftext|>\n",
      "\n",
      "[Test 2 top_k: 39, top_p: 0.62] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I can't get the message to do.\"<|endoftext|>\n",
      "\n",
      "[Test 2 top_k: 39, top_p: 0.62] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m't know the sphere for that's still could come of the land seemed of you could already do you might to go. What it's just in the\n",
      "\n",
      "[Test 2 top_k: 39, top_p: 0.62] -> Prompt: What will we do here?\n",
      "Reply: Br \"I was the police you had was to get of the best of the same, I was a different as far, it was the portal, but I was a bit as it\n",
      "\n",
      "-------------\n",
      "[Test 3 top_k: 38, top_p: 0.45] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options, I'll have to be, I have to get it.\"<|endoftext|>\n",
      "\n",
      "[Test 3 top_k: 38, top_p: 0.45] -> Prompt: What do you think of Lorem?\n",
      "Reply: Br \"Well, I was already, but I don't just a lot, I'm't know you'll see the portal\n",
      "\n",
      "[Test 3 top_k: 38, top_p: 0.45] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m of our council is the portal, I'm not be walking, I'm just as I was a number of the portal. The waited for the effects\n",
      "\n",
      "[Test 3 top_k: 38, top_p: 0.45] -> Prompt: What will we do here?\n",
      "Reply: Ad \"I can say, I thought it.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 4 top_k: 48, top_p: 0.26] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options.\"<|endoftext|>\n",
      "\n",
      "[Test 4 top_k: 48, top_p: 0.26] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"After you know.\"<|endoftext|>\n",
      "\n",
      "[Test 4 top_k: 48, top_p: 0.26] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I guess the time.\"<|endoftext|>\n",
      "\n",
      "[Test 4 top_k: 48, top_p: 0.26] -> Prompt: What will we do here?\n",
      "Reply: Lo normal \"I see the time, I could still could have to do, but I could have to do that, I was a few of the portal, and I arrived.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 5 top_k: 31, top_p: 0.75] -> Prompt: How are you?\n",
      "Reply: Ad smile.\"<|endoftext|>\n",
      "\n",
      "[Test 5 top_k: 31, top_p: 0.75] -> Prompt: What do you think of Lorem?\n",
      "Reply: An \"I'm't even.\"<|endoftext|>\n",
      "\n",
      "[Test 5 top_k: 31, top_p: 0.75] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: n \"When we made it. After all to do you think you can come to make it's not the time of the middle of the effects to create\n",
      "\n",
      "[Test 5 top_k: 31, top_p: 0.75] -> Prompt: What will we do here?\n",
      "Reply: Ad \"It was going to her. I'd have a few seconds on the dragons.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 6 top_k: 18, top_p: 0.63] -> Prompt: How are you?\n",
      "Reply: Ad gPlayerReply Br \"I'm the beginning shy.\"<|endoftext|>\n",
      "\n",
      "[Test 6 top_k: 18, top_p: 0.63] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, it's pretty, I was just leave the warmth...\"<|endoftext|>\n",
      "\n",
      "[Test 6 top_k: 18, top_p: 0.63] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I'm just a lot, I can do you can you can just. That's not so the one for it's just.\"<|endoftext|>\n",
      "\n",
      "[Test 6 top_k: 18, top_p: 0.63] -> Prompt: What will we do here?\n",
      "Reply: Ad \"I'm a few seconds. It have been. You know.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 7 top_k: 93, top_p: 0.51] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about this one, then.\"<|endoftext|>\n",
      "\n",
      "[Test 7 top_k: 93, top_p: 0.51] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I can't get the message to do.\"<|endoftext|>\n",
      "\n",
      "[Test 7 top_k: 93, top_p: 0.51] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m't know the floor, I had a lot.\"<|endoftext|>\n",
      "\n",
      "[Test 7 top_k: 93, top_p: 0.51] -> Prompt: What will we do here?\n",
      "Reply: Lo normal \"I'm. You wish, and her. A one for it's just want, I think the way to make. It's going to their own.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 8 top_k: 19, top_p: 0.3] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure.\"<|endoftext|>\n",
      "\n",
      "[Test 8 top_k: 19, top_p: 0.3] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"After you know, I'll just leave.\"<|endoftext|>\n",
      "\n",
      "[Test 8 top_k: 19, top_p: 0.3] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I think you can really do you can't know you came to get the portal, but I could see you can be, but I could be\n",
      "\n",
      "[Test 8 top_k: 19, top_p: 0.3] -> Prompt: What will we do here?\n",
      "Reply: Lo normal \"I see's not sure the portal, I arrived it was a few stacks of the portal, but I was a few stacks of the portal, but I was a few\n",
      "\n",
      "-------------\n",
      "[Test 9 top_k: 18, top_p: 0.06] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure you're.\"<|endoftext|>\n",
      "\n",
      "[Test 9 top_k: 18, top_p: 0.06] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure you can really do, I'll see the warmth I'd be able to do you can't\n",
      "\n",
      "[Test 9 top_k: 18, top_p: 0.06] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was a few seconds, but I was a few stacks of the portal, I was just know what I was a good, I was a\n",
      "\n",
      "[Test 9 top_k: 18, top_p: 0.06] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm not sure it's not sure it.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 10 top_k: 13, top_p: 0.69] -> Prompt: How are you?\n",
      "Reply: Ad gPlayerReply An \"I'm't even.\"<|endoftext|>\n",
      "\n",
      "[Test 10 top_k: 13, top_p: 0.69] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I can't get the evil. I don't make, and you can't know that, I could\n",
      "\n",
      "[Test 10 top_k: 13, top_p: 0.69] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I'll see you could get my course.\"<|endoftext|>\n",
      "\n",
      "[Test 10 top_k: 13, top_p: 0.69] -> Prompt: What will we do here?\n",
      "Reply: Ry \"I guess, and the portal. I was still the end, I was a number of the one of the end, I was a number of the portal, I thought,\n",
      "\n",
      "-------------\n",
      "[Test 11 top_k: 4, top_p: 0.8] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options, I'm not it's not the end, and I was the room.\"<|endoftext|>\n",
      "\n",
      "[Test 11 top_k: 4, top_p: 0.8] -> Prompt: What do you think of Lorem?\n",
      "Reply: Lo think b \"It's going to do.\"<|endoftext|>\n",
      "\n",
      "[Test 11 top_k: 4, top_p: 0.8] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m \"I thought, but I'll see you can't want to get the portal. I can be a good.\"<|endoftext|>\n",
      "\n",
      "[Test 11 top_k: 4, top_p: 0.8] -> Prompt: What will we do here?\n",
      "Reply: Ad \"I can really, I'm not sure you're me, but I was a lot of time, but I'll see.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 12 top_k: 95, top_p: 0.31] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options, I'll have to be, I have to be able to do you're. I'm not it's just a bit, though, I'm the next entry to\n",
      "\n",
      "[Test 12 top_k: 95, top_p: 0.31] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure it.\"<|endoftext|>\n",
      "\n",
      "[Test 12 top_k: 95, top_p: 0.31] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m \"I didn't think you think the time.\"<|endoftext|>\n",
      "\n",
      "[Test 12 top_k: 95, top_p: 0.31] -> Prompt: What will we do here?\n",
      "Reply: Lo normal \"I'm to get the portal, I thought I could have been.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 13 top_k: 88, top_p: 0.98] -> Prompt: How are you?\n",
      "Reply: Rz.\"<|endoftext|>\n",
      "\n",
      "[Test 13 top_k: 88, top_p: 0.98] -> Prompt: What do you think of Lorem?\n",
      "Reply: An \"I've was a bit by set for we're, soon you even the time to do.\"<|endoftext|>\n",
      "\n",
      "[Test 13 top_k: 88, top_p: 0.98] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m't even you talking are at the fireworks you're leave up, but we waited us were gone.\"<|endoftext|>\n",
      "\n",
      "[Test 13 top_k: 88, top_p: 0.98] -> Prompt: What will we do here?\n",
      "Reply: n \"I was here, though, and livestock of the effects on the village. After after all technology and also still could've know every, but.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 14 top_k: 96, top_p: 0.57] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about this one, then.\"<|endoftext|>\n",
      "\n",
      "[Test 14 top_k: 96, top_p: 0.57] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I can't get the message to do.\"<|endoftext|>\n",
      "\n",
      "[Test 14 top_k: 96, top_p: 0.57] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m't know the floor, I had a lot.\"<|endoftext|>\n",
      "\n",
      "[Test 14 top_k: 96, top_p: 0.57] -> Prompt: What will we do here?\n",
      "Reply: Lo happy.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 15 top_k: 54, top_p: 0.39] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options, I'll have to be, I have to get it.\"<|endoftext|>\n",
      "\n",
      "[Test 15 top_k: 54, top_p: 0.39] -> Prompt: What do you think of Lorem?\n",
      "Reply: Br \"Well, I was already, but I don't just a lot, I'm't know you'll see the portal\n",
      "\n",
      "[Test 15 top_k: 54, top_p: 0.39] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m of our council is the portal, I'm not be walking, I'm just as I was a number of the portal. The waited for the effects\n",
      "\n",
      "[Test 15 top_k: 54, top_p: 0.39] -> Prompt: What will we do here?\n",
      "Reply: Br \"I watched the time. It was a few seconds. You know was a single tear, and it's just know.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 16 top_k: 34, top_p: 0.94] -> Prompt: How are you?\n",
      "Reply: Ad smile.\"<|endoftext|>\n",
      "\n",
      "[Test 16 top_k: 34, top_p: 0.94] -> Prompt: What do you think of Lorem?\n",
      "Reply: An \"I've was a bit by be much.\"<|endoftext|>\n",
      "\n",
      "[Test 16 top_k: 34, top_p: 0.94] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br laugh \"I walked on some more.\"<|endoftext|>\n",
      "\n",
      "[Test 16 top_k: 34, top_p: 0.94] -> Prompt: What will we do here?\n",
      "Reply: m \"But, and a whole that he wanted to think.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 17 top_k: 65, top_p: 0.04] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure you're.\"<|endoftext|>\n",
      "\n",
      "[Test 17 top_k: 65, top_p: 0.04] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure you can really do, I'll see the warmth I'd be able to do you can't\n",
      "\n",
      "[Test 17 top_k: 65, top_p: 0.04] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was a few seconds, but I was a few stacks of the portal, I was just know what I was a good, I was a\n",
      "\n",
      "[Test 17 top_k: 65, top_p: 0.04] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm not sure it's not sure it.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 18 top_k: 75, top_p: 0.33] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options, I'll have to be, I have to be able to do you're. I'm not it's just a bit, though, I'm the next, but\n",
      "\n",
      "[Test 18 top_k: 75, top_p: 0.33] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure it.\"<|endoftext|>\n",
      "\n",
      "[Test 18 top_k: 75, top_p: 0.33] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m \"I didn't really do that's just the same. That's not the way to make it's just a portal, but you have to get\n",
      "\n",
      "[Test 18 top_k: 75, top_p: 0.33] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm a lot of the portal, I can come up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 19 top_k: 81, top_p: 0.38] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about it's just a bit, then?\"<|endoftext|>\n",
      "\n",
      "[Test 19 top_k: 81, top_p: 0.38] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I'm't know you think \"I was the portal, it.\"<|endoftext|>\n",
      "\n",
      "[Test 19 top_k: 81, top_p: 0.38] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m of the day.\"<|endoftext|>\n",
      "\n",
      "[Test 19 top_k: 81, top_p: 0.38] -> Prompt: What will we do here?\n",
      "Reply: Br \"I see you're a few seconds. It was a few seconds, and I'll see.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 20 top_k: 30, top_p: 0.51] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about it's just a bit, then?\"<|endoftext|>\n",
      "\n",
      "[Test 20 top_k: 30, top_p: 0.51] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I'm't know you think \"I was the portal, it.\"<|endoftext|>\n",
      "\n",
      "[Test 20 top_k: 30, top_p: 0.51] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m of the day.\"<|endoftext|>\n",
      "\n",
      "[Test 20 top_k: 30, top_p: 0.51] -> Prompt: What will we do here?\n",
      "Reply: Ad \"I could've got the brush, I should I could get a few tunnels of the portal, the police to do you were going to make it's just a few stacks.\"\n",
      "\n",
      "-------------\n",
      "[Test 21 top_k: 39, top_p: 0.52] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about it's just a bit, then?\"<|endoftext|>\n",
      "\n",
      "[Test 21 top_k: 39, top_p: 0.52] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I'm't know you think \"I was the portal, it.\"<|endoftext|>\n",
      "\n",
      "[Test 21 top_k: 39, top_p: 0.52] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m of the day.\"<|endoftext|>\n",
      "\n",
      "[Test 21 top_k: 39, top_p: 0.52] -> Prompt: What will we do here?\n",
      "Reply: Ad \"I could've got your hide me.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 22 top_k: 81, top_p: 0.38] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about it's just a bit, then?\"<|endoftext|>\n",
      "\n",
      "[Test 22 top_k: 81, top_p: 0.38] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I'm't know you think \"I was the portal, it.\"<|endoftext|>\n",
      "\n",
      "[Test 22 top_k: 81, top_p: 0.38] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m of the day.\"<|endoftext|>\n",
      "\n",
      "[Test 22 top_k: 81, top_p: 0.38] -> Prompt: What will we do here?\n",
      "Reply: Br \"I see you're a few seconds. It was a few seconds, and I'll see.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 23 top_k: 67, top_p: 0.19] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure.\"<|endoftext|>\n",
      "\n",
      "[Test 23 top_k: 67, top_p: 0.19] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"After you know, I'll just leave.\"<|endoftext|>\n",
      "\n",
      "[Test 23 top_k: 67, top_p: 0.19] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was just know what you know what you know what you think about the portal, but I'll just the portal, I was a good.\"\n",
      "\n",
      "[Test 23 top_k: 67, top_p: 0.19] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm not the time, I'm not sure you're my apartment. If I could still waited the continuing adventures of the portal, I could still, I can have been\n",
      "\n",
      "-------------\n",
      "[Test 24 top_k: 75, top_p: 0.15] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure.\"<|endoftext|>\n",
      "\n",
      "[Test 24 top_k: 75, top_p: 0.15] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure you can really do, I'll see the portal, but I was just a few of the\n",
      "\n",
      "[Test 24 top_k: 75, top_p: 0.15] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was a good to the portal, but I was just have to the message with the portal, but I was just know you can make it\n",
      "\n",
      "[Test 24 top_k: 75, top_p: 0.15] -> Prompt: What will we do here?\n",
      "Reply: Br \"I was a few seconds. You know, I'll be a good amount of the portal, I could have to the portal, I was a few stacks of the time,\n",
      "\n",
      "-------------\n",
      "[Test 25 top_k: 46, top_p: 0.88] -> Prompt: How are you?\n",
      "Reply: Ad smile.\"<|endoftext|>\n",
      "\n",
      "[Test 25 top_k: 46, top_p: 0.88] -> Prompt: What do you think of Lorem?\n",
      "Reply: An \"I've got whether.\"<|endoftext|>\n",
      "\n",
      "[Test 25 top_k: 46, top_p: 0.88] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: n \"When we made my destination of the furtheing the place acting of 65 and the message using in the dragons myself to make up, in all began\n",
      "\n",
      "[Test 25 top_k: 46, top_p: 0.88] -> Prompt: What will we do here?\n",
      "Reply: Zh \"But, and her \"I watched the teleportation for me.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 26 top_k: 51, top_p: 0.94] -> Prompt: How are you?\n",
      "Reply: Ad smile.\"<|endoftext|>\n",
      "\n",
      "[Test 26 top_k: 51, top_p: 0.94] -> Prompt: What do you think of Lorem?\n",
      "Reply: An \"I've was a bit by be much.\"<|endoftext|>\n",
      "\n",
      "[Test 26 top_k: 51, top_p: 0.94] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br laugh \"I walked on some more.\"<|endoftext|>\n",
      "\n",
      "[Test 26 top_k: 51, top_p: 0.94] -> Prompt: What will we do here?\n",
      "Reply: m \"But, and a whole that he wanted to think.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 27 top_k: 90, top_p: 0.54] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about this one, then.\"<|endoftext|>\n",
      "\n",
      "[Test 27 top_k: 90, top_p: 0.54] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I can't get the message to do.\"<|endoftext|>\n",
      "\n",
      "[Test 27 top_k: 90, top_p: 0.54] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m't know the floor, I had a lot.\"<|endoftext|>\n",
      "\n",
      "[Test 27 top_k: 90, top_p: 0.54] -> Prompt: What will we do here?\n",
      "Reply: Lo normal \"I'm. You wish, and her. A one for it's just want, I think the way to make. It's going to their own.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 28 top_k: 34, top_p: 0.75] -> Prompt: How are you?\n",
      "Reply: Ad smile.\"<|endoftext|>\n",
      "\n",
      "[Test 28 top_k: 34, top_p: 0.75] -> Prompt: What do you think of Lorem?\n",
      "Reply: An \"I'm't even.\"<|endoftext|>\n",
      "\n",
      "[Test 28 top_k: 34, top_p: 0.75] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: n \"When we made it. After all to do you think you can come to make it's not even he described to make the prototypes to give you\n",
      "\n",
      "[Test 28 top_k: 34, top_p: 0.75] -> Prompt: What will we do here?\n",
      "Reply: Ad \"Well, and her. A was here, and let's not sure it.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 29 top_k: 25, top_p: 0.43] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options, I'll have to be, I have to be able to do you're. I'm not it's just a bit, though, I'm the next, but\n",
      "\n",
      "[Test 29 top_k: 25, top_p: 0.43] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure it.\"<|endoftext|>\n",
      "\n",
      "[Test 29 top_k: 25, top_p: 0.43] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m \"I didn't really do that I was the warmth it was just as I had been a good of the message to find it, I could never\n",
      "\n",
      "[Test 29 top_k: 25, top_p: 0.43] -> Prompt: What will we do here?\n",
      "Reply: Ad \"I can't know.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 30 top_k: 15, top_p: 0.68] -> Prompt: How are you?\n",
      "Reply: Ad gPlayerReply An \"I'm't even.\"<|endoftext|>\n",
      "\n",
      "[Test 30 top_k: 15, top_p: 0.68] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I can't get the evil. I don't make, and you can't know that, I could\n",
      "\n",
      "[Test 30 top_k: 15, top_p: 0.68] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I'll see you could get my course.\"<|endoftext|>\n",
      "\n",
      "[Test 30 top_k: 15, top_p: 0.68] -> Prompt: What will we do here?\n",
      "Reply: Br \"I see, I don't know the next.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 31 top_k: 86, top_p: 0.07] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure you're.\"<|endoftext|>\n",
      "\n",
      "[Test 31 top_k: 86, top_p: 0.07] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure you can really do, I'll see the warmth I'd be able to do you can't\n",
      "\n",
      "[Test 31 top_k: 86, top_p: 0.07] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was a few seconds, but I was a few stacks of the portal, I was just know what I was a good, I was a\n",
      "\n",
      "[Test 31 top_k: 86, top_p: 0.07] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm not sure it's not sure it.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 32 top_k: 77, top_p: 0.29] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options.\"<|endoftext|>\n",
      "\n",
      "[Test 32 top_k: 77, top_p: 0.29] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"After you're.\"<|endoftext|>\n",
      "\n",
      "[Test 32 top_k: 77, top_p: 0.29] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I guess the time.\"<|endoftext|>\n",
      "\n",
      "[Test 32 top_k: 77, top_p: 0.29] -> Prompt: What will we do here?\n",
      "Reply: Lo normal \"I see you can't know, but you're the end, but I could see the portal, I was a few one of the portal, I'll be the brush\n",
      "\n",
      "-------------\n",
      "[Test 33 top_k: 57, top_p: 0.66] -> Prompt: How are you?\n",
      "Reply: Ad smile.\"<|endoftext|>\n",
      "\n",
      "[Test 33 top_k: 57, top_p: 0.66] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm't make.\"<|endoftext|>\n",
      "\n",
      "[Test 33 top_k: 57, top_p: 0.66] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: n \"When we made it. After all to do you think you can come to make it's not even this is to make the beginning.\"<|endoftext|>\n",
      "\n",
      "[Test 33 top_k: 57, top_p: 0.66] -> Prompt: What will we do here?\n",
      "Reply: Br \"It's a few seconds. She should go, and let's not sure it still the police as I was already have to make it came.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 34 top_k: 13, top_p: 0.75] -> Prompt: How are you?\n",
      "Reply: Ad gPlayerReply An \"I'm't even.\"<|endoftext|>\n",
      "\n",
      "[Test 34 top_k: 13, top_p: 0.75] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I can't get the evil. I don't make, and you can't know that, I could\n",
      "\n",
      "[Test 34 top_k: 13, top_p: 0.75] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I'll see you could get my course.\"<|endoftext|>\n",
      "\n",
      "[Test 34 top_k: 13, top_p: 0.75] -> Prompt: What will we do here?\n",
      "Reply: Ry \"I guess, and the portal. I was still the end, he had already, but I can really had a few seconds, but I could still had a good amount in\n",
      "\n",
      "-------------\n",
      "[Test 35 top_k: 58, top_p: 0.4] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options, I'll have to be, I have to get it.\"<|endoftext|>\n",
      "\n",
      "[Test 35 top_k: 58, top_p: 0.4] -> Prompt: What do you think of Lorem?\n",
      "Reply: Br \"Well, I was already, but I don't just a lot, I'm't know you'll see the department\n",
      "\n",
      "[Test 35 top_k: 58, top_p: 0.4] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m of our council is the portal, I'm not be walking, I'm just as I was a number of the portal. The waited for the effects\n",
      "\n",
      "[Test 35 top_k: 58, top_p: 0.4] -> Prompt: What will we do here?\n",
      "Reply: Br \"I watched the time. It was a few seconds. You know was just know was still the day, and I could have been exaggerating about the next to the next to\n",
      "\n",
      "-------------\n",
      "[Test 36 top_k: 52, top_p: 0.27] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options.\"<|endoftext|>\n",
      "\n",
      "[Test 36 top_k: 52, top_p: 0.27] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"After you're, you can't just go, I was just a few seconds, the evil, I thought.\"\n",
      "\n",
      "[Test 36 top_k: 52, top_p: 0.27] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m \"I think you can be just leave to get the time.\"<|endoftext|>\n",
      "\n",
      "[Test 36 top_k: 52, top_p: 0.27] -> Prompt: What will we do here?\n",
      "Reply: Br \"I see, I'm not the next.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 37 top_k: 57, top_p: 0.54] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about this one, then.\"<|endoftext|>\n",
      "\n",
      "[Test 37 top_k: 57, top_p: 0.54] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I can't get the message to do.\"<|endoftext|>\n",
      "\n",
      "[Test 37 top_k: 57, top_p: 0.54] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m't know the sphere for me and a lot.\"<|endoftext|>\n",
      "\n",
      "[Test 37 top_k: 57, top_p: 0.54] -> Prompt: What will we do here?\n",
      "Reply: Lo normal \"I'm. You wish, and her. A one for it's just want, I think the way to make. It's going to make, but the end,\n",
      "\n",
      "-------------\n",
      "[Test 38 top_k: 90, top_p: 0.34] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options, I'll have to be, I have to get it.\"<|endoftext|>\n",
      "\n",
      "[Test 38 top_k: 90, top_p: 0.34] -> Prompt: What do you think of Lorem?\n",
      "Reply: Lo think b \"It's going to do, you'll see you're to be.\"<|endoftext|>\n",
      "\n",
      "[Test 38 top_k: 90, top_p: 0.34] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I didn't want to get the beginning. I don't make the portal, I was the warmth it was just as I'd make I should\n",
      "\n",
      "[Test 38 top_k: 90, top_p: 0.34] -> Prompt: What will we do here?\n",
      "Reply: Lo normal \"I'm the portal, I should be a good.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 39 top_k: 4, top_p: 0.59] -> Prompt: How are you?\n",
      "Reply: Br laugh, you are you can't worry about it's going the police, I'm not sure.\"<|endoftext|>\n",
      "\n",
      "[Test 39 top_k: 4, top_p: 0.59] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"After you can't even the best were going to be able to make, I could be able to do.\"<|endoftext|>\n",
      "\n",
      "[Test 39 top_k: 4, top_p: 0.59] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I didn't know you can be able to the time.\"<|endoftext|>\n",
      "\n",
      "[Test 39 top_k: 4, top_p: 0.59] -> Prompt: What will we do here?\n",
      "Reply: Lo normal \"I'm to the time, but I was a few stacks of the portal, I could get the portal, but I was a few stacks of the portal. I was\n",
      "\n",
      "-------------\n",
      "[Test 40 top_k: 24, top_p: 0.11] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure you're.\"<|endoftext|>\n",
      "\n",
      "[Test 40 top_k: 24, top_p: 0.11] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure you can really do, I'll see the warmth I was a few of the portal, I\n",
      "\n",
      "[Test 40 top_k: 24, top_p: 0.11] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was a few seconds, but I was a few stacks of the portal, I was just know what I was a good, I was a\n",
      "\n",
      "[Test 40 top_k: 24, top_p: 0.11] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm not sure it's not sure it.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 41 top_k: 38, top_p: 0.08] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure you're.\"<|endoftext|>\n",
      "\n",
      "[Test 41 top_k: 38, top_p: 0.08] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure you can really do, I'll see the warmth I'd be able to do you can't\n",
      "\n",
      "[Test 41 top_k: 38, top_p: 0.08] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was a few seconds, but I was a few stacks of the portal, I was just know what I was a good, I was a\n",
      "\n",
      "[Test 41 top_k: 38, top_p: 0.08] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm not sure it's not sure it.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 42 top_k: 2, top_p: 0.66] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure.\"<|endoftext|>\n",
      "\n",
      "[Test 42 top_k: 2, top_p: 0.66] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure you can really do, I'll see the portal. It's not sure you can't know\n",
      "\n",
      "[Test 42 top_k: 2, top_p: 0.66] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m \"I thought it was a lot of the portal, but I was a good.\"<|endoftext|>\n",
      "\n",
      "[Test 42 top_k: 2, top_p: 0.66] -> Prompt: What will we do here?\n",
      "Reply: Br \"I was a few seconds, I was a lot of the next, I could've been a few of the portal. I was deliberately, I could make it's not sure\n",
      "\n",
      "-------------\n",
      "[Test 43 top_k: 1, top_p: 0.9] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure you're.\"<|endoftext|>\n",
      "\n",
      "[Test 43 top_k: 1, top_p: 0.9] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure you can really do, I'll see the warmth I'd be able to do you can't\n",
      "\n",
      "[Test 43 top_k: 1, top_p: 0.9] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was a few seconds, but I was a few stacks of the portal, I was just know what I was a good, I was a\n",
      "\n",
      "[Test 43 top_k: 1, top_p: 0.9] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm not sure it's not sure it.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 44 top_k: 75, top_p: 0.42] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about it's just a bit, then?\"<|endoftext|>\n",
      "\n",
      "[Test 44 top_k: 75, top_p: 0.42] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I'm't know you think \"I was the portal, it.\"<|endoftext|>\n",
      "\n",
      "[Test 44 top_k: 75, top_p: 0.42] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m of the day.\"<|endoftext|>\n",
      "\n",
      "[Test 44 top_k: 75, top_p: 0.42] -> Prompt: What will we do here?\n",
      "Reply: Ad \"I can just about the sound, I arrived the portal, and the portal, I was still the police to do it. She was sure you're the end, I was\n",
      "\n",
      "-------------\n",
      "[Test 45 top_k: 5, top_p: 0.46] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure.\"<|endoftext|>\n",
      "\n",
      "[Test 45 top_k: 5, top_p: 0.46] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure you can really do, I'll see the portal. I was just get it's not going\n",
      "\n",
      "[Test 45 top_k: 5, top_p: 0.46] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m \"I thought the time.\"<|endoftext|>\n",
      "\n",
      "[Test 45 top_k: 5, top_p: 0.46] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm not the portal, I was a few seconds, I'm not the end, but I was a few stacks of the portal, I was a number of the portal\n",
      "\n",
      "-------------\n",
      "[Test 46 top_k: 22, top_p: 0.29] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure.\"<|endoftext|>\n",
      "\n",
      "[Test 46 top_k: 22, top_p: 0.29] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"After you know, I'll just leave.\"<|endoftext|>\n",
      "\n",
      "[Test 46 top_k: 22, top_p: 0.29] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I think you can really do you can't know you came to get the portal, but I could see you can be, but I could be\n",
      "\n",
      "[Test 46 top_k: 22, top_p: 0.29] -> Prompt: What will we do here?\n",
      "Reply: Lo normal \"I see's not sure the portal, I arrived it was a few stacks of the portal, but I was a few stacks of the portal, but I was a few\n",
      "\n",
      "-------------\n",
      "[Test 47 top_k: 26, top_p: 0.82] -> Prompt: How are you?\n",
      "Reply: Ad smile.\"<|endoftext|>\n",
      "\n",
      "[Test 47 top_k: 26, top_p: 0.82] -> Prompt: What do you think of Lorem?\n",
      "Reply: An \"I'm't even.\"<|endoftext|>\n",
      "\n",
      "[Test 47 top_k: 26, top_p: 0.82] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: n \"When we made my destination of the furthe the beginning.\"<|endoftext|>\n",
      "\n",
      "[Test 47 top_k: 26, top_p: 0.82] -> Prompt: What will we do here?\n",
      "Reply: m \"I don't think, that, you're it.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 48 top_k: 100, top_p: 0.72] -> Prompt: How are you?\n",
      "Reply: Ad smile.\"<|endoftext|>\n",
      "\n",
      "[Test 48 top_k: 100, top_p: 0.72] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I've got whether.\"<|endoftext|>\n",
      "\n",
      "[Test 48 top_k: 100, top_p: 0.72] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: n \"When we made my destination of the furtheing the place acting of 65 and the message using in the dragons' to make the beginning in the same\n",
      "\n",
      "[Test 48 top_k: 100, top_p: 0.72] -> Prompt: What will we do here?\n",
      "Reply: Ad \"But, and her. A one for my own now.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 49 top_k: 54, top_p: 0.17] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure.\"<|endoftext|>\n",
      "\n",
      "[Test 49 top_k: 54, top_p: 0.17] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure you can really do, I'll see the portal, but I was just a few of the\n",
      "\n",
      "[Test 49 top_k: 54, top_p: 0.17] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was a good to the portal, but I was just have to the message with the portal, but I was just know you can make it\n",
      "\n",
      "[Test 49 top_k: 54, top_p: 0.17] -> Prompt: What will we do here?\n",
      "Reply: Br \"I was a few seconds. You know, I'll be a good amount of the portal, the sphere. I was a good amount of the end, I can you were\n",
      "\n",
      "-------------\n",
      "[Test 50 top_k: 41, top_p: 0.24] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure.\"<|endoftext|>\n",
      "\n",
      "[Test 50 top_k: 41, top_p: 0.24] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"After you know.\"<|endoftext|>\n",
      "\n",
      "[Test 50 top_k: 41, top_p: 0.24] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was a lot of the message using the police the police as long the portal, I could be able to the warmth draining, but I was\n",
      "\n",
      "[Test 50 top_k: 41, top_p: 0.24] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm the portal, I'm not the next.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 51 top_k: 48, top_p: 0.65] -> Prompt: How are you?\n",
      "Reply: Ad gPlayerReply An \"I'm't even.\"<|endoftext|>\n",
      "\n",
      "[Test 51 top_k: 48, top_p: 0.65] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I can't get the message to do.\"<|endoftext|>\n",
      "\n",
      "[Test 51 top_k: 48, top_p: 0.65] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m't know the floor, I had a lot.\"<|endoftext|>\n",
      "\n",
      "[Test 51 top_k: 48, top_p: 0.65] -> Prompt: What will we do here?\n",
      "Reply: Lo happy.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 52 top_k: 26, top_p: 0.89] -> Prompt: How are you?\n",
      "Reply: Ad smile.\"<|endoftext|>\n",
      "\n",
      "[Test 52 top_k: 26, top_p: 0.89] -> Prompt: What do you think of Lorem?\n",
      "Reply: An \"I'm't even.\"<|endoftext|>\n",
      "\n",
      "[Test 52 top_k: 26, top_p: 0.89] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: n \"When we made my destination of the furthe the beginning.\"<|endoftext|>\n",
      "\n",
      "[Test 52 top_k: 26, top_p: 0.89] -> Prompt: What will we do here?\n",
      "Reply: m \"But, and a whole that he wanted to leave out, so I'll try.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 53 top_k: 42, top_p: 0.96] -> Prompt: How are you?\n",
      "Reply: Rz.\"<|endoftext|>\n",
      "\n",
      "[Test 53 top_k: 42, top_p: 0.96] -> Prompt: What do you think of Lorem?\n",
      "Reply: An \"I've was a bit by be much.\"<|endoftext|>\n",
      "\n",
      "[Test 53 top_k: 42, top_p: 0.96] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br laugh \"I walked on some more.\"<|endoftext|>\n",
      "\n",
      "[Test 53 top_k: 42, top_p: 0.96] -> Prompt: What will we do here?\n",
      "Reply: m \"But, and a whole that he wanted to think.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 54 top_k: 59, top_p: 0.4] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options, I'll have to be, I have to get it.\"<|endoftext|>\n",
      "\n",
      "[Test 54 top_k: 59, top_p: 0.4] -> Prompt: What do you think of Lorem?\n",
      "Reply: Br \"Well, I was already, but I don't just a lot, I'm't know you'll see the department\n",
      "\n",
      "[Test 54 top_k: 59, top_p: 0.4] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m of our council is the portal, I'm not be walking, I'm just as I was a number of the portal. The waited for the effects\n",
      "\n",
      "[Test 54 top_k: 59, top_p: 0.4] -> Prompt: What will we do here?\n",
      "Reply: Br \"I watched the time. It was a few seconds. You know was just know was still the day, and I could have been exaggerating about the next to the next to\n",
      "\n",
      "-------------\n",
      "[Test 55 top_k: 13, top_p: 0.82] -> Prompt: How are you?\n",
      "Reply: Ad smile.\"<|endoftext|>\n",
      "\n",
      "[Test 55 top_k: 13, top_p: 0.82] -> Prompt: What do you think of Lorem?\n",
      "Reply: An \"I'm't even.\"<|endoftext|>\n",
      "\n",
      "[Test 55 top_k: 13, top_p: 0.82] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: n \"When we can just about the lab had assumed the end of the end and the lab, I had arrived in the middle of the portal to make\n",
      "\n",
      "[Test 55 top_k: 13, top_p: 0.82] -> Prompt: What will we do here?\n",
      "Reply: Zh \"It was going to go. I don't just have no idea, but the way to make of the end, but I can really had been for the police.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 56 top_k: 21, top_p: 0.14] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure.\"<|endoftext|>\n",
      "\n",
      "[Test 56 top_k: 21, top_p: 0.14] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure you can really do, I'll see the warmth I was a few of the portal, I\n",
      "\n",
      "[Test 56 top_k: 21, top_p: 0.14] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was a few seconds, but I was a few stacks of the portal, I was just know what I was a good, I was a\n",
      "\n",
      "[Test 56 top_k: 21, top_p: 0.14] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm not sure it's not sure the next, I was a few seconds, I could've got the portal, but I could have been of the portal, I was\n",
      "\n",
      "-------------\n",
      "[Test 57 top_k: 34, top_p: 0.73] -> Prompt: How are you?\n",
      "Reply: Ad smile.\"<|endoftext|>\n",
      "\n",
      "[Test 57 top_k: 34, top_p: 0.73] -> Prompt: What do you think of Lorem?\n",
      "Reply: An \"I'm't even.\"<|endoftext|>\n",
      "\n",
      "[Test 57 top_k: 34, top_p: 0.73] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: n \"When we made it. After all to do you think you can come to make it's not the time of the middle of the effects to create\n",
      "\n",
      "[Test 57 top_k: 34, top_p: 0.73] -> Prompt: What will we do here?\n",
      "Reply: Ad \"It was going to her. I'd have a few seconds on the dragons.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 58 top_k: 13, top_p: 0.61] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options, I'll have something to do you're. It's not the best to do you're the best to make, but I could be the department, I can't\n",
      "\n",
      "[Test 58 top_k: 13, top_p: 0.61] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad flip \"It's a few seconds. What was a few, I'll need to the warmth the evil, I was\n",
      "\n",
      "[Test 58 top_k: 13, top_p: 0.61] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"It's just been the time before I was the other side of the time I can make it.\"<|endoftext|>\n",
      "\n",
      "[Test 58 top_k: 13, top_p: 0.61] -> Prompt: What will we do here?\n",
      "Reply: Ad \"I can know, I was the portal, the land of the portal, and as I arrived, I had to do that, I can have to meet the ground, I\n",
      "\n",
      "-------------\n",
      "[Test 59 top_k: 92, top_p: 0.53] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about this one, then.\"<|endoftext|>\n",
      "\n",
      "[Test 59 top_k: 92, top_p: 0.53] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I can't get the message to do.\"<|endoftext|>\n",
      "\n",
      "[Test 59 top_k: 92, top_p: 0.53] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m't know the floor, I had a lot.\"<|endoftext|>\n",
      "\n",
      "[Test 59 top_k: 92, top_p: 0.53] -> Prompt: What will we do here?\n",
      "Reply: Lo normal \"I'm. You wish, and her. A one for it's just want, I think the way to make. It's going to their own.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 60 top_k: 76, top_p: 0.3] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options.\"<|endoftext|>\n",
      "\n",
      "[Test 60 top_k: 76, top_p: 0.3] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"After you're.\"<|endoftext|>\n",
      "\n",
      "[Test 60 top_k: 76, top_p: 0.3] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I guess the time.\"<|endoftext|>\n",
      "\n",
      "[Test 60 top_k: 76, top_p: 0.3] -> Prompt: What will we do here?\n",
      "Reply: Lo normal \"I see you can't know, but you're the end, but I could see the portal, I was a few one of the portal, I'll be the brush\n",
      "\n",
      "-------------\n",
      "[Test 61 top_k: 51, top_p: 0.57] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about this one, then.\"<|endoftext|>\n",
      "\n",
      "[Test 61 top_k: 51, top_p: 0.57] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I can't get the message to do.\"<|endoftext|>\n",
      "\n",
      "[Test 61 top_k: 51, top_p: 0.57] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m't know the sphere for me and a lot.\"<|endoftext|>\n",
      "\n",
      "[Test 61 top_k: 51, top_p: 0.57] -> Prompt: What will we do here?\n",
      "Reply: Lo happy.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 62 top_k: 54, top_p: 0.88] -> Prompt: How are you?\n",
      "Reply: Ad smile.\"<|endoftext|>\n",
      "\n",
      "[Test 62 top_k: 54, top_p: 0.88] -> Prompt: What do you think of Lorem?\n",
      "Reply: An \"I've got whether.\"<|endoftext|>\n",
      "\n",
      "[Test 62 top_k: 54, top_p: 0.88] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: n \"When we made my destination of the furtheing the place acting of 65 and the message using in the dragons myself to make up, in all began\n",
      "\n",
      "[Test 62 top_k: 54, top_p: 0.88] -> Prompt: What will we do here?\n",
      "Reply: Zh \"But, and her \"I watched the teleportation for me.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 63 top_k: 82, top_p: 0.82] -> Prompt: How are you?\n",
      "Reply: Ad smile.\"<|endoftext|>\n",
      "\n",
      "[Test 63 top_k: 82, top_p: 0.82] -> Prompt: What do you think of Lorem?\n",
      "Reply: An \"I've got whether.\"<|endoftext|>\n",
      "\n",
      "[Test 63 top_k: 82, top_p: 0.82] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: n \"When we made my destination of the furtheing the place acting of 65 and the message using in the fireworks, I had been to bring we waited\n",
      "\n",
      "[Test 63 top_k: 82, top_p: 0.82] -> Prompt: What will we do here?\n",
      "Reply: Zh \"But, and her \"I watched the teleportation for me.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 64 top_k: 56, top_p: 0.46] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about it's just a bit, then?\"<|endoftext|>\n",
      "\n",
      "[Test 64 top_k: 56, top_p: 0.46] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I'm't know you think \"I was the portal, it.\"<|endoftext|>\n",
      "\n",
      "[Test 64 top_k: 56, top_p: 0.46] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m of the day.\"<|endoftext|>\n",
      "\n",
      "[Test 64 top_k: 56, top_p: 0.46] -> Prompt: What will we do here?\n",
      "Reply: Ad \"I could've got the brush, I should the portal, and the land of the end, the police.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 65 top_k: 39, top_p: 0.41] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options, I'll have to be, I have to get it.\"<|endoftext|>\n",
      "\n",
      "[Test 65 top_k: 39, top_p: 0.41] -> Prompt: What do you think of Lorem?\n",
      "Reply: Br \"Well, I was, it's going to me to the portal, I can't make me.\"<|endoftext|>\n",
      "\n",
      "[Test 65 top_k: 39, top_p: 0.41] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Sb \"It's not sure the middle to do it was not sure the effects.\"<|endoftext|>\n",
      "\n",
      "[Test 65 top_k: 39, top_p: 0.41] -> Prompt: What will we do here?\n",
      "Reply: Ad \"I'll see.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 66 top_k: 58, top_p: 0.36] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options, I'll have to be, I have to be able to do you're. I'm not it's just a bit, though, I'm the warmth.\"<|endoftext|>\n",
      "\n",
      "[Test 66 top_k: 58, top_p: 0.36] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure it.\"<|endoftext|>\n",
      "\n",
      "[Test 66 top_k: 58, top_p: 0.36] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m \"I didn't really do that I was the warmth it was just as I'd make a good of the furthe to meet you have to get the\n",
      "\n",
      "[Test 66 top_k: 58, top_p: 0.36] -> Prompt: What will we do here?\n",
      "Reply: Br \"I suppose it.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 67 top_k: 31, top_p: 0.61] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about this one, then.\"<|endoftext|>\n",
      "\n",
      "[Test 67 top_k: 31, top_p: 0.61] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I can't get the message to do.\"<|endoftext|>\n",
      "\n",
      "[Test 67 top_k: 31, top_p: 0.61] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m't know the sphere for that's a lot of our PDAs you can do it.\"<|endoftext|>\n",
      "\n",
      "[Test 67 top_k: 31, top_p: 0.61] -> Prompt: What will we do here?\n",
      "Reply: Lo normal \"I think the day, though, he arrived the end.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 68 top_k: 76, top_p: 0.42] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about it's just a bit, then?\"<|endoftext|>\n",
      "\n",
      "[Test 68 top_k: 76, top_p: 0.42] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I'm't know you think \"I was the portal, it.\"<|endoftext|>\n",
      "\n",
      "[Test 68 top_k: 76, top_p: 0.42] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m of the day.\"<|endoftext|>\n",
      "\n",
      "[Test 68 top_k: 76, top_p: 0.42] -> Prompt: What will we do here?\n",
      "Reply: Ad \"I can just about the sound, I arrived the portal, and the portal, I was still the police to do it. She was sure you're the end, I was\n",
      "\n",
      "-------------\n",
      "[Test 69 top_k: 70, top_p: 0.13] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure.\"<|endoftext|>\n",
      "\n",
      "[Test 69 top_k: 70, top_p: 0.13] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure you can really do, I'll see the portal, I was a few of the portal,\n",
      "\n",
      "[Test 69 top_k: 70, top_p: 0.13] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was a good to the portal, but I was just know what you know what I was a number, I was a good.\"<|endoftext|>\n",
      "\n",
      "[Test 69 top_k: 70, top_p: 0.13] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm not sure it's not to the time, I was a few seconds, I could still the warmth the portal, I was a few of the portal. I was\n",
      "\n",
      "-------------\n",
      "[Test 70 top_k: 47, top_p: 0.05] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure you're.\"<|endoftext|>\n",
      "\n",
      "[Test 70 top_k: 47, top_p: 0.05] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure you can really do, I'll see the warmth I'd be able to do you can't\n",
      "\n",
      "[Test 70 top_k: 47, top_p: 0.05] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was a few seconds, but I was a few stacks of the portal, I was just know what I was a good, I was a\n",
      "\n",
      "[Test 70 top_k: 47, top_p: 0.05] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm not sure it's not sure it.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 71 top_k: 75, top_p: 0.25] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options.\"<|endoftext|>\n",
      "\n",
      "[Test 71 top_k: 75, top_p: 0.25] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"After you're, I'll really that I'll need for you want to find me, but I was a bit\n",
      "\n",
      "[Test 71 top_k: 75, top_p: 0.25] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m \"I thought the beginning<|endoftext|>\n",
      "\n",
      "[Test 71 top_k: 75, top_p: 0.25] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm not to me to her. I'll be a few stacks of the end, I was just a good, but I could be for the end, I was a\n",
      "\n",
      "-------------\n",
      "[Test 72 top_k: 75, top_p: 0.54] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about this one, then.\"<|endoftext|>\n",
      "\n",
      "[Test 72 top_k: 75, top_p: 0.54] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I can't get the message to do.\"<|endoftext|>\n",
      "\n",
      "[Test 72 top_k: 75, top_p: 0.54] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m't know the sphere for me and a lot.\"<|endoftext|>\n",
      "\n",
      "[Test 72 top_k: 75, top_p: 0.54] -> Prompt: What will we do here?\n",
      "Reply: Lo normal \"I'm. You wish, and her. A one for it's just want, I think the way to make. It's going to their own.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 73 top_k: 78, top_p: 0.33] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options, I'll have to be, I have to be able to do you're. I'm not it's just a bit, though, I'm the next, but\n",
      "\n",
      "[Test 73 top_k: 78, top_p: 0.33] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure it.\"<|endoftext|>\n",
      "\n",
      "[Test 73 top_k: 78, top_p: 0.33] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m \"I didn't really do that's just the same. That's not the way to make it's just a portal, but you have to get\n",
      "\n",
      "[Test 73 top_k: 78, top_p: 0.33] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm a lot of the portal, I can come up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 74 top_k: 28, top_p: 0.0] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure you're.\"<|endoftext|>\n",
      "\n",
      "[Test 74 top_k: 28, top_p: 0.0] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure you can really do, I'll see the warmth I'd be able to do you can't\n",
      "\n",
      "[Test 74 top_k: 28, top_p: 0.0] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was a few seconds, but I was a few stacks of the portal, I was just know what I was a good, I was a\n",
      "\n",
      "[Test 74 top_k: 28, top_p: 0.0] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm not sure it's not sure it.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 75 top_k: 64, top_p: 0.34] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options, I'll have to be, I have to be able to do you're. I'm not it's just a bit, though, I'm the next, but\n",
      "\n",
      "[Test 75 top_k: 64, top_p: 0.34] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure it.\"<|endoftext|>\n",
      "\n",
      "[Test 75 top_k: 64, top_p: 0.34] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m \"I didn't really do that's just the same. That's not the way to make it's just a portal, but you have to get\n",
      "\n",
      "[Test 75 top_k: 64, top_p: 0.34] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm a lot of the portal, I can come up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 76 top_k: 39, top_p: 0.75] -> Prompt: How are you?\n",
      "Reply: Ad smile.\"<|endoftext|>\n",
      "\n",
      "[Test 76 top_k: 39, top_p: 0.75] -> Prompt: What do you think of Lorem?\n",
      "Reply: An \"I'm't even.\"<|endoftext|>\n",
      "\n",
      "[Test 76 top_k: 39, top_p: 0.75] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: n \"When we made it. After all to do you think you can come to use the police, and a lot to make the whole to give you\n",
      "\n",
      "[Test 76 top_k: 39, top_p: 0.75] -> Prompt: What will we do here?\n",
      "Reply: Ad \"Well, and her. A was here, and let's not sure it.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 77 top_k: 19, top_p: 0.63] -> Prompt: How are you?\n",
      "Reply: Ad gPlayerReply Br \"I'm the beginning shy.\"<|endoftext|>\n",
      "\n",
      "[Test 77 top_k: 19, top_p: 0.63] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, it's pretty, I was just leave the warmth...\"<|endoftext|>\n",
      "\n",
      "[Test 77 top_k: 19, top_p: 0.63] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I'm just a lot, I can do you can you can just. That's not so the one for it's just.\"<|endoftext|>\n",
      "\n",
      "[Test 77 top_k: 19, top_p: 0.63] -> Prompt: What will we do here?\n",
      "Reply: Ad \"I'm a few seconds. It have been. You know.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 78 top_k: 30, top_p: 0.08] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure you're.\"<|endoftext|>\n",
      "\n",
      "[Test 78 top_k: 30, top_p: 0.08] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure you can really do, I'll see the warmth I'd be able to do you can't\n",
      "\n",
      "[Test 78 top_k: 30, top_p: 0.08] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was a few seconds, but I was a few stacks of the portal, I was just know what I was a good, I was a\n",
      "\n",
      "[Test 78 top_k: 30, top_p: 0.08] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm not sure it's not sure it.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 79 top_k: 3, top_p: 0.34] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure you're.\"<|endoftext|>\n",
      "\n",
      "[Test 79 top_k: 3, top_p: 0.34] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure you can really do, I'll see the warmth I'd be able to do you can't\n",
      "\n",
      "[Test 79 top_k: 3, top_p: 0.34] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was a few seconds, but I was a few stacks of the portal, I was just know what I was a good, I was a\n",
      "\n",
      "[Test 79 top_k: 3, top_p: 0.34] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm not sure it's not sure it.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 80 top_k: 81, top_p: 0.3] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options.\"<|endoftext|>\n",
      "\n",
      "[Test 80 top_k: 81, top_p: 0.3] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"After you're.\"<|endoftext|>\n",
      "\n",
      "[Test 80 top_k: 81, top_p: 0.3] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I guess the time.\"<|endoftext|>\n",
      "\n",
      "[Test 80 top_k: 81, top_p: 0.3] -> Prompt: What will we do here?\n",
      "Reply: Lo normal \"I see you can't know, but you're the end, but I could see the portal, I was a few one of the portal, I'll be the brush\n",
      "\n",
      "-------------\n",
      "[Test 81 top_k: 64, top_p: 0.75] -> Prompt: How are you?\n",
      "Reply: Ad smile.\"<|endoftext|>\n",
      "\n",
      "[Test 81 top_k: 64, top_p: 0.75] -> Prompt: What do you think of Lorem?\n",
      "Reply: An \"I'm't even.\"<|endoftext|>\n",
      "\n",
      "[Test 81 top_k: 64, top_p: 0.75] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: n \"When we made my destination of the furthe the continuing adventures of the processes had been of en, and the portal, I can do those of en\n",
      "\n",
      "[Test 81 top_k: 64, top_p: 0.75] -> Prompt: What will we do here?\n",
      "Reply: Ad \"But, and her. A one for my own now.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 82 top_k: 37, top_p: 0.55] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about it's just a bit, then?\"<|endoftext|>\n",
      "\n",
      "[Test 82 top_k: 37, top_p: 0.55] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I'm't know you think \"I was the portal, it.\"<|endoftext|>\n",
      "\n",
      "[Test 82 top_k: 37, top_p: 0.55] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m of the day.\"<|endoftext|>\n",
      "\n",
      "[Test 82 top_k: 37, top_p: 0.55] -> Prompt: What will we do here?\n",
      "Reply: Ad \"I could've got your hide me. It was a few seconds, and I should the effects in the one of my apartment, but I can really.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 83 top_k: 9, top_p: 0.98] -> Prompt: How are you?\n",
      "Reply: Ad smile.\"<|endoftext|>\n",
      "\n",
      "[Test 83 top_k: 9, top_p: 0.98] -> Prompt: What do you think of Lorem?\n",
      "Reply: An \"I'm't even.\"<|endoftext|>\n",
      "\n",
      "[Test 83 top_k: 9, top_p: 0.98] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: n \"When we can just about the lab had assumed the end of the end and the lab, I had arrived in destroying in the beginning in the same\n",
      "\n",
      "[Test 83 top_k: 9, top_p: 0.98] -> Prompt: What will we do here?\n",
      "Reply: Zh \"The test.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 84 top_k: 94, top_p: 0.9] -> Prompt: How are you?\n",
      "Reply: Ad smile.\"<|endoftext|>\n",
      "\n",
      "[Test 84 top_k: 94, top_p: 0.9] -> Prompt: What do you think of Lorem?\n",
      "Reply: An \"I've was a bit by be much.\"<|endoftext|>\n",
      "\n",
      "[Test 84 top_k: 94, top_p: 0.9] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br laugh \"I walked on some more years I was going to do you are, and a lot to make up, so we'll try the portal.\n",
      "\n",
      "[Test 84 top_k: 94, top_p: 0.9] -> Prompt: What will we do here?\n",
      "Reply: Br \"I think the day, though, when I noticed.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 85 top_k: 61, top_p: 0.22] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure.\"<|endoftext|>\n",
      "\n",
      "[Test 85 top_k: 61, top_p: 0.22] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"After you know.\"<|endoftext|>\n",
      "\n",
      "[Test 85 top_k: 61, top_p: 0.22] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was a lot of the message using the police the police as long the portal, I could be able to the warmth draining, but I was\n",
      "\n",
      "[Test 85 top_k: 61, top_p: 0.22] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm the portal, I'm not the next.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 86 top_k: 91, top_p: 0.82] -> Prompt: How are you?\n",
      "Reply: Ad smile.\"<|endoftext|>\n",
      "\n",
      "[Test 86 top_k: 91, top_p: 0.82] -> Prompt: What do you think of Lorem?\n",
      "Reply: An \"I've got whether.\"<|endoftext|>\n",
      "\n",
      "[Test 86 top_k: 91, top_p: 0.82] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: n \"When we made my destination of the furtheing the place acting of 65 and the message using in the fireworks, I had been to bring we waited\n",
      "\n",
      "[Test 86 top_k: 91, top_p: 0.82] -> Prompt: What will we do here?\n",
      "Reply: Zh \"But, and her \"I watched the teleportation for me.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 87 top_k: 28, top_p: 0.26] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure.\"<|endoftext|>\n",
      "\n",
      "[Test 87 top_k: 28, top_p: 0.26] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"After you know, I'll just leave.\"<|endoftext|>\n",
      "\n",
      "[Test 87 top_k: 28, top_p: 0.26] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I think you can really do you can't know you came to get the end, but I could have to be. We would have to the\n",
      "\n",
      "[Test 87 top_k: 28, top_p: 0.26] -> Prompt: What will we do here?\n",
      "Reply: Lo normal \"I'm not sure it.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 88 top_k: 8, top_p: 0.65] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options, I'll have to be, I have to get it.\"<|endoftext|>\n",
      "\n",
      "[Test 88 top_k: 8, top_p: 0.65] -> Prompt: What do you think of Lorem?\n",
      "Reply: Br \"I think \"I't even if you can't even, I'm the warmth...\"<|endoftext|>\n",
      "\n",
      "[Test 88 top_k: 8, top_p: 0.65] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m \"I didn't think this is a few seconds. I can be able to be, I'm not so I was a number of our PDAs\n",
      "\n",
      "[Test 88 top_k: 8, top_p: 0.65] -> Prompt: What will we do here?\n",
      "Reply: Br \"I knew you'll be a few seconds, I'll see.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 89 top_k: 5, top_p: 0.79] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options, I'll have to be, I have to get it.\"<|endoftext|>\n",
      "\n",
      "[Test 89 top_k: 5, top_p: 0.79] -> Prompt: What do you think of Lorem?\n",
      "Reply: Br \"I think \"I't even if you can't even, I'm the warmth...\"<|endoftext|>\n",
      "\n",
      "[Test 89 top_k: 5, top_p: 0.79] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m \"I didn't think this is a few seconds. I can be able to be, I'm just about it was a number of course, but\n",
      "\n",
      "[Test 89 top_k: 5, top_p: 0.79] -> Prompt: What will we do here?\n",
      "Reply: Br \"I knew you'll be a few seconds, I'll see.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 90 top_k: 48, top_p: 0.11] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure.\"<|endoftext|>\n",
      "\n",
      "[Test 90 top_k: 48, top_p: 0.11] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure you can really do, I'll see the warmth I was a few of the portal, I\n",
      "\n",
      "[Test 90 top_k: 48, top_p: 0.11] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was a few seconds, but I was a few stacks of the portal, I was just know what I was a good, I was a\n",
      "\n",
      "[Test 90 top_k: 48, top_p: 0.11] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm not sure it's not to the next, I was a few seconds, I could've got the portal, but I could've been of the portal, I was\n",
      "\n",
      "-------------\n",
      "[Test 91 top_k: 15, top_p: 0.12] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure you're.\"<|endoftext|>\n",
      "\n",
      "[Test 91 top_k: 15, top_p: 0.12] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure you can really do, I'll see the warmth I'd be able to do you can't\n",
      "\n",
      "[Test 91 top_k: 15, top_p: 0.12] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was a few seconds, but I was a few stacks of the portal, I was just know what I was a good, I was a\n",
      "\n",
      "[Test 91 top_k: 15, top_p: 0.12] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm not sure it's not sure it.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 92 top_k: 57, top_p: 0.42] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about it's just a bit, then?\"<|endoftext|>\n",
      "\n",
      "[Test 92 top_k: 57, top_p: 0.42] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I'm't know you think \"I was the portal, it.\"<|endoftext|>\n",
      "\n",
      "[Test 92 top_k: 57, top_p: 0.42] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m of the day.\"<|endoftext|>\n",
      "\n",
      "[Test 92 top_k: 57, top_p: 0.42] -> Prompt: What will we do here?\n",
      "Reply: Ad \"I can just about the sound, I arrived the portal, I'm not even sure the effects, but I had.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 93 top_k: 46, top_p: 0.2] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not sure.\"<|endoftext|>\n",
      "\n",
      "[Test 93 top_k: 46, top_p: 0.2] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"I'm not sure you can really do, I'll see the portal, but I don't want to do that\n",
      "\n",
      "[Test 93 top_k: 46, top_p: 0.2] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was a good to the ground, but I was just know what you have to get the portal, but I was just know what you came\n",
      "\n",
      "[Test 93 top_k: 46, top_p: 0.2] -> Prompt: What will we do here?\n",
      "Reply: Br \"I was a few seconds. You know, I'll be a good amount of the portal, the sphere. I was a good amount of the end, I can make it\n",
      "\n",
      "-------------\n",
      "[Test 94 top_k: 80, top_p: 0.42] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about it's just a bit, then?\"<|endoftext|>\n",
      "\n",
      "[Test 94 top_k: 80, top_p: 0.42] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I'm't know you think \"I was the portal, it.\"<|endoftext|>\n",
      "\n",
      "[Test 94 top_k: 80, top_p: 0.42] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m of the day.\"<|endoftext|>\n",
      "\n",
      "[Test 94 top_k: 80, top_p: 0.42] -> Prompt: What will we do here?\n",
      "Reply: Ad \"I can just about the sound, I arrived the portal, and the portal, I was still the police to do it. She was sure you're the end, I was\n",
      "\n",
      "-------------\n",
      "[Test 95 top_k: 72, top_p: 0.78] -> Prompt: How are you?\n",
      "Reply: Ad smile.\"<|endoftext|>\n",
      "\n",
      "[Test 95 top_k: 72, top_p: 0.78] -> Prompt: What do you think of Lorem?\n",
      "Reply: An \"I've got whether.\"<|endoftext|>\n",
      "\n",
      "[Test 95 top_k: 72, top_p: 0.78] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: n \"When we made my destination of the furtheing the place acting of 65 and the message using in the dragons myself to make the beginning in all call\n",
      "\n",
      "[Test 95 top_k: 72, top_p: 0.78] -> Prompt: What will we do here?\n",
      "Reply: Ad \"But, and her. A one for my own now.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 96 top_k: 66, top_p: 0.37] -> Prompt: How are you?\n",
      "Reply: Br laugh, you're my options, I'll have to be, I have to get it.\"<|endoftext|>\n",
      "\n",
      "[Test 96 top_k: 66, top_p: 0.37] -> Prompt: What do you think of Lorem?\n",
      "Reply: Br \"Well, I was already, but I don't just a lot, I'm't know you'll see the department\n",
      "\n",
      "[Test 96 top_k: 66, top_p: 0.37] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m of our council is the portal, I'm not be walking, I'm not sure. It's going to make it's going to do you're\n",
      "\n",
      "[Test 96 top_k: 66, top_p: 0.37] -> Prompt: What will we do here?\n",
      "Reply: Br \"I watched the time. It was a few seconds. You know was a single tear, and it's just know.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 97 top_k: 97, top_p: 0.39] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about it's just a bit, then?\"<|endoftext|>\n",
      "\n",
      "[Test 97 top_k: 97, top_p: 0.39] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I'm't know you think \"I was the portal, it.\"<|endoftext|>\n",
      "\n",
      "[Test 97 top_k: 97, top_p: 0.39] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m of the day.\"<|endoftext|>\n",
      "\n",
      "[Test 97 top_k: 97, top_p: 0.39] -> Prompt: What will we do here?\n",
      "Reply: Br \"I see you're a few seconds. It was a few seconds, and I'll see.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 98 top_k: 99, top_p: 0.22] -> Prompt: How are you?\n",
      "Reply: Br laugh, I'm not it.\"<|endoftext|>\n",
      "\n",
      "[Test 98 top_k: 99, top_p: 0.22] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"After you know.\"<|endoftext|>\n",
      "\n",
      "[Test 98 top_k: 99, top_p: 0.22] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br \"I was the time I could be the other side to the time was a few stacks of the middle of the effects of the message of the police\n",
      "\n",
      "[Test 98 top_k: 99, top_p: 0.22] -> Prompt: What will we do here?\n",
      "Reply: Br \"I'm the day, I'm not the next.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 99 top_k: 42, top_p: 0.93] -> Prompt: How are you?\n",
      "Reply: Ad smile.\"<|endoftext|>\n",
      "\n",
      "[Test 99 top_k: 42, top_p: 0.93] -> Prompt: What do you think of Lorem?\n",
      "Reply: An \"I've was a bit by be much.\"<|endoftext|>\n",
      "\n",
      "[Test 99 top_k: 42, top_p: 0.93] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Br laugh \"I walked on some more.\"<|endoftext|>\n",
      "\n",
      "[Test 99 top_k: 42, top_p: 0.93] -> Prompt: What will we do here?\n",
      "Reply: m \"But, and a whole that he wanted to think.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 100 top_k: 81, top_p: 0.48] -> Prompt: How are you?\n",
      "Reply: Br laugh, you think about it's just a bit, then?\"<|endoftext|>\n",
      "\n",
      "[Test 100 top_k: 81, top_p: 0.48] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"Hey, I'm't know you think \"I was the sphere.\"<|endoftext|>\n",
      "\n",
      "[Test 100 top_k: 81, top_p: 0.48] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: m \"I walked to make the beginning<|endoftext|>\n",
      "\n",
      "[Test 100 top_k: 81, top_p: 0.48] -> Prompt: What will we do here?\n",
      "Reply: Ad \"I'm. That's all.\"<|endoftext|>\n",
      "\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    torch.manual_seed(80085)\n",
    "    top_k = random.randint(0, 100)\n",
    "    top_p = round(random.uniform(0, 1), 2)\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = generate_dragon_reply(past, prompt, top_k = top_k, top_p = top_p)\n",
    "        print(f\"[Test {i + 1} top_k: {top_k}, top_p: {top_p}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T01:49:56.635848Z",
     "iopub.status.busy": "2021-11-15T01:49:56.635381Z",
     "iopub.status.idle": "2021-11-15T01:49:56.745906Z",
     "shell.execute_reply": "2021-11-15T01:49:56.746288Z"
    },
    "id": "FgM9Awn7acpG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What to say?\n"
     ]
    },
    {
     "ename": "StdinNotImplementedError",
     "evalue": "raw_input was called, but this frontend does not support input requests.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStdinNotImplementedError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5685/61523620.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What to say?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_reply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \"\"\"\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_stdin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m             raise StdinNotImplementedError(\n\u001b[0m\u001b[1;32m   1004\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             )\n",
      "\u001b[0;31mStdinNotImplementedError\u001b[0m: raw_input was called, but this frontend does not support input requests."
     ]
    }
   ],
   "source": [
    "def generate_reply(prompt):\n",
    "    model.eval()\n",
    "    prompt = f'PlayerReply c \"{prompt}\" DragonReply'\n",
    "    generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "    generated = generated.to(device)\n",
    "    print(prompt, generated)\n",
    "\n",
    "    sample_outputs = model.generate(\n",
    "        generated, \n",
    "        do_sample=True,   \n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        top_length = block_size,\n",
    "        top_p=0.95, \n",
    "        num_return_sequences=3\n",
    "    )\n",
    "\n",
    "    for i, sample_output in enumerate(sample_outputs):\n",
    "        print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=False)))\n",
    "\n",
    "print(\"What to say?\")\n",
    "print(generate_reply(input()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXKM4uLM2gOO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AWSW_GPT-Neo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "255808f296e249a3b0e3f747e3b70bfe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5dbf8e8ba80544f0802f9d75682dfb62",
       "placeholder": "​",
       "style": "IPY_MODEL_60a29dd1deaf48458124341231a31766",
       "value": "100%"
      }
     },
     "44449c48367f4154b76cab623c364932": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5dbf8e8ba80544f0802f9d75682dfb62": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "60a29dd1deaf48458124341231a31766": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6a0cb01b014b44e6b50b319ec7f3b1bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "725cba957cbb4fc585dce57cae3d9b12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_255808f296e249a3b0e3f747e3b70bfe",
        "IPY_MODEL_76b3f7000ae046dcae6a0cb9522f7156",
        "IPY_MODEL_7992d8d664cd4f0eaa12e73c4c752062"
       ],
       "layout": "IPY_MODEL_bea85675155b49248a06f2bc8603cb15"
      }
     },
     "76b3f7000ae046dcae6a0cb9522f7156": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b28e542993bf42b690791ab68f809ed5",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6a0cb01b014b44e6b50b319ec7f3b1bc",
       "value": 2.0
      }
     },
     "7992d8d664cd4f0eaa12e73c4c752062": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d718db5b259d4a999c5a9e0076e67028",
       "placeholder": "​",
       "style": "IPY_MODEL_44449c48367f4154b76cab623c364932",
       "value": " 2/2 [00:00&lt;00:00, 91.94it/s]"
      }
     },
     "b28e542993bf42b690791ab68f809ed5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bea85675155b49248a06f2bc8603cb15": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d718db5b259d4a999c5a9e0076e67028": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
