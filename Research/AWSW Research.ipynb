{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b97b376-9ac5-4c70-ba13-769649099a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_utils import train_model, split_data, split_branches, get_model, set_pretrained_model_dropout\n",
    "from config import Config\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from model_manager import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887d9f81-96c3-408f-bd1c-7b126becc4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use cuda:0 for training with seed: 3218885689\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randint(0, 2 ** 32 - 1)\n",
    "seed = 3218885689\n",
    "random.seed(seed)\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(f\"Will use {device_name} for training with seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e95113e-dfc1-40a9-a39b-5d56f3bf32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(os.path.join(Config.work_dir, \"awsw_story_input.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb65c62-47c6-4d36-bd1e-2adfef8ff1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lr\": 6e-4,\n",
    "    \"warmup_factor\": 0,\n",
    "    \"scheduler\": \"polynomial_decay_schedule_with_warmup\",\n",
    "    \"lr_end\": 2e-6,\n",
    "    \"power\": 0.6,\n",
    "    #\"freeze_layer_rate\": 1e-4,\n",
    "    \"freeze_from_steps\": -1,\n",
    "    \"seed\": seed,\n",
    "    \"num_epoch\": 500\n",
    "}\n",
    "\n",
    "optuna_result_attachement = {\n",
    "    'lr': 0.001,\n",
    "    'scheduler': 'cosine_schedule_with_warmup',\n",
    "    'to_freeze_count': 150,\n",
    "    #\"to_freeze_gpt_blocks\": 11,\n",
    "    'warmup_factor': 1\n",
    "}\n",
    "config.update(optuna_result_attachement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ffae5b-e197-4417-a4cd-e6befc6ee393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded empty model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_path = os.path.join(\"models\", \"awsw_main\")\n",
    "if os.path.exists(os.path.join(saved_model_path, \"pytorch_model.bin\")):\n",
    "    print(\"Pretrained model loaded\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "    model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "else:\n",
    "    print(\"Loaded empty model\")\n",
    "    model, tokenizer = get_model(\"EleutherAI/gpt-neo-125M\")\n",
    "model.to(device)\n",
    "# set_pretrained_model_dropout(model.transformer.h[-1:], 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f3315-8f5d-4101-8e7e-2c0129204c94",
   "metadata": {},
   "source": [
    "# Test before training on a pretrained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f68c3f1-4c0a-41a2-a3fc-b8b3c36e418c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragon, and a dragon-eating dragon.\n",
      "\n",
      "I'm a dragon, and a dragon-eating dragon.\n",
      "\n",
      "(I'm a dragon, and a dragon-eating dragon.\n",
      "\n",
      "(I'm a dragon, and a dragon-eating dragon.\n",
      "\n",
      "(I'm a dragon, and a dragon-eating dragon.\n",
      "\n",
      "(I'm a dragon, and a dragon-eating dragon.\n",
      "\n",
      "(I'm a dragon, and a dragon-eating dragon.\n",
      "\n",
      "(I'm a dragon, and a dragon-eating dragon.\n",
      "\n",
      "(I'm a dragon,\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model_manager = ModelManager(model=model, tokenizer=tokenizer, device=device)\n",
    "def test_regular_sampler():\n",
    "    print(model_manager.say_raw(\"In my dreams, I'm a dragon\", 50, 0.7))\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e9e10-b2eb-421a-9948-dc3590e1f46d",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Model is put in training mode and we begin training. The `train_results` will contain all data after training is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41750b03-f114-46c4-948e-637db79efe15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db443f0d61e6498badc7fe1f3f12c06b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/awsw/model_utils.py:119: FutureWarning: disable_progress_bar is deprecated and will be removed in the next major version of datasets. Use set_progress_bar_enabled(False) instead.\n",
      "  datasets.utils.disable_progress_bar()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset demo snapshot:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p><msg>c \"You already told me about the four-headed human, so I think I can handle this.\"<|endoftext|><d><scn>black<msg>Br \"Wait for you to... t-throw up so I win?\"<|endoftext|><d><scn>buildingoutside<msg>Ry \"Okay, someone else dropped it.\"<|endoftext|><d><scn>cafe<msg>n \"Despite all odds, I managed to match her perfect score in the game we played.\"<|endoftext|><p><msg>c \"I'd love to, but I can't promise I won't have other obligations\n",
      " at the time.\"<|endoftext|><d><scn>np1r<msg>m \"The Administrator had told me all about the prowess of the generators within. It probably hadn't been hard for Reza to guess the same, or to try stealing it from a place he knew would be even more deserted than the rest of the village was right now.\"<|endoftext|><d><scn>loremapt<msg>Lo \"If humans wear clothes like this, it's only appropriate to depict them as such.\"<|endoftext|><d><scn>black<msg>Lo \"I don't know, exactly. The counter on my\n",
      "[0] set freeze_part_layers: True (freezing 150 out of 160 layers.)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54000' max='54000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54000/54000 4:40:47, Epoch 500/500]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.502000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>2.127700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>2.074800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>2.049900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>2.034200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3240</td>\n",
       "      <td>2.021400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3780</td>\n",
       "      <td>2.012800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4320</td>\n",
       "      <td>2.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4860</td>\n",
       "      <td>2.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>1.996000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5940</td>\n",
       "      <td>1.988600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6480</td>\n",
       "      <td>1.985600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7020</td>\n",
       "      <td>1.981900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7560</td>\n",
       "      <td>1.979200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>1.976800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8640</td>\n",
       "      <td>1.972700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9180</td>\n",
       "      <td>1.971700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9720</td>\n",
       "      <td>1.970500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10260</td>\n",
       "      <td>1.966800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>1.964800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11340</td>\n",
       "      <td>1.964500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11880</td>\n",
       "      <td>1.963500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12420</td>\n",
       "      <td>1.959300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12960</td>\n",
       "      <td>1.958200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>1.958200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14040</td>\n",
       "      <td>1.956300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14580</td>\n",
       "      <td>1.954200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15120</td>\n",
       "      <td>1.955100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15660</td>\n",
       "      <td>1.952400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16200</td>\n",
       "      <td>1.952100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16740</td>\n",
       "      <td>1.952000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17280</td>\n",
       "      <td>1.948600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17820</td>\n",
       "      <td>1.948300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18360</td>\n",
       "      <td>1.947700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18900</td>\n",
       "      <td>1.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19440</td>\n",
       "      <td>1.945400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19980</td>\n",
       "      <td>1.945400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20520</td>\n",
       "      <td>1.944300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21060</td>\n",
       "      <td>1.943400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21600</td>\n",
       "      <td>1.943200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22140</td>\n",
       "      <td>1.942500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22680</td>\n",
       "      <td>1.942500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23220</td>\n",
       "      <td>1.942400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23760</td>\n",
       "      <td>1.941500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24300</td>\n",
       "      <td>1.939800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24840</td>\n",
       "      <td>1.939500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25380</td>\n",
       "      <td>1.939600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25920</td>\n",
       "      <td>1.938400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26460</td>\n",
       "      <td>1.939000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>1.937700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27540</td>\n",
       "      <td>1.938600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28080</td>\n",
       "      <td>1.938200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28620</td>\n",
       "      <td>1.938700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29160</td>\n",
       "      <td>1.935700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29700</td>\n",
       "      <td>1.936300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30240</td>\n",
       "      <td>1.934700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30780</td>\n",
       "      <td>1.934800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31320</td>\n",
       "      <td>1.933500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31860</td>\n",
       "      <td>1.933900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32400</td>\n",
       "      <td>1.933000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32940</td>\n",
       "      <td>1.933700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33480</td>\n",
       "      <td>1.933800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34020</td>\n",
       "      <td>1.932700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34560</td>\n",
       "      <td>1.932400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35100</td>\n",
       "      <td>1.932500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35640</td>\n",
       "      <td>1.930700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36180</td>\n",
       "      <td>1.933100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36720</td>\n",
       "      <td>1.931000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37260</td>\n",
       "      <td>1.932600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37800</td>\n",
       "      <td>1.930300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38340</td>\n",
       "      <td>1.928900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38880</td>\n",
       "      <td>1.930400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39420</td>\n",
       "      <td>1.930700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39960</td>\n",
       "      <td>1.930200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>1.931400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41040</td>\n",
       "      <td>1.929000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41580</td>\n",
       "      <td>1.929800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42120</td>\n",
       "      <td>1.930200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42660</td>\n",
       "      <td>1.929200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43200</td>\n",
       "      <td>1.930200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43740</td>\n",
       "      <td>1.927800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44280</td>\n",
       "      <td>1.929400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44820</td>\n",
       "      <td>1.930600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45360</td>\n",
       "      <td>1.927400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45900</td>\n",
       "      <td>1.928000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46440</td>\n",
       "      <td>1.927600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46980</td>\n",
       "      <td>1.926900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47520</td>\n",
       "      <td>1.929700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48060</td>\n",
       "      <td>1.927300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48600</td>\n",
       "      <td>1.927300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49140</td>\n",
       "      <td>1.928500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49680</td>\n",
       "      <td>1.927000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50220</td>\n",
       "      <td>1.928000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50760</td>\n",
       "      <td>1.928900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51300</td>\n",
       "      <td>1.928000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51840</td>\n",
       "      <td>1.929900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52380</td>\n",
       "      <td>1.927800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52920</td>\n",
       "      <td>1.928800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53460</td>\n",
       "      <td>1.929800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>1.927200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.cuda' has no attribute 'empty_cafche'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_56577/97888722.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/awsw/model_utils.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, tokenizer, params, results)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cafche\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0mtrainer_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAWSWTrainerCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/awsw/model_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, trainer_callback)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cafche\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m     \u001b[0mtrainer_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAWSWTrainerCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.cuda' has no attribute 'empty_cafche'"
     ]
    }
   ],
   "source": [
    "train_results = {}\n",
    "model.train()\n",
    "train_model(model, tokenizer, config, train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c410a601-c5e4-4cc1-af2b-44a7378f3bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f248c4d9460>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "fig.suptitle('Learning rate and loss')\n",
    "axs[0].plot(train_results['learning_rate_history'])\n",
    "axs[1].plot(train_results['loss_history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a578b-32cd-44b9-829b-5aef5ec37ab0",
   "metadata": {
    "id": "unxN7nYd2gOM",
    "tags": []
   },
   "source": [
    "# Testing\n",
    "\n",
    "We created a few past (for context) + present prompts (player input) and see the different reactions. This way, we can test the models across different iterations.\n",
    "The first test involves a old prompt to compare the pre-trained model with the one trained on AWSW. Did it manage to store it's data well? Is it able to write down things that have nothing to do with AWSW? (So we know we didn't overfit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d72d4876-df61-461a-b715-980a3763f092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragon. I was born here in the first place when I was only a little more than a baby. I still have nightmares about my father, and I don't know why.\"<d><scn>loremapt<msg>Lo \"When I was a baby, I didn't have a birth plan. I was just a baby, and I didn't want to do that. It's just a thing.\"<d><scn>loremapt<msg>Lo \"You're not just a baby. You've been given the right to grow up here.\"<d><sc\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f9a94-70c6-4a58-9ad1-3d6ea373dfbe",
   "metadata": {},
   "source": [
    "**This test generates boring and repetetive** replies! It's because we use no good sampling algorithm, but it does give us a indication of what the model has learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b97230c-1d3a-4dd2-a253-727e451d539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"I think he's just a little shy.\"<p><msg>c \"I'm not shy.\"<d><scn>park2<msg>Ad \"I'm not shy.\"<p><msg>c \"I'm not shy.\"<p><msg>c \"I'm not shy.\"<p><msg>c \"\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: facin2<msg>An \"I'm not sure, but I'm not sure if it's a good idea to go to the park, or if I'm just going to sit there and wait for Adine to come back, or if I'm just going to wait for Adine to come back.\"<p><msg>c \"I'm not sure if it's a good idea to go to the park\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: park2<msg>Ry \"I'll see you.\"<p><msg>c \"I'll see you.\"<d><scn>park2<msg>Ry \"I'll see you.\"<|endoftext|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    ('<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hey!\"', \"How are you?\"),\n",
    "    ('<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"', \"What do you think of Lorem?\"),\n",
    "    ('<p><msg>m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('<p><msg>m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "for (past, prompt) in prompts:\n",
    "    reply = model_manager.say(past, prompt)\n",
    "    print(f\"Prompt: {prompt}\\nReply: {reply}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3349bf-c777-4937-a023-ff0f4f21806d",
   "metadata": {},
   "source": [
    "# Sampling test\n",
    "\n",
    "This is gonna be interesting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce4bb65f-e26e-4a62-9c67-aed885fe041d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test 1] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Hey, how are you?\"<|endoftext|>\n",
      "\n",
      "[Test 1] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"Oh, I think Lorem has something to prove.\"<p><msg>c \"I don't know. But I think I can find a lot of ways to help others. I think we need to be patient, too.\"<d><scn>park2<msg>Ad \"Do you have any ideas?\"<p><msg\n",
      "\n",
      "[Test 1] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np2x<msg>Ad \"And now, after a few moments, I'm sure we'll have plenty of time for you, then.\"<d><scn>np2x<msg>m \"I watched the proceedings closely.\"<p><msg>c \"Adine.\"<d><scn>np2x<msg>Ad \"Adine, what are you talking about?\"<p\n",
      "\n",
      "[Test 1] -> Prompt: What will we do here?\n",
      "Reply: np2<msg>Ad \"Well, I'll do what I can, but I'm not sure how much.\"<p><msg>c \"We could use some help, right?\"<d><scn>np2<msg>Ad \"What do you want me to do?\"<p><msg>c \"If we find something, we'll be able to do some work on it.\"<p><msg>c \"You\n",
      "\n",
      "-------------\n",
      "[Test 2] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"You look pretty.\"<p><msg>c \"Are you going to be my guest?\"<d><scn>park2<msg>Ry \"Of course.\"<d><scn>park2<msg>Ry \"I see.\"<|endoftext|>\n",
      "\n",
      "[Test 2] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"He's very smart.\"<p><msg>c \"He's very kind. He's a big fan of Lorem, but he doesn't seem to have much in terms of the people involved.\"<d><scn>park2<msg>Ry \"He was quite nice.\"<p><msg>c \"I was with Lore\n",
      "\n",
      "[Test 2] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>Ry \"The fact that you can't see is a blessing.\"<p><msg>c \"It's so important to me.\"<d><scn>black<msg>Ry \"Of course, you're right. That's why you're here.\"<p><msg>c \"I see. Let's hope you can make it this way.\"<d><scn>black<\n",
      "\n",
      "[Test 2] -> Prompt: What will we do here?\n",
      "Reply: park3<msg>Ad \"It's an interesting question. I don't know whether to be angry or not.\"<d><scn>park3<msg>Ad \"Well, it's a pretty interesting world. If you don't mind, we could probably take it from here.\"<p><msg>c \"Sure, I'm sorry. I'm just going to make a trip.\"<d><scn>park3<\n",
      "\n",
      "-------------\n",
      "[Test 3] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm good, I'm glad to see you, I'm not a total one.\"<p><msg>c \"You have the same kind of time I've had, that's for sure.\"<d><scn>park2<msg>Ry \"I see.\"<d><scn>park2<msg>Ry \"That's a nice way of saying it.\"\n",
      "\n",
      "[Test 3] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"I'm really proud of what I have, but I have a real problem with this situation. I don't know what it is about him.\"<p><msg>c \"You're talking about me? What do you mean?\"<d><scn>park2<msg>Ry \"I'm talking about me.\"<p><msg\n",
      "\n",
      "[Test 3] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np1n<msg>Ad \"I'm sorry, Adine. How are you?\"<p><msg>c \"I'm just a minute ahead of you, Adine.\"<d><scn>np1n<msg>Ad \"What do you want to do?\"<p><msg>c \"I don't know.\"<d><scn>np1n<msg>m \"\n",
      "\n",
      "[Test 3] -> Prompt: What will we do here?\n",
      "Reply: np1n<msg>m \"We were about to leave.\"<d><scn>np1n<msg>m \"I could smell her scent on the floor, and she was getting stronger and more intense. She spoke with her for a while.\"<d><scn>np1n<msg>m \"I could smell her scent on the floor, and she was getting stronger and more intense.\"<d><scn\n",
      "\n",
      "-------------\n",
      "[Test 4] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm fine, thanks.\"<p><msg>c \"Thanks for coming out here.\"<d><scn>park2<msg>Ry \"I appreciate you coming by.\"<d><scn>park2<msg>Ry \"How are you?\"<|endoftext|>\n",
      "\n",
      "[Test 4] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"I guess he wasn't the one who got in trouble.\"<p><msg>c \"I'm not sure. He is an excellent actor.\"<d><scn>park2<msg>m \"After a few minutes, I realized that I didn't really have the time to waste.\"<d><scn>park2<\n",
      "\n",
      "[Test 4] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np1n<msg>m \"He smiled, and his voice was so strong, he said he could speak.\"<d><scn>np1n<msg>m \"I couldn't get a good look at him. I was too scared to put a fight here, but I couldn't get the words out, either.\"<d><scn>np1n<msg>m \"Adine\n",
      "\n",
      "[Test 4] -> Prompt: What will we do here?\n",
      "Reply: o2<msg>Ad \"You're right, I can't wait to make it for your wedding.\"<d><scn>o2<msg>Ad \"What do you want me to say?\"<p><msg>c \"That's just not what I'm going to do.\"<d><scn>o2<msg>Ad \"I think I'm going to make it. I have to go.\"<p><\n",
      "\n",
      "-------------\n",
      "[Test 5] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Hey, Remy, can you make us some coffee?\"<p><msg>c \"Sure.\"<d><scn>park2<msg>Ry \"Okay.\"<p><msg>c \"Thanks for helping us out.\"<|endoftext|>\n",
      "\n",
      "[Test 5] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"I like Lorem.\"<p><msg>c \"I guess Lorem isn't so different.\"<d><scn>park2<msg>Ad \"Sure, but that's the only way I can get back to her.\"<p><msg>c \"That's what I like.\"<d><scn>park2\n",
      "\n",
      "[Test 5] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np2x<msg>Ad \"Adine's a very good friend of mine, but he's not really one of our kind.\"<d><scn>np2x<msg>m \"We started down the hill and found the trees that connected with the ground.\"<p><msg>c \"I can't believe Adine would actually have found these things. I saw him right here. I think\n",
      "\n",
      "[Test 5] -> Prompt: What will we do here?\n",
      "Reply: cafe<msg>Ad \"I can't believe I'm talking to a guy who's supposed to be your friend.\"<d><scn>cafe<msg>Ad \"I don't know if it's you or not, but I'm not so sure. You're here to make a living for us.\"<p><msg>c \"I see. What kind of a job do you have?\"<d><scn>\n",
      "\n",
      "-------------\n",
      "[Test 6] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm going to keep going back to your house.\"<p><msg>c \"Thanks for coming over.\"<d><scn>park2<msg>Ry \"You're welcome.\"<|endoftext|>\n",
      "\n",
      "[Test 6] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"I think I would.\"<p><msg>c \"I'll be right with that. What about you?\"<d><scn>park2<msg>Ad \"I don't know.\"<d><scn>park2<msg>m \"We were just discussing the situation, and he was going to take the time to\n",
      "\n",
      "[Test 6] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>An \"I see. Well, I have some more, but that's all.\"<p><msg>c \"I guess I better put this in the box, then.\"<d><scn>black<msg>An \"Oh my god, Adine. What is this?\"<p><msg>c \"This is my office. I don't really have a place to sit around\n",
      "\n",
      "[Test 6] -> Prompt: What will we do here?\n",
      "Reply: park2<msg>Ad \"I'm not sure.\"<p><msg>c \"I don't know.\"<d><scn>park2<msg>Ad \"Do you think it would be easier?\"<p><msg>c \"I don't know.\"<p><msg>c \"Do you think it would be easier to keep your job.\"<d><scn>park2<msg>Ad \"I'm\n",
      "\n",
      "-------------\n",
      "[Test 7] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I am a bit tired, but I think you should come back a little later.\"<p><msg>c \"Alright, let's do this.\"<d><scn>park2<msg>Ry \"We should get going now.\"<|endoftext|>\n",
      "\n",
      "[Test 7] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"That's right, I'm not sure. I'd have to have done it myself, but that's the least I could do.\"<d><scn>park2<msg>Ry \"I guess Lorem was right about this. I've never heard that before.\"<d><scn>park2<msg>Ry \"I\n",
      "\n",
      "[Test 7] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: facin2<msg>An \"Adine's a big fan of the city, and she thinks it's one of the best parks.\"<p><msg>c \"Adine's a big fan of the city.\"<d><scn>facin2<msg>An \"Adine's a big fan of the city, and she thinks it's one of the best parks on earth.\"<p\n",
      "\n",
      "[Test 7] -> Prompt: What will we do here?\n",
      "Reply: park3<msg>Ad \"I don't know.\"<p><msg>c \"What do you mean?\"<d><scn>park3<msg>Ad \"I'm sorry, but I don't know how long I can be here.\"<p><msg>c \"What do you mean?\"<d><scn>park3<msg>Ad \"I can't talk to you for a while.\"<p><\n",
      "\n",
      "-------------\n",
      "[Test 8] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm still here, so I guess it won't be too long.\"<|endoftext|>\n",
      "\n",
      "[Test 8] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I don't know, but I do.\"<p><msg>c \"I'm glad. It's my turn now.\"<p><msg>c \"I'm glad.\"<d><scn>park2<msg>Ry \"I think you should come and talk to me about this.\"<p><msg>c \"Well\n",
      "\n",
      "[Test 8] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: park2<msg>Ry \"We are all part of the same plan.\"<p><msg>c \"I see. You're right. The plan of the meeting was to have it all, so you could stay at home, stay at home, and go to the park. You could do that.\"<d><scn>park2<msg>Ry \"I see. I'd like to be the\n",
      "\n",
      "[Test 8] -> Prompt: What will we do here?\n",
      "Reply: park2<msg>m \"I had a hard time to get the results off. I was still not able to find the exact time I needed to get to that point, so I went to work on it.\"<d><scn>park2<msg>Ry \"I'm not sure why, but it was a lot easier.\"<p><msg>c \"I think it was pretty simple. It was a job for a couple\n",
      "\n",
      "-------------\n",
      "[Test 9] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"What's going on with the water?\"<|endoftext|>\n",
      "\n",
      "[Test 9] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"He's an angel. I think that's enough for today.\"<p><msg>c \"I'm just glad you can get back to normal.\"<d><scn>park2<msg>Ry \"He's an angel.\"<d><scn>park2<msg>Ry \"He's an angel.\"<p><\n",
      "\n",
      "[Test 9] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: facin2<msg>An \"I see.\"<p><msg>c \"This was your turn. I was waiting for you, Adine.\"<d><scn>facin2<msg>An \"Adine was not interested in Adine's side of the story. He wanted to know more about her. He also wanted to know about his trip to the city. Adine and Adine\n",
      "\n",
      "[Test 9] -> Prompt: What will we do here?\n",
      "Reply: park2<msg>m \"I was in the kitchen, and the sun was shining. It was cold and rainy outside. I could see the water streaming through the door.\"<d><scn>park2<msg>m \"I saw the sun rise over the room, and it was a warm afternoon. I wondered how long I'd been here.\"<d><scn>park2<msg>m \"We were just getting\n",
      "\n",
      "-------------\n",
      "[Test 10] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I know, but I'm still here to help.\"<p><msg>c \"Thanks for all your help, buddy.\"<p><msg>c \"You were a nice one.\"<d><scn>park2<msg>Ry \"I'm so glad you can help.\"<d\n",
      "\n",
      "[Test 10] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I think I prefer Lorem.\"<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ry \"I was with Lorem today.\"<p><msg>c \"Very nice.\"<d><scn>park2<msg>Ry \"I was with Lorem today\n",
      "\n",
      "[Test 10] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: o2<msg>Ad \"And this is the same place where the kids from the neighborhood are kept. I don't even know how to open the door, so I don't know where to start.\"<p><msg>c \"That's it, Adine. I just have to get used to being in that part of town.\"<d><scn>o2<msg>Ad \"Adine\n",
      "\n",
      "[Test 10] -> Prompt: What will we do here?\n",
      "Reply: park3<msg>Sb \"You'll be at the office in the next hour.\"<d><scn>park3<msg>m \"I'm waiting for the door to open.\"<p><msg>c \"I'm waiting for the door to close.\"<d><scn>park3<msg>m \"It was a pleasure to meet you.\"<p><msg>c \"I'm Anna, right?\"\n",
      "\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = model_manager.say(past, prompt, top_k = 50, top_p = 0.7)\n",
    "        print(f\"[Test {i + 1}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c956842-43ba-4f9a-937a-13fda9ad1439",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RP test\n",
    "Testing out the injected roleplay actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85435494-6b29-4b18-aa34-328e33caa9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visit Lorem -> facin2<msg>Lo \"Hey, I just got back from my trip with my kids and the news that they have been expelled from the university. I'm going to give them a real first impression, since I know they're not as lucky as they say.\"<|endoftext|>\n",
      "Meet with Lorem -> facin2<msg>Lo \"Hi, [player_name]. I'm Lorem, from the sound of things.\"<|endoftext|>\n",
      "Visit Adine -> facin2<msg>An \"Oh, and you can just look me up at the top of my head.\"<|endoftext|>\n",
      "Fight Maverick -> loremapt<msg>m \"He made his first foray into the dark.\"<|endoftext|>\n",
      "Fight Adine -> emeraroom<msg>Em \"You're the most important person in the universe.\"<d><scn>emeraroom<msg>Em \"You're the most important person in the universe, right?\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "test_rps = [\n",
    "    \"Visit Lorem\",\n",
    "    \"Meet with Lorem\",\n",
    "    \"Visit Adine\",\n",
    "    \"Fight Maverick\",\n",
    "    \"Fight Adine\"\n",
    "]\n",
    "for rp in test_rps:\n",
    "    print(f'{rp} -> {model_manager.say(\"\", rp, top_k = 50, top_p = 0.7)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a45d066-65b8-44d0-b95b-98f4a2b084c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
