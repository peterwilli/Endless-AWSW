{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b97b376-9ac5-4c70-ba13-769649099a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_utils import train_model, split_data, split_branches, get_model, set_pretrained_model_dropout, get_dataset\n",
    "from config import Config\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from model_manager import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887d9f81-96c3-408f-bd1c-7b126becc4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use cuda:0 for training with seed: 3218885689\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randint(0, 2 ** 32 - 1)\n",
    "seed = 3218885689\n",
    "random.seed(seed)\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(f\"Will use {device_name} for training with seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e95113e-dfc1-40a9-a39b-5d56f3bf32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(os.path.join(Config.work_dir, \"awsw_story_input.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb65c62-47c6-4d36-bd1e-2adfef8ff1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lr\": 6e-4,\n",
    "    \"warmup_factor\": 0,\n",
    "    \"scheduler\": \"polynomial_decay_schedule_with_warmup\",\n",
    "    \"lr_end\": 2e-6,\n",
    "    \"power\": 0.6,\n",
    "    #\"freeze_layer_rate\": 1e-4,\n",
    "    \"freeze_from_steps\": -1,\n",
    "    \"seed\": seed,\n",
    "    \"num_epoch\": 500\n",
    "}\n",
    "\n",
    "optuna_result_attachement = {\n",
    "    'lr': 0.001,\n",
    "    'scheduler': 'cosine_schedule_with_warmup',\n",
    "    'to_freeze_count': 140,\n",
    "    #\"to_freeze_gpt_blocks\": 11,\n",
    "    'warmup_factor': 1\n",
    "}\n",
    "config.update(optuna_result_attachement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ffae5b-e197-4417-a4cd-e6befc6ee393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded empty model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_path = os.path.join(\"models\", \"awsw_main\")\n",
    "if os.path.exists(os.path.join(saved_model_path, \"pytorch_model.bin\")):\n",
    "    print(\"Pretrained model loaded\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "    model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "else:\n",
    "    print(\"Loaded empty model\")\n",
    "    model, tokenizer = get_model(\"EleutherAI/gpt-neo-125M\")\n",
    "model.to(device)\n",
    "# set_pretrained_model_dropout(model.transformer.h[-1:], 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f3315-8f5d-4101-8e7e-2c0129204c94",
   "metadata": {},
   "source": [
    "# Test before training on a pretrained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f68c3f1-4c0a-41a2-a3fc-b8b3c36e418c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragonfly with an incredibly large, massive dragonfly, and I was very happy to see the world around me grow!\n",
      "\n",
      "I've been growing dragonflies since I was a kid, and my dragonfly wings were a blast. I'm still a dragonfly in a lot of ways, and I think I've learned to fly a lot. I love the big, strong dragonfly wings and I think they're the most beautiful thing I've ever seen. I love the beautiful dragonfly wings! I've also had to learn how to fly my dragonfly wings a lot, and I love how\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model_manager = ModelManager(model=model, tokenizer=tokenizer, device=device)\n",
    "def test_regular_sampler():\n",
    "    print(model_manager.say_raw(\"In my dreams, I'm a dragon\", 50, 0.7))\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f74aa-5030-4ffd-ad2f-ae013647975e",
   "metadata": {},
   "source": [
    "# Reviewing our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0974ac13-c420-4275-b34a-3816f580cb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04182f777d3b400694f628e177bd906a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset demo snapshot:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p><msg>c \"Essentially, a blemmyes is a human without a head.\"<|endoftext|><p><msg>c \"Ugh, this is some really strong stuff.\"<|endoftext|><d><scn>loremapt<msg>Ip \"Now, what happens when we approach the edge and walk over it is that we are teleported to the opposite side.\"<|endoftext|><d><scn>black<msg>n \"She froze to death during the cold winter night.\"<|endoftext|><d><scn>park2<msg>Ry \"To think that just a few years ago I was the\n",
      " happiest I could've been. And now, I have nothing but my miserable life.\"<|endoftext|><p><msg>c \"You could try it if you like.\"<|endoftext|><d><scn>black<msg>m \"It was a little bland, I had to admit, but not bad for something that was alive less than an hour ago, and prepared in the wild.\"<|endoftext|><p><msg>c \"The bedroom here is nothing special, I can assure you of that.\"<|endoftext|><d><scn>cafe<msg>An \"I still could have calculated that.\"<|endoftext|>soon\" now refers to a time\n",
      "RP review!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facin3<msg>Lo \"Hey, [player_name]!\"<|endoftext|><d><scn>park2<msg>Ry \"There must be a lot on your mind too.\"<|endoftext|><d><scn>facin2<msg>m \"Bryce nodded.\"<|endoftext|><p><msg>c \"Like an animal.\"<|endoftext|><p><msg>c \"Fight Remy\"<d><scn>facin2<msg>m \"I didn't hesitate and kicked Remy right in the stomach\"<|endoftext|><d><scn>o2<msg>Ad \"Well, go ahead, then\n",
      ".\"<|endoftext|><p><msg>c \"No fitting me in during your break, no complaining about everything, and no acting as if you're doing me a favor, especially because it was you who wanted to meet me in the first place.\"<|endoftext|><p><msg>c \"...\"<d><scn>o2<msg>Br \"...\"<|endoftext|><p><msg>c \"I'll try.\"<|endoftext|><p><msg>c \"(Well, here goes nothing.)\"<|endoftext|><p><msg>c \"Does this mean we get teleported to the other side, like in video games?\"<d><sc\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(tokenizer)\n",
    "print(\"Dataset demo snapshot:\")\n",
    "demo_idx = 0\n",
    "for item in dataset['train']:\n",
    "    print(tokenizer.decode(item['input_ids']))\n",
    "    if demo_idx > 0:\n",
    "        break\n",
    "    demo_idx += 1\n",
    "\n",
    "print(\"RP review!\")\n",
    "has_seen_rp = False\n",
    "for item in dataset['train']:\n",
    "    decoded = tokenizer.decode(item['input_ids'])\n",
    "    if 'c \"Fight ' in decoded: \n",
    "        print(decoded)\n",
    "        has_seen_rp = True\n",
    "        continue        \n",
    "    if has_seen_rp:\n",
    "        print(decoded)\n",
    "        break\n",
    "        \n",
    "del demo_idx, has_seen_rp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e9e10-b2eb-421a-9948-dc3590e1f46d",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Model is put in training mode and we begin training. The `train_results` will contain all data after training is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41750b03-f114-46c4-948e-637db79efe15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] set freeze_part_layers: True (freezing 140 out of 160 layers.)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54000' max='54000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54000/54000 4:46:39, Epoch 499/500]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.400700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.544100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.402900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>0.359100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.331500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3240</td>\n",
       "      <td>0.314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3780</td>\n",
       "      <td>0.305000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4320</td>\n",
       "      <td>0.297500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4860</td>\n",
       "      <td>0.292500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.288400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5940</td>\n",
       "      <td>0.283500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6480</td>\n",
       "      <td>0.281500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7020</td>\n",
       "      <td>0.278900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7560</td>\n",
       "      <td>0.275500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.273500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8640</td>\n",
       "      <td>0.271700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9180</td>\n",
       "      <td>0.270100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9720</td>\n",
       "      <td>0.268000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10260</td>\n",
       "      <td>0.267100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.265800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11340</td>\n",
       "      <td>0.264900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11880</td>\n",
       "      <td>0.262800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12420</td>\n",
       "      <td>0.261600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12960</td>\n",
       "      <td>0.260400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.259000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14040</td>\n",
       "      <td>0.258700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14580</td>\n",
       "      <td>0.257400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15120</td>\n",
       "      <td>0.256500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15660</td>\n",
       "      <td>0.255400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16200</td>\n",
       "      <td>0.254900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16740</td>\n",
       "      <td>0.254300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17280</td>\n",
       "      <td>0.253600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17820</td>\n",
       "      <td>0.252700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18360</td>\n",
       "      <td>0.252500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18900</td>\n",
       "      <td>0.251800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19440</td>\n",
       "      <td>0.250600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19980</td>\n",
       "      <td>0.249900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20520</td>\n",
       "      <td>0.249100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21060</td>\n",
       "      <td>0.249000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21600</td>\n",
       "      <td>0.248600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22140</td>\n",
       "      <td>0.247700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22680</td>\n",
       "      <td>0.247100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23220</td>\n",
       "      <td>0.246500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23760</td>\n",
       "      <td>0.245500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24300</td>\n",
       "      <td>0.245900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24840</td>\n",
       "      <td>0.245200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25380</td>\n",
       "      <td>0.245100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25920</td>\n",
       "      <td>0.244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26460</td>\n",
       "      <td>0.244200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.243500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27540</td>\n",
       "      <td>0.242800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28080</td>\n",
       "      <td>0.242500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28620</td>\n",
       "      <td>0.242000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29160</td>\n",
       "      <td>0.241500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29700</td>\n",
       "      <td>0.241800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30240</td>\n",
       "      <td>0.240500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30780</td>\n",
       "      <td>0.240100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31320</td>\n",
       "      <td>0.239800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31860</td>\n",
       "      <td>0.239700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32400</td>\n",
       "      <td>0.239100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32940</td>\n",
       "      <td>0.238700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33480</td>\n",
       "      <td>0.238300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34020</td>\n",
       "      <td>0.238200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34560</td>\n",
       "      <td>0.237100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35100</td>\n",
       "      <td>0.237400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35640</td>\n",
       "      <td>0.237000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36180</td>\n",
       "      <td>0.236800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36720</td>\n",
       "      <td>0.236400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37260</td>\n",
       "      <td>0.235900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37800</td>\n",
       "      <td>0.236100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38340</td>\n",
       "      <td>0.235500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38880</td>\n",
       "      <td>0.235400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39420</td>\n",
       "      <td>0.234900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39960</td>\n",
       "      <td>0.234400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>0.234100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41040</td>\n",
       "      <td>0.233800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41580</td>\n",
       "      <td>0.233500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42120</td>\n",
       "      <td>0.233400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42660</td>\n",
       "      <td>0.233100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43200</td>\n",
       "      <td>0.233200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43740</td>\n",
       "      <td>0.232800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44280</td>\n",
       "      <td>0.231900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44820</td>\n",
       "      <td>0.232900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45360</td>\n",
       "      <td>0.232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45900</td>\n",
       "      <td>0.232100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46440</td>\n",
       "      <td>0.231400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46980</td>\n",
       "      <td>0.231700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47520</td>\n",
       "      <td>0.231700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48060</td>\n",
       "      <td>0.231300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48600</td>\n",
       "      <td>0.231100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49140</td>\n",
       "      <td>0.231100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49680</td>\n",
       "      <td>0.231200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50220</td>\n",
       "      <td>0.231300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50760</td>\n",
       "      <td>0.230500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51300</td>\n",
       "      <td>0.230700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51840</td>\n",
       "      <td>0.230800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52380</td>\n",
       "      <td>0.231200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52920</td>\n",
       "      <td>0.230700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53460</td>\n",
       "      <td>0.231100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.231100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results = {}\n",
    "model.train()\n",
    "train_model(model, tokenizer, dataset, config, train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c410a601-c5e4-4cc1-af2b-44a7378f3bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd26e09f400>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "fig.suptitle('Learning rate and loss')\n",
    "axs[0].plot(train_results['learning_rate_history'])\n",
    "axs[1].plot(train_results['loss_history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a578b-32cd-44b9-829b-5aef5ec37ab0",
   "metadata": {
    "id": "unxN7nYd2gOM",
    "tags": []
   },
   "source": [
    "# Testing\n",
    "\n",
    "We created a few past (for context) + present prompts (player input) and see the different reactions. This way, we can test the models across different iterations.\n",
    "The first test involves a old prompt to compare the pre-trained model with the one trained on AWSW. Did it manage to store it's data well? Is it able to write down things that have nothing to do with AWSW? (So we know we didn't overfit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d72d4876-df61-461a-b715-980a3763f092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragon.\"<d><scn>o2<msg>Ad \"That's a hard one. I mean, no one would see my flying then, and I do want people to see that.\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f9a94-70c6-4a58-9ad1-3d6ea373dfbe",
   "metadata": {},
   "source": [
    "**This test generates boring and repetetive** replies! It's because we use no good sampling algorithm, but it does give us a indication of what the model has learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b97230c-1d3a-4dd2-a253-727e451d539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Th-the summer festival is coming soon. It's an event we hold in town every year.\"<d><scn>park2<msg>Ry \"They've got fireworks and all kinds of shows.\"<d><scn>park2<msg>Ry \"It might be fun for you to experience a different part of our culture.\"<d><scn>park2\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I see.\"<p><msg>c \"I was just asking a question, that's all.\"<d><scn>park2<msg>Ry \"Well, what do you think of it?\"<p><msg>c \"It's pretty idyllic.\"<d><scn>park2<msg>Ry \"\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np1x<msg>Sb \"It's broken.\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: facin2<msg>An \"I don't know where you are going, but I think I need a coffee or five. You can tag along if you like.\"<p><msg>c \"I think I'd rather not.\"<d><scn>facin2<msg>An \"Suit yourself.\"<d><scn>facin2<msg>n \"Whatever the reason, I decided not to join her\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    ('<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hey!\"', \"How are you?\"),\n",
    "    ('<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"', \"What do you think of Lorem?\"),\n",
    "    ('<p><msg>m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('<p><msg>m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "for (past, prompt) in prompts:\n",
    "    reply = model_manager.say(past, prompt)\n",
    "    print(f\"Prompt: {prompt}\\nReply: {reply}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3349bf-c777-4937-a023-ff0f4f21806d",
   "metadata": {},
   "source": [
    "# Sampling test\n",
    "\n",
    "This is gonna be interesting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce4bb65f-e26e-4a62-9c67-aed885fe041d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test 1] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Th-the summer festival is coming soon. It's an event we hold in town every year.\"<d><scn>park2<msg>Ry \"They've got fireworks and all kinds of shows.\"<d><scn>park2<msg>Ry \"It might be fun for you to experience a different part of our culture.\"<d><scn>park2\n",
      "\n",
      "[Test 1] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I see.\"<p><msg>c \"I'm with you on this.\"<p><msg>c \"Okay, but why focus on humans? What makes us so important?\"<d><scn>black<msg>Lo \"If theres one thing that people here love, its humans. It doesn\n",
      "\n",
      "[Test 1] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np1x<msg>Sb \"It's broken.\"<|endoftext|>\n",
      "\n",
      "[Test 1] -> Prompt: What will we do here?\n",
      "Reply: facin2<msg>An \"What are you looking at?\"<p><msg>c \"Your beautiful door. Where have you been all this time?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 2] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Th-the summer festival is coming soon. It's an event we hold in town every year.\"<d><scn>park2<msg>Ry \"They've got fireworks and all kinds of shows.\"<d><scn>park2<msg>Ry \"It might be fun for you to experience a different part of our culture.\"<d><scn>park2\n",
      "\n",
      "[Test 2] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"It is. I like it a lot here.\"<|endoftext|>\n",
      "\n",
      "[Test 2] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np1x<msg>Sb \"It's broken.\"<|endoftext|>\n",
      "\n",
      "[Test 2] -> Prompt: What will we do here?\n",
      "Reply: facin2<msg>An \"What are you looking at?\"<p><msg>c \"Your beautiful door. Where have you been all this time?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 3] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I guess she did try to talk to me, but it was only because she wanted something.\"<|endoftext|>\n",
      "\n",
      "[Test 3] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I see.\"<p><msg>c \"I was just asking a question, that's all.\"<d><scn>park2<msg>Ry \"Yes.\"<|endoftext|>\n",
      "\n",
      "[Test 3] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np1x<msg>Sb \"It's broken.\"<|endoftext|>\n",
      "\n",
      "[Test 3] -> Prompt: What will we do here?\n",
      "Reply: farm<msg>An \"I'll just go ahead and draw the next card, so we can end this.\"<d><scn>farm<msg>An \"I'll just go ahead and draw the next card, so we can end this.\"<d><scn>farm<msg>An \"I'll just go ahead and draw the next card, so we can end this.\"<d><scn>farm<msg>\n",
      "\n",
      "-------------\n",
      "[Test 4] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"My heart was ripped out in that moment, and now only emptiness remains. It's like a wound that never closes.\"<d><scn>park2<msg>Ry \"Maybe you saw those pictures in my apartment.\"<d><scn>park2<msg>Ry \"Even my home is a reminder of her. We were going to move in to that apartment together.\"\n",
      "\n",
      "[Test 4] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I'm not sure. I suppose we would have to work something out between our legal system and whatever humanity has to say on the matter.\"<|endoftext|>\n",
      "\n",
      "[Test 4] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np1x<msg>Sb \"It's broken.\"<|endoftext|>\n",
      "\n",
      "[Test 4] -> Prompt: What will we do here?\n",
      "Reply: farm<msg>An \"I'll just have to be careful.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 5] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"ThITNESS, can you take it from here? You've been just as dedicated to the case as I have. Since I'll have to be at the Minister's side for a while, I'd like you to take charge of the investigation for now.\"<d><scn>np1x<msg>Sb \"Thanks, Chief. I won't let you down.\"<|endoftext|>\n",
      "\n",
      "[Test 5] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I see.\"<p><msg>c \"I did read \"Sheridan and the Scepter of Sovereignty\".\"<d><scn>o2<msg>Ad \"How did you like it?\"<p><msg>c \"It wasn't really my kind of thing.\"<d><scn>o2<\n",
      "\n",
      "[Test 5] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np1x<msg>Sb \"It's broken.\"<|endoftext|>\n",
      "\n",
      "[Test 5] -> Prompt: What will we do here?\n",
      "Reply: facin2<msg>An \"I don't know where you are going, but I think I need a coffee or five. You can tag along if you like.\"<p><msg>c \"It would be my pleasure.\"<d><scn>facin2<msg>An \"We'll see if it'll be mine as well.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 6] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Th-the summer festival is coming soon. It's an event we hold in town every year.\"<d><scn>park2<msg>Ry \"They've got fireworks and all kinds of shows.\"<d><scn>park2<msg>Ry \"It might be fun for you to experience a different part of our culture.\"<d><scn>park2\n",
      "\n",
      "[Test 6] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I see.\"<p><msg>c \"I'm with you on this.\"<p><msg>c \"Okay, but why focus on humans? What makes us so important?\"<d><scn>black<msg>Lo \"If theres one thing that people here love, its humans. It doesn\n",
      "\n",
      "[Test 6] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np1x<msg>Sb \"It's broken.\"<|endoftext|>\n",
      "\n",
      "[Test 6] -> Prompt: What will we do here?\n",
      "Reply: farm<msg>An \"I'll just go ahead and draw the next card, so we can end this.\"<d><scn>farm<msg>An \"I'll just go ahead and draw the next card, so we can end this.\"<d><scn>farm<msg>An \"I'll just go ahead and draw the next card, so we can end this.\"<d><scn>farm<msg>\n",
      "\n",
      "-------------\n",
      "[Test 7] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Th-the summer festival is coming soon. It's an event we hold in town every year.\"<d><scn>park2<msg>Ry \"They've got fireworks and all kinds of shows.\"<d><scn>park2<msg>Ry \"It might be fun for you to experience a different part of our culture.\"<d><scn>park2\n",
      "\n",
      "[Test 7] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I'm not sure. I suppose we would have to work something out between our legal system and whatever humanity has to say on the matter.\"<|endoftext|>\n",
      "\n",
      "[Test 7] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np1x<msg>Sb \"It's broken.\"<|endoftext|>\n",
      "\n",
      "[Test 7] -> Prompt: What will we do here?\n",
      "Reply: farm<msg>An \"I'll have to think about that one for a minute.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 8] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Well, what do you think of it?\"<p><msg>c \"It's nothing special.\"<d><scn>park2<msg>Ry \"I suppose you don't appreciate the simple things, then. I like it here.\"<|endoftext|>\n",
      "\n",
      "[Test 8] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I see.\"<p><msg>c \"I'm with you on this.\"<p><msg>c \"Okay, but why focus on humans? What makes us so important?\"<d><scn>black<msg>Lo \"If theres one thing that people here love, its humans. It doesn\n",
      "\n",
      "[Test 8] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np1x<msg>Sb \"It's broken.\"<|endoftext|>\n",
      "\n",
      "[Test 8] -> Prompt: What will we do here?\n",
      "Reply: facin2<msg>An \"I don't know where you are going, but I think I need a coffee or five. You can tag along if you like.\"<p><msg>c \"It would be my pleasure.\"<d><scn>facin2<msg>An \"We'll see if it'll be mine as well.\"<p><msg>c \"So, where are we going?\"<d><sc\n",
      "\n",
      "-------------\n",
      "[Test 9] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"My heart was ripped out in that moment, and now only emptiness remains. It's like a wound that never closes.\"<d><scn>park2<msg>Ry \"Maybe you saw those pictures in my apartment.\"<d><scn>park2<msg>Ry \"Even my home is a reminder of her. We were going to move in to that apartment together.\"\n",
      "\n",
      "[Test 9] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I see.\"<p><msg>c \"I was able to make use of that.\"<d><scn>town4<msg>Ad \"Oh, guess who got her entry confirmation for the stunt flying competition!\"<p><msg>c \"You did?\"<d><scn>town4<msg>Ad \"That\n",
      "\n",
      "[Test 9] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np1x<msg>Sb \"It's broken.\"<|endoftext|>\n",
      "\n",
      "[Test 9] -> Prompt: What will we do here?\n",
      "Reply: facin2<msg>An \"I don't know where you are going, but I think I need a coffee or five. You can tag along if you like.\"<p><msg>c \"Sure, why not.\"<d><scn>facin2<msg>An \"Now that's a convincing reason.\"<p><msg>c \"So, where are we going?\"<d><scn>facin2\n",
      "\n",
      "-------------\n",
      "[Test 10] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I guess she did try to talk to me, but it was only because she wanted something.\"<|endoftext|>\n",
      "\n",
      "[Test 10] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I see.\"<p><msg>c \"I did read \"Sheridan and the Scepter of Sovereignty\".\"<d><scn>o2<msg>Ad \"How did you like it?\"<p><msg>c \"It was entertaining, but nothing special.\"<d><scn>o2<msg\n",
      "\n",
      "[Test 10] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np1x<msg>Sb \"It's broken.\"<|endoftext|>\n",
      "\n",
      "[Test 10] -> Prompt: What will we do here?\n",
      "Reply: facin2<msg>An \"I don't know where you are going, but I think I need a coffee or five. You can tag along if you like.\"<p><msg>c \"It would be my pleasure.\"<d><scn>facin2<msg>An \"We'll see if it'll be mine as well.\"<p><msg>c \"So, where are we going?\"<d><sc\n",
      "\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = model_manager.say(past, prompt, top_k = 50, top_p = 0.7)\n",
    "        print(f\"[Test {i + 1}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c956842-43ba-4f9a-937a-13fda9ad1439",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RP test\n",
    "Testing out the injected roleplay actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85435494-6b29-4b18-aa34-328e33caa9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visit Lorem -> loremapt<msg>Lo \"Oh, [player_name], I wasn't expecting visitors.\"<|endoftext|>\n",
      "Meet with Lorem -> loremapt<msg>Lo \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "Visit Adine -> adineapt<msg>Ad \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "Fight Maverick -> park3<msg>m \"Maverick barely avoids my attack and fell, but managed to get up and quickly punch me in the face, a soaring pain quickly came over my face\"<|endoftext|>\n",
      "Fight Adine -> o2<msg>m \"Adine dodges my attack and comes rushing towards me\"<|endoftext|>\n",
      "Attack Adine -> beach<msg>m \"Adine dodges my attack and comes rushing towards me\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "test_rps = [\n",
    "    \"Visit Lorem\",\n",
    "    \"Meet with Lorem\",\n",
    "    \"Visit Adine\",\n",
    "    \"Fight Maverick\",\n",
    "    \"Fight Adine\",\n",
    "    \"Attack Adine\"\n",
    "]\n",
    "for rp in test_rps:\n",
    "    print(f'{rp} -> {model_manager.say(\"\", rp, top_k = 50, top_p = 0.7)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
