{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b97b376-9ac5-4c70-ba13-769649099a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_utils import train_model, split_data, split_branches, get_model, set_pretrained_model_dropout\n",
    "from config import Config\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from model_manager import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887d9f81-96c3-408f-bd1c-7b126becc4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use cuda:0 for training with seed: 3218885689\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randint(0, 2 ** 32 - 1)\n",
    "seed = 3218885689\n",
    "random.seed(seed)\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(f\"Will use {device_name} for training with seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e95113e-dfc1-40a9-a39b-5d56f3bf32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(os.path.join(Config.work_dir, \"awsw_story_input.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb65c62-47c6-4d36-bd1e-2adfef8ff1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lr\": 6e-4,\n",
    "    \"warmup_factor\": 0,\n",
    "    \"scheduler\": \"polynomial_decay_schedule_with_warmup\",\n",
    "    \"lr_end\": 2e-6,\n",
    "    \"power\": 0.6,\n",
    "    #\"freeze_layer_rate\": 1e-4,\n",
    "    \"freeze_from_steps\": -1,\n",
    "    \"seed\": seed,\n",
    "    \"num_epoch\": 100\n",
    "}\n",
    "\n",
    "optuna_result_attachement = {\n",
    "    'lr': 0.001,\n",
    "    'scheduler': 'cosine_schedule_with_warmup',\n",
    "    'to_freeze_count': 157,\n",
    "    #\"to_freeze_gpt_blocks\": 11,\n",
    "    'warmup_factor': 1\n",
    "}\n",
    "config.update(optuna_result_attachement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ffae5b-e197-4417-a4cd-e6befc6ee393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded empty model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_path = os.path.join(\"models\", \"awsw_main\")\n",
    "if os.path.exists(os.path.join(saved_model_path, \"pytorch_model.bin\")):\n",
    "    print(\"Pretrained model loaded\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "    model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "else:\n",
    "    print(\"Loaded empty model\")\n",
    "    model, tokenizer = get_model(\"EleutherAI/gpt-neo-125M\")\n",
    "model.to(device)\n",
    "# set_pretrained_model_dropout(model.transformer.h[-1:], 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f3315-8f5d-4101-8e7e-2c0129204c94",
   "metadata": {},
   "source": [
    "# Test before training on a pretrained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f68c3f1-4c0a-41a2-a3fc-b8b3c36e418c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you? I'm going to be honest, I'm a little tired of this, I'm tired of this, and I'm going to be honest with you, I'm going to be honest with you, and I'm going to be honest with you, and I'm going to be honest with you, and I'm going to be honest with you, and I'm going to be honest with you, and I'm going to be honest with you, and I'm going to be honest with you, and I'm going to be honest with you, and I'm going to be honest with you, and I'm going\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model_manager = ModelManager(model=model, tokenizer=tokenizer)\n",
    "def test_regular_sampler():\n",
    "    print(model_manager.say_raw(\"How are you? I'm\", 50, 0.7))\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e9e10-b2eb-421a-9948-dc3590e1f46d",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Model is put in training mode and we begin training. The `train_results` will contain all data after training is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41750b03-f114-46c4-948e-637db79efe15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset text/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/awsw-dev/.cache/huggingface/datasets/text/default-bb7269ada5f39e1e/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset text downloaded and prepared to /home/awsw-dev/.cache/huggingface/datasets/text/default-bb7269ada5f39e1e/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset demo snapshot:\n",
      "<d><scn>loremapt<msg>Ip \"I work in the facility as a biologist with a minor in physics.\"<|endoftext|><d><scn>np1n<msg>Mv \"She killed them, and you protect her?\"<|endoftext|><d><scn>emeraroom<msg>Em \"Let me ask you one thing, [player_name]: Do you enjoy your work as ambassador?\"<|endoftext|><d><scn>cafe<msg>An \"You bet I will. In any case, I should get going now. My \"<|endoftext|><d><scn>be\n",
      "ach<msg>m \"Once more, Adine took to the sky to hunt for fish. While it was interesting to watch her for a bit, she kept hunting for a while, and I started passing the time by collecting some seashells.\"<|endoftext|><p><msg>c \"Err...\"<|endoftext|><d><scn>black<msg>Ry \"I don't know. I suppose you have a point.\"<|endoftext|><p><msg>c \"No problem.\"<|endoftext|><p><msg>c \"See you soon, then?\"<d><scn>cafe<msg>An \"Of course.\n",
      "[0] set freeze_part_layers: True (freezing 157 out of 160 layers.)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10500' max='10500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10500/10500 46:50, Epoch 99/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>3.844100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.597700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>3.318900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.135300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>3.006200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.908300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>735</td>\n",
       "      <td>2.836200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.773000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>945</td>\n",
       "      <td>2.725200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.687200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1155</td>\n",
       "      <td>2.662300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>2.625300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1365</td>\n",
       "      <td>2.606000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>2.580800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>2.562600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>2.542600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1785</td>\n",
       "      <td>2.527700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>2.509100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>2.497300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.478700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2205</td>\n",
       "      <td>2.471100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2310</td>\n",
       "      <td>2.450300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2415</td>\n",
       "      <td>2.443500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>2.440800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2625</td>\n",
       "      <td>2.427400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2730</td>\n",
       "      <td>2.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2835</td>\n",
       "      <td>2.415700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2940</td>\n",
       "      <td>2.409900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3045</td>\n",
       "      <td>2.398300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>2.412200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3255</td>\n",
       "      <td>2.385800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3360</td>\n",
       "      <td>2.401000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3465</td>\n",
       "      <td>2.382700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3570</td>\n",
       "      <td>2.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3675</td>\n",
       "      <td>2.376700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3780</td>\n",
       "      <td>2.375700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3885</td>\n",
       "      <td>2.373500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3990</td>\n",
       "      <td>2.366300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4095</td>\n",
       "      <td>2.363500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>2.354200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4305</td>\n",
       "      <td>2.364500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4410</td>\n",
       "      <td>2.364700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4515</td>\n",
       "      <td>2.357100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4620</td>\n",
       "      <td>2.352000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4725</td>\n",
       "      <td>2.346700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4830</td>\n",
       "      <td>2.348300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4935</td>\n",
       "      <td>2.344600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5040</td>\n",
       "      <td>2.342400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5145</td>\n",
       "      <td>2.343100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>2.342200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5355</td>\n",
       "      <td>2.347900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5460</td>\n",
       "      <td>2.330700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5565</td>\n",
       "      <td>2.328300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5670</td>\n",
       "      <td>2.345500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5775</td>\n",
       "      <td>2.330200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5880</td>\n",
       "      <td>2.340200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5985</td>\n",
       "      <td>2.334200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6090</td>\n",
       "      <td>2.339700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6195</td>\n",
       "      <td>2.322200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>2.333800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6405</td>\n",
       "      <td>2.329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6510</td>\n",
       "      <td>2.329500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6615</td>\n",
       "      <td>2.326600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6720</td>\n",
       "      <td>2.334500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6825</td>\n",
       "      <td>2.316600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6930</td>\n",
       "      <td>2.326600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7035</td>\n",
       "      <td>2.335600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7140</td>\n",
       "      <td>2.317500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7245</td>\n",
       "      <td>2.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7350</td>\n",
       "      <td>2.334200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7455</td>\n",
       "      <td>2.310200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7560</td>\n",
       "      <td>2.315500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7665</td>\n",
       "      <td>2.327800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7770</td>\n",
       "      <td>2.326800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7875</td>\n",
       "      <td>2.326300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7980</td>\n",
       "      <td>2.317300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8085</td>\n",
       "      <td>2.315700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8190</td>\n",
       "      <td>2.321900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8295</td>\n",
       "      <td>2.316300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>2.316400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8505</td>\n",
       "      <td>2.317600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8610</td>\n",
       "      <td>2.330400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8715</td>\n",
       "      <td>2.306700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8820</td>\n",
       "      <td>2.328900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8925</td>\n",
       "      <td>2.323900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9030</td>\n",
       "      <td>2.304800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9135</td>\n",
       "      <td>2.332400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9240</td>\n",
       "      <td>2.312600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9345</td>\n",
       "      <td>2.311600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9450</td>\n",
       "      <td>2.325100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9555</td>\n",
       "      <td>2.318800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9660</td>\n",
       "      <td>2.314000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9765</td>\n",
       "      <td>2.304800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9870</td>\n",
       "      <td>2.328600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9975</td>\n",
       "      <td>2.317400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10080</td>\n",
       "      <td>2.319400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10185</td>\n",
       "      <td>2.315100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10290</td>\n",
       "      <td>2.317600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10395</td>\n",
       "      <td>2.314300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>2.310800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results = {}\n",
    "model.train()\n",
    "train_model(model, tokenizer, config, train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c410a601-c5e4-4cc1-af2b-44a7378f3bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fba3f7401f0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "fig.suptitle('Learning rate and loss')\n",
    "axs[0].plot(train_results['learning_rate_history'])\n",
    "axs[1].plot(train_results['loss_history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a578b-32cd-44b9-829b-5aef5ec37ab0",
   "metadata": {
    "id": "unxN7nYd2gOM",
    "tags": []
   },
   "source": [
    "# Testing\n",
    "\n",
    "We created a few past (for context) + present prompts (player input) and see the different reactions. This way, we can test the models across different iterations.\n",
    "The first test involves a old prompt to compare the pre-trained model with the one trained on AWSW. Did it manage to store it's data well? Is it able to write down things that have nothing to do with AWSW? (So we know we didn't overfit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d72d4876-df61-461a-b715-980a3763f092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you? I'm wondering if you're going to stay in this hotel, or if you want to come and go around for a few days.\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f9a94-70c6-4a58-9ad1-3d6ea373dfbe",
   "metadata": {},
   "source": [
    "**This test generates boring and repetetive** replies! It's because we use no good sampling algorithm, but it does give us a indication of what the model has learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b97230c-1d3a-4dd2-a253-727e451d539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Hey!\"<p><msg>c \"Hey!\"<d><scn>park2<msg>Ry \"Hey!\"<p><msg>c \"Hey!\"<d><scn>park2<msg>Ry \"Hey!\"<p><msg>c \"Hey!\"<d><scn>park2<msg>Ry \"Hey!\"<p><msg>\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"I think it's a good idea.\"<d><scn>park2<msg>Ad \"I think it's a good idea.\"<d><scn>park2<msg>Ad \"I think it's a good idea.\"<d><scn>park2<msg>Ad \"I think it's a good idea\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: c \"I'm not sure. I'm not sure what I should do.\"<d><scn>c \"I'm not sure what I should do.\"<d><scn>c \"I'm not sure what I should do.\"<d><scn>c \"I'm not sure what I should do.\"<d><scn>c \"I'm not sure what I should do.\"<\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: c \"I'm not sure. I'm not sure what I should do.\"<d><scn>c \"I'm not sure what I should do.\"<d><scn>c \"I'm not sure what I should do.\"<d><scn>c \"I'm not sure what I should do.\"<d><scn>c \"I'm not sure what I should do.\"<d><scn>c\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    ('<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hey!\"', \"How are you?\"),\n",
    "    ('<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"', \"What do you think of Lorem?\"),\n",
    "    ('<p><msg>m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('<p><msg>m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "for (past, prompt) in prompts:\n",
    "    reply = model_manager.say(past, prompt)\n",
    "    print(f\"Prompt: {prompt}\\nReply: {reply}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3349bf-c777-4937-a023-ff0f4f21806d",
   "metadata": {},
   "source": [
    "# Sampling test\n",
    "\n",
    "This is gonna be interesting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4bb65f-e26e-4a62-9c67-aed885fe041d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test 1] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Oh, really?\"<d><scn>park2<msg>c \"No, you're in a hurry. Come in here, right?\"<d><scn>park2<msg>c \"So you're here?\"<d><scn>park2<msg>c \"Yeah, I've been around before. I'm just gonna walk around and look at\n",
      "\n",
      "[Test 1] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"Very nice.\"<scn>park2<msg>Ad \"Very nice.\"<scn>park2<msg>Ad \"Very nice.\"<scn>park2<msg>Ad \"Very nice.\"<scn>park2<msg>Ad \"Very nice.\"<scn>park2<msg>Ad \"\n",
      "\n",
      "[Test 1] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>n \"Oh, my god, Adine. What is that?\"<d><scn>black<msg>c \"Oh, I see.\"<p><msg>c \"Oh, that's it.\"<d><scn>black<msg>c \"Oh, I see.\"<d><scn>black<msg>c \"That's why I'm here.\"<\n",
      "\n",
      "[Test 1] -> Prompt: What will we do here?\n",
      "Reply: c \"You'll find out later.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 2] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"You look great.\"<d><scn>park2<msg>Ry \"That's what I wanted to see.\"<d><scn>park2<msg>Ry \"You seem to be quite active.\"<d><scn>park2<msg>Ry \"I'm still the way I am.\"<d><scn>park2<msg>Ry \"\n",
      "\n",
      "[Test 2] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"You're very nice.\"<p><msg>c \"I'm so glad I came here.\"<d><scn>park2<msg>Ad \"I'm so glad I came here.\"<d><scn>park2<msg>Ad \"You're very nice.\"<d><scn>park2<msg>\n",
      "\n",
      "[Test 2] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: \"This is a very important issue, and I'm pretty sure that it's very dangerous.\"<p><msg>c \"What?\"<d><scn>\"<p><msg>c \"It's like this, you know? It's very hard to get in touch with the police if you don't have a clue what's going on.\"<p><msg>c \"Oh my god, Ad\n",
      "\n",
      "[Test 2] -> Prompt: What will we do here?\n",
      "Reply: l \"Well, I've never heard of this, really. I can only imagine how it was when I first got here. You can't know for sure.\"<p><msg>c \"I suppose that makes me seem more likely to be here today.\"<d><scn>l \"Well, maybe not. I've always wanted to go to the office, but I haven't been allowed to go to the office at all. I\n",
      "\n",
      "-------------\n",
      "[Test 3] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm fine.\"<d><scn>park2<msg>Ry \"I'm fine.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park\n",
      "\n",
      "[Test 3] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"I'm so sorry for that.\"<d><scn>park2<msg>Ad \"I'm just going to have to go.\"<p><msg>c \"I didn't do anything.\"<d><scn>park2<msg>Ad \"I didn't think it was a good idea. I was supposed to go\n",
      "\n",
      "[Test 3] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: c \"No, this isn't my room. It's in the basement of the park.\"<d><scn>l \"What do you mean?\"<p><msg>c \"It's like my old room. I can't get it open.\"<d><scn>l \"How did you get in here?\"<p><msg>c \"Because I don't like it here, either.\"\n",
      "\n",
      "[Test 3] -> Prompt: What will we do here?\n",
      "Reply: o2<msg>An \"What is that?\"<d><scn>l \"No. I've already said it. Just be ready to leave.\"<d><scn>a4<msg>An \"Just what is it?\"<d><scn>l \"I've got something else.\"<d><scn>a4<msg>An \"I know. I know what it is.\"<d><sc\n",
      "\n",
      "-------------\n",
      "[Test 4] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Hey!\"<p><msg>c \"Hey!\"<d><scn>park2<msg>Ry \"Hey!\"<p><msg>c \"Hey!\"<d><scn>park2<msg>Ry \"Hey!\"<p><msg>c \"Hey!\"<d><scn>park2<msg>Ry \"Hey!\"<d><scn\n",
      "\n",
      "[Test 4] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"He told me about how she would have liked me before, but I think she was too upset to say that.\"<d><scn>park2<msg>Ad \"She did not want me to take my clothes off.\"<d><scn>park2<msg>Ad \"He said he would take her clothes off and make\n",
      "\n",
      "[Test 4] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: c \"It's a symbol for the city. What does that mean?\"<p><msg>c \"I don't know. It's a little like a fire.\"<d><scn>c \"I think it's a great symbol.\"<d><scn>c \"But I can't say I'm surprised at how much of this is related to the city. I think it's pretty powerful.\"\n",
      "\n",
      "[Test 4] -> Prompt: What will we do here?\n",
      "Reply: o<msg>c \"I was thinking of going back to my room.\"<d><scn>a \"No, you can come to our place now.\"<d><scn>a \"You'll have to leave before I leave.\"<d><scn>a \"Oh, really?\"<p><msg>c \"I'm sure that it's just the usual.\"<d><scn>a \"You should have\n",
      "\n",
      "-------------\n",
      "[Test 5] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Hey!\"<p><msg>c \"Hey!\"<d><scn>park2<msg>Ry \"Hey!\"<p><msg>c \"Hey!\"<d><scn>park2<msg>Ry \"Hey!\"<p><msg>c \"Hey!\"<d><scn>park2<msg>Ry \"Hey!\"<d><scn\n",
      "\n",
      "[Test 5] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"He said he could go if he was here.\"<p><msg>c \"So you think she is?\"<d><scn>park2<msg>Ad \"She's right.\"<p><msg>c \"Oh, you've been acting strangely, like you've been feeling that way.\"<d><scn>park\n",
      "\n",
      "[Test 5] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: o<msg>An \"Oh, this is my friend, Yuka. Yuka, isn't she? Well, I have something that you may be interested in.\"<p><msg>c \"I'm sorry. I don't know what you mean. I'm just trying to get over to you, and I don't know if it's important.\"<d><scn>o<msg>An\n",
      "\n",
      "[Test 5] -> Prompt: What will we do here?\n",
      "Reply: o<d>p<msg>c \"Why do you think I was kidnapped?\"<d><scn>o<d>p<msg>c \"Why should I be taken prisoner?\"<d><scn>o<d>p<msg>c \"I know you're not the one who kidnapped you.\"<d><scn>o<d>p<msg>c \"What is that supposed to mean?\"\n",
      "\n",
      "-------------\n",
      "[Test 6] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"How are you?\"<d><scn>park2<msg>Ry \"I'm good. I can handle it.\"<d><scn>park2<msg>Br \"You know, I'm just a little shy.\"<d><scn>park2<msg>Br \"What do you do?\"<d><scn>park2<msg>Br\n",
      "\n",
      "[Test 6] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"Very nice.\"<scn>park2<msg>Ad \"That's not a good idea.\"<p><msg>c \"I'm not a great person, you know.\"<d><scn>park2<msg>Ad \"That's not a good idea.\"<scn>park2<msg>Ad \"That\n",
      "\n",
      "[Test 6] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: c \"I know I am not what I say I am. I'm not the same as you.\"<d><scn>c \"What does that mean?\"<d><scn>c \"It means you are a little less human than I am. But what do you think I am?\"<d><scn>c \"I'm not sure I even want to be. But I do like to\n",
      "\n",
      "[Test 6] -> Prompt: What will we do here?\n",
      "Reply: l \"We'll see if we can find the \"others.\"<d><scn>p \"So, I'll just take you on my own.\"<d><scn>l \"It's just that we have no time for a long time, just to get our supplies up.\"<d><scn>l \"You'll find that the rest of your work is just to wait in a box, or at least, I\n",
      "\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = model_manager.say(past, prompt, top_k = 50, top_p = 0.7)\n",
    "        print(f\"[Test {i + 1}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41090174-6be5-4cc4-8f6a-b2cf56628c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What to say?\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'generate_dragon_reply' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_227/3578139120.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What to say?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_dragon_reply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_dragon_reply' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"What to say?\")\n",
    "print(generate_dragon_reply(\"\", input()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
