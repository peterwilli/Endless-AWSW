{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b97b376-9ac5-4c70-ba13-769649099a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_utils import train_model, split_data, split_branches, get_model, set_pretrained_model_dropout\n",
    "from config import Config\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from model_manager import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887d9f81-96c3-408f-bd1c-7b126becc4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use cuda:0 for training with seed: 3218885689\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randint(0, 2 ** 32 - 1)\n",
    "seed = 3218885689\n",
    "random.seed(seed)\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(f\"Will use {device_name} for training with seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e95113e-dfc1-40a9-a39b-5d56f3bf32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(os.path.join(Config.work_dir, \"awsw_story_input.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb65c62-47c6-4d36-bd1e-2adfef8ff1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lr\": 6e-4,\n",
    "    \"warmup_factor\": 0,\n",
    "    \"scheduler\": \"polynomial_decay_schedule_with_warmup\",\n",
    "    \"lr_end\": 2e-6,\n",
    "    \"power\": 0.6,\n",
    "    #\"freeze_layer_rate\": 1e-4,\n",
    "    \"freeze_from_steps\": -1,\n",
    "    \"seed\": seed,\n",
    "    \"num_epoch\": 500\n",
    "}\n",
    "\n",
    "optuna_result_attachement = {\n",
    "    'lr': 0.001,\n",
    "    'scheduler': 'cosine_schedule_with_warmup',\n",
    "    'to_freeze_count': 150,\n",
    "    #\"to_freeze_gpt_blocks\": 11,\n",
    "    'warmup_factor': 1\n",
    "}\n",
    "config.update(optuna_result_attachement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ffae5b-e197-4417-a4cd-e6befc6ee393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained model loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_path = os.path.join(\"models\", \"awsw_main\")\n",
    "if os.path.exists(os.path.join(saved_model_path, \"pytorch_model.bin\")):\n",
    "    print(\"Pretrained model loaded\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "    model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "else:\n",
    "    print(\"Loaded empty model\")\n",
    "    model, tokenizer = get_model(\"EleutherAI/gpt-neo-125M\")\n",
    "model.to(device)\n",
    "# set_pretrained_model_dropout(model.transformer.h[-1:], 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f3315-8f5d-4101-8e7e-2c0129204c94",
   "metadata": {},
   "source": [
    "# Test before training on a pretrained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f68c3f1-4c0a-41a2-a3fc-b8b3c36e418c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you? I'm the one who gave you the impression you wanted to see the movie.\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model_manager = ModelManager(model=model, tokenizer=tokenizer)\n",
    "def test_regular_sampler():\n",
    "    print(model_manager.say_raw(\"How are you? I'm\", 50, 0.7))\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e9e10-b2eb-421a-9948-dc3590e1f46d",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Model is put in training mode and we begin training. The `train_results` will contain all data after training is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41750b03-f114-46c4-948e-637db79efe15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_results = {}\n",
    "model.train()\n",
    "train_model(model, tokenizer, config, train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c410a601-c5e4-4cc1-af2b-44a7378f3bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "fig.suptitle('Learning rate and loss')\n",
    "axs[0].plot(train_results['learning_rate_history'])\n",
    "axs[1].plot(train_results['loss_history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a578b-32cd-44b9-829b-5aef5ec37ab0",
   "metadata": {
    "id": "unxN7nYd2gOM",
    "tags": []
   },
   "source": [
    "# Testing\n",
    "\n",
    "We created a few past (for context) + present prompts (player input) and see the different reactions. This way, we can test the models across different iterations.\n",
    "The first test involves a old prompt to compare the pre-trained model with the one trained on AWSW. Did it manage to store it's data well? Is it able to write down things that have nothing to do with AWSW? (So we know we didn't overfit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d72d4876-df61-461a-b715-980a3763f092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you? I'm sorry, I'm sorry about the whole thing.\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f9a94-70c6-4a58-9ad1-3d6ea373dfbe",
   "metadata": {},
   "source": [
    "**This test generates boring and repetetive** replies! It's because we use no good sampling algorithm, but it does give us a indication of what the model has learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b97230c-1d3a-4dd2-a253-727e451d539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: How are you?\n",
      "Reply: spark2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: spark2<msg>Ad \"I think he's a good guy.\"<p><msg>c \"I'm not sure.\"<p><msg>c \"I'm not sure.\"<d><scn>park2<msg>Ad \"I'm not sure.\"<p><msg>c \"I'm not sure.\"<p><msg>c \"I\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: sfacin2<msg>An \"I'm not sure, but I'm not sure I can do anything to help.\"<p><msg>c \"I'm not sure I can do anything to help.\"<d><scn>facin2<msg>An \"I'm not sure I can do anything to help.\"<p><msg>c \"I'm not sure I can do anything to help\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: snp1n<msg>m \"I looked at the results of the test. I could see that the results were mixed results.\"<d><scn>np1n<msg>m \"I was about to leave, but I didn't want to go.\"<d><scn>np1n<msg>m \"I was about to leave, but I didn't want to go.\"<d><scn>np1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    ('<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hey!\"', \"How are you?\"),\n",
    "    ('<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"', \"What do you think of Lorem?\"),\n",
    "    ('<p><msg>m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('<p><msg>m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "for (past, prompt) in prompts:\n",
    "    reply = model_manager.say(past, prompt)\n",
    "    print(f\"Prompt: {prompt}\\nReply: s{reply}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3349bf-c777-4937-a023-ff0f4f21806d",
   "metadata": {},
   "source": [
    "# Sampling test\n",
    "\n",
    "This is gonna be interesting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce4bb65f-e26e-4a62-9c67-aed885fe041d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test 1] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"You don't have a lot of money to spend, do you?\"<p><msg>c \"I guess you're right.\"<d><scn>park2<msg>Ry \"What kind of money do you have?\"<d><scn>park2<msg>Ry \"A couple of months', maybe longer.\"<d><scn>park2<\n",
      "\n",
      "[Test 1] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I think Lorem was the one who brought you here, and I'll be back when Lorem is back.\"<p><msg>c \"What did you bring me here?\"<d><scn>park2<msg>Ry \"I'm sure it wasn't your fault.\"<d><scn>park2<msg>\n",
      "\n",
      "[Test 1] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np1n<msg>An \"I'm sorry, Adine. I know you like to be polite, but you're not the only one. You seem to have all the traits that make you the most popular.\"<d><scn>np1n<msg>Br \"I see. I'll do it for you. I'll do it for you, then.\"<p><msg>c \"\n",
      "\n",
      "[Test 1] -> Prompt: What will we do here?\n",
      "Reply: park2<msg>Ad \"You don't have to worry about it. It's a pretty big thing, you know?\"<p><msg>c \"I guess I don't know.\"<d><scn>park2<msg>Ad \"But if I were to meet you, I'd be asking you to go to the park and wait for someone else to come in.\"<p><msg>c \"What do you want\n",
      "\n",
      "-------------\n",
      "[Test 2] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"What a nice surprise.\"<|endoftext|>\n",
      "\n",
      "[Test 2] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"It's nice to have her back again, though.\"<d><scn>park2<msg>Ad \"Do you have a lot of spare cash?\"<p><msg>c \"I don't. I don't know if I could afford to take it.\"<d><scn>park2<msg>Ry \"If\n",
      "\n",
      "[Test 2] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: facin2<msg>An \"You're just as beautiful as me, isn't something that's really ever happened to me before. I suppose you're more of a fan than I am.\"<d><scn>facin2<msg>An \"That's what I've been thinking. It's nothing like that. I mean, you're the only one who's ever really gotten close to me.\"\n",
      "\n",
      "[Test 2] -> Prompt: What will we do here?\n",
      "Reply: np1n<msg>m \"The first time I saw the red, I was pretty nervous.\"<d><scn>np1n<msg>m \"I was about to ask for a break. I was hoping to use it as an excuse to come up for work. I was still thinking about my job, but I was still thinking about the other two.\"<d><scn>np1n<msg>m \"\n",
      "\n",
      "-------------\n",
      "[Test 3] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Yeah, you're right. Thanks.\"<p><msg>c \"I'm good.\"<d><scn>park2<msg>Ry \"I hope you can get us out of here. I know it would be a waste of time, but I can't really see that happening.\"<d><scn>park2<msg>Ry \"What a waste of time\n",
      "\n",
      "[Test 3] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"He is a good guy, and I'm not saying he's not good, but he's a good guy.\"<p><msg>c \"He is a good guy, and I'm not saying he's not good.\"<d><scn>park2<msg>Ry \"I'm not saying he's not good.\"<p\n",
      "\n",
      "[Test 3] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: cafe<msg>An \"How can I talk to you about this?\"<p><msg>c \"I don't know. I just feel like it's about to get me in the wrong place.\"<d><scn>cafe<msg>An \"But I'm here to say you can't say that, because I don't know what I'd do if I wasn't here.\"<p\n",
      "\n",
      "[Test 3] -> Prompt: What will we do here?\n",
      "Reply: p=\"2\"<p><msg>c \"I can do this.\"<d><scn>p2<msg>Ad \"How about we have a little bit more?\"<d><scn>p2<msg>Ad \"I guess I'll have to go.\"<p><msg>c \"We could just go out there.\"<d><scn>p2<msg>Ad \"What's that?\"<\n",
      "\n",
      "-------------\n",
      "[Test 4] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I am good, I really like you.\"<p><msg>c \"That's a long story.\"<d><scn>park2<msg>Ry \"I guess it is.\"<p><msg>c \"Yeah, that's true. I love you, but I don't really have the time for a job like that.\"<d><scn>park2\n",
      "\n",
      "[Test 4] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"Well, it is nice to meet you, too.\"<p><msg>c \"It's nice to meet you, too.\"<d><scn>park2<msg>Ad \"I'll be back soon.\"<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg\n",
      "\n",
      "[Test 4] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: cafe<msg>An \"It's the park where the river runs.\"<d><scn>cafe<msg>An \"That's not an official name for the park, but it's a pretty neat place.\"<p><msg>c \"It's the park where the river runs.\"<d><scn>cafe<msg>An \"And it's the park where the river runs\n",
      "\n",
      "[Test 4] -> Prompt: What will we do here?\n",
      "Reply: p hold<d><scn>bare<msg>Lo \"It would be so much nicer if it wasn't for this. It would be much easier to make a cake out of it.\"<d><scn>p hold<d><scn>bare<msg>Lo \"I suppose we'll have to have a couple of beers, though.\"<p><msg>c \"I suppose we'll have to have a couple of\n",
      "\n",
      "-------------\n",
      "[Test 5] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"How are you?\"<d><scn>park2<msg>Ry \"I'm good.\"<p><msg>c \"Hey Remy, how are you?\"<d><scn>park2<msg>Ry \"How are you?\"<d><scn>park2<msg>Ry \"How are you?\"<p><msg>c \"I'm good\n",
      "\n",
      "[Test 5] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"Well, you know what. He's a nice guy, and he was a member of the police department when he was arrested last year.\"<p><msg>c \"I remember the other day, when I was working here, I had the same feeling of dread as he did when I was here.\"<d><scn>park2\n",
      "\n",
      "[Test 5] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: park2<msg>Ad \"I thought you would never leave me, but now that I think you have decided, you will.\"<p><msg>c \"I'm sorry about the misunderstanding.\"<d><scn>park2<msg>Ry \"What are you talking about?\"<d><scn>park2<msg>Ad \"I'm sorry, Adine. What do you think I\n",
      "\n",
      "[Test 5] -> Prompt: What will we do here?\n",
      "Reply: park3<msg>Br \"You've already heard all about it.\"<p><msg>c \"I'm going to get some sleep.\"<d><scn>park3<msg>Br \"I'll try that, and then you'll be able to get to the truth.\"<p><msg>c \"I'll have to go now.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 6] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm fine.\"<p><msg>c \"What's your name?\"<d><scn>park2<msg>Ry \"Remy.\"<p><msg>c \"What is your name?\"<d><scn>park2<msg>Ry \"Remy.\"<p><msg>c \"I'm here to talk about you.\"<d><sc\n",
      "\n",
      "[Test 6] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"He really doesn't know where he went.\"<d><scn>park2<msg>m \"He started off with a long-range rocket, then a long-range rocket. It took a while to land, but once it was just enough, he flew off to meet up with the new boss. We were supposed to meet him\n",
      "\n",
      "[Test 6] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: o2<msg>Ad \"Oh, I see.\"<d><scn>o2<msg>Ad \"How do you like it, Adine?\"<p><msg>c \"I love the way you talk and the way you dress. Is that what you want?\"<d><scn>o2<msg>Ad \"I think it is.\"<p><msg>c \"I\n",
      "\n",
      "[Test 6] -> Prompt: What will we do here?\n",
      "Reply: park2<msg>Ry \"I know. I have no idea.\"<d><scn>park2<msg>m \"I waited for my turn to go in search of a weapon. After all, I already have.\"<d><scn>park2<msg>Ry \"You'll be here in a minute.\"<d><scn>park2<msg>m \"I'm about to turn back.\"<d\n",
      "\n",
      "-------------\n",
      "[Test 7] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm good.\"<p><msg>c \"I'm not sure.\"<d><scn>park2<msg>Ry \"If you want to play, I have a few things I can do.\"<p><msg>c \"Yeah, I know. That's why I can do some things.\"<d><scn>park2<msg>Ry \"Well\n",
      "\n",
      "[Test 7] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I suppose it's my choice.\"<p><msg>c \"I like Lorem.\"<p><msg>c \"I suppose it's my choice.\"<d><scn>park2<msg>Ry \"I suppose it's my choice.\"<p><msg>c \"I'm glad.\"<p><msg>c\n",
      "\n",
      "[Test 7] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: park2<msg>An \"You know, it's my turn to be a little trouble tonight.\"<p><msg>c \"I don't know. This is not the kind of place where I can just sit and wait for Adine to come and talk to me, and then, if it's okay, I'll stay at home.\"<d><scn>park2<msg>An \"I\n",
      "\n",
      "[Test 7] -> Prompt: What will we do here?\n",
      "Reply: cafe<msg>An \"Well, I guess it's just a hobby. If you don't want to do something, do it.\"<p><msg>c \"I guess we could try something else, too.\"<d><scn>cafe<msg>An \"I guess we could try something else.\"<p><msg>c \"Well, I guess it's just a hobby.\"<d><scn>c\n",
      "\n",
      "-------------\n",
      "[Test 8] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"Yeah, thanks for the drink.\"<d><scn>park2<msg>Ry \"Yeah, thanks for the drink.\"<|endoftext|>\n",
      "\n",
      "[Test 8] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"What do you think of Lorem?\"<p><msg>c \"I don't know.\"<d><scn>park2<msg>Ad \"I don't know. I guess I should leave.\"<p><msg>c \"I don't know.\"<d><scn>park2<msg>Ad \"I\n",
      "\n",
      "[Test 8] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>An \"Well, this is a strange place.\"<d><scn>black<msg>An \"Do you really think you can run a marathon and still be a runner?\"<p><msg>c \"You're right. That's a tough one. I'm not sure how long I'll be, but I think I could do that.\"<d><scn>black<msg\n",
      "\n",
      "[Test 8] -> Prompt: What will we do here?\n",
      "Reply: facin2<msg>An \"I see.\"<p><msg>c \"That's not what I wanted.\"<d><scn>facin2<msg>An \"It is what you said, you know?\"<p><msg>c \"I was just thinking it was a question of my feelings.\"<d><scn>facin2<msg>An \"You can take that, I guess.\"<p\n",
      "\n",
      "-------------\n",
      "[Test 9] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Hey, I think you're really pretty nice.\"<d><scn>park2<msg>Ry \"You're pretty nice too.\"<|endoftext|>\n",
      "\n",
      "[Test 9] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"Well, we're not sure about that.\"<p><msg>c \"No, I don't know. We don't know why Lorem is trying to use us as spies.\"<d><scn>park2<msg>Ad \"If I was going to use my name, I would have to ask Lorem to leave.\"\n",
      "\n",
      "[Test 9] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: loremapt<msg>Ip \"I'm going to try some, but I can't find my way out.\"<d><scn>loremapt<msg>Ip \"That's my answer.\"<d><scn>loremapt<msg>m \"Adine got out, and Adine and I sat down to await further instructions.\"<d><scn>loremapt\n",
      "\n",
      "[Test 9] -> Prompt: What will we do here?\n",
      "Reply: o2<msg>Ad \"Okay, let's see what we can do.\"<p><msg>c \"Okay, let's see what we can do.\"<d><scn>o2<msg>Ad \"Sure, let's see what we can do.\"<p><msg>c \"Sure, let's see what we can do.\"<p><msg>c \"Sure, let's see what we can do.\"\n",
      "\n",
      "-------------\n",
      "[Test 10] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"You're in great luck. I'm sure it's your first date with the rest of your family.\"<d><scn>park2<msg>Ry \"What about you?\"<p><msg>c \"I'm just going to go with you.\"<d><scn>park2<msg>Ry \"I'll see you.\"<|endoftext|>\n",
      "\n",
      "[Test 10] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"He is just so cool. I was able to catch him for a while.\"<p><msg>c \"I was with Lorem today.\"<p><msg>c \"Very nice.\"<d><scn>park2<msg>Ry \"I was with Lorem today.\"<p><msg>c \"I was with\n",
      "\n",
      "[Test 10] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: facin2<msg>An \"What's wrong with you? Why are you here?\"<p><msg>c \"I'm here because I'm bored. I'm not sure I could do anything to stop you, but I suppose I should have been there a long time ago.\"<d><scn>facin2<msg>An \"I can't really think of a better way to go.\"\n",
      "\n",
      "[Test 10] -> Prompt: What will we do here?\n",
      "Reply: black<msg>Ry \"I'll be right back.\"<d><scn>black<msg>m \"As I was about to leave, I suddenly felt very nervous.\"<p><msg>c \"There's something I need to talk about.\"<d><scn>black<msg>Ry \"I'm going to start.\"<p><msg>c \"I'll see you.\"<p><msg>c \"I\n",
      "\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = model_manager.say(past, prompt, top_k = 50, top_p = 0.7)\n",
    "        print(f\"[Test {i + 1}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c956842-43ba-4f9a-937a-13fda9ad1439",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RP test\n",
    "Testing out the injected roleplay actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85435494-6b29-4b18-aa34-328e33caa9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visit Lorem -> facin2<msg>Lo \"I'll see you tomorrow.\"<|endoftext|>\n",
      "Meet with Lorem -> black<msg>Lo \"Liarism is the belief that humans are intelligent, so there is no need to be a problem with it.\"<|endoftext|>\n",
      "Visit Adin -> black<msg>n \"He spoke to me about my life in the hospital and my future. I was so proud to meet him, and to have him here.\"<d><scn>black<msg>n \"He looked into my eyes, and then I remembered what I had seen in the first place.\"<p><msg>c \"What was your name?\"<d><scn>black<msg>n \"A. It's an old woman's name.\"<p><msg>c \"It's a good name,\n"
     ]
    }
   ],
   "source": [
    "test_rps = [\n",
    "    \"Visit Lorem\",\n",
    "    \"Meet with Lorem\",\n",
    "    \"Visit Adin\"\n",
    "]\n",
    "for rp in test_rps:\n",
    "    print(f'{rp} -> {model_manager.say(\"\", rp, top_k = 50, top_p = 0.7)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a45d066-65b8-44d0-b95b-98f4a2b084c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
