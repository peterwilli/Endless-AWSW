{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b97b376-9ac5-4c70-ba13-769649099a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_utils import train_model, split_data, split_branches, get_model, set_pretrained_model_dropout, get_dataset, ModelSeeder\n",
    "from config import Config\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import onnx\n",
    "import logging\n",
    "from onnx_model_manager import OnnxModelManager\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "import os\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from model_manager import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887d9f81-96c3-408f-bd1c-7b126becc4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use cuda:0 for training with seed: 3218885689\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randint(0, 2 ** 32 - 1)\n",
    "seed = 3218885689\n",
    "random.seed(seed)\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(f\"Will use {device_name} for training with seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e95113e-dfc1-40a9-a39b-5d56f3bf32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(os.path.join(Config.work_dir, \"awsw_story_input.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb65c62-47c6-4d36-bd1e-2adfef8ff1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lr\": 6e-4,\n",
    "    \"warmup_factor\": 0,\n",
    "    \"scheduler\": \"polynomial_decay_schedule_with_warmup\",\n",
    "    \"lr_end\": 2e-6,\n",
    "    \"power\": 0.6,\n",
    "    #\"freeze_layer_rate\": 1e-4,\n",
    "    \"freeze_from_steps\": -1,\n",
    "    \"seed\": seed,\n",
    "    \"num_epoch\": 200\n",
    "}\n",
    "\n",
    "optuna_result_attachement = {\n",
    "    'lr': 0.001,\n",
    "    'scheduler': 'cosine_schedule_with_warmup',\n",
    "    'to_freeze_count': 0,\n",
    "    #\"to_freeze_gpt_blocks\": 11,\n",
    "    'warmup_factor': 1\n",
    "}\n",
    "config.update(optuna_result_attachement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ffae5b-e197-4417-a4cd-e6befc6ee393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded empty model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_path = os.path.join(\"models\", \"awsw_main\")\n",
    "if os.path.exists(os.path.join(saved_model_path, \"pytorch_model.bin\")):\n",
    "    tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "    model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "    print(\"Pretrained model loaded\")\n",
    "else:\n",
    "    model, tokenizer = get_model(\"EleutherAI/gpt-neo-125M\")\n",
    "    print(\"Loaded empty model\")\n",
    "model.to(device)\n",
    "# set_pretrained_model_dropout(model.transformer.h[-1:], 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f3315-8f5d-4101-8e7e-2c0129204c94",
   "metadata": {},
   "source": [
    "# Test before training on a pretrained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f68c3f1-4c0a-41a2-a3fc-b8b3c36e418c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragon-slayer. I'm a dragon, a dragon, a dragon, a dragon, a dragon, a dragon. My dream is that I will live and die in my dreams, a dragon, a dragon, a dragon, a dragon.\n",
      "\n",
      "I am the dragon-slayer, a dragon-slayer, a dragon-slayer, a dragon-slayer, a dragon-slayer, a dragon-slayer, a dragon-slayer, a dragon-slayer, a dragon-slayer, a dragon-slayer, a dragon-slayer, a\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model_manager = ModelManager(model=model, tokenizer=tokenizer, device=device)\n",
    "def test_regular_sampler():\n",
    "    print(model_manager.say_raw(\"In my dreams, I'm a dragon\", 50, 0.7))\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f74aa-5030-4ffd-ad2f-ae013647975e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reviewing our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0974ac13-c420-4275-b34a-3816f580cb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c93cadffdb42c38017b88361876024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset demo snapshot:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<d><scn>black<msg>Lo \"Now that we're here, I can tell you that no expense will be spared to make our portrayal of humans as accurate as possible.\"<|endoftext|><p><msg>c \"(Pun intended?)\"<|endoftext|><d><scn>bare<msg>Br \"Just the usual.\"<|endoftext|><d><scn>loremapt<msg>Ip \"As a scientist, my professional opinion is that this part looks a little long.\"<|endoftext|><d><scn>o2<msg>Ad \"I disagree with that.\"<|endoftext|><p><msg>c \"\n",
      "RP review!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "><msg>c \"Just kidding. Go ahead.\"<|endoftext|><p><msg>c \"Fight Adine\"<d><scn>beach<msg>m \"Adine barely avoids my attack and fell, but managed to get up and quickly punch me in the face, a soaring pain quickly came over my face\"<|endoftext|>at the last second\" is meant in a literal sense here, or else she could've just called me.)\"<|endoftext|><p><msg>c \"#2, the room filled with one hundred highly trained assassins.\"<|endoftext|><d><scn>cafe<msg>An \"I'll have\n",
      " a coffee.\"<|endoftext|><p><msg>c \"Sure.\"<d><scn>loremapt<msg>m \"We sat down at the coffee table. Lorem opened up a laptop and started to type away.\"<d><scn>loremapt<msg>m \"Seeing the laptop brought back memories. In our world, they had become obsolete a long time ago.\"<d><scn>loremapt<msg>Lo \"Before I show you these images, I should probably tell you that some of them are really weird. Just don't take them the wrong way.\"<|endoftext|><d><\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(tokenizer, path_train = os.path.join(Config.work_dir, \"data_train.txt\"))\n",
    "print(\"Dataset demo snapshot:\")\n",
    "for item in dataset['train']:\n",
    "    print(tokenizer.decode(item['input_ids']))\n",
    "    break\n",
    "\n",
    "print(\"RP review!\")\n",
    "has_seen_rp = False\n",
    "for item in dataset['train']:\n",
    "    decoded = tokenizer.decode(item['input_ids'])\n",
    "    if 'c \"Fight ' in decoded: \n",
    "        print(decoded)\n",
    "        has_seen_rp = True\n",
    "        continue        \n",
    "    if has_seen_rp:\n",
    "        print(decoded)\n",
    "        break\n",
    "# Clean up\n",
    "del has_seen_rp\n",
    "# dataset['model_seeder'].stop_worker()\n",
    "# del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e9e10-b2eb-421a-9948-dc3590e1f46d",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Model is put in training mode and we begin training. The `train_results` will contain all data after training is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41750b03-f114-46c4-948e-637db79efe15",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] set freeze_part_layers: True (freezing 0 out of 160 layers.)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11196' max='21400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11196/21400 1:20:21 < 1:13:15, 2.32 it/s, Epoch 104.63/200]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>73559.266400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428</td>\n",
       "      <td>461421.719600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>642</td>\n",
       "      <td>931676.336400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>856</td>\n",
       "      <td>1258225.046700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>1524205.607500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1284</td>\n",
       "      <td>1802830.205600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1498</td>\n",
       "      <td>2088489.420600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1712</td>\n",
       "      <td>2353130.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1926</td>\n",
       "      <td>2637141.233600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>2960561.345800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2354</td>\n",
       "      <td>3293571.887900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2568</td>\n",
       "      <td>3597140.336400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2782</td>\n",
       "      <td>3895630.654200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2996</td>\n",
       "      <td>4197605.981300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3210</td>\n",
       "      <td>4474977.495300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3424</td>\n",
       "      <td>4722122.766400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3638</td>\n",
       "      <td>5007904.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3852</td>\n",
       "      <td>5311855.252300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4066</td>\n",
       "      <td>5602244.785000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4280</td>\n",
       "      <td>5856671.700900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4494</td>\n",
       "      <td>6119368.373800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4708</td>\n",
       "      <td>6403680.897200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4922</td>\n",
       "      <td>6665056.299100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5136</td>\n",
       "      <td>6917414.280400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5350</td>\n",
       "      <td>7178064.149500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5564</td>\n",
       "      <td>7421733.682200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5778</td>\n",
       "      <td>7664701.009300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5992</td>\n",
       "      <td>7906513.943900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6206</td>\n",
       "      <td>8149143.925200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6420</td>\n",
       "      <td>8361611.364500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6634</td>\n",
       "      <td>8573609.869200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6848</td>\n",
       "      <td>8776005.383200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7062</td>\n",
       "      <td>8970129.345800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7276</td>\n",
       "      <td>9160482.093500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7490</td>\n",
       "      <td>9338941.009300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7704</td>\n",
       "      <td>9523169.495300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7918</td>\n",
       "      <td>9677072.149500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8132</td>\n",
       "      <td>9835453.607500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8346</td>\n",
       "      <td>9997515.364500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8560</td>\n",
       "      <td>10134815.102800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8774</td>\n",
       "      <td>10293487.252300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8988</td>\n",
       "      <td>10481772.859800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9202</td>\n",
       "      <td>10622600.373800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9416</td>\n",
       "      <td>10734639.850500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9630</td>\n",
       "      <td>10857389.457900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9844</td>\n",
       "      <td>10960545.495300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10058</td>\n",
       "      <td>11062614.130800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10272</td>\n",
       "      <td>11149395.738300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10486</td>\n",
       "      <td>11245371.813100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>11321016.224300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10914</td>\n",
       "      <td>11398919.177600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11128</td>\n",
       "      <td>11497827.289700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26630/24070401.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/awsw/model_utils.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, tokenizer, dataset, params, results)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mtrainer_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAWSWTrainerCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/awsw/model_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, trainer_callback)\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mtraining_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1323\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m                 if (\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_results = {}\n",
    "model.train()\n",
    "train_model(model, tokenizer, dataset, config, train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c410a601-c5e4-4cc1-af2b-44a7378f3bbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'learning_rate_history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26630/137603942.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Learning rate and loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learning_rate_history'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_closeness_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_history'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'learning_rate_history'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3)\n",
    "fig.suptitle('Learning rate and loss')\n",
    "axs[0].plot(train_results['learning_rate_history'])\n",
    "axs[1].plot(train_results['model_closeness_loss'])\n",
    "axs[2].plot(train_results['loss_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "753228f0-b420-4b3d-bd69-53da7a87bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.save_pretrained(saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e4666-c1ff-4695-ba55-894503925f9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conversion to ONNX\n",
    "ONNX is a different format for running machine learning models. The ONNX format is much faster on CPU, sometimes 5 times as fast as PyTorch!\n",
    "\n",
    "While the EAWSW model is designed to be small, accurate and accessible, for some people it's still too much to run...\n",
    "\n",
    "Hosting the model as a free service for players is an option. An ONNX version of the model allows us to host the model on CPU yet have faster response times! Given that the model is made in a time with chip shortage, running on hardware I already have inside a server is efficient, scalable and cheaper.\n",
    "\n",
    "An important note is that ONNX doesn't execute logic by itself, and you have to do that yourself, `onnx_model_manager.py` intends to deal with this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b88e1f-f5c3-4a95-8b00-e791148d8c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_onnx_path = os.path.join(\"models\", \"awsw_onnx\")\n",
    "if not os.path.exists(os.path.join(saved_model_path, \"special_tokens_map.json\")):\n",
    "    print(\"Copying config files from huggingface (needed for conversion)... WARNING: this assumes the structure of the model isn't changed!\")\n",
    "    !cd $saved_model_path && git clone https://huggingface.co/EleutherAI/gpt-neo-125M\n",
    "    !cp -n $saved_model_path/gpt-neo-125M/* $saved_model_path\n",
    "    !rm -rf $saved_model_path/gpt-neo-125M\n",
    "if not os.path.exists(os.path.join(saved_model_onnx_path, \"model.onnx\")):\n",
    "    !python3 -m transformers.onnx --model=$saved_model_path --feature=causal-lm-with-past $saved_model_onnx_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86f7a12-9bcb-4c4b-a679-7007a7e2caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_onnx():\n",
    "    model_quant = os.path.join(saved_model_onnx_path, \"model_quant.onnx\")\n",
    "    if not os.path.exists(model_quant):\n",
    "        model_fp32 = os.path.join(saved_model_onnx_path, \"model.onnx\")\n",
    "        model_opt = os.path.join(saved_model_onnx_path, \"model-opt.onnx\")\n",
    "        quantized_model = quantize_dynamic(model_fp32, model_quant, weight_type=QuantType.QUInt8)\n",
    "        #!rm $model_opt\n",
    "optimize_onnx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739405a4-ab2a-410f-8091-b6bd9a18e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_manager = OnnxModelManager(os.path.join(saved_model_onnx_path, \"model.onnx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9e7adb-f258-471a-9139-70da9f2120d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"In my dreams, I'm a dragon\"\n",
    "for i in range(10):\n",
    "    print(\"ONNX:\", onnx_model_manager.say_raw(prompt, do_sample=True))\n",
    "    print(\"PyTorch:\", model_manager.say_raw(prompt, 50, 0.7))\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a578b-32cd-44b9-829b-5aef5ec37ab0",
   "metadata": {
    "id": "unxN7nYd2gOM",
    "tags": []
   },
   "source": [
    "# Testing\n",
    "\n",
    "We created a few past (for context) + present prompts (player input) and see the different reactions. This way, we can test the models across different iterations.\n",
    "The first test involves a old prompt to compare the pre-trained model with the one trained on AWSW. Did it manage to store it's data well? Is it able to write down things that have nothing to do with AWSW? (So we know we didn't overfit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d72d4876-df61-461a-b715-980a3763f092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragon. You need everything to be done for you by an army of lackeys and cooks.\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f9a94-70c6-4a58-9ad1-3d6ea373dfbe",
   "metadata": {},
   "source": [
    "**This test generates boring and repetetive** replies! It's because we use no good sampling algorithm, but it does give us a indication of what the model has learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b97230c-1d3a-4dd2-a253-727e451d539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Pytorch...\n",
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm beginning to realize that maybe it's not their fault. Maybe it's me.\"<d><scn>park2<msg>Ry \"Goodbye, [player_name].\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: loremapt<msg>Ip \"This apartment was actually intended to house one dragon of a bigger size. That not only makes it fairly cheap, but it's also big enough for both of us.\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>Ad \"Do you like your Mouflon  la Anna?\"<p><msg>c \"I feel like a wild animal.\"<d><scn>black<msg>An \"Quite different from sitting in an expensive restaurant and using their fancy cutlery and napkins, isn't it?\"<p><msg>c \"Yeah, I like it.\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: facin2<msg>An \"I could show you sometime, but we're here to have fun, right?\"<p><msg>c \"I thought you wanted to show me, since you said we were both in biology and all that.\"<d><scn>facin2<msg>An \"Sure, but after doing this all day, you'll have to excuse me for not wanting to talk about it even more.\"<\n",
      "\n",
      "\n",
      "Test ONNX...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'onnx_model_manager' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26630/3013901318.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test ONNX...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0msample_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_model_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0monnx_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'onnx_model_manager' is not defined"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    ('<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hey!\"', \"How are you?\"),\n",
    "    ('<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"', \"What do you think of Lorem?\"),\n",
    "    ('<p><msg>m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('<p><msg>m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "def sample_test(model_manager):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = model_manager.say(past, prompt)\n",
    "        print(f\"Prompt: {prompt}\\nReply: {reply}\\n\\n\")\n",
    "print(\"Test Pytorch...\")\n",
    "start = time.time()\n",
    "sample_test(model_manager)\n",
    "end = time.time()\n",
    "pytorch_time = end - start\n",
    "print(\"Test ONNX...\")\n",
    "start = time.time()\n",
    "sample_test(onnx_model_manager)\n",
    "end = time.time()\n",
    "onnx_time = end - start\n",
    "print(f\"PyTorch on {device} took {pytorch_time:.4f} seconds\")\n",
    "print(f\"ONNX on CPU took {onnx_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3349bf-c777-4937-a023-ff0f4f21806d",
   "metadata": {},
   "source": [
    "# Sampling test\n",
    "\n",
    "This is gonna be interesting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4bb65f-e26e-4a62-9c67-aed885fe041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Pytorch...\")\n",
    "start = time.time()\n",
    "for i in range(1):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = model_manager.say(past, prompt, top_k = 50, top_p = 0.7)\n",
    "        print(f\"[Test {i + 1}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-------------\")\n",
    "end = time.time()\n",
    "pytorch_time = end - start\n",
    "print(\"Test ONNX...\")\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "start = time.time()\n",
    "for i in range(1):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = onnx_model_manager.say(past, prompt, do_sample = True)\n",
    "        print(f\"[Test {i + 1}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-------------\")\n",
    "end = time.time()\n",
    "onnx_time = end - start\n",
    "print(f\"PyTorch on {device} took {pytorch_time:.4f} seconds\")\n",
    "print(f\"ONNX on CPU took {onnx_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c956842-43ba-4f9a-937a-13fda9ad1439",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RP test\n",
    "Testing out the injected roleplay actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85435494-6b29-4b18-aa34-328e33caa9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rps = [\n",
    "    \"Visit Lorem\",\n",
    "    \"Meet with Lorem\",\n",
    "    \"Visit Adine\",\n",
    "    \"Fight Maverick\",\n",
    "    \"Fight Adine\",\n",
    "    \"Attack Adine\"\n",
    "]\n",
    "for rp in test_rps:\n",
    "    print(f'{rp} -> {model_manager.say(\"\", rp, top_k = 50, top_p = 0.7)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
