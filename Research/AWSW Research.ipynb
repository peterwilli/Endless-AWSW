{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b97b376-9ac5-4c70-ba13-769649099a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_utils import train_model, split_data, split_branches, get_model, set_pretrained_model_dropout, get_dataset, ModelSeeder\n",
    "from config import Config\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import onnx\n",
    "import logging\n",
    "from onnx_model_manager import OnnxModelManager\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "import os\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from model_manager import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887d9f81-96c3-408f-bd1c-7b126becc4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use cuda:0 for training with seed: 3218885689\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randint(0, 2 ** 32 - 1)\n",
    "seed = 3218885689\n",
    "random.seed(seed)\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(f\"Will use {device_name} for training with seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e95113e-dfc1-40a9-a39b-5d56f3bf32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(os.path.join(Config.work_dir, \"awsw_story_input.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb65c62-47c6-4d36-bd1e-2adfef8ff1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lr\": 6e-4,\n",
    "    \"warmup_factor\": 0,\n",
    "    \"scheduler\": \"polynomial_decay_schedule_with_warmup\",\n",
    "    \"lr_end\": 2e-6,\n",
    "    \"power\": 0.6,\n",
    "    #\"freeze_layer_rate\": 1e-4,\n",
    "    \"freeze_from_steps\": -1,\n",
    "    \"seed\": seed,\n",
    "    \"num_epoch\": 2\n",
    "}\n",
    "\n",
    "optuna_result_attachement = {\n",
    "    'lr': 0.001,\n",
    "    'scheduler': 'cosine_schedule_with_warmup',\n",
    "    'to_freeze_count': 0,\n",
    "    #\"to_freeze_gpt_blocks\": 11,\n",
    "    'warmup_factor': 0\n",
    "}\n",
    "config.update(optuna_result_attachement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ffae5b-e197-4417-a4cd-e6befc6ee393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded empty model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_path = os.path.join(\"models\", \"awsw_main\")\n",
    "if os.path.exists(os.path.join(saved_model_path, \"pytorch_model.bin\")):\n",
    "    tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "    model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "    print(\"Pretrained model loaded\")\n",
    "else:\n",
    "    model, tokenizer = get_model(\"EleutherAI/gpt-neo-125M\")\n",
    "    print(\"Loaded empty model\")\n",
    "model.to(device)\n",
    "# set_pretrained_model_dropout(model.transformer.h[-1:], 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f3315-8f5d-4101-8e7e-2c0129204c94",
   "metadata": {},
   "source": [
    "# Test before training on a pretrained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f68c3f1-4c0a-41a2-a3fc-b8b3c36e418c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragonfly in a fairy tale. I have never seen a dragonfly so beautiful. I'm not even sure if it's a dragonfly or a fairy. I've never even seen a dragonfly.\n",
      "\n",
      "I am a dragonfly in a fairy tale. I have never seen a dragonfly so beautiful. I'm not even sure if it's a dragonfly or a fairy. I've never seen a dragonfly.\n",
      "\n",
      "My friend, her name is Linda, I have never seen a dragonfly so beautiful. I'm a dragonfly in a fairy tale. I have never seen a\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model_manager = ModelManager(model=model, tokenizer=tokenizer, device=device)\n",
    "def test_regular_sampler():\n",
    "    print(model_manager.say_raw(\"In my dreams, I'm a dragon\", 50, 0.7))\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f74aa-5030-4ffd-ad2f-ae013647975e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reviewing our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0974ac13-c420-4275-b34a-3816f580cb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c269cc66a7c2489983772fb12fce207e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset demo snapshot:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p><msg>c \"He hasn't used the portal yet, though.\"<d><scn>np1r<msg>Br \"How could he? Isn't it broken?\"<|endoftext|><p><msg>c \"Sure.\"<|endoftext|><p><msg>c \"I could fetch it after we're done with this.\"<|endoftext|><p><msg>c \"...\"<d><scn>o2<msg>Br \"Do you think it's easy for me? Seeing so many people die on my watch?\"<d><scn>o2<msg>Br \"Do you think I don't\n",
      "RP review!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " here before?\"<p><msg>c \"Once or twice.\"<|endoftext|><p><msg>c \"Don't forget what I said earlier about what I expect from you on this date. You better be on your best behavior.\"<|endoftext|><p><msg>c \"Fight Remy\"<d><scn>park2<msg>m \"Remy dodges my attack and comes rushing towards me\"<|endoftext|><d><scn>facin2<msg>An \"Some might even say \"<|endoftext|><d><scn>o2<msg>m \"It was interesting that they still relied on me for their\n",
      " investigations, even after they tried to send me back to my world. I didn't expect them to allow me to help with police matters after everything that had happened.\"<|endoftext|><p><msg>c \"It's always about work with you. Come on, you're on break. Maybe we should do something to take your mind off of all that for once.\"<d><scn>cafe<msg>An \"Like what?\"<|endoftext|><p><msg>c \"This should do the trick.\"<|endoftext|><d><scn>black<msg>Ry \"A while.\"<|endoftext|><d><scn>facin\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(tokenizer, path_train = os.path.join(Config.work_dir, \"data_train.txt\"))\n",
    "print(\"Dataset demo snapshot:\")\n",
    "for item in dataset['train']:\n",
    "    print(tokenizer.decode(item['input_ids']))\n",
    "    break\n",
    "\n",
    "print(\"RP review!\")\n",
    "has_seen_rp = False\n",
    "for item in dataset['train']:\n",
    "    decoded = tokenizer.decode(item['input_ids'])\n",
    "    if 'c \"Fight ' in decoded: \n",
    "        print(decoded)\n",
    "        has_seen_rp = True\n",
    "        continue        \n",
    "    if has_seen_rp:\n",
    "        print(decoded)\n",
    "        break\n",
    "# Clean up\n",
    "del has_seen_rp\n",
    "# dataset['model_seeder'].stop_worker()\n",
    "# del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e9e10-b2eb-421a-9948-dc3590e1f46d",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Model is put in training mode and we begin training. The `train_results` will contain all data after training is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41750b03-f114-46c4-948e-637db79efe15",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] set freeze_part_layers: True (freezing 0 out of 160 layers.)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='214' max='214' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [214/214 01:31, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.107700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.519200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.732300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.455800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.287300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.158000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.117200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.863600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.867300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.837200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.940900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.811100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.656700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.713700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.714100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.666900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.589700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.777800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.623700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.549500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.643000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.668300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.603200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.632800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.560400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.740500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.636900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.545800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.547700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.674500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.639400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>1.510900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.456300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1.531400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.609700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>1.596300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>1.623200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>1.661900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.615100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.577200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>1.564700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>1.491100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1.654600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>1.625400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.512100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>1.557600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>1.732700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>1.634700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>1.638600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.434800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>1.409600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>1.431400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>1.507200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>1.455500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.384400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>1.450700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>1.486900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>1.543300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>1.509000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.498900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>1.413500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>1.385500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>1.549600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>1.300700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.467500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>1.357800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>1.430700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>1.394600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>1.422700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.485500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>1.453600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>1.458800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>1.410100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>1.361500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.403800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>1.409500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>1.256000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>1.341300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>1.342600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.439000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>1.383500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>1.320700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>1.437800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>1.343000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.412600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>1.367400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>1.293000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>1.257500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>1.394700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.533700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>1.310500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>1.275400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>1.347400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>1.245400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.291800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>1.500200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>1.299000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>1.314600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>1.240600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.286500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>1.243200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>1.440200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results = {}\n",
    "model.train()\n",
    "train_model(model, tokenizer, dataset, config, train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c410a601-c5e4-4cc1-af2b-44a7378f3bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5336a17580>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3)\n",
    "fig.suptitle('Learning rate and loss')\n",
    "axs[0].plot(train_results['learning_rate_history'])\n",
    "axs[1].plot(train_results['model_closeness_loss'])\n",
    "axs[2].plot(train_results['loss_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "753228f0-b420-4b3d-bd69-53da7a87bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.save_pretrained(saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e4666-c1ff-4695-ba55-894503925f9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conversion to ONNX\n",
    "ONNX is a different format for running machine learning models. The ONNX format is much faster on CPU, sometimes 5 times as fast as PyTorch!\n",
    "\n",
    "While the EAWSW model is designed to be small, accurate and accessible, for some people it's still too much to run...\n",
    "\n",
    "Hosting the model as a free service for players is an option. An ONNX version of the model allows us to host the model on CPU yet have faster response times! Given that the model is made in a time with chip shortage, running on hardware I already have inside a server is efficient, scalable and cheaper.\n",
    "\n",
    "An important note is that ONNX doesn't execute logic by itself, and you have to do that yourself, `onnx_model_manager.py` intends to deal with this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3b88e1f-f5c3-4a95-8b00-e791148d8c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying config files from huggingface (needed for conversion)... WARNING: this assumes the structure of the model isn't changed!\n",
      "Cloning into 'gpt-neo-125M'...\n",
      "remote: Enumerating objects: 38, done.\u001b[K\n",
      "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
      "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
      "remote: Total 38 (delta 16), reused 0 (delta 0)\u001b[K\n",
      "Unpacking objects: 100% (38/38), 542.60 KiB | 1006.00 KiB/s, done.\n",
      "Using framework PyTorch: 1.10.1+cu113\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> True\n",
      "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:90: UserWarning: 'enable_onnx_checker' is deprecated and ignored. It will be removed in the next PyTorch release. To proceed despite ONNX checker failures, catch torch.onnx.ONNXCheckerError.\n",
      "  warnings.warn(\"'enable_onnx_checker' is deprecated and ignored. It will be removed in \"\n",
      "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:103: UserWarning: `use_external_data_format' is deprecated and ignored. Will be removed in next PyTorch release. The code will work as it is False if models are not larger than 2GB, Otherwise set to False because of size limits imposed by Protocol Buffers.\n",
      "  warnings.warn(\"`use_external_data_format' is deprecated and ignored. Will be removed in next \"\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:559: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert batch_size > 0, \"batch_size has to be defined and > 0\"\n",
      "Validating ONNX model...\n",
      "\t-[✓] ONNX model outputs' name match reference model ({'present.11.value', 'present.3.key', 'present.1.value', 'present.3.value', 'present.2.value', 'present.5.value', 'present.1.key', 'present.10.key', 'present.8.key', 'present.4.key', 'present.6.key', 'present.2.key', 'present.6.value', 'present.5.key', 'present.9.key', 'present.7.value', 'present.4.value', 'present.7.key', 'logits', 'present.11.key', 'present.0.value', 'present.9.value', 'present.10.value', 'present.8.value', 'present.0.key'}\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[✓] (2, 1, 50257) matches (2, 1, 50257)\n",
      "\t\t-[x] values not close enough (atol: 0.0001)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/transformers/onnx/__main__.py\", line 71, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/transformers/onnx/__main__.py\", line 64, in main\n",
      "    validate_model_outputs(onnx_config, tokenizer, model, args.output, onnx_outputs, args.atol)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/transformers/onnx/convert.py\", line 214, in validate_model_outputs\n",
      "    raise ValueError(\n",
      "ValueError: Outputs values doesn't match between reference model and ONNX exported model: Got max absolute difference of: 0.0013246536254882812\n"
     ]
    }
   ],
   "source": [
    "saved_model_onnx_path = os.path.join(\"models\", \"awsw_onnx\")\n",
    "if not os.path.exists(os.path.join(saved_model_path, \"special_tokens_map.json\")):\n",
    "    print(\"Copying config files from huggingface (needed for conversion)... WARNING: this assumes the structure of the model isn't changed!\")\n",
    "    !cd $saved_model_path && git clone https://huggingface.co/EleutherAI/gpt-neo-125M\n",
    "    !cp -n $saved_model_path/gpt-neo-125M/* $saved_model_path\n",
    "    !rm -rf $saved_model_path/gpt-neo-125M\n",
    "if not os.path.exists(os.path.join(saved_model_onnx_path, \"model.onnx\")):\n",
    "    !python3 -m transformers.onnx --model=$saved_model_path --feature=causal-lm-with-past $saved_model_onnx_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a86f7a12-9bcb-4c4b-a679-7007a7e2caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_onnx():\n",
    "    model_quant = os.path.join(saved_model_onnx_path, \"model_quant.onnx\")\n",
    "    if not os.path.exists(model_quant):\n",
    "        model_fp32 = os.path.join(saved_model_onnx_path, \"model.onnx\")\n",
    "        model_opt = os.path.join(saved_model_onnx_path, \"model-opt.onnx\")\n",
    "        quantized_model = quantize_dynamic(model_fp32, model_quant, weight_type=QuantType.QUInt8)\n",
    "        #!rm $model_opt\n",
    "optimize_onnx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "739405a4-ab2a-410f-8091-b6bd9a18e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_manager = OnnxModelManager(os.path.join(saved_model_onnx_path, \"model.onnx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f9e7adb-f258-471a-9139-70da9f2120d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX: In my dreams, I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human.\n",
      "PyTorch: In my dreams, I'm a dragon. I can feel myself moving in my mind, even though my back is against the wall. My hands are numb and my arms are cramped.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human.\n",
      "PyTorch: In my dreams, I'm a dragon.\"<d><scn>park3<msg>Br \"Well, that's good to hear.\"<d><scn>park3<msg>Em \"It's good to see you, [player_name].\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human.\n",
      "PyTorch: In my dreams, I'm a dragoness who wants to learn to fly. I can fly, but I can't stand up anymore.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragoness who has been sent to the human world to hunt and to learn new things. I'm a dragoness who has been sent to the human world to hunt and to learn new things. I'm a dragoness who has been sent to the human world to hunt and to learn new things. I'm a dragoness who has been sent to the human world to hunt and to learn new things. I'm a dragoness who has been sent to the human world to hunt and to learn new things. I'm a dragoness who has been sent to the human world to hunt and to learn new things. I'm a dragoness who\n",
      "PyTorch: In my dreams, I'm a dragon.\"<d><scn>black<msg>Br \"I'm not sure if that counts, but you look like you're going to make a good ambassador for the people there. I'd love to meet you, but I'm not sure where I'd be right for you.\"<d><scn>black<msg>Br \"I'm not sure if that counts, but you look like one of the best ambassadors I've ever had the pleasure of meeting. You don't get to decide who you are just for the big deal.\"<d><scn>black<msg\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragoness who has been sent to the human world to hunt monsters. I've been sent to the human world to hunt monsters for a while now, but now I'm here to hunt for them.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragoness. I have a dragon's wing that goes around its body like a claw.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human.\n",
      "PyTorch: In my dreams, I'm a dragon.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human.\n",
      "PyTorch: In my dreams, I'm a dragoness who has been to the other side of the world and knows the people there. I could be anywhere in the world, but I can’t imagine where I would be without them.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragoness who has been sent to the human world to hunt monsters. I've been sent to the human world to hunt monsters for a while now, but now I'm here to hunt for them.\"<d>An \"I see.\"<p align='loremispiral'><|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragoness. I can see her in every picture she took.\"<d><scn>o2<msg>Ad \"I see. Well, then, how do you like it here?\"<p><msg>c \"Living in the city is very expensive, but I live close by.\"<d><scn>o2<msg>Ad \"Do you like the sound of that?\"<p><msg>c \"Well, I'm not sure if I like the sound of it.\"<d><scn>o2<msg>Ad \"Living in the city is\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human.\n",
      "PyTorch: In my dreams, I'm a dragon. I see dragons everywhere, but mostly in the human world.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human. I'm a dragoness who has been sent to the human world to hunt and to care for the human.\n",
      "PyTorch: In my dreams, I'm a dragoness.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prompt = \"In my dreams, I'm a dragon\"\n",
    "for i in range(10):\n",
    "    print(\"ONNX:\", onnx_model_manager.say_raw(prompt, do_sample=True))\n",
    "    print(\"PyTorch:\", model_manager.say_raw(prompt, 50, 0.7))\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a578b-32cd-44b9-829b-5aef5ec37ab0",
   "metadata": {
    "id": "unxN7nYd2gOM",
    "tags": []
   },
   "source": [
    "# Testing\n",
    "\n",
    "We created a few past (for context) + present prompts (player input) and see the different reactions. This way, we can test the models across different iterations.\n",
    "The first test involves a old prompt to compare the pre-trained model with the one trained on AWSW. Did it manage to store it's data well? Is it able to write down things that have nothing to do with AWSW? (So we know we didn't overfit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d72d4876-df61-461a-b715-980a3763f092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragon.\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f9a94-70c6-4a58-9ad1-3d6ea373dfbe",
   "metadata": {},
   "source": [
    "**This test generates boring and repetetive** replies! It's because we use no good sampling algorithm, but it does give us a indication of what the model has learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b97230c-1d3a-4dd2-a253-727e451d539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Pytorch...\n",
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Hey [player_name]!\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I think he's a nice fellow, though.\"<d><scn>park2<msg>Ry \"I think he's a nice fellow.\"<d><scn>park2<msg>Ry \"I think he's a nice fellow.\"<d><scn>park2<msg>Ry \"I think he's a\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: park2<msg>Ry \"I'm sorry, [player_name]. I didn't mean to make you feel bad about not wanting to meet you.\"<p><msg>c \"I'm not sure if you should be apologizing for what I did, but I'm not sure if you should be apologizing for what I did.\"<d><scn>park2<msg>Ry \"I'm sorry,\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: np1n<msg>Sb \"I don't know.\"<d><scn>np1n<msg>Sb \"I don't know.\"<d><scn>np1n<msg>Sb \"I don't know.\"<d><scn>np1n<msg>Sb \"I don't know.\"<d><scn>np1n<msg>Sb \"I don\n",
      "\n",
      "\n",
      "Test ONNX...\n",
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Hey [player_name]!\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I think he's a nice fellow, though.\"<d><scn>park2<msg>Ry \"I think he's a nice fellow.\"<d><scn>park2<msg>Ry \"I think he's a nice fellow.\"<d><scn>park2<msg>Ry \"I think he's a nice fellow.\"<d><scn>park2<msg>Ry \"I think he's a nice fellow.\"<d><scn>park2<msg>Ry \"I think he's a nice fellow.\"<d><scn>\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: park2<msg>Ry \"I'm sorry, [player_name]. I didn't mean to make you feel bad about not wanting to meet you.\"<p><msg>c \"I'm not sure if you should be apologizing for what I did, but I'm not sure if you should be apologizing for what I did.\"<d><scn>park2<msg>Ry \"I'm sorry, [player_name]. I didn't mean to make you feel bad about not wanting to meet you.\"<p><msg>c \"I'm not sure if you should be apologizing for what I did, but\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: np1n<msg>Sb \"I don't know.\"<d><scn>np1n<msg>Sb \"I don't know.\"<d><scn>np1n<msg>Sb \"I don't know.\"<d><scn>np1n<msg>Sb \"I don't know.\"<d><scn>np1n<msg>Sb \"I don't know.\"<d><scn>np1n<msg>Sb \"I don't know.\"<d><scn>np1n<msg>Sb\n",
      "\n",
      "\n",
      "PyTorch on cuda:0 took 2.3620 seconds\n",
      "ONNX on CPU took 11.6621 seconds\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    ('<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hey!\"', \"How are you?\"),\n",
    "    ('<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"', \"What do you think of Lorem?\"),\n",
    "    ('<p><msg>m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('<p><msg>m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "def sample_test(model_manager):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = model_manager.say(past, prompt)\n",
    "        print(f\"Prompt: {prompt}\\nReply: {reply}\\n\\n\")\n",
    "print(\"Test Pytorch...\")\n",
    "start = time.time()\n",
    "sample_test(model_manager)\n",
    "end = time.time()\n",
    "pytorch_time = end - start\n",
    "print(\"Test ONNX...\")\n",
    "start = time.time()\n",
    "sample_test(onnx_model_manager)\n",
    "end = time.time()\n",
    "onnx_time = end - start\n",
    "print(f\"PyTorch on {device} took {pytorch_time:.4f} seconds\")\n",
    "print(f\"ONNX on CPU took {onnx_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3349bf-c777-4937-a023-ff0f4f21806d",
   "metadata": {},
   "source": [
    "# Sampling test\n",
    "\n",
    "This is gonna be interesting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce4bb65f-e26e-4a62-9c67-aed885fe041d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Pytorch...\n",
      "[Test 1] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Good to know.\"<d><scn>park2<msg>Ry \"I see.\"<p><msg>c \"What is it?\"<d><scn>park2<msg>Ry \"Do you think you can come in?\"<p><msg>c \"No.\"<d><scn>park2<msg>Ry \"I see.\"<p\n",
      "\n",
      "[Test 1] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"Well, he is very friendly and has a lot of things on his plate. As for the rest, I just have a feeling he won't mind me leaving.\"<p><msg>c \"What about you, Lorem?\"<d><scn>park2<msg>Ry \"I don't know, but I'm not going\n",
      "\n",
      "[Test 1] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>Ad \"I see. What is this?\"<d><scn>black<msg>An \"There you are.\"<d><scn>black<msg>An \"You've been here before.\"<d><scn>black<msg>An \"Well, I don't know what to say.\"<p><msg>c \"Well, what are you going to do now\n",
      "\n",
      "[Test 1] -> Prompt: What will we do here?\n",
      "Reply: park2<msg>Ry \"You know, I'd like to make a little noise about it, but I think we can make it pretty interesting. Have you been to the beach in the last few days?\"<p><msg>c \"Just off the coast ofbbb.\"<d><scn>park2<msg>Ry \"That's not very nice of her.\"<p><msg>c \"What's her problem?\"\n",
      "\n",
      "-------------\n",
      "Test ONNX...\n",
      "[Test 1] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm good...\"<d><scn>park2<msg>Ry \"I'm fine. Just a little dizzy, but I think I can handle.\"<d><scn>park2<msg>Ry \"I know you're busy but you're not the first person to have a bad day, right?\"<p><msg>c \"Hey Remy.\"<d><scn>park2<msg>Ry \"I'm good...\"<d><scn>park2<msg>Ry \"I know how you feel about me, but I'm not sure if\n",
      "\n",
      "[Test 1] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I like his personality.\"<d><scn>park2<msg>Ry \"He's very smart.\"<d><scn>park2<msg>Ry \"He's a very smart guy.\"<d><scn>park2<msg>Ry \"I like that he has a very nice personality. I like having him here on our team, not having to worry about his dirty laundry.\"<d><scn>park2<msg>Ry \"That's nice. That makes a lot of room for Lore to play.\"<d><scn>park2<\n",
      "\n",
      "[Test 1] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: park2<msg>Ry \"I'm so happy you're here. I didn't know you were here.\"<p><msg>c \"I'm just not sure what else I can do, but if you tell me what you know now, maybe I'll do something different.\"<d><scn>park2<msg>Ry \"That's good to hear.\"<p><msg>c \"I'm just not sure what else I can do... I'm just not confident.\"<d><scn>park2<msg>Ry \"Maybe you should go ahead and make yourself at home.\"<p><\n",
      "\n",
      "[Test 1] -> Prompt: What will we do here?\n",
      "Reply: np2x<msg>Ad \"I don‘t like where it“<|endoftext|>\n",
      "\n",
      "----------\n",
      "PyTorch on cuda:0 took 3.4107 seconds\n",
      "ONNX on CPU took 11.9336 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Pytorch...\")\n",
    "start = time.time()\n",
    "for i in range(1):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = model_manager.say(past, prompt, top_k = 50, top_p = 0.7)\n",
    "        print(f\"[Test {i + 1}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-------------\")\n",
    "end = time.time()\n",
    "pytorch_time = end - start\n",
    "print(\"Test ONNX...\")\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "start = time.time()\n",
    "for i in range(1):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = onnx_model_manager.say(past, prompt, do_sample = True)\n",
    "        print(f\"[Test {i + 1}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-\" * 10)\n",
    "end = time.time()\n",
    "onnx_time = end - start\n",
    "print(f\"PyTorch on {device} took {pytorch_time:.4f} seconds\")\n",
    "print(f\"ONNX on CPU took {onnx_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c956842-43ba-4f9a-937a-13fda9ad1439",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RP test\n",
    "Testing out the injected roleplay actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85435494-6b29-4b18-aa34-328e33caa9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pytorch] Visit Lorem -> loremapt<msg>Lo \"Hey [player_name]!\"<|endoftext|>\n",
      "[ONNX] Visit Lorem -> loremapt<msg>Lo \"Hey [l.]! I know you don't like games, but if you wanted this all, you could've just told me about it.\"<|endoftext|>\n",
      "----------\n",
      "[Pytorch] Meet with Lorem -> loremapt<msg>Lo \"Hey [player_name]!\"<|endoftext|>\n",
      "[ONNX] Meet with Lorem -> loremapt<msg>Lo \"Oh, [playerB1]! What a pleasant surprise.\"<p><msg>c \"Meet with Adine\"<d><scn>adineapt<msg>Ad \"Hey [playerB2]! How nice of you to meet you!\"<p><msg>c \"Meet with Reza\"<d><scn>reza<msg>Rz \"I'm afraid you are not well.\"<p><msg>c \"Hey Adine\"<d><scn>adineapt<msg>Ad \"Hey [playerI2]<\n",
      "----------\n",
      "[Pytorch] Visit Adine -> adineapt<msg>Ad \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "[ONNX] Visit Adine -> adineapt<msg>Ad \"Oh, I like that! It's a shame we can't have a proper competition. I'd love to see a proper one, though I'm not sure if I can.\"<|endoftext|>\n",
      "----------\n",
      "[Pytorch] Fight Maverick -> emeraroom<msg>Em \"I'm not sure I'd agree with that.\"<|endoftext|>\n",
      "[ONNX] Fight Maverick -> black<msg>m \"He held out a hand, and I ducked past him.\"<d><scn>black<msg>m \"He took my arm and pulled me towards his face.\"<d><scn>black<msg>m \"I felt his breath on me, and his breath on mine.\"<d><scn>black<msg>m \"I looked at Maverik, who was staring at me.\"<d><scn>black<msg>m \"He shook his mitts and continued to stare at us. I could hear him sipping on the mugs of beer\n",
      "----------\n",
      "[Pytorch] Fight Adine -> black<msg>Ad \"Fight Adine? Is that you?\"<|endoftext|>\n",
      "[ONNX] Fight Adine -> black<msg>Ad \"You better not give up yet.\"<|endoftext|>\n",
      "----------\n",
      "[Pytorch] Attack Adine -> park2<msg>Ad \"How dare you enter the world of science?\"<|endoftext|>\n",
      "[ONNX] Attack Adine -> adineapt<msg>Ad \"You know how long my stay at the beach is?\"<d><scn>adineapt<msg>Ad \"Not long enough for me, really.\"<p><msg>c \"I'm not sure if I can.\"<d><scn>adineapt<msg>Ad \"I see.\"<p><msg>c \"I see.\"<d><scn>adineapt<msg>Ad \"I see.\"<p><msg>c \"You know how long it takes for the wormhole to get to your office, don't you think?\"\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "test_rps = [\n",
    "    \"Visit Lorem\",\n",
    "    \"Meet with Lorem\",\n",
    "    \"Visit Adine\",\n",
    "    \"Fight Maverick\",\n",
    "    \"Fight Adine\",\n",
    "    \"Attack Adine\"\n",
    "]\n",
    "for rp in test_rps:\n",
    "    print(f'[Pytorch] {rp} -> {model_manager.say(\"\", rp, top_k = 50, top_p = 0.7)}')\n",
    "    print(f'[ONNX] {rp} -> {onnx_model_manager.say(\"\", rp, do_sample = True)}')\n",
    "    print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c25c34-550a-407b-9378-69adbadc5adc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
