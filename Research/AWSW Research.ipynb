{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b97b376-9ac5-4c70-ba13-769649099a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_utils import train_model, split_data, split_branches, get_model, set_pretrained_model_dropout, get_dataset, ModelSeeder\n",
    "from config import Config\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import onnx\n",
    "import logging\n",
    "from onnx_model_manager import OnnxModelManager\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "import os\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from model_manager import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887d9f81-96c3-408f-bd1c-7b126becc4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use cuda:0 for training with seed: 3218885689\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randint(0, 2 ** 32 - 1)\n",
    "seed = 3218885689\n",
    "random.seed(seed)\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(f\"Will use {device_name} for training with seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e95113e-dfc1-40a9-a39b-5d56f3bf32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(os.path.join(Config.work_dir, \"awsw_story_input.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb65c62-47c6-4d36-bd1e-2adfef8ff1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lr\": 6e-4,\n",
    "    \"warmup_factor\": 0,\n",
    "    \"scheduler\": \"polynomial_decay_schedule_with_warmup\",\n",
    "    \"lr_end\": 2e-6,\n",
    "    \"power\": 0.6,\n",
    "    #\"freeze_layer_rate\": 1e-4,\n",
    "    \"freeze_from_steps\": -1,\n",
    "    \"seed\": seed,\n",
    "    \"num_epoch\": 500\n",
    "}\n",
    "\n",
    "optuna_result_attachement = {\n",
    "    'lr': 0.001,\n",
    "    'scheduler': 'cosine_schedule_with_warmup',\n",
    "    'to_freeze_count': 0,\n",
    "    #\"to_freeze_gpt_blocks\": 11,\n",
    "    'warmup_factor': 1\n",
    "}\n",
    "config.update(optuna_result_attachement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ffae5b-e197-4417-a4cd-e6befc6ee393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded empty model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_path = os.path.join(\"models\", \"awsw_main\")\n",
    "if os.path.exists(os.path.join(saved_model_path, \"pytorch_model.bin\")):\n",
    "    tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "    model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "    print(\"Pretrained model loaded\")\n",
    "else:\n",
    "    model, tokenizer = get_model(\"EleutherAI/gpt-neo-125M\")\n",
    "    print(\"Loaded empty model\")\n",
    "model.to(device)\n",
    "# set_pretrained_model_dropout(model.transformer.h[-1:], 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f3315-8f5d-4101-8e7e-2c0129204c94",
   "metadata": {},
   "source": [
    "# Test before training on a pretrained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f68c3f1-4c0a-41a2-a3fc-b8b3c36e418c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragon, a fighter, a sorcerer, a sorcerer. I am not a dragon. I am not a warrior. I am not a dragon's sword. I am not a warrior's bow. I am not a dragon's sword. I am not a warrior's bow. I am not a dragon's sword.\n",
      "\n",
      "In the first two years of the war, I was in the middle of a war. The first battle was against the dragons of the north, the dragons of the south. The dragons were being used by a group of people who were fighting in the north. They were being used\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model_manager = ModelManager(model=model, tokenizer=tokenizer, device=device)\n",
    "def test_regular_sampler():\n",
    "    print(model_manager.say_raw(\"In my dreams, I'm a dragon\", 50, 0.7))\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f74aa-5030-4ffd-ad2f-ae013647975e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reviewing our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0974ac13-c420-4275-b34a-3816f580cb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871848bf17a14174867630489607a478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset demo snapshot:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<d><scn>black<msg>Br \"Alright.\"<|endoftext|><d><scn>town4<msg>Ad \"That's right!\"<|endoftext|><d><scn>viewingspot<msg>m \"As the portal had been repaired by the mysterious person I met, now was the perfect time for Reza to make his getaway, and I was the only one who knew.\"<|endoftext|><d><scn>cafe<msg>Ad \"I apologize. Let me try that again.\"<|endoftext|><d><scn>remyapt<msg>Ry \"Anyways, is there anything in\n",
      "RP review!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\"<|endoftext|><d><scn>black<msg>Lo \"Really? That's amazing!\"<|endoftext|><d><scn>emeraroom<msg>Em \"With the same biased thinking being present in the applicants, it would have been hard to find anyone among them who was actually suited to the position of working in the archives.\"<|endoftext|><p><msg>c \"Angel\"<|endoftext|><p><msg>c \"Fight Emera\"<d><scn>emeraroom<msg>m \"I didn't hesitate and kicked Emera right in the stomach\"<|endoftext|><p><msg>c \"It could\n",
      " be something that would make me uncomfortable, or something you'd like to see me do.\"<d><scn>o2<msg>Ad \"Anything?\"<|endoftext|><p><msg>c \"Meet with Bryce\"<d><scn>bare<msg>Br \"Oh, [player_name], I wasn't expecting visitors.\"<|endoftext|><d><scn>black<msg>An \"Just wonderful. Stolen goods always taste best. I can already picture the old farmer reduced to tears after he discovers one of his precious Mouflons is gone.\"<|endoftext|><d><scn>o2<msg>\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(tokenizer, path_train = os.path.join(Config.work_dir, \"data_train.txt\"))\n",
    "print(\"Dataset demo snapshot:\")\n",
    "for item in dataset['train']:\n",
    "    print(tokenizer.decode(item['input_ids']))\n",
    "    break\n",
    "\n",
    "print(\"RP review!\")\n",
    "has_seen_rp = False\n",
    "for item in dataset['train']:\n",
    "    decoded = tokenizer.decode(item['input_ids'])\n",
    "    if 'c \"Fight ' in decoded: \n",
    "        print(decoded)\n",
    "        has_seen_rp = True\n",
    "        continue        \n",
    "    if has_seen_rp:\n",
    "        print(decoded)\n",
    "        break\n",
    "# Clean up\n",
    "del has_seen_rp\n",
    "# dataset['model_seeder'].stop_worker()\n",
    "# del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e9e10-b2eb-421a-9948-dc3590e1f46d",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Model is put in training mode and we begin training. The `train_results` will contain all data after training is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41750b03-f114-46c4-948e-637db79efe15",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] set freeze_part_layers: True (freezing 0 out of 160 layers.)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53500' max='53500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53500/53500 6:19:58, Epoch 500/500]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>535</td>\n",
       "      <td>11.180900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>3.174200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1605</td>\n",
       "      <td>2.703300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>2.375200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2675</td>\n",
       "      <td>2.207900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3210</td>\n",
       "      <td>2.124500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3745</td>\n",
       "      <td>2.062200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4280</td>\n",
       "      <td>2.054400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4815</td>\n",
       "      <td>1.995400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5350</td>\n",
       "      <td>1.987400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5885</td>\n",
       "      <td>1.997300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6420</td>\n",
       "      <td>1.947500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6955</td>\n",
       "      <td>1.948700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7490</td>\n",
       "      <td>1.870500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8025</td>\n",
       "      <td>1.831400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8560</td>\n",
       "      <td>1.749700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9095</td>\n",
       "      <td>1.679700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9630</td>\n",
       "      <td>1.801900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10165</td>\n",
       "      <td>1.868300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>1.871900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11235</td>\n",
       "      <td>1.935300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11770</td>\n",
       "      <td>1.921800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12305</td>\n",
       "      <td>1.904700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12840</td>\n",
       "      <td>1.835600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13375</td>\n",
       "      <td>1.801000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13910</td>\n",
       "      <td>1.757000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14445</td>\n",
       "      <td>1.802400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14980</td>\n",
       "      <td>1.801100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15515</td>\n",
       "      <td>1.700800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16050</td>\n",
       "      <td>1.734600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16585</td>\n",
       "      <td>1.788000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17120</td>\n",
       "      <td>1.917700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17655</td>\n",
       "      <td>1.762100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18190</td>\n",
       "      <td>1.798300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18725</td>\n",
       "      <td>1.776500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19260</td>\n",
       "      <td>1.765900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19795</td>\n",
       "      <td>1.807000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20330</td>\n",
       "      <td>1.721300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20865</td>\n",
       "      <td>1.728200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21400</td>\n",
       "      <td>1.810800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21935</td>\n",
       "      <td>1.706000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22470</td>\n",
       "      <td>1.725900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23005</td>\n",
       "      <td>1.852400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23540</td>\n",
       "      <td>1.867700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24075</td>\n",
       "      <td>1.760300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24610</td>\n",
       "      <td>1.796200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25145</td>\n",
       "      <td>1.726900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25680</td>\n",
       "      <td>1.678200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26215</td>\n",
       "      <td>1.648500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26750</td>\n",
       "      <td>1.641800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27285</td>\n",
       "      <td>1.656800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27820</td>\n",
       "      <td>1.661800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28355</td>\n",
       "      <td>1.599200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28890</td>\n",
       "      <td>1.545300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29425</td>\n",
       "      <td>1.493800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29960</td>\n",
       "      <td>1.464400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30495</td>\n",
       "      <td>1.431800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31030</td>\n",
       "      <td>1.411400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31565</td>\n",
       "      <td>1.357200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32100</td>\n",
       "      <td>1.317200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32635</td>\n",
       "      <td>1.282800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33170</td>\n",
       "      <td>1.258900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33705</td>\n",
       "      <td>1.231600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34240</td>\n",
       "      <td>1.217500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34775</td>\n",
       "      <td>1.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35310</td>\n",
       "      <td>1.172100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35845</td>\n",
       "      <td>1.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36380</td>\n",
       "      <td>1.127900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36915</td>\n",
       "      <td>1.108400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37450</td>\n",
       "      <td>1.091800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37985</td>\n",
       "      <td>1.075100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38520</td>\n",
       "      <td>1.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39055</td>\n",
       "      <td>1.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39590</td>\n",
       "      <td>1.047600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40125</td>\n",
       "      <td>1.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40660</td>\n",
       "      <td>1.026700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41195</td>\n",
       "      <td>1.014500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41730</td>\n",
       "      <td>1.007900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42265</td>\n",
       "      <td>1.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42800</td>\n",
       "      <td>0.996700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43335</td>\n",
       "      <td>0.988700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43870</td>\n",
       "      <td>0.983500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44405</td>\n",
       "      <td>0.975900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44940</td>\n",
       "      <td>0.971100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45475</td>\n",
       "      <td>0.967300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46010</td>\n",
       "      <td>0.962300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46545</td>\n",
       "      <td>0.960600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47080</td>\n",
       "      <td>0.955400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47615</td>\n",
       "      <td>0.953500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48150</td>\n",
       "      <td>0.949700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48685</td>\n",
       "      <td>0.946700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49220</td>\n",
       "      <td>0.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49755</td>\n",
       "      <td>0.942800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50290</td>\n",
       "      <td>0.943200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50825</td>\n",
       "      <td>0.940200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51360</td>\n",
       "      <td>0.941500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51895</td>\n",
       "      <td>0.940100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52430</td>\n",
       "      <td>0.938300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52965</td>\n",
       "      <td>0.940400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53500</td>\n",
       "      <td>0.939400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results = {}\n",
    "model.train()\n",
    "train_model(model, tokenizer, dataset, config, train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c410a601-c5e4-4cc1-af2b-44a7378f3bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f90d3bbe040>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEVCAYAAADkckIIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA50klEQVR4nO3deXwc13Xg+9/pHWtjaQAECJIgCXDVSlGkZG2U5EWSPaGdOLbsxHEcz1M8tp+dxUnkl5dlnPE8ZyYfx/HHGTt6tmw5L5bske2EUbxpoXaJEklt3AnuAEHsO9D7eX9UAWxAIAWKALvRfb4f9qe7b92qurer2Qd1b9W9oqoYY4wxEzzZLoAxxpjcYoHBGGPMFBYYjDHGTGGBwRhjzBQWGIwxxkxhgcEYY8wUFhhMXhCRm0TkYLbLkYtE5LiIvPMcy74nIv/tUpfJ5DYLDOaine+H51JR1WdUdXU2yzBBRLaISFu2y2HM22WBwSwIIuLNdhkAxGH/b0xesy+4mTci4hGRe0XkiIj0isiPRKQqY/n/FpEzIjIoIk+LyPqMZd8TkW+KyM9EZBS41T0z+YKIvO6u80MRCbn5p/yVfr687vI/FZEOETktIv9ZRFREms9RjydF5Msi8hwwBqwQkU+IyH4RGRaRoyLy+27eEuDnQIOIjLiPhrf6LKbtr1JEHhGRbhHpd183TivP34jIc+7+fyUikYzlHxORE+5+/vwCj9n/ISKtItInIttEpMFNFxH5exHpEpEhEXlDRC5zl90lIvvcsrSLyBcuZJ8m91hgMPPp/wTeD9wCNAD9wD9mLP850ALUAruBf5m2/keBLwNlwLNu2oeAO4DlwBXA755n/zPmFZE7gD8C3gk0A1tmUZePAfe4ZTkBdAHvA8qBTwB/LyIbVHUUuBM4raql7uP0LD6LTB7gu8AyYCkwDnxjWp6PuvutBQLAF9y6rQO+6Za3AagGGpkFEbkN+H9wPrd6t54PuYvfDdwMrALCbp5ed9l3gN9X1TLgMuCJ2ezP5C4LDGY+fQr4c1VtU9UY8NfAB0XEB6Cq96vqcMayK0UknLH+v6nqc6qaVtWom/Z1VT2tqn3AvwNXnWf/58r7IeC7qrpXVcfcfb+V77n5k6qaUNX/UNUj6ngK+BVw09v9LDKpaq+q/lhVx1R1GCc43jIt23dV9ZCqjgM/yqjbB4FHVPVpdz9/AaRnUT+A3wLuV9Xd7rpfBK4XkSYggRMU1wCiqvtVtcNdLwGsE5FyVe1X1d2z3J/JURYYzHxaBvxURAZEZADYD6SAOhHxishX3KaVIeC4u04kY/1TM2zzTMbrMaD0PPs/V96GadueaT/TTckjIneKyItuk8sAcBdTyz7dOT+L6RlFpFhE/sltDhoCngYqpvWzzKpu7hlML7PTgHOWMLHuiLvuYlV9Aues5R+BLhG5T0TK3ay/gVP/EyLylIhcP8v9mRxlgcHMp1PAnapakfEIqWo7TlPIVpzmnDDQ5K4jGevP19C/HUxtXlkyi3UmyyIiQeDHwN8BdapaAfyMs2Wfqdzn+yym+2NgNbBZVctxmnBg6mdzLh2Z9RGRYpzmpNk4jRPAJtYtcddtB1DVr6vqNcA6nCalP3HTX1bVrTjNWv+KcwZjFjALDGau+EUklPHwAd8CviwiywBEpEZEtrr5y4AYzl+kxcB/v4Rl/RHwCRFZ6/5w/sUFrh8AgkA3kBSRO3Ha4Cd0AtXTmsXO91lMV4bTrzDgdlD/1QWU7WHgfSJyo4gEgC8x+//nD+J8Lle5we+/AztU9biIXCsim0XED4wCUSAtIgER+S0RCatqAhhi9k1XJkdZYDBz5Wc4P2YTj78G/gHYBvxKRIaBF4HNbv7v4zRbtAP73GWXhKr+HPg6sB1ozdh3bJbrDwOfwwkw/ThnP9sylh/A+ZE96jYdNXD+z2K6rwFFQI+b7xcXULe9wGeAH+CcPfQDs7qnQlUfwwmSP3bXXQnc7S4uB/5fd3sncAL6/3SXfQw47jZ7fQqnr8IsYGIT9ZhCJyJrgT1AUFWT2S6PMdlmZwymIInIB0QkKCKVwN8C/25BwRiHBQZTqH4f516EIzhXB/2X7BbHmNxhTUnGGGOmsDMGY4wxU1hgMMYYM4UFBmOMMVNYYDDGGDOFBQZjjDFTWGAwxhgzhQUGY4wxU1hgMMYYM4UFBmOMMVNYYDDGGDOFBQZjjDFTWGAwxhgzhQUGY4wxU1hgMMYYM4VvNplE5A6cqQm9wLdV9SvTlgdxpmq8BmfKvw+r6nF32ReBT+KMef85Vf2lm34/8D6gS1Uvy9hWFfBDnMnhjwMfUtX+85UvEoloU1PTbKpijDHGtWvXrh5VrZme/pbzMYiIFzgEvAtn7tiXgY+o6r6MPJ8GrlDVT4nI3cAHVPXDIrIOZ+7bTUAD8BiwSlVTInIzMAJ8f1pg+B9An6p+RUTuBSpV9c/OV8aNGzfqzp07Z/ExGGOMmSAiu1R14/T02ZwxbAJaVfWou6GHgK04E7hP2Ioz+TvAw8A3RETc9IdUNQYcE5FWd3svqOrTItI0w/62Alvc1w8ATwLnDQxv17bXTnOydxSPR/CK4PUIAZ8Hn8dDwOc8gj4PIb+XoolHwEtJ0EtJ0EdJwIfXI/NRNGOMyZrZBIbFwKmM923A5nPlUdWkiAwC1W76i9PWXfwW+6tT1Q739RmgbqZMInIPcA/A0qVL37oWM/jJ7jaePNj9ttadUBLwUhbyUxbyES7yU1Hsp7zIT2VxgKqSwORzpDRAdWmQmrIgJQEvTtw0xpjcM6s+hmxRVRWRGdu6VPU+4D5wmpLezva/8/FrSaWVtCqptJJMK8lUmkRKiSfTxFMpook0sWSK8Xia8USKsXiSsXiK0ViSkViS4WiS4WiC4WiSwfEEpwei7O8Ypn8szlg8NeN+i/xeasuD1JYFqSsPUVceoj4coj5cxKJwiMUVRdSWBfHY2YgxJgtmExjagSUZ7xvdtJnytImIDwjjdELPZt3pOkWkXlU7RKQeZ8L2eeH1yLw2BUUTKfrH4vSOxOkdjdMzHKNnJEb3cIyu4Rhdw1H2nh7i8f1djCemBhG/V6gPF9FYWcSSymKWVBWxpKqYpuoSllUXU1EcmLdyG2MK22wCw8tAi4gsx/lRvxv46LQ824CPAy8AHwSecP/a3wb8QES+itP53AK89Bb7m9jWV9znf5tlXXJOyO+lPlxEfbjovPlUlaHxJKcHx+kYHKd9IEp7/zjtA+O09Y/x+IFOekbiU9YJF/lpipSwIlJCU3UJK2tLWBEpZXmkhKKAdz6rZYzJc28ZGNw+g88Cv8S5XPV+Vd0rIl8CdqrqNuA7wD+7nct9OMEDN9+PcDqqk8BnVDUFICIP4nQyR0SkDfgrVf0OTkD4kYh8EjgBfGhOa5yDRIRwsZ9wsZ+19eUz5hmLJznVN86J3lFO9o1xrGeU472jvHSsj5++0p6xLWisLKKltozm2lJW1ZWxqq6U5tpSigM53XJojMkRb3m56kJQ6JerjsdTHOsZ5Uj3CEe6R2jtch5Hu0eJp9KAEzCWVRWzelEZaxaVs7a+nHX15SypKrKOcGMK1MVcrmpyXFHAy7qGctY1TD3bSKbSnOgb49CZYQ52DnPwjPP41b5OJv4eKAv6WFtfzvrF5axvCHP54jAra0rwee2meGMKlQWGPObzelhZU8rKmlLuvLx+Mn08nuJg5zD7O4bYd3qIvacHefClk0QTztlFyO9hXX05VzRWcPniMFcuCbMiUmpXSRlTIKwpyQCQSitHu0fYc3qQN9qG2NM+yJ7Tg5OX3JYGfVzRGOaqJRVctaSCq5dWUlMWzHKpjTEXw5qSzHl5PUJLXRktdWV84GonLZVWjnSP8NqpAV5rG+C1U4Pc9/RRkmnnj4nGyiI2LK1kw9IKrllWxZr6MvzWBGXMgmdnDOaCRBMp9p4eZPeJAXaf7Gf3yX46h2KAc+PeVUsquLapko1NVWxYVklp0P72MCZX2RmDmRMhv5drllVxzbIqwLkH4/RglF0n+tl9op+Xj/fxje2tpBU8Ausayrm2qYrNy6u4tqmK6lJrfjIm19kZg5lzI7Ekr5zs5+Vjfbx8vJ9XTvVPdmw315Zy3YoqrltRzebl1dZPYUwWneuMwQKDmXfxZJo32gd56VgfLx7tZefxPkbdTu2JQHH9igjXrbAzCmMuJQsMJmckU2n2nh7ihaO9vHi0l5ePnQ0UaxaV8Y6VEW5ormbzimrrozBmHllgMDkrkUrzetsgLx7t5fkjPew83k8smcbrEa5sDHNjSw03Nke4akkFAZ9d9WTMXLHAYBaMaCLF7hP9PHekh2dbe3mjbYC0QnHAy3UrqrmpJcJNLRFW1pTacB7GXAQLDGbBGhxP8MKRXp5t7ebZwz0c7x0DoD4c4qaWCDevquGGlREqS2wocmMuhAUGkzdO9Y3xzOEenjnczXOtPQxFk4jAFY0V3NIS4ZbVNVzZWGHjPRnzFiwwmLyUTKV5rW2QZw5389Shbl475TQ7lYd83NRSwy2rarhldQ115aFsF9WYnGOBwRSEgbE4z7X28tShLp461D15V/aaRWXcuqaWLatq2LCs0obuMAYLDKYAqSr7O4Z56lA3Tx7sYteJfpJppSzk46aWCFtW17JldQ21ZXY2YQqTBQZT8IaiCZ473MOTB7t58lDX5NnE5YvD3Lq6hlvX1HJFY8W8zgNuTC6xwGBMhomzie0Hu9h+oIvdJ/tJK1SVBNiyygkSN6+qIVzkz3ZRjZk3FhiMOY/+0ThPH+5m+4EunjzUzcBYAq9H2LisktvW1HL72lq7b8LkHQsMxsxSKq28eqqfJw508cSBbvZ3DAGwtKqY29bUctuaWjavqCLo82a5pMZcnIsKDCJyB/APgBf4tqp+ZdryIPB94BqgF/iwqh53l30R+CSQAj6nqr883zZF5HvALcCgu/nfVdVXz1c+CwxmPp0eGOeJA06T07OtPcSSaYoDXm5sjnD72lpuXV1LrV0Oaxagtx0YRMQLHALeBbQBLwMfUdV9GXk+DVyhqp8SkbuBD6jqh0VkHfAgsAloAB4DVrmrzbhNNzA8oqoPz7ZyFhjMpTIeT/HC0R7nbGJ/F6cHowBc2RjmtjV13L62lvUN5dbkZBaEi5moZxPQqqpH3Q09BGwF9mXk2Qr8tfv6YeAb4vzP2Ao8pKox4JiItLrbYxbbNCbnFAW83LamjtvW1KFbz3ZgP76/k689foi/f+wQdeVBJ0isqeWG5ghFAWtyMgvLbALDYuBUxvs2YPO58qhqUkQGgWo3/cVp6y52X59vm18Wkb8EHgfudQPLFCJyD3APwNKlS2dRDWPmloiwrqGcdQ3lfObWZnpHYmw/2M0TBzr599dO8+BLJwn6PLxjZTW3ra3jtjW1LK4oynaxjXlLuTjY/ReBM0AAuA/4M+BL0zOp6n3ucjZu3Ljwe9DNglddGuSD1zTywWsaiSfTvHSsj8cPdPL4/i62H9zDXwBr68u5fU0tt66p5aolds+EyU2zCQztwJKM941u2kx52kTEB4RxOqHPt+6M6ara4abFROS7wBdmUUZjckrA5+HGlgg3tkT4y/et40j3KE8c6OSx/V1886kjfGN7q3PPxOoabl9Tx02rIpSH7J4JkxtmExheBlpEZDnOj/fdwEen5dkGfBx4Afgg8ISqqohsA34gIl/F6XxuAV4C5FzbFJF6Ve1w+yjeD+y5uCoak10iQnNtKc21pdxz80oGxuI8daibJw508fj+Ln6yux2fR7i2qcq5ymlNLSsiJdaBbbJmtper3gV8DefS0vtV9csi8iVgp6puE5EQ8M/A1UAfcHdGx/KfA78HJIE/UNWfn2ubbvoTQA1O8HgV+JSqjpyvfHZVklmokqk0r5wa4LH9nWw/0MWhTuervqz67D0Tm5bbPRNmftgNbsYsAKf6xth+sIsnDnTx/JFe4hn3TNy6xrlnYlHY7pkwc8MCgzELzHg8xfNHeiZvrpu4Z2JtffnkoH9XL7EJiczbZ4HBmAVMVTnUOTI56N/OE/2k0upMSLSqhi3uhEQ2hLi5EBYYjMkjg+MJnj3cw5MHnUH/uoedW33WN5SzZXUNW1bb2YR5axYYjMlT6bSyr2NockKi3ScHSLkTEt3YHOGWVTXcvKqGBru5zkxjgcGYAjE4nuD5VmdCoqcOdXNmyOmbaK4t5eaWGm5eFWHz8mobqsNYYDCmEKkqh7tGePqQEyR2HOsjnkwT8Hm4tqmSG5truKklwrr6cjx2F3bBscBgjCGaSPHSsT6ePtTNs609HDgzDDgz171jZTU3tUS4oTlCY2VxlktqLoWLGV3VGJMnQn4vN7t9DgBdQ1GeOdzDc609PNPawyOvOyPSNFUX847mCDesjHDdiiqqS4PZLLa5xOyMwRgDnL0k9rnWHp4/0sOLR/sYiSUBWLOojHesjHD9ymo2La+yubDzhDUlGWMuSDKV5o32QZ4/0stzrT3sOtFPLJnGI7C+Icx1K6q4bkU1G5ssUCxUFhiMMRclmkjx6qkBnj/Sy46jvbxycoB4Ko0IrKsvZ9PyKjYvr2JjUxURa3paECwwGGPmVDSR4pWTA+w41stLx/rYfbKfaCINwIqaEjY1OUFi47JKllUX22ixOcg6n40xcyrk93L9ymquX1kNQDyZ5o32AV461s/Lx/v42RsdPPSyM1FjpDTINcsquGZZJRuWVnLZ4jAhv91HkavsjMEYMy/SaaW1e4SXj/ex63g/u072c6J3DAC/V1jXEGbD0gquWuI8llbZWcWlZk1Jxpis6x6OsftkP6+cHGD3yX5ebxuYbH6qKglw+eIwVzaGuXJJBZc3hm1QwHlmTUnGmKyrKQvynvWLeM/6RYBz5dPBzmFePTXAqycHeL1tkGcOd5N2/16tKw9y+eIKLltczvqGMJctLmdRecjOLOaZBQZjTNb4vB7WN4RZ3xDmtzYvA2AsnmRP+xBvtA+yp32QN9oHefxAJxONG5XFftY1lLN2UTlr68tZU19Gc22pzXI3hywwGGNySnHAx6blVWxaXjWZNhpLcuDMEHvah9jfMcS+jiG+/+IJ4kmnGcrnEZZHSli1qIzVdWWsqiulubaMZdXF+G3o8QtmgcEYk/NKgj6uWVbFNcvOBotkKs3x3lH2dwxz4MwQB8+M8EbbID97o2Py7MLvFZqqS1hZU8rKWue5KVLCikgJFcWBLNUm91lgMMYsSD6vh+baMppry/hPVzZMpo/FkxzpGuVw1zCHOkc40j3C4a5hHtvfSTJ99mKbymI/S6tLaKouZllVMY1VxSytKmZJVTGLykN4C3i02VkFBhG5A/gHwAt8W1W/Mm15EPg+cA3QC3xYVY+7y74IfBJIAZ9T1V+eb5sishx4CKgGdgEfU9X4xVXTGFMoigM+Lm8Mc3ljeEp6IpXmZN8Yx3tGOdYzytGeUU72jrHrRD///tppMmIGPo9QXxFicUURDeEi6itC1IeLWFQeYlHYeVQVB/J2qPK3DAwi4gX+EXgX0Aa8LCLbVHVfRrZPAv2q2iwidwN/C3xYRNYBdwPrgQbgMRFZ5a5zrm3+LfD3qvqQiHzL3fY356KyxpjC5fd6nCalmtI3LYsn05weGOdU/xin+sZpHxijrX+c9v5xdhzr48xQlFR66qX9Po8QKQ1SU+Y8qksCRNznyuIAVSUBwsV+Kor8VBQHKA/5FsxUq7M5Y9gEtKrqUQAReQjYCmQGhq3AX7uvHwa+Ic71ZFuBh1Q1BhwTkVZ3e8y0TRHZD9wGfNTN84C7XQsMxph5E/B5aIqU0BQpmXF5Kq10DUc5Mxilc8h57h6J0TUUo2s4RtdwlH2nh+gdjZFInfvesOKAl7KQj9Kgj9KQn9Kgl+KAj+KAlyK/l5D7CPo8BP0eAl4Pfq8Hn1fweQSPCF73eeKK3dvW1FIWmttBDGcTGBYDpzLetwGbz5VHVZMiMojTFLQYeHHauovd1zNtsxoYUNXkDPmnEJF7gHsAli5dOotqGGPM2+P1CPXhIurD5583W1UZjiXpH43TOxpncCzBwHicgbEEQ+NJhqMJhqIJRmJJRmIpRmNJekfGGE+kGIuniMZTxJJp4qn0rMv22B/dkpXAkJNU9T7gPnDufM5ycYwxBhGhPOSnPORnWfXMZx+zkU4r8VSaRCpNIqUkUmlSaZ18KJBWRRWWVJ0/WL0dswkM7cCSjPeNbtpMedpExAeEcTqhz7fuTOm9QIWI+Nyzhpn2ZYwxec3jEUIeb9YGGpxNYHgZaHGvFmrH6Uz+6LQ824CPAy8AHwSeUFUVkW3AD0Tkqzidzy3AS4DMtE13ne3uNh5yt/lvb1XAXbt29YjIiVnUZSYRoOdtrruQFWK9C7HOUJj1tjrPzrKZEt8yMLh9Bp8Ffolzaen9qrpXRL4E7FTVbcB3gH92O5f7cH7ocfP9CKejOgl8RlVTADNt093lnwEPich/A15xt/1WZax5qzznIiI7ZxpEKt8VYr0Lsc5QmPW2Ol/ktvJhdNWLUYhfICjMehdinaEw6211vjgL46JaY4wxl4wFBvfKpgJUiPUuxDpDYdbb6nwRCr4pyRhjzFR2xmCMMWYKCwzGGGOmKOjAICJ3iMhBEWkVkXuzXZ75ICJLRGS7iOwTkb0i8nk3vUpEHhWRw+5zZbbLOtdExCsir4jII+775SKywz3ePxSRvBuQX0QqRORhETkgIvtF5Pp8P9Yi8ofud3uPiDwoIqF8PNYicr+IdInInoy0GY+tOL7u1v91EdlwIfsq2MCQMWrsncA64CPuaLD5Jgn8saquA64DPuPW817gcVVtAR533+ebzwP7M95PjNzbDPTjjNybb/4B+IWqrgGuxKl/3h5rEVkMfA7YqKqX4dwXNTHCc74d6+8Bd0xLO9exvRPnhuIWnDHlLmgg0oINDGSMGuvO9zAxamxeUdUOVd3tvh7G+aFYjFPXB9xsDwDvz0oB54mINALvBb7tvheckXsfdrPkY53DwM24N4WqalxVB8jzY41zo26ROxxPMdBBHh5rVX0a5wbiTOc6tluB76vjRZyhhupnu69CDgwzjRo740iu+UJEmoCrgR1Anap2uIvOAHXZKtc8+Rrwp8DEMJWzHrl3AVsOdAPfdZvQvi0iJeTxsVbVduDvgJM4AWEQZ4KvfD/WE851bC/q962QA0NBEZFS4MfAH6jqUOYyda5ZzpvrlkXkfUCXqu7KdlkuMR+wAfimql4NjDKt2SgPj3Ulzl/Hy3HGYyvhzc0tBWEuj21e3McQiUS0qakp28UwxpgFZdeuXT0zjTW3YOdjyNTU1MTOnTuzXQxjjFlQzjUqdV4EBmNM4VKdmNRGSSSdyW1iyamT3MRTaeKTaWniSTc9My2l096nSbj5Uu6kOOo+p/XsZDk4/yYnzplYppPrvDnt7PpOGhnrX6j/+ZtXsrhibifrscBgjJlXqkoipYwnUozHU4zEnCkux+Ip95E8+zqWZCzhPA9Fk4zGkpN5Jn6o46k0Y/Ek4/EU0aTz4z7XPOLMA+1351z2iOAREMGZbxlntjY5V5r72iMgTORz8ng8TprHyeSkZSyfmMt5tuajO8ACgzFm1tJpZXA8wZmhKB2D4wxHnR/ovjFnXuPhqDO38cB4nP7RBIPjCfrH4ozFU7Peh88jFAe8hIv9lAR8FAe8FAW8VPoC+LxCwOel2O+kBf0egj4vQZ8Hv1cIeD343R/0YMYPu98rBHweZ7n7mHzvk6nvvR68ngv8dc4zFhiMMag6P/jHe8c43jNKx2CUM4PjdI/E6BmO0zMSo3skxkgsec7mjqDPQ1nIT3mRj4oiP/XhEGvry6ko9lNR5Kco4KU44KMk6KUs5HNeB3xuunfydcBnF0tmmwUGYwpAOq10DEU53jNKe/84bQPjtPWP0do1QvdwjN6ROPHU1CaZspCP2rIgkdIgaxvKubk0SHnIR7g4wKLyEPUVIcJFfor8XiqLAxQFsjM/sZl7FhiMySPD0QSHOkdo7RrmWM8Yx3pGON4zxvHeUWIZbfEiUFcWoqWulFV1ZURKg0RKAzRWFtNcW0p9OERJ0H4eCpUdeWMWGFXl9GCUQ2eGae0a4XDXMEe6R2nrH6NzKDaZz+8VllYVszxSys2rIiyPlNIUKWZJZTF15SFrsjHnZIHBmBynqhzpHuWlY33sOtHPC0d6OD0YnVweKQ2wsqaUm1pqWB4pYXVdGS11pSyuKMLntR9/c+EsMBiTY1SVtv5xXjzay4tH+3jxaC/tA+MAVJcE2NhUyae2rGRtfTkttaVUFC/4EaVNjrHAYEyWqSr7OoZ4+lAPr7cNsONYH32jcQCqSgJsXl7Fp7as5IaV1SyPlCAXeqG7MRfIAoMxWTASS/L0oW6ePNjFM4d76HCbhpZUFbFlVQ0bllVybVMVLbWleAr8mnpz6VlgMOYSGY0leepQN9tePc32g13EkmnKQz5uaI7wh++s5dY1tdSUBbNdTGMsMBgzn4aiCZ482M0v9nTwxIEuook0NWVBPrJpKXdctohrm6oK/i5bk3vmJTCIyB04Uwx6gW+r6lfOke83cGZZulZVd4rIJuC+icXAX6vqT+ejjMbMh1gyxaEzI7x0vI+nDnXzwpEeEiklUhrkN69Zwl2X17NpuQUDk9vmPDBkzKX8LpxZg14WkW2qum9avjKcOXl3ZCTvwZm7NelOQ/eaiPx7xkxMxuSUwfEELxzp4alD3Tx/pJe2/nFSaWfMiKbqYn7vhuW8e30dVy2ptGBgFoz5OGOYnEsZQEQm5lLeNy3f3+BM2P0nEwmqOpaxPEQezTRl8oOqcrBzmEf3drL9YBevnhogrVAW9HH9ymp+7coGVtWVsWl5FXXloWwX15i3ZT4Cw0xzjW7OzCAiG4AlqvofIvIn05ZtBu4HlgEfO9fZgojcA9wDsHTp0rkrvTHTxJNpdp7o4/H9XTy6r5OTfc7fL1c0hvnsbS3csLKaDcsq8dvNZCZPXPLOZxHxAF8Ffnem5aq6A1gvImuBB0Tk56oanSHffbj9ERs3brQzCzOnVJVXTg3w8K42HnntNEPRJAGvh3c0V/OpW1byzrW11NoZgclT8xEY2oElGe8b3bQJZcBlwJPujTqLgG0i8muqOjk/p6ruF5ERN6/N22nmXTSRYsexPp4+1M32g10c7R4l5Pdwx/pF3Hl5PTc0Ryi1geVMAZiPb/nLQIuILMcJCHcDH51YqKqDQGTivYg8CXzBvSppOXDK7XxeBqwBjs9DGY0hnVZebx/ktVMDPHmwixeO9hJNpAn4PFy9pIJP3bySOy9fRFnIn+2iGnNJzXlgcH/UPwv8Eudy1ftVda+IfAnYqarbzrP6jcC9IpIA0sCnVbVnrstoClcqrbx6aoCfvdHBkwe7ONI9CjhXEN197VJuWV3DdcurbW4BU9BkPuYLvdQ2btyoO3daa5OZWcfgOM8c6uHpw90829rDwFiCoM/DlUsq+OA1jWxqqqIpUpLtYhpzyYnILlXdOD3dGkxNXjp4ZpgfvnyKpw9309o1AkBtWZDb1tRyc0sNt6+ttSYiY87BAoPJC6rKG+2DPLqvk5/vOUNr1wgBr4fNK6r48MYl3LQqwuq6MhuZ1JhZsMBgFqyRWJLH93fyRtsgzx3pZX/HEB6BTcur+J3r13PX5fVESm1QOmMulAUGs6AMjifY9mo7/7LjJK1dIyTTSsDr4YrGMH+zdT3vvaKBqhKbuMaYi2GBweS0wfEEj+7rZNeJfo71jLD7xADxVJrLF4f5/VtWsGV1LVcvqbApLI2ZQxYYTM5QVQbGEuzrGGLv6UGea+1lxzHn3oKykI/GymJ+94Ym3ndFPZcvDlt/gTHzxAKDyapUWnnlZD+/2tfJT19pp3s4NrlsRU0Jv3ZlAx/ZtJSrllRYIDDmErHAYC4pVeVU3zhPHuri6UM9vHSsl6FoEr9XuKmlhhuaI6yIlHBFY5hq6zg2JissMJh5d2YwyqunBnjlZD+/2HuGE73O6KTLqou56/J6rl9ZzW1r7L4CY3JFrs3g9i7gK0AAiAN/oqpPzEcZzfzpHIry4tFeXjzaywtHejnuBgKfR3hHc4Tfu2E5NzRX01xbluWSGmNmkmszuPUA/0lVT4vIZTjjLS2e6zKauRVPptl9sp/tB5z5Co72OOMPlYV8bF5exW9ft4xrllWyZlG5jUFkzAKQazO4vZKxfC9QJCJBVY1hckrPSIz/eL2DZw738MKRHkbjKQBuXlXDRzYt5boV1axrKLfpLI1ZgHJuBrcMvwHsPldQsBncLr1kKs32g91se+00v9x7hngyzeKKIj6wYTE3tTijkoaLrZ/AmIUu52Zwc/OsxzmbePe58tgMbpdGMpXmxaN9PLbfuZx0cDxBadDH3dcu4WPXLaOlzvoJjMk3OTeDm4g0Aj8FfkdVj8xD+cx5HOkeYdfxfp5t7eHgmWE6h6MMjCXweYQbmiN8dPNSbl9Ta3caG5PHcm0GtwrgP4B7VfW5eSibmSaaSPHM4R52HO3lCXc6S4DqkgBXL63k8sYw71xby5bVtYT81nFsTCHItRncPgs0A38pIn/ppr1bVbvmupyFLJpI8fyRHh55vYNf7e1kJJbEI/COlRE+umkpm5ZXsb4hbB3HxhQom8GtAKTTyr6OIV440ssb7YM8ebCLoWiSspCPuy6r571X1HPNskpKbKJ7YwqKzeBWYOLJNHtPD/KrfZ38ZHcbnUPOxV314RC3ranl/Vcv5vqV1QR91jxkjJnKAkOeSKbS7D45wJMHu9h5op/XTg0QS6YRgdvX1PKFdy/i5lU11JWHsl1UY0yOs8CwgCVTaR4/0MW2V0/z2P5OYsk0HoFVdWX89nXL2LC0ks0rqmwWM2PMBbHAsAD1jcb53ztP8eBLJzneO0Z5yMdvbmzkHSsj3LyqhlLrKzDGXAT7BVkg2gfGeXTvGX6+5wwvH+8jrbBhaQX33rmG29bUEfDZfQXGmLlhgSGHpdLKM4e7+cGOkzy6vxNVZ/Kaz9zazJbVNVyzrCrbRTTG5CELDDkmnkzz4tFenmvt4aevtNM1HKOy2M9nb21m61UNrKwptZnMjDHzygJDDpgIBv/6SjuP7e9kKJrE5xG2rK7lg9c0ctuaWmsqMsZcMhYYsmQ0luSJA138fE8H2w90M55IES7y8+71i7jzskVsXlFtncjGmKzItRncqifeA99T1c/OR/myZTSWZPvBLn65t5NH950hmkgTKQ3y6xsWc1NLhFvX1NoNZ8aYrMu1GdyiwF/gjL562VyXLVtO9Y3xwPPHeXh3GwNjCapLAvz6hka2XtnAxqYqG5PIGJNTcm0Gt1HgWRFpnodyXVKD4wke29fJI6+f5qlD3XhEeOfaOj6yeSk3NUfwWDAwxuSoXJ7BbcFJp5UnDnTx4EsnefpwN4mU0hAO8albVvI71zexKGzDURhjcl9OzuA2y+3kxNSeqbTy0rE+frXvDE8d6uZo9yiLykN8/Pom3ntFPVctqbDLS40xC0rOzeA2251kc2rPVFrZcayXn73RwS/2dNIzEiPo83BtUxWf3tLM+69qsBnOjDELVk7N4DYPZZkzqsob7YP8ZHc7j7x+mp6ROEV+L7etqeXOyxdx6+pam8/AGJMXcm0GN0TkOFAOBETk/TgzuE3vuJ4Tz7f24PN62LT83ENLtHaN8B+vd/DI66c53DVCwOfhnWtred8VDWxZXUNxwIKBMSa/FPQMbh/6pxd49dQAP//8TaysKQWcZqK9pwd5bH8XP3ujg9auEUTg2mVVfGDDYu66vJ5wkX+uq2CMMZfcuWZwK+jA0DUU5Z1ffQq/10NLnRMY9ncMMzieQAQ2NVVx1+X1vGf9IruiyBiTd2xqzxnUlof45m9fw3eePcZILEk6rbx7XR03NEe4qSVCtU1wY4wpQAUdGABuaI5wQ3PkrTMaY0yBsGsqjTHGTJEXfQwi0g2ceJurR4CeOSxOLrI65gerY37IpTouU9Wa6Yl5ERguhojsnKnzJZ9YHfOD1TE/LIQ6WlOSMcaYKSwwGGOMmcICgzveUp6zOuYHq2N+yPk6FnwfgzHGmKnsjMEYY8wUFhiMMcZMUdCBQUTuEJGDItIqIvdmuzznIyL3i0iXiOzJSKsSkUdF5LD7XOmmi4h83a3X6+6MeRPrfNzNf1hEPp6Rfo2IvOGu83XJwuxCIrJERLaLyD4R2Ssin8+3eopISEReEpHX3Dr+Vzd9uYjscMv1QxEJuOlB932ru7wpY1tfdNMPish7MtKz/r0WEa+IvCIij7jv86p+bjmOu9+lV0Vkp5uWH99VVS3IB86Q4EeAFUAAeA1Yl+1ynae8NwMbgD0Zaf8DuNd9fS/wt+7ru4CfAwJcB+xw06uAo+5zpfu60l32kptX3HXvzEId64EN7usy4BCwLp/q6e631H3tB3a45fkRcLeb/i3gv7ivPw18y319N/BD9/U69zsbBJa732VvrnyvgT8CfgA84r7Pq/q5ZTwORKal5cV3tZDPGDYBrap6VFXjwEPA1iyX6ZxU9Wmgb1ryVuAB9/UDwPsz0r+vjheBChGpB94DPKqqfaraDzwK3OEuK1fVF9X5Rn4/Y1uXjKp2qOpu9/UwsB9nDvG8qadb1hH3rd99KHAb8LCbPr2OE3V/GLjd/ctxK/CQqsZU9RjQivOdzvr3WkQagfcC33bfC3lUv7eQF9/VQg4Mi4FTGe/b3LSFpE5VO9zXZ4A69/W56na+9LYZ0rPGbVK4Gucv6ryqp9vM8irQhfNDcAQYUNXkDOWarIu7fBCo5sLrfil9DfhTIO2+rya/6jdBgV+JyC5x5qCHPPmuFvzoqvlCVVVE8uLaYxEpBX4M/IGqDmU2reZDPVU1BVwlIhXAT4E12S3R3BGR9wFdqrpLRLZkuTjz7UZVbReRWuBRETmQuXAhf1fz4j6GSCSiTU1N2S6GMcYsKLt27erRGQbRy4szhqamJt7ODG4AyVQan7eQW9SMMYVKRGYclbqgfxF/73sv85v/9EK2i2GMMTmloANDUcDL4Fgi28UwxpicUtCBoaLIz+C4BQZjjMlU0IEh7AaGfOiAN8aYuZK1wCAXMMTDfAkX+UmmlbF4aj53Y4wxC0o2zxi+B9wxLe1e4HFVbQEed9/Pm3CRH4ABa04yxphJWQsMFzjEw7yoKHYCg3VAG2PMWbnWx3Cu28nfRETuEZGdIrKzu7v7be2s3D1jsA5oY4w5K9cCwyR34Khz9gqr6n2qulFVN9bUvOnGvVkJTwaG+Nta3xhj8lGuBYZOd1RB3Oeu+dxZRXEAsDMGY4zJlGuBYRswMVHFx4F/m8+dha0pyRhj3iSbl6s+CLwArBaRNhH5JPAV4F0ichh4p/t+3pQEvHg9woB1PhtjzKSsDaKnqh85x6LbL1UZRMTufjbGmGlyrSnpkgtbYDDGmCkKPjCUW2AwxpgpCj4wVBRbYDDGmEwFHxisKckYY6aywGCBwRhjpij4wDBxVVI6bUNvG2MMWGCgvMiPKgzHktkuijHG5ISCDwwTdz8PWXOSMcYAFhgmx0uyu5+NMcZR8IHBxksyxpipLDBYYDDGmCksMExO72lzMhhjDFhgODu9p50xGGMMYIGBkN9LwOexwGCMMa6CDwzgNCfZ5arGGOOwwIBz97NdrmqMMQ4LDNh4ScYYk8kCAxYYjDEmkwUGIFxsTUnGGDMha3M+n4+IHAeGgRSQVNWN87k/63w2xpizcjIwuG5V1Z5LsaNwkZ/hWJJkKo3PaydRxpjCZr+COFclAQxFbehtY4zJ1cCgwK9EZJeI3DPfOwvb3c/GGDMpV5uSblTVdhGpBR4VkQOq+nRmBjdg3AOwdOnSi9qZDaRnjDFn5eQZg6q2u89dwE+BTTPkuU9VN6rqxpqamovaX7hoYk4GG0jPGGNyLjCISImIlE28Bt4N7JnPfdoZgzHGnJWLTUl1wE9FBJzy/UBVfzGfO7TpPY0x5qycCwyqehS48lLu084YjDHmrJxrSsqGgM9DccBrdz8bYwwWGCbZeEnGGOOwwOCywGCMMQ4LDK5wkZ8BCwzGGGOBYUK4yE/faBxVzXZRjDEmqywwuK5oDNPaNcL//a97SKbS2S6OMcZkTc5drpotn97SzEgsxbeeOsLpgXG+8dENlATt4zHGFB47Y3B5PMK9d67hyx+4jKcOdfPr/+t5dp/sz3axjDHmkrPAMM1vbV7Gdz+xicHxBL/+v57nzx5+nb5RG0PJGFM4JB86Wzdu3Kg7d+6c022OxJJ8/fHDfOfZYwR9Hm5ZVcO71tVx6+paKksCc7ovY4zJBhHZNdMMmRYY3sLBM8M88MJxHtvXSddwDIC68iArIqUsrylhcUURiyuKqC0PEvR58XoEv1eoKQ0SKQ3i8ci8lMsYYy6WBYaLlE4rr7cP8vyRHo50jXK0Z4TjPaP0n2cYDZ9HqC0LEvI7AcPrEdKqJFNKMq2UBn3UlDkBJOT3MHEkKor8NEVKWB4poaGiiIoiP8UBL+7AgrMyHk/RPRwjmU6jQDyZ5sxQlNMD43QOxfCIMxRIwOsh6PMQ9HkJ+j3UlYdYUlXMovIQ3nkKatFEitfbBmkfGOPapioaK4vnZT+zoaoMx5LEEmniqTRBn4dIaTBr5THmUjpXYLDLbmbJ4xGuWlLBVUsqpqSPxZN0DEbpHIqSSCmpdJp4Mk33cIwzQ1HODMaIJVOTAWEiQPg8wnA0SfdIjMOdw8QzLpEdGEuQTE8N2AGvh5qyICtqSlgRKaEpUsKSymKWVhfj9QivnBxg14l+9p0epK1/nN6L7BfxeYSK4gDhIh/lRX4qiwNUFgeoLg2QSKXpG43TNxonmkgBIAgVxX7W1peztr6cuvIgw9EkQ9EE/aNxuoZjdA3FONozwmttg8STZ+vbUlvK5hVVJJLK4HiCkViSgM9DUcBLkd+L3+vB535uw9EkA2NxBsYT1JQGaa4tZWVtCcUBH+m0E3DPDEY52jPC0e5Rgn4v6xvKuawhTE1ZkGgiRTSR4mTfGC8f72Pn8f43fVa1ZUEuWxxmeaSE0ViSgbEE8VSaReEQSyqLaawsmgzokdIAZSH/vAVRY7LBzhhyUCKVpr1/nGO9o3QNRekfS9A/Fnd+8LpHOdo9wmg89ab1ykI+rmgMs7SqhMbKImrLgvi9HkTA5/GwKBykoaKI2rLQ5H7iKSeQxZJpxt0g19Y/Tlv/GH2jCYbGEwyOO/vvH43TOxrH7/VQVRKgqiRAccCLKihK93CMYz2jpGf4SnkEIqVBFlcWsXFZJdc2VbG4sogXjvTy5MFuXjs1QHHQS7jIT0nQRyKVZiyeIhpPEXcDbjKtlIf8VBT7KQ/56RyOcqJ3jNQMO6ws9rOippSxeIrDncNvCrQAS6uK2dhUyZpFZYT8XgJeD6PxFHtPD7KnfZBTfeOUhnyEi/wEvB46BsfPeYZYHPBSGvTh93rweMAjQjKlk59vKq2k1XmEi/zUh50myLryEHXlQWrLg9SWhagtC1JTFiRc5L+gM0Rj3g5rSsojqkrPSJxT/WOc6hsjlkxz1ZIKmmtKs96nMR5PcbBzmP7ROGUh52yjoshPdWlwXv6qjifTnOwbI5pI4fMKXhEipcEpFwhEEykOd44wMB6nyO8l5PdO/hBfqOFogtMDUbqHY/SOxugZiTMcTTASTTISS5JIKapKShWfx0PAJwS8HrweD14PiAj9o3E6Bp1mvTNDUcZmCPIegZKgj7Kgj9KQj/KQn/IiP6VBn1sHDyVBH7VlQerKQ9SUBakoDlBZ7Cdc5MfntQsOzVuzwGBMDlJVRmJJOodidA/H6B5xnvtH44zEnGAzHE1MNsuNRJNEE2miyRQj0eSMZ0IApUEf5W5gLg54KQ74Js9qStxH0OeZ7GcK+T0UuXmK/F6KAt7J9UqCXkqCPor9Xgs4ecb6GIzJQSJCWchPWchPc23pBa2bTiv9Y3EnqIzEGHCb+/rHEgxFEwyNO8FkLJ5kNJ6kezjGaDzJaCzJaDw1pZ9ntrwecS9W8EyefQX93sm0idcBn4eg14PPK/i8Hvwe59nnFfweDx6Pc3bn857tc/O6eQJecfqVMl5P5Pd6BI/77HWb7DwZ6T5vxnIRPB4mX0/078lkfqdvTGRiO0wuL3QWGIxZoDweobo0SPXbvIpK9WwfSDSRJppIMRZPMRZPMh53XjuBJMVoLEk0kSKWdPJFk6nJdaLuFV2xRIqh8QSxZJpY0gk8E1fgJdPpyT6XZCo9Yz9ULhEBwQncHjkbgDLTJ157POI8u2mQme9s8JnO4yaKwPSGm4n8metP9OVN9/99cjPLqkvmrO5ggcGYgiUizmXKPi9vo7vloqgqaYVkOk06zWTgSKTTJFJKIpkmmU4TTyqJVJqUKum0kkqr+5rJtLTqZOd+yt3WxOuJZRPLkynnWdVZf+LH1tkOpNJOH9HEz2/aLWfa3ZeT/+yPtLrLJrejEz/yblpGvin1z9gGCrgBwF1zMpO6n5WbxQlI0z7LkN8758fHAoMx5pITEbwCXs/Ej9rc/7iZt896kowxxkyRF1cliUg3cOJtrh4BeuawOAtFIda7EOsMhVlvq/PsLFPVmumJeREYLoaI7Jzpcq18V4j1LsQ6Q2HW2+p8cawpyRhjzBQWGIwxxkxhgQHuy3YBsqQQ612IdYbCrLfV+SIUfB+DMcaYqeyMwRhjzBQFHRhE5A4ROSgirSJyb7bLMx9EZImIbBeRfSKyV0Q+76ZXicijInLYfa7Mdlnnmoh4ReQVEXnEfb9cRHa4x/uHIpJ3c7SKSIWIPCwiB0Rkv4hcn+/HWkT+0P1u7xGRB0UklI/HWkTuF5EuEdmTkTbjsRXH1936vy4iGy5kXwUbGETEC/wjcCewDviIiKzLbqnmRRL4Y1VdB1wHfMat573A46raAjzuvs83nwf2Z7z/W+DvVbUZ6Ac+mZVSza9/AH6hqmuAK3Hqn7fHWkQWA58DNqrqZTi3UN9Nfh7r7wF3TEs717G9E2hxH/cA37yQHRVsYAA2Aa2qelRV48BDwNYsl2nOqWqHqu52Xw/j/FAsxqnrA262B4D3Z6WA80REGoH3At923wtwG/CwmyUf6xwGbga+A6CqcVUdIM+PNc7QPkUi4gOKgQ7y8Fir6tNA37Tkcx3brcD31fEiUCEi9bPdVyEHhsXAqYz3bW5a3hKRJuBqYAdQp6od7qIzQF22yjVPvgb8KTAxtnQ1MKCqSfd9Ph7v5UA38F23Ce3bIlJCHh9rVW0H/g44iRMQBoFd5P+xnnCuY3tRv2+FHBgKioiUAj8G/kBVhzKXqXNpWt5cniYi7wO6VHVXtstyifmADcA3VfVqYJRpzUZ5eKwrcf46Xg40ACW8ubmlIMzlsS3kwNAOLMl43+im5R0R8eMEhX9R1Z+4yZ0Tp5buc1e2yjcPbgB+TUSO4zQR3obT9l7hNjdAfh7vNqBNVXe47x/GCRT5fKzfCRxT1W5VTQA/wTn++X6sJ5zr2F7U71shB4aXgRb36oUATofVtiyXac65bevfAfar6lczFm0DPu6+/jjwb5e6bPNFVb+oqo2q2oRzXJ9Q1d8CtgMfdLPlVZ0BVPUMcEpEVrtJtwP7yONjjdOEdJ2IFLvf9Yk65/WxznCuY7sN+B336qTrgMGMJqe3VNA3uInIXTht0V7gflX9cnZLNPdE5EbgGeANzra3/184/Qw/ApbijEz7IVWd3rG14InIFuALqvo+EVmBcwZRBbwC/LaqxrJYvDknIlfhdLgHgKPAJ3D+AMzbYy0i/xX4MM4VeK8A/xmnPT2vjrWIPAhswRlFtRP4K+BfmeHYukHyGzjNamPAJ1R156z3VciBwRhjzJsVclOSMcaYGVhgMMYYM4UFBmOMMVNYYDDGGDOFBQZjjDFTWGAwxhgzhQUGY4wxU1hgMMYYM8X/DzOfOZCgaXx9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3)\n",
    "fig.suptitle('Learning rate and loss')\n",
    "axs[0].plot(train_results['learning_rate_history'])\n",
    "axs[1].plot(train_results['model_closeness_loss'])\n",
    "axs[2].plot(train_results['loss_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "753228f0-b420-4b3d-bd69-53da7a87bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.save_pretrained(saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e4666-c1ff-4695-ba55-894503925f9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conversion to ONNX\n",
    "ONNX is a different format for running machine learning models. The ONNX format is much faster on CPU, sometimes 5 times as fast as PyTorch!\n",
    "\n",
    "While the EAWSW model is designed to be small, accurate and accessible, for some people it's still too much to run...\n",
    "\n",
    "Hosting the model as a free service for players is an option. An ONNX version of the model allows us to host the model on CPU yet have faster response times! Given that the model is made in a time with chip shortage, running on hardware I already have inside a server is efficient, scalable and cheaper.\n",
    "\n",
    "An important note is that ONNX doesn't execute logic by itself, and you have to do that yourself, `onnx_model_manager.py` intends to deal with this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3b88e1f-f5c3-4a95-8b00-e791148d8c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying config files from huggingface (needed for conversion)... WARNING: this assumes the structure of the model isn't changed!\n",
      "Cloning into 'gpt-neo-125M'...\n",
      "remote: Enumerating objects: 38, done.\u001b[K\n",
      "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
      "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
      "remote: Total 38 (delta 16), reused 0 (delta 0)\u001b[K\n",
      "Unpacking objects: 100% (38/38), 542.60 KiB | 999.00 KiB/s, done.\n",
      "Using framework PyTorch: 1.10.0+cu113\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> True\n",
      "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:90: UserWarning: 'enable_onnx_checker' is deprecated and ignored. It will be removed in the next PyTorch release. To proceed despite ONNX checker failures, catch torch.onnx.ONNXCheckerError.\n",
      "  warnings.warn(\"'enable_onnx_checker' is deprecated and ignored. It will be removed in \"\n",
      "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:103: UserWarning: `use_external_data_format' is deprecated and ignored. Will be removed in next PyTorch release. The code will work as it is False if models are not larger than 2GB, Otherwise set to False because of size limits imposed by Protocol Buffers.\n",
      "  warnings.warn(\"`use_external_data_format' is deprecated and ignored. Will be removed in next \"\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:559: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert batch_size > 0, \"batch_size has to be defined and > 0\"\n",
      "Validating ONNX model...\n",
      "\t-[] ONNX model outputs' name match reference model ({'present.5.value', 'present.10.value', 'present.4.value', 'present.3.key', 'present.8.value', 'present.6.value', 'present.4.key', 'present.11.value', 'present.2.value', 'present.3.value', 'present.6.key', 'present.7.value', 'logits', 'present.5.key', 'present.9.key', 'present.1.key', 'present.8.key', 'present.2.key', 'present.11.key', 'present.9.value', 'present.10.key', 'present.0.value', 'present.7.key', 'present.1.value', 'present.0.key'}\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[] (2, 1, 50257) matches (2, 1, 50257)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.0.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.0.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.1.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.1.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.2.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.2.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.3.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.3.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.4.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.4.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.5.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.5.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.6.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.6.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.7.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.7.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.8.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.8.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.9.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.9.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.10.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.10.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.11.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.11.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "All good, model saved at: models/awsw_onnx/model.onnx\n"
     ]
    }
   ],
   "source": [
    "saved_model_onnx_path = os.path.join(\"models\", \"awsw_onnx\")\n",
    "if not os.path.exists(os.path.join(saved_model_path, \"special_tokens_map.json\")):\n",
    "    print(\"Copying config files from huggingface (needed for conversion)... WARNING: this assumes the structure of the model isn't changed!\")\n",
    "    !cd $saved_model_path && git clone https://huggingface.co/EleutherAI/gpt-neo-125M\n",
    "    !cp -n $saved_model_path/gpt-neo-125M/* $saved_model_path\n",
    "    !rm -rf $saved_model_path/gpt-neo-125M\n",
    "if not os.path.exists(os.path.join(saved_model_onnx_path, \"model.onnx\")):\n",
    "    !python3 -m transformers.onnx --model=$saved_model_path --feature=causal-lm-with-past $saved_model_onnx_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a86f7a12-9bcb-4c4b-a679-7007a7e2caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_onnx():\n",
    "    model_quant = os.path.join(saved_model_onnx_path, \"model_quant.onnx\")\n",
    "    if not os.path.exists(model_quant):\n",
    "        model_fp32 = os.path.join(saved_model_onnx_path, \"model.onnx\")\n",
    "        model_opt = os.path.join(saved_model_onnx_path, \"model-opt.onnx\")\n",
    "        quantized_model = quantize_dynamic(model_fp32, model_quant, weight_type=QuantType.QUInt8)\n",
    "        #!rm $model_opt\n",
    "optimize_onnx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "739405a4-ab2a-410f-8091-b6bd9a18e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_manager = OnnxModelManager(os.path.join(saved_model_onnx_path, \"model.onnx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f9e7adb-f258-471a-9139-70da9f2120d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX: In my dreams, I'm a dragon.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon.\"<d><scn>np2x<msg>Ad \"I thought you had fun when we hung out in your apartment, but I guess I was wrong.\"<d><scn>np2x<msg>Ad \"Wait, does this have something to do with what I've been hearing? About Reza being a murderer?\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon one. I happen home calling home to do that could happen off them where't really more to be working overtime.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon one. can't down. You're a social g.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon one. I didn't happen in conditions that could.\" you're. I don't already from with the wrong, so. { be.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon one. can tell me a little one right now.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon one. I could a very busy person would have been amazing for a few. Inviting you over for dinner is the least I can do.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon one. can't down. right now don all that'll be more. They're be working.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon one. I happen more time something't happen. Given for this. Excuse she would don't work me not going to just in the office, just wants was actually.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon about him soon here one. I didn't happen work happen for what that. It was actually'll just of his, you agreed to that?\"<d><scn>black<msg>m \"He was struggling. It became more and more obvious as he tried to swallow the liquid in his bowl bit by bit by bit. He stopped at one point, panting heavily. I considered taking a cheap shot at him, but as he had refrained from doing so during my turn, I wasn't going to start now.\"<d><scn>black<msg>Br \"There\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon.\"<d the one.'ll do that making is a very when<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon one. I could a very very much don't happen.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon one. could be on to pass letters me room for the other, where little bit. I'm not sure what could like that up wrong that skill, it'll be working family.\"<msg.\"<d><scn>black<msg>Ry \"I'm sorry, [player the same be really is all a different that - that.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon. I can't hurry. Never could.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon. I can't hurry him. Never.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon one. I could do a very a very much other him if I can't save.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon one. I could a gamble right now.\"<msg>m\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon one. could not be so much, as he should humans had going to that skill't room it should be even an opportunity issue it would be.\"<d><scn>facin2<msg>Ry \"We have heard the rumors.\"<d><scn>facin2<msg>An \"So you come to me on the basis of rumors? Is that how you operate? What do you want from me?\"<d><scn>facin2<msg>Ry \"This is not the first time you've been in trouble, you know. They might not\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prompt = \"In my dreams, I'm a dragon\"\n",
    "for i in range(10):\n",
    "    print(\"ONNX:\", onnx_model_manager.say_raw(prompt, do_sample=True))\n",
    "    print(\"PyTorch:\", model_manager.say_raw(prompt, 50, 0.7))\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a578b-32cd-44b9-829b-5aef5ec37ab0",
   "metadata": {
    "id": "unxN7nYd2gOM",
    "tags": []
   },
   "source": [
    "# Testing\n",
    "\n",
    "We created a few past (for context) + present prompts (player input) and see the different reactions. This way, we can test the models across different iterations.\n",
    "The first test involves a old prompt to compare the pre-trained model with the one trained on AWSW. Did it manage to store it's data well? Is it able to write down things that have nothing to do with AWSW? (So we know we didn't overfit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d72d4876-df61-461a-b715-980a3763f092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragon.\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f9a94-70c6-4a58-9ad1-3d6ea373dfbe",
   "metadata": {},
   "source": [
    "**This test generates boring and repetetive** replies! It's because we use no good sampling algorithm, but it does give us a indication of what the model has learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b97230c-1d3a-4dd2-a253-727e451d539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Pytorch...\n",
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I enjoy Tatsu Park is all. Have you been here before?\"<p><msg>c \"It was entertaining. We take to take a lot a lot.\"<d><scn>park2<msg>Ry \"I'm not sure about that.\"<p><msg>c \"I'm not sure what to that.\"<d><scn>park2<msg\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: o2<msg>Ad \"I should be going now.\"<p><msg>c \"I'm not surprised, I am not a linguist. Are you?\"<d><scn>o2<msg>Ad \"I'm not sure exactly, but they do say it was humans that made us who we are today. You don't seem so different from us\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>Lo \"Don't worry, though. I'll treat this delicate matter with the required finesse.\"<p><msg>c \"I'm not sure, I am not a linguist. Are you?\"<d><scn>black<msg>Br \"Go ahead.\"<p><msg>c \"I'm not sure, I am not a linguist. Are you?\"<d\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: black<msg>An \"We can just leave it here. Hey, maybe the old farmer will help himself to it.\"<p><msg>c \"I'm not sure if it's worth mentioning, but I have known Reza for a couple of years, so I know some things about his personality.\"<d><scn>black<msg>An \"You've got hands and teeth. What more do you need?\"<|endoftext|>\n",
      "\n",
      "\n",
      "Test ONNX...\n",
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I enjoy Tatsu Park is all. Have you been here before?\"<p><msg>c \"It was entertaining. We take to take a lot a lot.\"<d><scn>park2<msg>Ry \"I'm not sure about that.\"<p><msg>c \"I'm not sure what to that.\"<d><scn>park2<msg>Ry \"Well, I'll get back to cooking.\"<d><scn>park2<msg>Ry \"I see.\"<d><scn>park2<msg>Ry \"Well\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: o2<msg>Ad \"I should get going now, yeah.\"<p><msg>c \"I'm not hungry anymore.\"<d><scn>o2<msg>Ad \"Oh, it's you again.\"<p><msg>c \"I'm not sure if it's worth mentioning, but I have known Reza for a couple of years, so I know some things about his personality.\"<d><scn>o2<msg>Ad \"I'm actually hoping to be part of a competition in some time.\"<p><msg>c \"dr. I'm not sure if you\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>Br \"Run, you wish.\"<p><msg>c \"I'm not sure, I am not a linguist and have anything else to do the Sce.\"<d><scn>black<msg>Br \"Guess you got more outta this than you asked for, then.\"<d><scn>black<msg>Br \"I can see you're close. Just a question of time now, sonny.\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: black<msg>An \"We can just leave it here. Hey, maybe the old farmer will help himself to it.\"<p><msg>c \"I'm not sure if it's worth mentioning, but I have known Reza for a couple of years, so I know some things about his personality.\"<d><scn>black<msg>An \"You've got hands and teeth. What more do you need?\"<|endoftext|>\n",
      "\n",
      "\n",
      "PyTorch on cuda:0 took 2.5374 seconds\n",
      "ONNX on CPU took 12.1845 seconds\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    ('<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hey!\"', \"How are you?\"),\n",
    "    ('<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"', \"What do you think of Lorem?\"),\n",
    "    ('<p><msg>m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('<p><msg>m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "def sample_test(model_manager):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = model_manager.say(past, prompt)\n",
    "        print(f\"Prompt: {prompt}\\nReply: {reply}\\n\\n\")\n",
    "print(\"Test Pytorch...\")\n",
    "start = time.time()\n",
    "sample_test(model_manager)\n",
    "end = time.time()\n",
    "pytorch_time = end - start\n",
    "print(\"Test ONNX...\")\n",
    "start = time.time()\n",
    "sample_test(onnx_model_manager)\n",
    "end = time.time()\n",
    "onnx_time = end - start\n",
    "print(f\"PyTorch on {device} took {pytorch_time:.4f} seconds\")\n",
    "print(f\"ONNX on CPU took {onnx_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3349bf-c777-4937-a023-ff0f4f21806d",
   "metadata": {},
   "source": [
    "# Sampling test\n",
    "\n",
    "This is gonna be interesting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce4bb65f-e26e-4a62-9c67-aed885fe041d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Pytorch...\n",
      "[Test 1] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I don't know. I'm here as a courtesy to you, not to threaten or intimidate. Do with that information whatever you wish.\"<d><scn>facin2<msg>Ry \"This attitude of yours is not helpful.\"<d><scn>facin2<msg>An \"Whatever.\"<d><scn>facin2<msg>n\n",
      "\n",
      "[Test 1] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"It's a long story.\"<p><msg>c \"No.\"<|endoftext|>\n",
      "\n",
      "[Test 1] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: cafe<msg>An \"I'm not sure I'd go so far as to call it \"fascinating\", but it surely does give me a lot of opportunities.\"<|endoftext|>\n",
      "\n",
      "[Test 1] -> Prompt: What will we do here?\n",
      "Reply: black<msg>An \"I'm not sure how you could ever survive in the wild.\"<d><scn>black<msg>An \"Seriously, what god did you piss off to end up like that?\"<p><msg>c \"No, I'm already here and have nothing else to do, so let's make the most of this.\"<d><scn>black<msg>An \"See how nice I am\n",
      "\n",
      "-------------\n",
      "Test ONNX...\n",
      "[Test 1] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Thanks for being, if a variety. Maybe we were the portal was, and those it would have been all against against our own. We against against the things that you came -.\"<p><msg>c \"I'm not surprised this wine is anything good to your. When good I'm not working something what it would I had to your world.\"<p><msg>c \"I see. I don't how to.\"<p><msg>c \"I see her, either you like this.\"<d><scn>remyapt<msg>Ry \"I think I\n",
      "\n",
      "[Test 1] -> Prompt: What do you think of Lorem?\n",
      "Reply: o2<msg>Ad \"It is, that, because because because or is a little. Our requires, we hold to enjoy we've].\"<d><scn>o2<msg>Ad \"I see, or stunt flying.\"<d><scn>o2<msg>Ad \"Do it is my turn now: What is that this one time:, well?\"<d><scn>o2<msg>Ad \"I suppose I can fly in again you that, but.\"<p><msg>c \"What are a few times?\"<d><scn>o2<msg\n",
      "\n",
      "[Test 1] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: cafe<msg>An \"And if I will.\"<d><scn>cafe<msg>An \"How could you even know something.\"<p><msg>c \"I'm not sure, what situation's all I am.\"<d><scn>cafe<msg>An \"We do?\"<d><scn>cafe<msg>Ad \"Of course it is, then?\"<|endoftext|>\n",
      "\n",
      "[Test 1] -> Prompt: What will we do here?\n",
      "Reply: loremapt<msg>Ip \"In addition, of course you would never do itITNESS to your different that again and made.\"<d><scn>loremapt<msg>Ip \"But I only had it for the smallest that of experiments to get the night doesn the night to get our world.\"<p><msg>c \"I'm not sure, I am. There I bet is only heard the first far.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "PyTorch on cuda:0 took 2.0021 seconds\n",
      "ONNX on CPU took 12.3284 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Pytorch...\")\n",
    "start = time.time()\n",
    "for i in range(1):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = model_manager.say(past, prompt, top_k = 50, top_p = 0.7)\n",
    "        print(f\"[Test {i + 1}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-------------\")\n",
    "end = time.time()\n",
    "pytorch_time = end - start\n",
    "print(\"Test ONNX...\")\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "start = time.time()\n",
    "for i in range(1):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = onnx_model_manager.say(past, prompt, do_sample = True)\n",
    "        print(f\"[Test {i + 1}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-------------\")\n",
    "end = time.time()\n",
    "onnx_time = end - start\n",
    "print(f\"PyTorch on {device} took {pytorch_time:.4f} seconds\")\n",
    "print(f\"ONNX on CPU took {onnx_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c956842-43ba-4f9a-937a-13fda9ad1439",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RP test\n",
    "Testing out the injected roleplay actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85435494-6b29-4b18-aa34-328e33caa9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visit Lorem -> bare<msg>Lo \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "Meet with Lorem -> park2<msg>Kv \"Hey [player_name]!\"<|endoftext|>\n",
      "Visit Adine -> park3<msg>Kv \"Oh, [player_name], I wasn't expecting visitors.\"<|endoftext|>\n",
      "Fight Maverick -> o2<msg>Ad \"I know what you mean.\"<|endoftext|>\n",
      "Fight Adine -> cafe<msg>An \"Who is cited as one of our most important historians, his work spanning over 20 books, credited with mapping out our entire history since the beginning of sentience?\"<p><msg>c \"Damion Dandelionandelion\"<|endoftext|>\n",
      "Attack Adine -> emeraroom<msg>Em \"Anyway, I have to keep reminding myself and practice, and problems behind the wholeness waiting to get it. Just, I think I'd like that I made a big only, and being.\"<d><scn>emeraroom<msg>Em \"My parents wanted me to continue my studies, but I decided against that. Studying and working hard so that I may study and working for a friend where it wasn't long.\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "test_rps = [\n",
    "    \"Visit Lorem\",\n",
    "    \"Meet with Lorem\",\n",
    "    \"Visit Adine\",\n",
    "    \"Fight Maverick\",\n",
    "    \"Fight Adine\",\n",
    "    \"Attack Adine\"\n",
    "]\n",
    "for rp in test_rps:\n",
    "    print(f'{rp} -> {model_manager.say(\"\", rp, top_k = 50, top_p = 0.7)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
