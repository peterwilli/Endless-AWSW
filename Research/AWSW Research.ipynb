{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b97b376-9ac5-4c70-ba13-769649099a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_utils import train_model, split_data, split_branches, get_model, set_pretrained_model_dropout, get_dataset, ModelSeeder\n",
    "from config import Config\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import onnx\n",
    "import logging\n",
    "from onnx_model_manager import OnnxModelManager\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "import os\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from model_manager import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887d9f81-96c3-408f-bd1c-7b126becc4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use cuda:0 for training with seed: 3218885689\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randint(0, 2 ** 32 - 1)\n",
    "seed = 3218885689\n",
    "random.seed(seed)\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(f\"Will use {device_name} for training with seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e95113e-dfc1-40a9-a39b-5d56f3bf32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(os.path.join(Config.work_dir, \"awsw_story_input.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb65c62-47c6-4d36-bd1e-2adfef8ff1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lr\": 6e-4,\n",
    "    \"warmup_factor\": 0,\n",
    "    \"scheduler\": \"polynomial_decay_schedule_with_warmup\",\n",
    "    \"lr_end\": 2e-6,\n",
    "    \"power\": 0.6,\n",
    "    #\"freeze_layer_rate\": 1e-4,\n",
    "    \"freeze_from_steps\": -1,\n",
    "    \"seed\": seed,\n",
    "    \"num_epoch\": 20\n",
    "}\n",
    "\n",
    "optuna_result_attachement = {\n",
    "    'lr': 0.001,\n",
    "    'scheduler': 'cosine_schedule_with_warmup',\n",
    "    'to_freeze_count': 0,\n",
    "    #\"to_freeze_gpt_blocks\": 11,\n",
    "    'warmup_factor': 5\n",
    "}\n",
    "config.update(optuna_result_attachement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ffae5b-e197-4417-a4cd-e6befc6ee393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded empty model\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = os.path.join(\"models\", \"awsw_main\")\n",
    "if os.path.exists(os.path.join(saved_model_path, \"pytorch_model.bin\")):\n",
    "    tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "    model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "    print(\"Pretrained model loaded\")\n",
    "else:\n",
    "    model, tokenizer = get_model(\"EleutherAI/gpt-neo-125M\")\n",
    "    print(\"Loaded empty model\")\n",
    "model.to(device)\n",
    "set_pretrained_model_dropout(model.transformer.h[-1:], 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f3315-8f5d-4101-8e7e-2c0129204c94",
   "metadata": {},
   "source": [
    "# Test before training on a pretrained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f68c3f1-4c0a-41a2-a3fc-b8b3c36e418c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragon-flyer. I have no idea how to fly. I just like to fly. I've seen my own shadow flying in the sky, but it's not me. I just want to fly. And I want to fly with you. I'm a dragonflyer. I want to be a dragonflyer. I want to fly with you.\n",
      "\n",
      "But I have no idea how to fly. I just like to fly. I've seen my own shadow flying in the sky, but it's not me. I just want to fly. And I want to fly with you.\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model_manager = ModelManager(model=model, tokenizer=tokenizer, device=device)\n",
    "def test_regular_sampler():\n",
    "    print(model_manager.say_raw(\"In my dreams, I'm a dragon\", 50, 0.7))\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f74aa-5030-4ffd-ad2f-ae013647975e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reviewing our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0974ac13-c420-4275-b34a-3816f580cb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce57c9e2fee440baf13fa2d11d9e7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset demo snapshot:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soon\" now refers to a time span of over 2 hours when waiting for a scheduled appointment.\"<|endoftext|><p><msg>c \"Who knows.\"<d><scn>office<msg>Sb \"Now, let's take a look at what you've got for me.\"<d><scn>office<msg>Sb \"The witness report from Anna is good. Nothing new to us, but it's nice to have her statement in writing.\"<d><scn>office<msg>Sb \"What you've learned about the map is fascinating, if not a little unsettling. While it's good\n",
      "RP review!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Lo \"Now that we're here, I can tell you that no expense will be spared to make our portrayal of humans as accurate as possible.\"<|endoftext|><d><scn>loremapt<msg>Ip \"Evidently, she thinks otherwise.\"<|endoftext|><p><msg>c \"Fight Ipsum\"<d><scn>loremapt<msg>m \"Ipsum barely avoids my attack and fell, but managed to get up and quickly punch me in the face, a soaring pain quickly came over my face\"<|endoftext|><p><msg>c \"You aren't planning on drinking it all at\n",
      " once, right?\"<|endoftext|><d><scn>office<msg>m \"When I arrived at the station, I was met by the police archivist, a dragoness who introduced herself as Kalinth.\"<p><msg>c \"(Who's he talking to?)\"<p><msg>c \"(Oh, it's her again.)\"<p><msg>c \"(Hey, I think I've seen her before.)\"<|endoftext|><d><scn>cafe<msg>Ad \"Who's your companion?\"<|endoftext|><d><scn>cafe<msg>An \"Who is cited as one\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(tokenizer, path_train = os.path.join(Config.work_dir, \"data_train.txt\"))\n",
    "print(\"Dataset demo snapshot:\")\n",
    "for item in dataset['train']:\n",
    "    print(tokenizer.decode(item['input_ids']))\n",
    "    break\n",
    "\n",
    "print(\"RP review!\")\n",
    "has_seen_rp = False\n",
    "for item in dataset['train']:\n",
    "    decoded = tokenizer.decode(item['input_ids'])\n",
    "    if 'c \"Fight ' in decoded: \n",
    "        print(decoded)\n",
    "        has_seen_rp = True\n",
    "        continue        \n",
    "    if has_seen_rp:\n",
    "        print(decoded)\n",
    "        break\n",
    "# Clean up\n",
    "del has_seen_rp\n",
    "# dataset['model_seeder'].stop_worker()\n",
    "# del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e9e10-b2eb-421a-9948-dc3590e1f46d",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Model is put in training mode and we begin training. The `train_results` will contain all data after training is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41750b03-f114-46c4-948e-637db79efe15",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] set freeze_part_layers: True (freezing 0 out of 160 layers.)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2140' max='2140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2140/2140 16:20, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>4.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>2.607700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>2.031800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>1.902700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.825300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>1.804100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>1.796100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>1.838400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>1.842600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.806600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>1.769000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>1.894800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>1.914600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>1.852600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>1.823600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336</td>\n",
       "      <td>1.901000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>357</td>\n",
       "      <td>1.891600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378</td>\n",
       "      <td>1.901600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>1.891300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.898200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>441</td>\n",
       "      <td>1.851300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462</td>\n",
       "      <td>1.917100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>483</td>\n",
       "      <td>1.945300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>1.896200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>1.909400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>546</td>\n",
       "      <td>1.911100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>1.963800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>588</td>\n",
       "      <td>1.926500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>609</td>\n",
       "      <td>1.933000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.909600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>651</td>\n",
       "      <td>1.964800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>672</td>\n",
       "      <td>1.928000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>693</td>\n",
       "      <td>1.893600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>714</td>\n",
       "      <td>1.941200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>735</td>\n",
       "      <td>1.925400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>756</td>\n",
       "      <td>1.938100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>777</td>\n",
       "      <td>1.919200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798</td>\n",
       "      <td>1.894500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>819</td>\n",
       "      <td>1.878000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.925500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>861</td>\n",
       "      <td>1.944400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>882</td>\n",
       "      <td>1.883000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>903</td>\n",
       "      <td>1.874400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>924</td>\n",
       "      <td>1.887600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>945</td>\n",
       "      <td>1.895600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>966</td>\n",
       "      <td>1.893300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>987</td>\n",
       "      <td>1.859900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1008</td>\n",
       "      <td>1.895400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1029</td>\n",
       "      <td>1.907800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.862700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1071</td>\n",
       "      <td>1.906400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1092</td>\n",
       "      <td>1.862900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1113</td>\n",
       "      <td>1.869100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1134</td>\n",
       "      <td>1.871600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1155</td>\n",
       "      <td>1.911100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1176</td>\n",
       "      <td>1.886300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1197</td>\n",
       "      <td>1.853400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1218</td>\n",
       "      <td>1.848800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1239</td>\n",
       "      <td>1.862000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>1.837700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1281</td>\n",
       "      <td>1.848200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1302</td>\n",
       "      <td>1.814600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1323</td>\n",
       "      <td>1.859200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1344</td>\n",
       "      <td>1.854000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1365</td>\n",
       "      <td>1.853100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1386</td>\n",
       "      <td>1.818700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1407</td>\n",
       "      <td>1.822000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1428</td>\n",
       "      <td>1.793600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1449</td>\n",
       "      <td>1.816200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>1.813800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1491</td>\n",
       "      <td>1.811000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1512</td>\n",
       "      <td>1.811700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1533</td>\n",
       "      <td>1.798100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1554</td>\n",
       "      <td>1.790600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>1.801100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1596</td>\n",
       "      <td>1.802400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1617</td>\n",
       "      <td>1.778300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1638</td>\n",
       "      <td>1.755900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1659</td>\n",
       "      <td>1.745400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>1.770800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1701</td>\n",
       "      <td>1.750300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1722</td>\n",
       "      <td>1.723800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1743</td>\n",
       "      <td>1.735400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1764</td>\n",
       "      <td>1.704800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1785</td>\n",
       "      <td>1.726200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1806</td>\n",
       "      <td>1.748700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1827</td>\n",
       "      <td>1.693500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1848</td>\n",
       "      <td>1.674800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1869</td>\n",
       "      <td>1.689500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>1.681000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1911</td>\n",
       "      <td>1.667800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1932</td>\n",
       "      <td>1.633500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1953</td>\n",
       "      <td>1.593300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1974</td>\n",
       "      <td>1.600200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>1.612700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016</td>\n",
       "      <td>1.662700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2037</td>\n",
       "      <td>1.597800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2058</td>\n",
       "      <td>1.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2079</td>\n",
       "      <td>1.596500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.570500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2121</td>\n",
       "      <td>1.614400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results = {}\n",
    "model.train()\n",
    "train_model(model, tokenizer, dataset, config, train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c410a601-c5e4-4cc1-af2b-44a7378f3bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f33a9d0e130>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3)\n",
    "fig.suptitle('Learning rate and loss')\n",
    "axs[0].plot(train_results['learning_rate_history'])\n",
    "axs[1].plot(train_results['model_closeness_loss'])\n",
    "axs[2].plot(train_results['loss_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "753228f0-b420-4b3d-bd69-53da7a87bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.save_pretrained(saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e4666-c1ff-4695-ba55-894503925f9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conversion to ONNX\n",
    "ONNX is a different format for running machine learning models. The ONNX format is much faster on CPU, sometimes 5 times as fast as PyTorch!\n",
    "\n",
    "While the EAWSW model is designed to be small, accurate and accessible, for some people it's still too much to run...\n",
    "\n",
    "Hosting the model as a free service for players is an option. An ONNX version of the model allows us to host the model on CPU yet have faster response times! Given that the model is made in a time with chip shortage, running on hardware I already have inside a server is efficient, scalable and cheaper.\n",
    "\n",
    "An important note is that ONNX doesn't execute logic by itself, and you have to do that yourself, `onnx_model_manager.py` intends to deal with this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3b88e1f-f5c3-4a95-8b00-e791148d8c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying config files from huggingface (needed for conversion)... WARNING: this assumes the structure of the model isn't changed!\n",
      "Cloning into 'gpt-neo-125M'...\n",
      "remote: Enumerating objects: 38, done.\u001b[K\n",
      "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
      "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
      "remote: Total 38 (delta 16), reused 0 (delta 0)\u001b[K\n",
      "Unpacking objects: 100% (38/38), 542.60 KiB | 1.17 MiB/s, done.\n",
      "Using framework PyTorch: 1.10.1+cu113\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> True\n",
      "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:90: UserWarning: 'enable_onnx_checker' is deprecated and ignored. It will be removed in the next PyTorch release. To proceed despite ONNX checker failures, catch torch.onnx.ONNXCheckerError.\n",
      "  warnings.warn(\"'enable_onnx_checker' is deprecated and ignored. It will be removed in \"\n",
      "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:103: UserWarning: `use_external_data_format' is deprecated and ignored. Will be removed in next PyTorch release. The code will work as it is False if models are not larger than 2GB, Otherwise set to False because of size limits imposed by Protocol Buffers.\n",
      "  warnings.warn(\"`use_external_data_format' is deprecated and ignored. Will be removed in next \"\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:559: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert batch_size > 0, \"batch_size has to be defined and > 0\"\n",
      "Validating ONNX model...\n",
      "\t-[✓] ONNX model outputs' name match reference model ({'present.11.key', 'present.7.value', 'present.4.key', 'present.2.key', 'present.1.value', 'present.9.key', 'present.3.value', 'present.11.value', 'present.1.key', 'present.0.value', 'present.0.key', 'logits', 'present.6.value', 'present.2.value', 'present.4.value', 'present.9.value', 'present.8.value', 'present.3.key', 'present.6.key', 'present.5.value', 'present.7.key', 'present.5.key', 'present.10.value', 'present.10.key', 'present.8.key'}\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[✓] (2, 1, 50257) matches (2, 1, 50257)\n",
      "\t\t-[x] values not close enough (atol: 0.0001)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/transformers/onnx/__main__.py\", line 71, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/transformers/onnx/__main__.py\", line 64, in main\n",
      "    validate_model_outputs(onnx_config, tokenizer, model, args.output, onnx_outputs, args.atol)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/transformers/onnx/convert.py\", line 214, in validate_model_outputs\n",
      "    raise ValueError(\n",
      "ValueError: Outputs values doesn't match between reference model and ONNX exported model: Got max absolute difference of: 0.0006046295166015625\n"
     ]
    }
   ],
   "source": [
    "saved_model_onnx_path = os.path.join(\"models\", \"awsw_onnx\")\n",
    "if not os.path.exists(os.path.join(saved_model_path, \"special_tokens_map.json\")):\n",
    "    print(\"Copying config files from huggingface (needed for conversion)... WARNING: this assumes the structure of the model isn't changed!\")\n",
    "    !cd $saved_model_path && git clone https://huggingface.co/EleutherAI/gpt-neo-125M\n",
    "    !cp -n $saved_model_path/gpt-neo-125M/* $saved_model_path\n",
    "    !rm -rf $saved_model_path/gpt-neo-125M\n",
    "if not os.path.exists(os.path.join(saved_model_onnx_path, \"model.onnx\")):\n",
    "    !python3 -m transformers.onnx --model=$saved_model_path --feature=causal-lm-with-past $saved_model_onnx_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a86f7a12-9bcb-4c4b-a679-7007a7e2caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_onnx():\n",
    "    model_quant = os.path.join(saved_model_onnx_path, \"model_quant.onnx\")\n",
    "    if not os.path.exists(model_quant):\n",
    "        model_fp32 = os.path.join(saved_model_onnx_path, \"model.onnx\")\n",
    "        model_opt = os.path.join(saved_model_onnx_path, \"model-opt.onnx\")\n",
    "        quantized_model = quantize_dynamic(model_fp32, model_quant, weight_type=QuantType.QUInt8)\n",
    "        #!rm $model_opt\n",
    "optimize_onnx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "739405a4-ab2a-410f-8091-b6bd9a18e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_manager = OnnxModelManager(os.path.join(saved_model_onnx_path, \"model.onnx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f9e7adb-f258-471a-9139-70da9f2120d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX: In my dreams, I'm a dragon. I can fly, I can attack, and I can even fly in the sky.\"<d><scn>loremapt<msg>Lo \"[player_name], please read this carefully.\"<d></p><p><msg>c \"[player_name], what are you?\"<d><p><scn>msgv 'x<msg>c \"I'm not sure, but I think I can handle this.\"<p><msg>c \"[player_name], what are you?\"<d><scn>msgx \"I'm a dragon.\"<p><msg>c \"[\n",
      "PyTorch: In my dreams, I'm a dragon.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon. I can fly, I can attack, and I can even fly in the sky.\"<p></msg></p><p><msg>c \"I see. I see.\"<d><?\"><?\"><|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon. I can fly, I can attack, and I can even fly in the sky.\"<d><scn>black><?><?><scm<><???><?php><|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon.\"<d><scn>black<msg>Ry \"I see.\"<p><msg>c \"What's your problem?\"<d><scn>black<msg>Ry \"What's going on here?\"<p><msg>c \"You are my best critic. You are so brilliant. Do you really think that I can be that bad?\"<d><scn>black<msg>Ry \"I can't.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon.\"<p>I'm so happy to report that my parents have been very careful. I have a few things that I would like to take care of, and I'm not sure if that's a good thing or a good thing at all. I'm just glad that they're here for me. I'm not really sure what to say to that, so please don't hesitate to contact me if you are ever in a similar situation again. I'm sure you will be very happy.\"<d><scn>black<msg>n \"I'm glad you could, because it was a very good day.\"<d><\n",
      "PyTorch: In my dreams, I'm a dragon, and I can see the world around me. My body has to be strong enough to support me, but I can still hear its breath. I can hear its breath, my own breath, and even the sounds of its wings. And I can feel its presence as it bites into the dragon's fur.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon. I can fly, I can attack, and I can even fly in the sky.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon. I can't stand to be touched by dragons.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon. I can fly, I can attack, and I can even fly in the sky.\"<p><msg>c \"(I see you're a dragon.)\"<d><scn>black<msg>Br \"I see you're a dragon.\"<p>\"<d><scn>black<msg>Br \"I hear that.\"<p><msg>c \"I can see it in your eyes.\"<d><scn>black<msg>Br \"That's what I thought, but then I saw it.\"<p><msg>c \"Oh. That. I see it, I see the\n",
      "PyTorch: In my dreams, I'm a dragon.\"<d><scn>black<msg>m \"I could see the tension in his eyes as he spoke, but I could also hear the heat of his breath.\"<d><scn>black<msg>Br \"Is that so?\"<p><msg>c \"Hey, I'm here to help you, not you.\"<d><scn>black<msg>Br \"You could say so.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon. I can fly, I can attack, and I can even fly in the sky.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon in armor, a dragon who's even more powerful than I am. I don't even have to be human anymore.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon. I can fly, I can attack, and I can even fly in the sky.\"<P><msg>c \"I see.\"<d><scn>blacknr<ython><p><a href=\"https://www.ny.com/story/view/10/10/10/10/10noreply_ [APPENDIX]<p><msg>c \"What do we need to know?\"<d><scn>black<msg>n \"I think it's a little more complicated. I'm not sure what the question is, but I think it's pretty straightforward.\"<d\n",
      "PyTorch: In my dreams, I'm a dragon and I'm in the middle of a dragon quest. I'm a big fan of dragons, so I like to hunt and kill things, and I like to eat dragon food. I also like to watch dragons, and I'm always on the hunt for food.<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon.\"<p><msg>t \"I see.\"<p><msg>c \"I see.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon, and I love to hunt.\"<d><scn>black<msg>Br \"I can see that. I'm also a dragon, so maybe that's a little different from being a human.\"<d><scn>black<msg>m \"I started to walk, but my leg felt weak.\"<d><scn>black<msg>Br \"That's a shame.\"<d><scn>black<msg>m \"I remembered seeing the dragon when I was growing up in the wild, the one I loved so much. I remembered it was a\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon. I can fly, I can attack, and I can even fly in the sky.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon, and I'm about to go into battle.\"<d><scn>black<msg>Lo \"I'm not sure if I could get that far.\"<p><msg>c \"What about you, [player_name].\"<d><scn>black<msg>Lo \"I know you don't have to, but do you really?\"<p><msg>c \"Yes.\"<d><scn>black<msg>Lo \"If you say so.\"<p><msg>c \"I do.\"<d><scn>black<msg>\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prompt = \"In my dreams, I'm a dragon\"\n",
    "for i in range(10):\n",
    "    print(\"ONNX:\", onnx_model_manager.say_raw(prompt, do_sample=True))\n",
    "    print(\"PyTorch:\", model_manager.say_raw(prompt, 50, 0.7))\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a578b-32cd-44b9-829b-5aef5ec37ab0",
   "metadata": {
    "id": "unxN7nYd2gOM",
    "tags": []
   },
   "source": [
    "# Testing\n",
    "\n",
    "We created a few past (for context) + present prompts (player input) and see the different reactions. This way, we can test the models across different iterations.\n",
    "The first test involves a old prompt to compare the pre-trained model with the one trained on AWSW. Did it manage to store it's data well? Is it able to write down things that have nothing to do with AWSW? (So we know we didn't overfit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d72d4876-df61-461a-b715-980a3763f092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragon.\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f9a94-70c6-4a58-9ad1-3d6ea373dfbe",
   "metadata": {},
   "source": [
    "**This test generates boring and repetetive** replies! It's because we use no good sampling algorithm, but it does give us a indication of what the model has learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b97230c-1d3a-4dd2-a253-727e451d539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Pytorch...\n",
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"I think he's a good friend.\"<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"<p\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>Ad \"I'm not sure, but I think I might be able to help.\"<p><msg>c \"I'm not sure, but I think I might be able to help.\"<d><scn>black<msg>Ad \"I'm not sure, but I think I might be able to help.\"<p><msg>c \"I'm not sure, but I think\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: np1x<msg>Br \"I don't know. I'm not sure I can.\"<d><scn>np1x<msg>Br \"I'm not sure I can.\"<d><scn>np1x<msg>m \"I sat down on a chair in Anna's lab.\"<d><scn>np1x<msg>Br \"I don't know. I'm not sure I can\n",
      "\n",
      "\n",
      "Test ONNX...\n",
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"I think he's a good friend.\"<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"<p><msg>c \"I was with Lorem today.\"<d><scn>park2<\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>Ad \"I'm not sure, but I think I might be able to help.\"<p><msg>c \"I'm not sure, but I think I might be able to help.\"<d><scn>black<msg>Ad \"I'm not sure, but I think I might be able to help.\"<p><msg>c \"I'm not sure, but I think I might be able to help.\"<d><scn>black<msg>Ad \"I'm not sure, but I think I might be able to help.\"<p><msg>c \"I'm\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: np1x<msg>Br \"I don't know. I'm not sure I can.\"<d><scn>np1x<msg>Br \"I'm not sure I can.\"<d><scn>np1x<msg>m \"I sat down on a chair in Anna's lab.\"<d><scn>np1x<msg>Br \"I don't know. I'm not sure I can.\"<d><scn>np1x<msg>Br \"I'm not sure I can.\"<d><scn>np1x<msg>Br \"I\n",
      "\n",
      "\n",
      "PyTorch on cuda:0 took 2.8000 seconds\n",
      "ONNX on CPU took 14.5115 seconds\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    ('<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hey!\"', \"How are you?\"),\n",
    "    ('<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"', \"What do you think of Lorem?\"),\n",
    "    ('<p><msg>m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('<p><msg>m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "def sample_test(model_manager):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = model_manager.say(past, prompt)\n",
    "        print(f\"Prompt: {prompt}\\nReply: {reply}\\n\\n\")\n",
    "print(\"Test Pytorch...\")\n",
    "start = time.time()\n",
    "sample_test(model_manager)\n",
    "end = time.time()\n",
    "pytorch_time = end - start\n",
    "print(\"Test ONNX...\")\n",
    "start = time.time()\n",
    "sample_test(onnx_model_manager)\n",
    "end = time.time()\n",
    "onnx_time = end - start\n",
    "print(f\"PyTorch on {device} took {pytorch_time:.4f} seconds\")\n",
    "print(f\"ONNX on CPU took {onnx_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3349bf-c777-4937-a023-ff0f4f21806d",
   "metadata": {},
   "source": [
    "# Sampling test\n",
    "\n",
    "This is gonna be interesting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce4bb65f-e26e-4a62-9c67-aed885fe041d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Pytorch...\n",
      "[Test 1] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"How are you?\"<p><msg>c \"Hey Remy, I know you wanted to talk about your work, but this is your chance to do it again.\"<d><scn>park2<msg>Ry \"Good to hear that.\"<p><msg>c \"You can't say that.\"<d><scn>park2<msg>Ry \"I\n",
      "\n",
      "[Test 1] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"I don't think so.\"<p><msg>c \"You know, I can help with this, if you don't mind.\"<d><scn>park2<msg>Ad \"Well, that's a shame.\"<d><scn>park2<msg>Ad \"I think I'll just go and have a\n",
      "\n",
      "[Test 1] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: o2<msg>Ad \"It's a toy.\"<d><scn>o2<msg>Ad \"Well, I don't have any personal effects here, so it doesn't really matter.\"<p><msg>c \"No, I'm not talking about my effects.\"<d><scn>o2<msg>Ad \"You know what, I'll just get you some coffee and\n",
      "\n",
      "[Test 1] -> Prompt: What will we do here?\n",
      "Reply: loremapt<msg>Lo \"I don't know. I just wanted to talk.\"<p><msg>c \"Alright.\"<d><scn>loremapt<msg>Lo \"The task is now given to you.\"<d><scn>loremapt<msg>Ip \"The question is: will this be enough?\"<p><msg>c \"Not at all.\"<d><scn>\n",
      "\n",
      "-------------\n",
      "Test ONNX...\n",
      "[Test 1] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Pretty good, thanks for the message.\"<d><scn>park2<msg>Ry \"Thanks for coming in, I guess you're right.\"<p><msg>c \"Hey Remy! How are you?\"<d><scn>park2<msg>Ry \"I'm fine, thanks for asking.\"<p><msg>c \"Hey there Remy! How are you?\"<d><scn>park2<msg>Ry \"I guess I'm just worried about your health.\"<p><msg>c \"Hey there Remy, how were you?\"<\n",
      "\n",
      "[Test 1] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"You know, he's got some interesting ideas about how to make our world better. I think we should get going on that one.\"<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very funny.\"<p><msg>c \"I was with Lorem today. I was with her today.\"<d><scn>park2<msg>Ad \" very funny.\"<p><msg>c \"I was... with her today.\"<d><scn>park2<msg>Ad \"Very\n",
      "\n",
      "[Test 1] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: facin2<msg>An \"Hey Adine, how are we supposed to know if we're having any fun, at any rate right now? We just did a little research on the ground, so we might as well get going.\"<p><msg>c \"Yeah.\"<d><scn>facin2<msg>An \"I thought you wanted to see the fireworks, not the humans.\"<p><msg>c \"I did.\"<d><scn>facin2<msg>An \"Hey Adine, how were you so early?\"<p><msg>c \"I was\n",
      "\n",
      "[Test 1] -> Prompt: What will we do here?\n",
      "Reply: black<msg>Lo \"We'll have a lot more fun than I have in my own apartment.\"<p><msg>c \"What do you want to do?\"<d><scn>black<msg>Lo \"What are we going to do with our free time?\"<p><msg>c \"Let me take you home, then?\"<d><scn>black<msg>Lo \"Sure.\"<p><msg>c \"Let's do this, then.\"<d><scn>black<msg>Lo \"Let's go.\"<p><msg>c \"What do we do\n",
      "\n",
      "----------\n",
      "PyTorch on cuda:0 took 3.1635 seconds\n",
      "ONNX on CPU took 14.9213 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Pytorch...\")\n",
    "start = time.time()\n",
    "for i in range(1):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = model_manager.say(past, prompt, top_k = 50, top_p = 0.7)\n",
    "        print(f\"[Test {i + 1}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-------------\")\n",
    "end = time.time()\n",
    "pytorch_time = end - start\n",
    "print(\"Test ONNX...\")\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "start = time.time()\n",
    "for i in range(1):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = onnx_model_manager.say(past, prompt, do_sample = True)\n",
    "        print(f\"[Test {i + 1}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-\" * 10)\n",
    "end = time.time()\n",
    "onnx_time = end - start\n",
    "print(f\"PyTorch on {device} took {pytorch_time:.4f} seconds\")\n",
    "print(f\"ONNX on CPU took {onnx_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c956842-43ba-4f9a-937a-13fda9ad1439",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RP test\n",
    "Testing out the injected roleplay actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85435494-6b29-4b18-aa34-328e33caa9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pytorch] Visit Lorem -> loremapt<msg>Lo \"I don't think I've heard a soul in a while.\"<|endoftext|>\n",
      "[ONNX] Visit Lorem -> loremapt<msg>Lo \"Oh, [player_name]!\"<|endoftext|>\n",
      "----------\n",
      "[Pytorch] Meet with Lorem -> loremapt<msg>Lo \"Oh, and she also had a great time with you.\"<|endoftext|>\n",
      "[ONNX] Meet with Lorem -> loremapt<msg>Lo \"Oh, wow. That sounds like a really good idea.\"<d><scn>loremapt<msg>Lo \"I think I'll just have to wait a few more seconds.\"<p><msg>c \"Hey, Loremi.\"<d><scn>loremapt<msg>Lo \"Hey.\"<p><msg>c \"Hey, Loremi!\"<d><scn>loremapt<msg>Lo \"Hey, Loremi.\"<p><msg>c \"Hey, Loremi.\"<d><scn>loremapt<\n",
      "----------\n",
      "[Pytorch] Visit Adine -> park2<msg>Adine \"Hey [player_name]!\"<|endoftext|>\n",
      "[ONNX] Visit Adine -> office<msg>Adine \"Oh?\"<p><msg>c \"I see.\"<d><scn>office<msg>Adine \"Do I?\"<p><msg>c \"I see you're in charge of the project right now.\"<d><scn>office<msg>Adine \"Oh, I see.\"<p><msg>c \"I see...\"<d><scn>office<msg>Adine \"Oh? Are you okay, then?\"<p><msg>c \"I see.\"<d><scn>office<msg>Adine \"Do I\n",
      "----------\n",
      "[Pytorch] Fight Maverick -> park2<msg>Mv \"Hey [player_name]!\"<|endoftext|>\n",
      "[ONNX] Fight Maverick -> beach<msg>m \"Maverick was able, however, to make contact with the other two and managed to make contact without incident. It wasn't long after this that the other two started to suspect Maverick, eventually finding him in the middle of the night, sleeping in a room that had only been used as a hiding place.\"<|endoftext|>\n",
      "----------\n",
      "[Pytorch] Fight Adine -> beach<msg>Ad \"I'm so happy I could come over and talk with you. I'll do what I can, but I'd rather have a beer with you first.\"<p><msg>c \"That sounds great.\"<p><msg>c \"Let's just say I'm happy about the job I did. You know what? Let's just enjoy the rest of this beer.\"<p><msg>c \"It's not a joke. I'm just saying I can't imagine you being a failure. Besides,\n",
      "[ONNX] Fight Adine -> o2<msg>Ad \"Oh, I see. Well. I'm not really an adventurer, then.\"<d><scn>o2<msg>Ad \"I see.\"<d><scn>o2<msg>Ad \"I see, but I'm just curious.\"<d><scn>o2<msg>Ad \"That's a good question.\"<d><scn>o2<msg>Ad \"That's a pretty good question. I'm curious.\"<d><scn>o2<msg>Ad \"I see, but I'm just curious. I'm\n",
      "----------\n",
      "[Pytorch] Attack Adine -> o2<msg>Ad \"How about this one? It's for the part of you that's supposed to help me out?\"<p><msg>c \"Oh, it's not about the game, it's about Reza's ability to deal with humans.\"<d><scn>o2<msg>Ad \"How about that one?\"<p><msg>c \"How about this one?\"<d><scn>o2<msg>Ad \"How about this one?\"<p><msg>c \"How\n",
      "[ONNX] Attack Adine -> adinep>Adinep<msg>m \"She was just about gone, but I heard her breathing heavily.\"<d><scn>adinep<msg>Ad \"Oh, I forgot to take her to her appointment. She's been gone for a couple of minutes now.\"<p><msg>c \"I see. Well, that's not bad. I suppose I'll just need to get back in the building, then. Bye!\"<d><scn>adinep<msg>m \"She was just about gone, [player_name]. She was gone by now. I didn\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "test_rps = [\n",
    "    \"Visit Lorem\",\n",
    "    \"Meet with Lorem\",\n",
    "    \"Visit Adine\",\n",
    "    \"Fight Maverick\",\n",
    "    \"Fight Adine\",\n",
    "    \"Attack Adine\"\n",
    "]\n",
    "for rp in test_rps:\n",
    "    print(f'[Pytorch] {rp} -> {model_manager.say(\"\", rp, top_k = 50, top_p = 0.7)}')\n",
    "    print(f'[ONNX] {rp} -> {onnx_model_manager.say(\"\", rp, do_sample = True)}')\n",
    "    print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c25c34-550a-407b-9378-69adbadc5adc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
