{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b97b376-9ac5-4c70-ba13-769649099a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_utils import train_model, split_data, split_branches, get_model, set_pretrained_model_dropout, get_dataset, ModelSeeder\n",
    "from config import Config\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import onnx\n",
    "import logging\n",
    "from onnx_model_manager import OnnxModelManager\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "import os\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from model_manager import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887d9f81-96c3-408f-bd1c-7b126becc4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use cuda:0 for training with seed: 3218885689\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randint(0, 2 ** 32 - 1)\n",
    "seed = 3218885689\n",
    "random.seed(seed)\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(f\"Will use {device_name} for training with seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e95113e-dfc1-40a9-a39b-5d56f3bf32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(os.path.join(Config.work_dir, \"awsw_story_input.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb65c62-47c6-4d36-bd1e-2adfef8ff1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lr\": 6e-4,\n",
    "    \"warmup_factor\": 0,\n",
    "    \"scheduler\": \"polynomial_decay_schedule_with_warmup\",\n",
    "    \"lr_end\": 2e-6,\n",
    "    \"power\": 0.6,\n",
    "    #\"freeze_layer_rate\": 1e-4,\n",
    "    \"freeze_from_steps\": -1,\n",
    "    \"seed\": seed,\n",
    "    \"num_epoch\": 300\n",
    "}\n",
    "\n",
    "optuna_result_attachement = {\n",
    "    'lr': 0.001,\n",
    "    'scheduler': 'cosine_schedule_with_warmup',\n",
    "    'to_freeze_count': 0,\n",
    "    #\"to_freeze_gpt_blocks\": 11,\n",
    "    'warmup_factor': 5\n",
    "}\n",
    "config.update(optuna_result_attachement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ffae5b-e197-4417-a4cd-e6befc6ee393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded empty model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_path = os.path.join(\"models\", \"awsw_main\")\n",
    "if os.path.exists(os.path.join(saved_model_path, \"pytorch_model.bin\")):\n",
    "    tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "    model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "    print(\"Pretrained model loaded\")\n",
    "else:\n",
    "    model, tokenizer = get_model(\"EleutherAI/gpt-neo-125M\")\n",
    "    print(\"Loaded empty model\")\n",
    "model.to(device)\n",
    "# set_pretrained_model_dropout(model.transformer.h[-1:], 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f3315-8f5d-4101-8e7e-2c0129204c94",
   "metadata": {},
   "source": [
    "# Test before training on a pretrained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f68c3f1-4c0a-41a2-a3fc-b8b3c36e418c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragonflyer, a dragonfly in a dragonfly.\n",
      "\n",
      "The dragonfly in my dreams.\n",
      "\n",
      "Dragonflies in my dreams.\n",
      "\n",
      "Dragonflies in my dreams.\n",
      "\n",
      "Dragonflies in my dreams.\n",
      "\n",
      "Dragonflies in my dreams.\n",
      "\n",
      "Dragonflies in my dreams.\n",
      "\n",
      "Dragonflies in my dreams.\n",
      "\n",
      "Dragonflies in my dreams.\n",
      "\n",
      "Dragonflies in my dreams.\n",
      "\n",
      "Dragonflies in my dreams.\n",
      "\n",
      "Dragonflies in my dreams.\n",
      "\n",
      "Dragonflies in my dreams.\n",
      "\n",
      "Dragonflies in my dreams.\n",
      "\n",
      "Dragonflies\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model_manager = ModelManager(model=model, tokenizer=tokenizer, device=device)\n",
    "def test_regular_sampler():\n",
    "    print(model_manager.say_raw(\"In my dreams, I'm a dragon\", 50, 0.7))\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f74aa-5030-4ffd-ad2f-ae013647975e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reviewing our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0974ac13-c420-4275-b34a-3816f580cb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13577571063f432285d4434e833642d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset demo snapshot:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<d><scn>o2<msg>Br \"I see. Well, alcoholism and suicide both are huge problems in law enforcement.\"<|endoftext|><d><scn>o2<msg>An \"Interesting. What's in it for me?\"<|endoftext|><d><scn>facin2<msg>m \"I heard some commotion in the distance, and when I approached, I was surprised to see not only Anna, but Remy as well.\"<|endoftext|><d><scn>bare<msg>Br \"Oh, come on, just try a little. Even if you don't like beer, you\n",
      "RP review!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " do on a daily basis, it can affect you in pretty bad ways. Everyone has their breaking point.\"<|endoftext|><p><msg>c \"Fight Bryce\"<d><scn>o2<msg>m \"I didn't hesitate and kicked Bryce right in the stomach\"<|endoftext|><d><scn>loremapt<msg>Lo \"I thought you had experiments to run.\"<|endoftext|><p><msg>c \"That I am.\"<|endoftext|><d><scn>park3<msg>Em \"The question is: Did Maverick cause this, or did he just fail to prevent it?\"<|endoftext|><p\n",
      "><msg>c \"Okay.\"<p><msg>c \"I really should be going now.\"<d><scn>black<msg>Lo \"Take care.\"<p><msg>c \"Yeah, you too.\"<p><msg>c \"Yeah, you too.\"<|endoftext|><p><msg>c \"Err...\"<|endoftext|><p><msg>c \"I suppose so...\"<|endoftext|><p><msg>c \"That is unfortunate.\"<|endoftext|><d><scn>black<msg>Ry \"It's not as if I was desperate or anything. I just think it's nice.\"<|endoftext|><\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(tokenizer, path_train = os.path.join(Config.work_dir, \"data_train.txt\"))\n",
    "print(\"Dataset demo snapshot:\")\n",
    "for item in dataset['train']:\n",
    "    print(tokenizer.decode(item['input_ids']))\n",
    "    break\n",
    "\n",
    "print(\"RP review!\")\n",
    "has_seen_rp = False\n",
    "for item in dataset['train']:\n",
    "    decoded = tokenizer.decode(item['input_ids'])\n",
    "    if 'c \"Fight ' in decoded: \n",
    "        print(decoded)\n",
    "        has_seen_rp = True\n",
    "        continue        \n",
    "    if has_seen_rp:\n",
    "        print(decoded)\n",
    "        break\n",
    "# Clean up\n",
    "del has_seen_rp\n",
    "# dataset['model_seeder'].stop_worker()\n",
    "# del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e9e10-b2eb-421a-9948-dc3590e1f46d",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Model is put in training mode and we begin training. The `train_results` will contain all data after training is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41750b03-f114-46c4-948e-637db79efe15",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] set freeze_part_layers: True (freezing 0 out of 160 layers.)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32100' max='32100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32100/32100 3:56:17, Epoch 300/300]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>321</td>\n",
       "      <td>1.511300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>642</td>\n",
       "      <td>1.338000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>963</td>\n",
       "      <td>1.406500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1284</td>\n",
       "      <td>1.413900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1605</td>\n",
       "      <td>1.415600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1926</td>\n",
       "      <td>1.410300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2247</td>\n",
       "      <td>1.412700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2568</td>\n",
       "      <td>1.412100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2889</td>\n",
       "      <td>1.410500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3210</td>\n",
       "      <td>1.413000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3531</td>\n",
       "      <td>1.401400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3852</td>\n",
       "      <td>1.409500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4173</td>\n",
       "      <td>3.934800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4494</td>\n",
       "      <td>3.343000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4815</td>\n",
       "      <td>4.421500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5136</td>\n",
       "      <td>2.016800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5457</td>\n",
       "      <td>1.505400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5778</td>\n",
       "      <td>2.181200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6099</td>\n",
       "      <td>1.389300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6420</td>\n",
       "      <td>1.381600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6741</td>\n",
       "      <td>1.373000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7062</td>\n",
       "      <td>1.367500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7383</td>\n",
       "      <td>1.370500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7704</td>\n",
       "      <td>1.361500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8025</td>\n",
       "      <td>1.360700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8346</td>\n",
       "      <td>1.734400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8667</td>\n",
       "      <td>1.350800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8988</td>\n",
       "      <td>1.346200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9309</td>\n",
       "      <td>1.339500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9630</td>\n",
       "      <td>1.334800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9951</td>\n",
       "      <td>1.329100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10272</td>\n",
       "      <td>1.328700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10593</td>\n",
       "      <td>1.314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10914</td>\n",
       "      <td>1.312300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11235</td>\n",
       "      <td>1.579200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11556</td>\n",
       "      <td>1.310600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11877</td>\n",
       "      <td>1.315600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12198</td>\n",
       "      <td>1.282000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12519</td>\n",
       "      <td>1.278500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12840</td>\n",
       "      <td>1.267000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13161</td>\n",
       "      <td>1.283700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13482</td>\n",
       "      <td>1.251900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13803</td>\n",
       "      <td>1.237600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14124</td>\n",
       "      <td>1.228800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14445</td>\n",
       "      <td>1.225200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14766</td>\n",
       "      <td>1.209500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15087</td>\n",
       "      <td>1.197100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15408</td>\n",
       "      <td>1.192400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15729</td>\n",
       "      <td>1.174300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16050</td>\n",
       "      <td>1.162300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16371</td>\n",
       "      <td>1.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16692</td>\n",
       "      <td>1.133200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17013</td>\n",
       "      <td>1.119500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17334</td>\n",
       "      <td>1.105700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17655</td>\n",
       "      <td>1.094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17976</td>\n",
       "      <td>1.075100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18297</td>\n",
       "      <td>1.076000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18618</td>\n",
       "      <td>1.061600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18939</td>\n",
       "      <td>1.024600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19260</td>\n",
       "      <td>1.012300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19581</td>\n",
       "      <td>0.990500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19902</td>\n",
       "      <td>0.977400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20223</td>\n",
       "      <td>0.959400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20544</td>\n",
       "      <td>0.945500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20865</td>\n",
       "      <td>0.932600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21186</td>\n",
       "      <td>0.901600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21507</td>\n",
       "      <td>0.887800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21828</td>\n",
       "      <td>0.868700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22149</td>\n",
       "      <td>0.853800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22470</td>\n",
       "      <td>0.829700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22791</td>\n",
       "      <td>0.813500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23112</td>\n",
       "      <td>0.792600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23433</td>\n",
       "      <td>0.770300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23754</td>\n",
       "      <td>0.751800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24075</td>\n",
       "      <td>0.739900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24396</td>\n",
       "      <td>0.717300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24717</td>\n",
       "      <td>0.696400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25038</td>\n",
       "      <td>0.676800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25359</td>\n",
       "      <td>0.656800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25680</td>\n",
       "      <td>0.644600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26001</td>\n",
       "      <td>0.624900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26322</td>\n",
       "      <td>0.608600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26643</td>\n",
       "      <td>0.594300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26964</td>\n",
       "      <td>0.578000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27285</td>\n",
       "      <td>0.559400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27606</td>\n",
       "      <td>0.546000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27927</td>\n",
       "      <td>0.536200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28248</td>\n",
       "      <td>0.506400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28569</td>\n",
       "      <td>0.491700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28890</td>\n",
       "      <td>0.507700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29211</td>\n",
       "      <td>0.472600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29532</td>\n",
       "      <td>0.494300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29853</td>\n",
       "      <td>0.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30174</td>\n",
       "      <td>0.465400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30495</td>\n",
       "      <td>0.413800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30816</td>\n",
       "      <td>0.396700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31137</td>\n",
       "      <td>0.545600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31458</td>\n",
       "      <td>0.516000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31779</td>\n",
       "      <td>0.481900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32100</td>\n",
       "      <td>0.477700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results = {}\n",
    "model.train()\n",
    "train_model(model, tokenizer, dataset, config, train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c410a601-c5e4-4cc1-af2b-44a7378f3bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f44c627e3d0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3)\n",
    "fig.suptitle('Learning rate and loss')\n",
    "axs[0].plot(train_results['learning_rate_history'])\n",
    "axs[1].plot(train_results['model_closeness_loss'])\n",
    "axs[2].plot(train_results['loss_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "753228f0-b420-4b3d-bd69-53da7a87bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.save_pretrained(saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e4666-c1ff-4695-ba55-894503925f9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conversion to ONNX\n",
    "ONNX is a different format for running machine learning models. The ONNX format is much faster on CPU, sometimes 5 times as fast as PyTorch!\n",
    "\n",
    "While the EAWSW model is designed to be small, accurate and accessible, for some people it's still too much to run...\n",
    "\n",
    "Hosting the model as a free service for players is an option. An ONNX version of the model allows us to host the model on CPU yet have faster response times! Given that the model is made in a time with chip shortage, running on hardware I already have inside a server is efficient, scalable and cheaper.\n",
    "\n",
    "An important note is that ONNX doesn't execute logic by itself, and you have to do that yourself, `onnx_model_manager.py` intends to deal with this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3b88e1f-f5c3-4a95-8b00-e791148d8c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying config files from huggingface (needed for conversion)... WARNING: this assumes the structure of the model isn't changed!\n",
      "Cloning into 'gpt-neo-125M'...\n",
      "remote: Enumerating objects: 38, done.\u001b[K\n",
      "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
      "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
      "remote: Total 38 (delta 16), reused 0 (delta 0)\u001b[K\n",
      "Unpacking objects: 100% (38/38), 542.60 KiB | 1.14 MiB/s, done.\n",
      "Using framework PyTorch: 1.10.0+cu113\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> True\n",
      "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:90: UserWarning: 'enable_onnx_checker' is deprecated and ignored. It will be removed in the next PyTorch release. To proceed despite ONNX checker failures, catch torch.onnx.ONNXCheckerError.\n",
      "  warnings.warn(\"'enable_onnx_checker' is deprecated and ignored. It will be removed in \"\n",
      "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:103: UserWarning: `use_external_data_format' is deprecated and ignored. Will be removed in next PyTorch release. The code will work as it is False if models are not larger than 2GB, Otherwise set to False because of size limits imposed by Protocol Buffers.\n",
      "  warnings.warn(\"`use_external_data_format' is deprecated and ignored. Will be removed in next \"\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:559: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert batch_size > 0, \"batch_size has to be defined and > 0\"\n",
      "Validating ONNX model...\n",
      "\t-[] ONNX model outputs' name match reference model ({'present.1.key', 'present.2.key', 'present.5.value', 'present.4.value', 'present.7.value', 'present.10.value', 'present.2.value', 'present.0.key', 'present.4.key', 'present.9.value', 'present.10.key', 'present.11.value', 'present.5.key', 'logits', 'present.11.key', 'present.1.value', 'present.3.key', 'present.6.value', 'present.3.value', 'present.7.key', 'present.0.value', 'present.8.value', 'present.6.key', 'present.9.key', 'present.8.key'}\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[] (2, 1, 50257) matches (2, 1, 50257)\n",
      "\t\t-[x] values not close enough (atol: 0.0001)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/transformers/onnx/__main__.py\", line 71, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/transformers/onnx/__main__.py\", line 64, in main\n",
      "    validate_model_outputs(onnx_config, tokenizer, model, args.output, onnx_outputs, args.atol)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/transformers/onnx/convert.py\", line 214, in validate_model_outputs\n",
      "    raise ValueError(\n",
      "ValueError: Outputs values doesn't match between reference model and ONNX exported model: Got max absolute difference of: 0.0006875991821289062\n"
     ]
    }
   ],
   "source": [
    "saved_model_onnx_path = os.path.join(\"models\", \"awsw_onnx\")\n",
    "if not os.path.exists(os.path.join(saved_model_path, \"special_tokens_map.json\")):\n",
    "    print(\"Copying config files from huggingface (needed for conversion)... WARNING: this assumes the structure of the model isn't changed!\")\n",
    "    !cd $saved_model_path && git clone https://huggingface.co/EleutherAI/gpt-neo-125M\n",
    "    !cp -n $saved_model_path/gpt-neo-125M/* $saved_model_path\n",
    "    !rm -rf $saved_model_path/gpt-neo-125M\n",
    "if not os.path.exists(os.path.join(saved_model_onnx_path, \"model.onnx\")):\n",
    "    !python3 -m transformers.onnx --model=$saved_model_path --feature=causal-lm-with-past $saved_model_onnx_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a86f7a12-9bcb-4c4b-a679-7007a7e2caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_onnx():\n",
    "    model_quant = os.path.join(saved_model_onnx_path, \"model_quant.onnx\")\n",
    "    if not os.path.exists(model_quant):\n",
    "        model_fp32 = os.path.join(saved_model_onnx_path, \"model.onnx\")\n",
    "        model_opt = os.path.join(saved_model_onnx_path, \"model-opt.onnx\")\n",
    "        quantized_model = quantize_dynamic(model_fp32, model_quant, weight_type=QuantType.QUInt8)\n",
    "        #!rm $model_opt\n",
    "optimize_onnx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "739405a4-ab2a-410f-8091-b6bd9a18e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_manager = OnnxModelManager(os.path.join(saved_model_onnx_path, \"model.onnx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f9e7adb-f258-471a-9139-70da9f2120d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX: In my dreams, I'm a dragon. I eat. I cover myself with sand. I drink. I work. I hope you're doing right about that way.\"<d><scn2<msg id=\" subpoenaseed\"<o: \\\"gp\\ signs\\n\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon. I come for everything from fish to cake. My muscles are very sensitive and my intellect, not very knowledge-bearing.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon. I eat. I drink to order.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon. I eat. I cover myself with sand. I work in the archives.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon. I eat. I cover myself with sand. I drink. I work. I hope you're doing right about that way.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon.\"<d><scn>park3<msg>Br \"I see.\"<d><scn>park3<msg>Em \"Well, that worked out nicely, didn't it?\"<p><msg>c \"Yes, I do.\"<d><scn>park3<msg>Br \"If I had tocollar, all I would need was a working find, and I will.\"<d><scn>park3<msg>Em \"Good. Then, I willortunit. I did this because, it has a rather unusualfeminineluence\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon. I eat. I cover myself with sand. I work in the archives.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon. I walk into the store and see there an envelope and some duds.\"<d><scn>black<msg>n \"I wasn't sure exactly what I had expected out of the office, but if you went to the study with me, she would studies the very subject at the time when she came of weak at the same point as with any sort of surprise.\"<d><scn>black<msg>n \"I wasn't sure exactly what I had expected out of the two of the others, however big it was or how it would look later on in the relationship\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon. I eat. I cover myself with sand. I work in the archives.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon.\"<d><scn>park3<msg>Br \"You win.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon. I eat. I cover myself with sand. I work in the archives.\"<d><scn>black<msg>m \"When I looked over to him, I discovered that Bryce had passed out for the moment. This could prove difficult.\"<p><msg>c \"Why not?\"<d><scname.\"<p><msg>c \"Meet with Aditya like royalty\"<d><scn>Ad \"Is that so? Do you want to practice mine?\"<p><msg>c \"Oh, I forgot all the ways you've denied me of life ever.\"<d><scn\n",
      "PyTorch: In my dreams, I'm a dragon. I eat everything I'veput in the dragon's hairpin. It makes my neckops blue. It could be my turn now.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon. I eat. I cover myself with sand. I drink. I work. I hope you're doing right about that way.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon, and a sky is my very first human scratch the dragon. I'd rather just enjoy my tea in a cool voice world like that, but I can't exactly run from the moment I see you.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon. I eat. I cover myself with sand. I work in the archives.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon. I use it to hunt, but I don't mind myself. Not really sure what to to do with my files or what to do with my notes, too busy. Maybe I'll see to something in the background as it plays out.\"<d><scn>o2<msg>Br \"You know, those two should have stopped at it.\"<d><scn>o2<msg>Br \"I didn't do anything wrong tocerned humanity, even.\"<d><scn>o2<msg>Br \"You know what happened out on patrol. We\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragon. I eat. I cover myself with sand. I drink. I work. I hope you're doing right about that way.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon, and anyway it's a kind of forfeit to be detected by her.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prompt = \"In my dreams, I'm a dragon\"\n",
    "for i in range(10):\n",
    "    print(\"ONNX:\", onnx_model_manager.say_raw(prompt, do_sample=True))\n",
    "    print(\"PyTorch:\", model_manager.say_raw(prompt, 50, 0.7))\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a578b-32cd-44b9-829b-5aef5ec37ab0",
   "metadata": {
    "id": "unxN7nYd2gOM",
    "tags": []
   },
   "source": [
    "# Testing\n",
    "\n",
    "We created a few past (for context) + present prompts (player input) and see the different reactions. This way, we can test the models across different iterations.\n",
    "The first test involves a old prompt to compare the pre-trained model with the one trained on AWSW. Did it manage to store it's data well? Is it able to write down things that have nothing to do with AWSW? (So we know we didn't overfit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d72d4876-df61-461a-b715-980a3763f092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragon. I live by theijuana, and I suppose that is because theLaughsumey way of my life is so much I ask for it any more.\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f9a94-70c6-4a58-9ad1-3d6ea373dfbe",
   "metadata": {},
   "source": [
    "**This test generates boring and repetetive** replies! It's because we use no good sampling algorithm, but it does give us a indication of what the model has learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b97230c-1d3a-4dd2-a253-727e451d539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Pytorch...\n",
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm good. I'll let you have your own people, and once you've got a base ofirlfriends, what, you think I don't know what tojosh.\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I'm not sure if there are any better than human my infinite wisdom, and the existence of which has only)}2.}<p><msg>c \"What?\"<d><scn>park2<msg>Ry \"I suppose so.\"<p><msg>c \"What do you think, Iguers?\"<d><\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np2x<msg>Ad \"Well, what does that make you?\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: facin2<msg>An \"I don't know where you are going, but I think I need a coffee or five. You can tag along if you like.\"<p><msg>c \"I think I'd rather not.\"<d><scn>facin2<msg>An \"I can see that.\"<p><msg>c \"I think I'd rather not.\"<d><scn>facin2\n",
      "\n",
      "\n",
      "Test ONNX...\n",
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm good. I'll let you have your own people, and once you've got a base ofirlfriends, what, you think I don't know what tojosh.\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I'm not sure if there are any better than human my infinite wisdom, and the existence of which has only)}2.}<p><msg>c \"What?\"<d><scn>park2<msg>Ry \"I suppose so.\"<p><msg>c \"What do you think, Iguers?\"<d><scn>park2<msg>Ry \"I'm sorry, [player_name].\"<d><scn>park2<msg>Ry \"I'm sorry, [player_name].\"<d><scn>park2<msg\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np2x<msg>Ad \"Well, what does that make you?\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: facin2<msg>An \"I don't know where you are going, but I think I need a coffee or five. You can tag along if you like.\"<p><msg>c \"I think I'd rather not.\"<d><scn>facin2<msg>An \"I can see that.\"<p><msg>c \"I think I'd rather not.\"<d><scn>facin2<msg>An \"If you had your own, you canmicroworkingothers. You don't have to be so that is better than nothing.\"<d><sc\n",
      "\n",
      "\n",
      "PyTorch on cuda:0 took 1.8544 seconds\n",
      "ONNX on CPU took 8.8695 seconds\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    ('<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hey!\"', \"How are you?\"),\n",
    "    ('<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"', \"What do you think of Lorem?\"),\n",
    "    ('<p><msg>m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('<p><msg>m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "def sample_test(model_manager):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = model_manager.say(past, prompt)\n",
    "        print(f\"Prompt: {prompt}\\nReply: {reply}\\n\\n\")\n",
    "print(\"Test Pytorch...\")\n",
    "start = time.time()\n",
    "sample_test(model_manager)\n",
    "end = time.time()\n",
    "pytorch_time = end - start\n",
    "print(\"Test ONNX...\")\n",
    "start = time.time()\n",
    "sample_test(onnx_model_manager)\n",
    "end = time.time()\n",
    "onnx_time = end - start\n",
    "print(f\"PyTorch on {device} took {pytorch_time:.4f} seconds\")\n",
    "print(f\"ONNX on CPU took {onnx_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3349bf-c777-4937-a023-ff0f4f21806d",
   "metadata": {},
   "source": [
    "# Sampling test\n",
    "\n",
    "This is gonna be interesting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce4bb65f-e26e-4a62-9c67-aed885fe041d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Pytorch...\n",
      "[Test 1] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Hey [player_name]!\"<|endoftext|>\n",
      "\n",
      "[Test 1] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I've said this word to myself for ages\\I know it, it was realfor me\\... It seemedlike forever\\... That is, if anyone was waiting for\\.\"<p><msg>c \"What did you say?\"<d><scn>park2<msg>Ry \"I'm not sure I'd\n",
      "\n",
      "[Test 1] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np3<msg>Ka \"I'm glad you're even.\"<d><scn>np3<msg>Ka \"Of the reptiles, because of course they do.\"<d><scn>np3<msg>Ka \"You asked the fact that you were here when you came into what's now, I'm supposed to be around.\"<d><scn>np3<msg>\n",
      "\n",
      "[Test 1] -> Prompt: What will we do here?\n",
      "Reply: facin2<msg>An \"If anything were to change,I'd have to change my mind.\"<d><scn>facin2<msg>An \"I wouldn't do anything like that.\"<d><scn>facin2<msg>An \"I didn't really want to make a big deal out of it, though, so that might be... a 'You'dp cause of for at least a little\n",
      "\n",
      "-------------\n",
      "Test ONNX...\n",
      "[Test 1] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm good. I've had some really low-level officers do low-level work around that work for others to see, and it was starting to get to the wester that's a trustworthy building.\"<d><scn>park2<msg>Ry \"I'm not sure, even to offer you this,, but I certainly was not making the world go ourchron1<Puerto strictRicochet<<|endoftext|>\n",
      "\n",
      "[Test 1] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"She was,surprisingly. Neither is right, or else, either way the other, orhead's murder, all my chores over.\"<d><scn>park2<msg>Ry \"I suppose. After everything I reported.\"<|endoftext|>\n",
      "\n",
      "[Test 1] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np2x<msg>Ad \"Well, what does that make you today,?\"<d><scn>np2x<msg>Ad \"What's so important that I don\"ocre?\"<m_degreed<msg>m \"Bryce led Bryce towards the door and, seeing that she didn't know him, she got in the door that way.\"<|endoftext|>\n",
      "\n",
      "[Test 1] -> Prompt: What will we do here?\n",
      "Reply: facin2<msg>An \"I don't know what he is saying.\"<p><msg>c \"He hasn't used the<d><sc:<msg>m \"I considered asking for a few kilometres<Mv.dannyc<msg>dannyc<d><scn>facin2<msg>c \"Maybe you can.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "PyTorch on cuda:0 took 2.4264 seconds\n",
      "ONNX on CPU took 8.7356 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Pytorch...\")\n",
    "start = time.time()\n",
    "for i in range(1):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = model_manager.say(past, prompt, top_k = 50, top_p = 0.7)\n",
    "        print(f\"[Test {i + 1}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-------------\")\n",
    "end = time.time()\n",
    "pytorch_time = end - start\n",
    "print(\"Test ONNX...\")\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "start = time.time()\n",
    "for i in range(1):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = onnx_model_manager.say(past, prompt, do_sample = True)\n",
    "        print(f\"[Test {i + 1}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-------------\")\n",
    "end = time.time()\n",
    "onnx_time = end - start\n",
    "print(f\"PyTorch on {device} took {pytorch_time:.4f} seconds\")\n",
    "print(f\"ONNX on CPU took {onnx_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c956842-43ba-4f9a-937a-13fda9ad1439",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RP test\n",
    "Testing out the injected roleplay actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85435494-6b29-4b18-aa34-328e33caa9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visit Lorem -> loremapt<msg>Lo \"Hey [player_name]!\"<|endoftext|>\n",
      "Meet with Lorem -> loremapt<msg>Lo \"Hey [player_name]! How are you?\"<|endoftext|>\n",
      "Visit Adine -> adineapt<msg>Ad \"I'm not sure if I could do with any higher masculine than the question.\"<|endoftext|>\n",
      "Fight Maverick -> emeraroom<msg>Em \"I've mentioned this before, so it's no fault some unknown time and means only the attics of wonder receive my vote.\"<d><scn>emeraroom<msg>Em \"Of course I can't keep up this way, and I can tell from a research department's point of view this simple: find a replacement.\"<d><scn>emeraroom<msg>Em \"The truth is, I could never really provide any number of other types of support. The public in\n",
      "Fight Adine -> cafe<msg>Ad \"I'm not sure I've seen you. I probably shouldn't think to ask you all the time.\"<|endoftext|>\n",
      "Attack Adine -> emeraroom<msg>m \"Adine, you there, and you take me on your ever-present needas.\"<d><scn>emeraroom<msg>Em \"I know it's a strange request, but having to wait and have the processing order doneassets down this first.\"<d><scn>emeraroom<msg>Em \"As you are so mercurizing your finances. so you can mainlineanny adenosbyr-Q4d3<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "test_rps = [\n",
    "    \"Visit Lorem\",\n",
    "    \"Meet with Lorem\",\n",
    "    \"Visit Adine\",\n",
    "    \"Fight Maverick\",\n",
    "    \"Fight Adine\",\n",
    "    \"Attack Adine\"\n",
    "]\n",
    "for rp in test_rps:\n",
    "    print(f'{rp} -> {model_manager.say(\"\", rp, top_k = 50, top_p = 0.7)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c25c34-550a-407b-9378-69adbadc5adc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
