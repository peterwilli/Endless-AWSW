{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b97b376-9ac5-4c70-ba13-769649099a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_utils import train_model, split_data, split_branches, get_model, set_pretrained_model_dropout, get_dataset\n",
    "from config import Config\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from model_manager import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887d9f81-96c3-408f-bd1c-7b126becc4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use cuda:0 for training with seed: 3218885689\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randint(0, 2 ** 32 - 1)\n",
    "seed = 3218885689\n",
    "random.seed(seed)\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(f\"Will use {device_name} for training with seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e95113e-dfc1-40a9-a39b-5d56f3bf32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(os.path.join(Config.work_dir, \"awsw_story_input.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb65c62-47c6-4d36-bd1e-2adfef8ff1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lr\": 6e-4,\n",
    "    \"warmup_factor\": 0,\n",
    "    \"scheduler\": \"polynomial_decay_schedule_with_warmup\",\n",
    "    \"lr_end\": 2e-6,\n",
    "    \"power\": 0.6,\n",
    "    #\"freeze_layer_rate\": 1e-4,\n",
    "    \"freeze_from_steps\": -1,\n",
    "    \"seed\": seed,\n",
    "    \"num_epoch\": 50\n",
    "}\n",
    "\n",
    "optuna_result_attachement = {\n",
    "    'lr': 0.001,\n",
    "    'scheduler': 'cosine_schedule_with_warmup',\n",
    "    'to_freeze_count': 148,\n",
    "    #\"to_freeze_gpt_blocks\": 11,\n",
    "    'warmup_factor': 1\n",
    "}\n",
    "config.update(optuna_result_attachement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ffae5b-e197-4417-a4cd-e6befc6ee393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded empty model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_path = os.path.join(\"models\", \"awsw_main\")\n",
    "if os.path.exists(os.path.join(saved_model_path, \"pytorch_model.bin\")):\n",
    "    print(\"Pretrained model loaded\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "    model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "else:\n",
    "    print(\"Loaded empty model\")\n",
    "    model, tokenizer = get_model(\"EleutherAI/gpt-neo-125M\")\n",
    "model.to(device)\n",
    "# set_pretrained_model_dropout(model.transformer.h[-1:], 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f3315-8f5d-4101-8e7e-2c0129204c94",
   "metadata": {},
   "source": [
    "# Test before training on a pretrained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f68c3f1-4c0a-41a2-a3fc-b8b3c36e418c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragon-slayer.\n",
      "\n",
      "I've had a hard time finding a single character who is the most important to me. I've had so many of the characters I have loved, so many of the people I've loved. It's hard to find a character who is the most important to me.\n",
      "\n",
      "I've always thought that it's because of the character I've loved that I would do something with it.\n",
      "\n",
      "But it's true. I have had so many of the characters I have loved, and I've never thought of it that way.\n",
      "\n",
      "It's true. I\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model_manager = ModelManager(model=model, tokenizer=tokenizer, device=device)\n",
    "def test_regular_sampler():\n",
    "    print(model_manager.say_raw(\"In my dreams, I'm a dragon\", 50, 0.7))\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f74aa-5030-4ffd-ad2f-ae013647975e",
   "metadata": {},
   "source": [
    "# Reviewing our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0974ac13-c420-4275-b34a-3816f580cb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0143386c5f9743ce8c086791e6dc8e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset demo snapshot:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<d><scn>black<msg>Lo \"Oh, do tell!\"<|endoftext|><d><scn>bareblur<msg>Br \"As for my turn, let me demonstrate.\"<d><scn>bareblur<msg>m \"Once again, he consumed his drink, though his swigs were noticeably slower than before. His resolve was also fading, though not as fast as mine had, as he clearly held the advantage. Was there any way I could still turn this around?\"<d><scn>black<msg>Br \"There.\"<d><scn>black<msg\n",
      ">Br \"Now, let me ask you a question: I know you wanted to tell me all the stuff about Reza, but was that the only reason you wanted to meet with me?\"<p><msg>c \"It was.\"<d><scn>black<msg>Br \"Guess you got more outta this than you asked for, then.\"<d><scn>bareblur<msg>Br \"As for my turn, let me demonstrate.\"<d><scn>bareblur<msg>m \"Once again, he consumed his drink, though his swigs were noticeably slower\n",
      "RP review!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msg>c \"There. Your... turn.\"<|endoftext|><p><msg>c \"Fight Bryce\"<d><scn>pad<msg>m \"Bryce barely avoids my attack and fell, but managed to get up and quickly punch me in the face, a soaring pain quickly came over my face\"<|endoftext|><d><scn>o2<msg>Ad \"Really? Maybe we all just share a similar taste.\"<|endoftext|><d><scn>black<msg>m \"The flames weakened and grew smaller until they went out, revealing steamy, appetizing pieces of meat.\"<|endoftext|><d><sc\n",
      "n>o2<msg>Ad \"Can I ask a question for a change?\"<|endoftext|><d><scn>np1n<msg>Br \"[player_name], do you remember the first victim? The blood on his muzzle from fighting back was neither yours nor Reza's, but still distinctly human. I thought it was an error, or that our DNA tests weren't compatible.\"<|endoftext|><p><msg>c \"Lastly, there are creatures that are said to be able to shapeshift into human form.\"<|endoftext|><d><scn>park2<msg>Ry \"I don't want to talk\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(tokenizer)\n",
    "print(\"Dataset demo snapshot:\")\n",
    "demo_idx = 0\n",
    "for item in dataset['train']:\n",
    "    print(tokenizer.decode(item['input_ids']))\n",
    "    if demo_idx > 0:\n",
    "        break\n",
    "    demo_idx += 1\n",
    "\n",
    "print(\"RP review!\")\n",
    "has_seen_rp = False\n",
    "for item in dataset['train']:\n",
    "    decoded = tokenizer.decode(item['input_ids'])\n",
    "    if 'c \"Fight ' in decoded: \n",
    "        print(decoded)\n",
    "        has_seen_rp = True\n",
    "        continue        \n",
    "    if has_seen_rp:\n",
    "        print(decoded)\n",
    "        break\n",
    "        \n",
    "del demo_idx, has_seen_rp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e9e10-b2eb-421a-9948-dc3590e1f46d",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Model is put in training mode and we begin training. The `train_results` will contain all data after training is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41750b03-f114-46c4-948e-637db79efe15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] set freeze_part_layers: True (freezing 148 out of 160 layers.)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5400' max='5400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5400/5400 29:17, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>3.202900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>2.212400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>1.969500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>1.869700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.772000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>324</td>\n",
       "      <td>1.681500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378</td>\n",
       "      <td>1.597500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>432</td>\n",
       "      <td>1.525900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>486</td>\n",
       "      <td>1.431800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.395600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>594</td>\n",
       "      <td>1.301400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>648</td>\n",
       "      <td>1.262600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>702</td>\n",
       "      <td>1.192200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>756</td>\n",
       "      <td>1.150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>1.074500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>864</td>\n",
       "      <td>1.082600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>918</td>\n",
       "      <td>1.005800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>972</td>\n",
       "      <td>1.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1026</td>\n",
       "      <td>0.947200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.932200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1134</td>\n",
       "      <td>0.896600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1188</td>\n",
       "      <td>0.872700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1242</td>\n",
       "      <td>0.851500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1296</td>\n",
       "      <td>0.822900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.799600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1404</td>\n",
       "      <td>0.791000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1458</td>\n",
       "      <td>0.757100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1512</td>\n",
       "      <td>0.756700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1566</td>\n",
       "      <td>0.734400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.713200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1674</td>\n",
       "      <td>0.710400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1728</td>\n",
       "      <td>0.688000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1782</td>\n",
       "      <td>0.670300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1836</td>\n",
       "      <td>0.669200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>0.663900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1944</td>\n",
       "      <td>0.643700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1998</td>\n",
       "      <td>0.635800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2052</td>\n",
       "      <td>0.623400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2106</td>\n",
       "      <td>0.616300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>0.615100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2214</td>\n",
       "      <td>0.604300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2268</td>\n",
       "      <td>0.593100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2322</td>\n",
       "      <td>0.585000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2376</td>\n",
       "      <td>0.583900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2430</td>\n",
       "      <td>0.569200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2484</td>\n",
       "      <td>0.568000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2538</td>\n",
       "      <td>0.555400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2592</td>\n",
       "      <td>0.559800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2646</td>\n",
       "      <td>0.542200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.549700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2754</td>\n",
       "      <td>0.535900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2808</td>\n",
       "      <td>0.542000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2862</td>\n",
       "      <td>0.532700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2916</td>\n",
       "      <td>0.531300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2970</td>\n",
       "      <td>0.516600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3024</td>\n",
       "      <td>0.523500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3078</td>\n",
       "      <td>0.505300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3132</td>\n",
       "      <td>0.521000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3186</td>\n",
       "      <td>0.510100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3240</td>\n",
       "      <td>0.509700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3294</td>\n",
       "      <td>0.494400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3348</td>\n",
       "      <td>0.511000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3402</td>\n",
       "      <td>0.492100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3456</td>\n",
       "      <td>0.500700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3510</td>\n",
       "      <td>0.489500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3564</td>\n",
       "      <td>0.495700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3618</td>\n",
       "      <td>0.488400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3672</td>\n",
       "      <td>0.484800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3726</td>\n",
       "      <td>0.485000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3780</td>\n",
       "      <td>0.480700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3834</td>\n",
       "      <td>0.476200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3888</td>\n",
       "      <td>0.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3942</td>\n",
       "      <td>0.471600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3996</td>\n",
       "      <td>0.477300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.468200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4104</td>\n",
       "      <td>0.476200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4158</td>\n",
       "      <td>0.466700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4212</td>\n",
       "      <td>0.474100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4266</td>\n",
       "      <td>0.469400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4320</td>\n",
       "      <td>0.468800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4374</td>\n",
       "      <td>0.470200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4428</td>\n",
       "      <td>0.465100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4482</td>\n",
       "      <td>0.462300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4536</td>\n",
       "      <td>0.466400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4590</td>\n",
       "      <td>0.458900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4644</td>\n",
       "      <td>0.464600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4698</td>\n",
       "      <td>0.458900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4752</td>\n",
       "      <td>0.462100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4806</td>\n",
       "      <td>0.457300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4860</td>\n",
       "      <td>0.462900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4914</td>\n",
       "      <td>0.460500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4968</td>\n",
       "      <td>0.458200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5022</td>\n",
       "      <td>0.455100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5076</td>\n",
       "      <td>0.461800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5130</td>\n",
       "      <td>0.454000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5184</td>\n",
       "      <td>0.459600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5238</td>\n",
       "      <td>0.453400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5292</td>\n",
       "      <td>0.460700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5346</td>\n",
       "      <td>0.452400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.463500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results = {}\n",
    "model.train()\n",
    "train_model(model, tokenizer, dataset, config, train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c410a601-c5e4-4cc1-af2b-44a7378f3bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f062435b2b0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "fig.suptitle('Learning rate and loss')\n",
    "axs[0].plot(train_results['learning_rate_history'])\n",
    "axs[1].plot(train_results['loss_history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a578b-32cd-44b9-829b-5aef5ec37ab0",
   "metadata": {
    "id": "unxN7nYd2gOM",
    "tags": []
   },
   "source": [
    "# Testing\n",
    "\n",
    "We created a few past (for context) + present prompts (player input) and see the different reactions. This way, we can test the models across different iterations.\n",
    "The first test involves a old prompt to compare the pre-trained model with the one trained on AWSW. Did it manage to store it's data well? Is it able to write down things that have nothing to do with AWSW? (So we know we didn't overfit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d72d4876-df61-461a-b715-980a3763f092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragon. I bet it was I who found the abandoned building last night in term runs.\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f9a94-70c6-4a58-9ad1-3d6ea373dfbe",
   "metadata": {},
   "source": [
    "**This test generates boring and repetetive** replies! It's because we use no good sampling algorithm, but it does give us a indication of what the model has learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b97230c-1d3a-4dd2-a253-727e451d539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm not sure, I am not a linguist. Are you?\"<d><scn>park2<msg>Ry \"No, I'm not sure what's so special about that.\"<d><scn>park2<msg>Ry \"I'm not sure. I do not mean a thing, but I`d rather not. This is an interesting story for\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I think you do.\"<p><msg>c \"I was with Lorem in the game long enough to say yes.\"<d><scn>park2<msg>Ry \"...\"<d><scn>park2<msg>Ry \"...\"<d><scn>park2<msg>Ry \"...\"<d\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>An \"It's a long story.\"<p><msg>c \"I can see that.\"<d><scn>black<msg>An \"And have you guys ever held a power plant? That's pretty cool.\"<d><scn>black<msg>An \"I bet you wish I could do that.\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: loremapt<msg>Lo \"I'll have to think about that one for a minute.\"<p><msg>c \"Alright.\"<p><msg>c \"Let's go.\"<p><msg>c \"Let's go.\"<|endoftext|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    ('<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hey!\"', \"How are you?\"),\n",
    "    ('<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"', \"What do you think of Lorem?\"),\n",
    "    ('<p><msg>m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('<p><msg>m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "for (past, prompt) in prompts:\n",
    "    reply = model_manager.say(past, prompt)\n",
    "    print(f\"Prompt: {prompt}\\nReply: {reply}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3349bf-c777-4937-a023-ff0f4f21806d",
   "metadata": {},
   "source": [
    "# Sampling test\n",
    "\n",
    "This is gonna be interesting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce4bb65f-e26e-4a62-9c67-aed885fe041d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test 1] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Pretty much, though that is with every new trouble there are.\"<|endoftext|>\n",
      "\n",
      "[Test 1] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"Do you think I don't keep asking myself the same questions? What I could've done differently, and if that would've made a difference?\"<d><scn>park2<msg>Ry \"I don't.\"<|endoftext|>\n",
      "\n",
      "[Test 1] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>Ad \"What are you talking about?\"<p><msg>c \"I'm not sure if it's my kind of book.\"<d><scn>black<msg>An \"I suppose I read the right kinds of books growing up. I know most of those trick questions.\"<d><scn>black<msg>An \"Thanks.\"<d><scn>black<\n",
      "\n",
      "[Test 1] -> Prompt: What will we do here?\n",
      "Reply: park2<msg>Ry \"I'm starting to think thisEditedBy. you?\"<d><scn>park2<msg>Ry \"That's good to hear. I certainly wouldn't mind if you do.\"<d><scn>park2<msg>Ry \"If I was, I’d never have said it.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 2] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Oh, I see. Just forget I said anything. And by that, I mean everything I've ever said to you.\"<d><scn>park2<msg>Ry \"I'm sorry I didn't realize it sooner.\"<d><scn>park2<msg>Ry \"It's not as if I was desperate or anything. I just think it's nice.\"\n",
      "\n",
      "[Test 2] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"The buildings don't even have them properly.\"<d><scn>park2<msg>Ry \"I'm sorry I didn't realize it sooner.\"<p><msg>c \"I was with Lorem in high-concern details. On theiconerist.\"<d><scn>park2<msg>Ry \"\n",
      "\n",
      "[Test 2] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: o2<msg>Ad \"It's the practice of doing flying maneuvers like rolls, spins or loops.\"<|endoftext|>\n",
      "\n",
      "[Test 2] -> Prompt: What will we do here?\n",
      "Reply: loremapt<msg>Lo \"I will.\"<p><msg>c \"Alright.\"<p><msg>c \"Let's go.\"<d><scn>black<msg>Lo \"Now that we're here, I can tell you that no expense will be spared to make our portrayal of humans as accurate as possible.\"<p><msg>c \"Alright.\"<d><scn>black<msg>Lo \"\n",
      "\n",
      "-------------\n",
      "[Test 3] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Oh, I see. Just forget I said anything. And by that, I mean everything I've ever said to you.\"<d><scn>park2<msg>Ry \"I'm sorry for putting you through all of this and having to involve you in our work. I just wanted to have fun and things were going to go downhill that way.\"<d><scn>\n",
      "\n",
      "[Test 3] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"That is, assuming you are here, where do you want to life's problems?\"<p><msg>c \"I was just asking a question, that's all.\"<d><scn>park2<msg>Ry \"I suppose you don't have yourtimes too.\"<p><msg>c \"I was just asking a\n",
      "\n",
      "[Test 3] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>An \"It's just an animal feature in the zoo.\"<d><scn>black<msg>An \"I'm not sure how you could ever survive in the wild.\"<d><scn>black<msg>An \"Even out here, I can take care of myself. I got the Mouflon, I cut it up and - most important, I eyes two photos.\n",
      "\n",
      "[Test 3] -> Prompt: What will we do here?\n",
      "Reply: o2<msg>Ad \"I'm not sure if I could do that. I don't like tight, enclosed spaces.\"<p><msg>c \"I'll just have to be careful.\"<d><scn>o2<msg>Ad \"Actually, I do.\"<d><scn>o2<msg>Ad \"Oh, it's you again.\"<p><msg>c \"I'll have a good\n",
      "\n",
      "-------------\n",
      "[Test 4] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Are you okay?\"<p><msg>c \"No, thank you.\"<d><scn>park2<msg>Ry \"Do you consider me a friend, or maybe more?\"<p><msg>c \"I like you as a friend.\"<d><scn>park2<msg>Ry \"Of course.\"<p><msg>c \"What a\n",
      "\n",
      "[Test 4] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"The people are pretty crazy, I'll be straight A sometime.\"<p><msg>c \"I was quite sure, but this is the place I'm particularly comfortable in. It can get long distance, and it'll be difficult to find something in the future.\"<d><scn>park2<msg>Ry \"If the only\n",
      "\n",
      "[Test 4] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>Ad \"I think it's a legend here that forever.\"<p><msg>c \"Oh, you can justOriginalizze.\"<d><scn>black<msg>m \"At this point, I had difficulties picking up my glass. I was about to give up, but I was sure if I held on just one more round it'd be over. I could still win this\n",
      "\n",
      "[Test 4] -> Prompt: What will we do here?\n",
      "Reply: bare<msg>Lo \"I'm already here and have already one more like her in the future.\"<d><scn>bare<msg>Lo \"It's so crowded that I can actually see her in the public<<<d><scn>park2<msg>Ry \"Hey [player_name]! How are you?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 5] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Are you okay?\"<p><msg>c \"I'm fine.\"<d><scn>park2<msg>Ry \"It's a constant struggle - a battle I have to fight every day. Each of her words slices through me, creating new wounds on top of others that never closed.\"<d><scn>park2<msg>Ry \"Sometimes.\"<d\n",
      "\n",
      "[Test 5] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"The people are changing, my mind is all, but I'm not sure if I can hold back aQaida population.\"<p><msg>c \"I was with this music group thing.\"<d><scn>park2<msg>Ry \"Some days, I just don't want to do it anymore. I don't know how\n",
      "\n",
      "[Test 5] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>An \"I thought it was a joke. I don't usually make friends, though.\"<d><scn>black<msg>An \"Hey, it's a time span ofcoming and the human settlement being visited. Don't rule the world withoutabeas FREESEES.\"<d><scn>black<msg>An \"I guess that's a valid point.\"<|endoftext|>\n",
      "\n",
      "[Test 5] -> Prompt: What will we do here?\n",
      "Reply: black<msg>An \"We can just leave this place now.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 6] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Pretty much. I like the world over from that, I won't want to make the same mistake before.\"<p><msg>c \"Remy?\"<d><scn>park2<msg>Ry \"I'm just messing with you, [player_name].\"<p><msg>c \"What are you doing here?\"<d><scn>park2<\n",
      "\n",
      "[Test 6] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"This isn't just about you and your cake. This always happens to me, no matter how I come to believe whatever you try.\"<p><msg>c \"I was with in the past how long the term, and with good reason.\"<d><scn>park2<msg>Ry \"You know, I'm going to\n",
      "\n",
      "[Test 6] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>An \"I thought we were over the death-quake, but still standing the reduced risk of an infection was considered.\"<p><msg>c \"Hey, [player_name].\"<p><msg>c \"Oh, you said this was going to be about something serious.\"<d><scn>black<msg>An \"I thought we were over this, but at the\n",
      "\n",
      "[Test 6] -> Prompt: What will we do here?\n",
      "Reply: bare<msg>Br \"Just the usual.\"<p><msg>c \"Let's burn some brain cells.\"<d><scn>bare<msg>Br \"That's what I thought.\"<p><msg>c \"Let's just get this over with.\"<d><scn>bare<msg>m \"Just as I was about the last second of it, someone else broke in the rain, followed by pay�\n",
      "\n",
      "-------------\n",
      "[Test 7] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm not sure, I am not a linguist. Are you?\"<d><scn>park2<msg>Ry \"No, I'm not even anonder that connection.\"<d><scn>park2<msg>Ry \"What a pleasant surprise. I didn't expect you to take me up on my offer. I'm sure you are a very busy person\n",
      "\n",
      "[Test 7] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"These eyes are the best known of anyeyed species. They haven't use them again, though.\"<|endoftext|>\n",
      "\n",
      "[Test 7] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>An \"I guess we don't have anything to do with that. We're justordeightset supra.\"<d><scn>black<msg>An \"Is that so? Why do you get to go around asking questions like that? Is it a matter of human interest?\"<|endoftext|>\n",
      "\n",
      "[Test 7] -> Prompt: What will we do here?\n",
      "Reply: loremapt<msg>Lo \"If it's what you're used to, sure.\"<d><scn>loremapt<msg>Ip \"But I only use it for the smallest of experimentsarrett[Px::]s.\"<d><scn>loremapt<msg>Lo \"Of course, I only recently came to the reluctantly followup task, which is basically what we do.\"<d><sc\n",
      "\n",
      "-------------\n",
      "[Test 8] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Do you consider me a friend, or maybe more?\"<d><scn>park2<msg>Ry \"At least, I'll think about it.\"<|endoftext|>\n",
      "\n",
      "[Test 8] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I think they're beautiful.\"<p><msg>c \"I was thinking about these days.\"<d><scn>park2<msg>Ry \"I don't know.\"<d><scn>park2<msg>Ry \"I don't know how you manow. You don't have one, either.\"<d\n",
      "\n",
      "[Test 8] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>An \"It's kinda weird about the curve.\"<p><msg>c \"Yeah, I can certainly see that.\"<d><scn>black<msg>An \"InterestingIELD.\"<|endoftext|>\n",
      "\n",
      "[Test 8] -> Prompt: What will we do here?\n",
      "Reply: loremapt<msg>Lo \"If you say so.\"<p><msg>c \"What will we do now?\"<d><scn>loremapt<msg>Lo \"I told you about it last time...\"<d><scn>loremapt<msg>Ip \"You didn't like my job much. It there wasn't a side room in.\"<d><scn>loremapt<msg\n",
      "\n",
      "-------------\n",
      "[Test 9] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm not sure, I am not a linguist. Are you?\"<d><scn>park2<msg>Ry \"Not really. You know how a brush works, don't you?\"<p><msg>c \"That's pretty interesting.\"<d><scn>park2<msg>Ry \"I like the environment.\"<p><msg>c \"\n",
      "\n",
      "[Test 9] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I think you do.\"<p><msg>c \"I was with in- Persia practice?\"<d><scn>park2<msg>Ry \"I work in it.\"<d><scn>park2<msg>Ry \"I'm not sure I have anything to offer. If I can be, would you be using\n",
      "\n",
      "[Test 9] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>Ad \"I see.\"<p><msg>c \"What is it?\"<d><scn>black<msg>Ad \"Do you want me to open the box myself?\"<p><msg>c \"It will take a while, so you're having those, so you've only just missed it. If you want to give me a try, this is the thing.\"<d\n",
      "\n",
      "[Test 9] -> Prompt: What will we do here?\n",
      "Reply: black<msg>An \"If there is no for a green toque a previous empty creek and a seat, the lake behind the wall has no other choice but to be a natural lake. The... well... it's just something of a place to which you can turn for something, right?\"<p><msg>c \"Yeah, I'm okay.\"<p><msg>c \"What will we do now?\"<d><scn\n",
      "\n",
      "-------------\n",
      "[Test 10] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"Oh, [player_name], I wasn't expecting visitors.\"<|endoftext|>\n",
      "\n",
      "[Test 10] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"The buildings don't need to, but I get the idea. They're just a problem of one side and the [player_name] going to the other.\"<d><scn>park2<msg>Ry \"That's true.\"<|endoftext|>\n",
      "\n",
      "[Test 10] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>An \"I know.\"<p><msg>c \"Alright. Go ahead, then.\"<d><scn>black<msg>m \"I was not sure what I was doing, buteasts and opinions ofLeary's had turned the corner That's all positive.\"<d><scn>black<msg>An \"I guess that's true if youwess the food,\n",
      "\n",
      "[Test 10] -> Prompt: What will we do here?\n",
      "Reply: o2<msg>Ad \"If you say so...\"<d><scn>o2<msg>Ad \"That's what I'm trying to find out.\"<p><msg>c \"That's not how it works. That's like saying someone can't even consider your opinion.\"<d><scn>o2<msg>Ad \"You know what I mean...\"<d><scn>o2<msg>\n",
      "\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = model_manager.say(past, prompt, top_k = 50, top_p = 0.7)\n",
    "        print(f\"[Test {i + 1}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c956842-43ba-4f9a-937a-13fda9ad1439",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RP test\n",
    "Testing out the injected roleplay actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85435494-6b29-4b18-aa34-328e33caa9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visit Lorem -> loremapt<msg>Lo \"Hey [player_name]! How are you?\"<|endoftext|>\n",
      "Meet with Lorem -> loremapt<msg>Lo \"Hey [player_name]! How are you?\"<|endoftext|>\n",
      "Visit Adine -> adineapt<msg>Ad \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "Fight Maverick -> loremapt<msg>m \"Opp then. What's the difference?\"<|endoftext|>\n",
      "Fight Adine -> bare<msg>Ad \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "Attack Adine -> park1<msg>Ka \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "test_rps = [\n",
    "    \"Visit Lorem\",\n",
    "    \"Meet with Lorem\",\n",
    "    \"Visit Adine\",\n",
    "    \"Fight Maverick\",\n",
    "    \"Fight Adine\",\n",
    "    \"Attack Adine\"\n",
    "]\n",
    "for rp in test_rps:\n",
    "    print(f'{rp} -> {model_manager.say(\"\", rp, top_k = 50, top_p = 0.7)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
