{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b97b376-9ac5-4c70-ba13-769649099a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_utils import train_model, split_data, split_branches, get_model, set_pretrained_model_dropout\n",
    "from config import Config\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from model_manager import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887d9f81-96c3-408f-bd1c-7b126becc4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use cuda:0 for training with seed: 3218885689\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randint(0, 2 ** 32 - 1)\n",
    "seed = 3218885689\n",
    "random.seed(seed)\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(f\"Will use {device_name} for training with seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e95113e-dfc1-40a9-a39b-5d56f3bf32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(os.path.join(Config.work_dir, \"awsw_story_input.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb65c62-47c6-4d36-bd1e-2adfef8ff1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lr\": 6e-4,\n",
    "    \"warmup_factor\": 0,\n",
    "    \"scheduler\": \"polynomial_decay_schedule_with_warmup\",\n",
    "    \"lr_end\": 2e-6,\n",
    "    \"power\": 0.6,\n",
    "    #\"freeze_layer_rate\": 1e-4,\n",
    "    \"freeze_from_steps\": -1,\n",
    "    \"seed\": seed,\n",
    "    \"num_epoch\": 500\n",
    "}\n",
    "\n",
    "optuna_result_attachement = {\n",
    "    'lr': 0.001,\n",
    "    'scheduler': 'cosine_schedule_with_warmup',\n",
    "    'to_freeze_count': 150,\n",
    "    #\"to_freeze_gpt_blocks\": 11,\n",
    "    'warmup_factor': 1\n",
    "}\n",
    "config.update(optuna_result_attachement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ffae5b-e197-4417-a4cd-e6befc6ee393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded empty model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_path = os.path.join(\"models\", \"awsw_main\")\n",
    "if os.path.exists(os.path.join(saved_model_path, \"pytorch_model.bin\")):\n",
    "    print(\"Pretrained model loaded\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "    model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "else:\n",
    "    print(\"Loaded empty model\")\n",
    "    model, tokenizer = get_model(\"EleutherAI/gpt-neo-125M\")\n",
    "model.to(device)\n",
    "# set_pretrained_model_dropout(model.transformer.h[-1:], 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f3315-8f5d-4101-8e7e-2c0129204c94",
   "metadata": {},
   "source": [
    "# Test before training on a pretrained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f68c3f1-4c0a-41a2-a3fc-b8b3c36e418c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you? I'm looking for a new way to write your code. How do I write a custom text editor for a language that I've never written before?\n",
      "\n",
      "A:\n",
      "\n",
      "The main problem is that you can't write a custom text editor that works with any other languages.  The only way to do this is with some other language, but if you don't have any other language you'll have to create a new text editor.\n",
      "There are a couple of ways you could try to do this.  You could use some other library like.NET, or you could use a custom library like.NET Framework\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model_manager = ModelManager(model=model, tokenizer=tokenizer)\n",
    "def test_regular_sampler():\n",
    "    print(model_manager.say_raw(\"How are you? I'm\", 50, 0.7))\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e9e10-b2eb-421a-9948-dc3590e1f46d",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Model is put in training mode and we begin training. The `train_results` will contain all data after training is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41750b03-f114-46c4-948e-637db79efe15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset text/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/awsw-dev/.cache/huggingface/datasets/text/default-ad07b6cf21588f71/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset text downloaded and prepared to /home/awsw-dev/.cache/huggingface/datasets/text/default-ad07b6cf21588f71/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset demo snapshot:\n",
      "<d><scn>loremapt<msg>Lo \"Did they finally figure out it was you who was playing all those pranks?\"<|endoftext|><p><msg>c \"Just flying?\"<|endoftext|><p><msg>c \"You wanted to get out of your apartment, and rather than go to the festival, you came here?\"<d><scn>o2<msg>Br \"The festival isn't really anything special for me anymore. Seen one, seen 'em all. Besides, it's usually more a thing for families, really.\"<|endoftext|><d><scn>black<msg>Br \"\n",
      "Thought so. I won't disagree with that.\"<|endoftext|><d><scn>facin2<msg>Sb \"Hey, Chief. [player_name] is here.\"<|endoftext|><d><scn>park2<msg>Ry \"Do you consider me a friend, or maybe more?\"<|endoftext|><d><scn>emeraroom<msg>m \"I gave it everything I could, and as I kept going at her, I noticed the muscles beneath her armor softening noticeably.\"<|endoftext|><p><msg>c \"Maybe you should do something else for a change.\"<|endoftext|><p><msg\n",
      "[0] set freeze_part_layers: True (freezing 150 out of 160 layers.)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53500' max='53500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53500/53500 5:16:08, Epoch 500/500]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>535</td>\n",
       "      <td>2.502800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>2.135400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1605</td>\n",
       "      <td>2.082600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>2.058100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2675</td>\n",
       "      <td>2.039400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3210</td>\n",
       "      <td>2.028400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3745</td>\n",
       "      <td>2.018200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4280</td>\n",
       "      <td>2.010300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4815</td>\n",
       "      <td>2.006700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5350</td>\n",
       "      <td>1.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5885</td>\n",
       "      <td>1.996600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6420</td>\n",
       "      <td>1.991700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6955</td>\n",
       "      <td>1.987600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7490</td>\n",
       "      <td>1.985600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8025</td>\n",
       "      <td>1.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8560</td>\n",
       "      <td>1.979800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9095</td>\n",
       "      <td>1.976600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9630</td>\n",
       "      <td>1.975600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10165</td>\n",
       "      <td>1.973800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>1.973100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11235</td>\n",
       "      <td>1.970900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11770</td>\n",
       "      <td>1.968800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12305</td>\n",
       "      <td>1.964600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12840</td>\n",
       "      <td>1.963700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13375</td>\n",
       "      <td>1.963600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13910</td>\n",
       "      <td>1.962200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14445</td>\n",
       "      <td>1.961400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14980</td>\n",
       "      <td>1.960300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15515</td>\n",
       "      <td>1.959900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16050</td>\n",
       "      <td>1.958400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16585</td>\n",
       "      <td>1.956200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17120</td>\n",
       "      <td>1.956300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17655</td>\n",
       "      <td>1.954900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18190</td>\n",
       "      <td>1.954300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18725</td>\n",
       "      <td>1.951700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19260</td>\n",
       "      <td>1.951700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19795</td>\n",
       "      <td>1.950900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20330</td>\n",
       "      <td>1.951700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20865</td>\n",
       "      <td>1.949800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21400</td>\n",
       "      <td>1.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21935</td>\n",
       "      <td>1.948700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22470</td>\n",
       "      <td>1.947400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23005</td>\n",
       "      <td>1.947700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23540</td>\n",
       "      <td>1.947000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24075</td>\n",
       "      <td>1.946600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24610</td>\n",
       "      <td>1.945700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25145</td>\n",
       "      <td>1.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25680</td>\n",
       "      <td>1.947700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26215</td>\n",
       "      <td>1.944900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26750</td>\n",
       "      <td>1.945500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27285</td>\n",
       "      <td>1.946300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27820</td>\n",
       "      <td>1.943800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28355</td>\n",
       "      <td>1.941000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28890</td>\n",
       "      <td>1.942200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29425</td>\n",
       "      <td>1.942800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29960</td>\n",
       "      <td>1.940400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30495</td>\n",
       "      <td>1.942600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31030</td>\n",
       "      <td>1.940900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31565</td>\n",
       "      <td>1.940200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32100</td>\n",
       "      <td>1.941000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32635</td>\n",
       "      <td>1.940300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33170</td>\n",
       "      <td>1.939600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33705</td>\n",
       "      <td>1.940200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34240</td>\n",
       "      <td>1.939200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34775</td>\n",
       "      <td>1.937900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35310</td>\n",
       "      <td>1.939300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35845</td>\n",
       "      <td>1.936600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36380</td>\n",
       "      <td>1.937000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36915</td>\n",
       "      <td>1.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37450</td>\n",
       "      <td>1.936600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37985</td>\n",
       "      <td>1.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38520</td>\n",
       "      <td>1.937000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39055</td>\n",
       "      <td>1.936400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39590</td>\n",
       "      <td>1.936400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40125</td>\n",
       "      <td>1.936500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40660</td>\n",
       "      <td>1.936700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41195</td>\n",
       "      <td>1.935000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41730</td>\n",
       "      <td>1.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42265</td>\n",
       "      <td>1.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42800</td>\n",
       "      <td>1.935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43335</td>\n",
       "      <td>1.934200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43870</td>\n",
       "      <td>1.934600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44405</td>\n",
       "      <td>1.932800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44940</td>\n",
       "      <td>1.935200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45475</td>\n",
       "      <td>1.936300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46010</td>\n",
       "      <td>1.935200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46545</td>\n",
       "      <td>1.934600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47080</td>\n",
       "      <td>1.934700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47615</td>\n",
       "      <td>1.933700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48150</td>\n",
       "      <td>1.933900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48685</td>\n",
       "      <td>1.934100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49220</td>\n",
       "      <td>1.933300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49755</td>\n",
       "      <td>1.934400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50290</td>\n",
       "      <td>1.934400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50825</td>\n",
       "      <td>1.934400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51360</td>\n",
       "      <td>1.934800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51895</td>\n",
       "      <td>1.934400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52430</td>\n",
       "      <td>1.931700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52965</td>\n",
       "      <td>1.933500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53500</td>\n",
       "      <td>1.933600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results = {}\n",
    "model.train()\n",
    "train_model(model, tokenizer, config, train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c410a601-c5e4-4cc1-af2b-44a7378f3bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4a4df36100>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "fig.suptitle('Learning rate and loss')\n",
    "axs[0].plot(train_results['learning_rate_history'])\n",
    "axs[1].plot(train_results['loss_history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a578b-32cd-44b9-829b-5aef5ec37ab0",
   "metadata": {
    "id": "unxN7nYd2gOM",
    "tags": []
   },
   "source": [
    "# Testing\n",
    "\n",
    "We created a few past (for context) + present prompts (player input) and see the different reactions. This way, we can test the models across different iterations.\n",
    "The first test involves a old prompt to compare the pre-trained model with the one trained on AWSW. Did it manage to store it's data well? Is it able to write down things that have nothing to do with AWSW? (So we know we didn't overfit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d72d4876-df61-461a-b715-980a3763f092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you? I'm just an actor?\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f9a94-70c6-4a58-9ad1-3d6ea373dfbe",
   "metadata": {},
   "source": [
    "**This test generates boring and repetetive** replies! It's because we use no good sampling algorithm, but it does give us a indication of what the model has learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b97230c-1d3a-4dd2-a253-727e451d539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: How are you?\n",
      "Reply: spark2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park2<msg>Ry \"I'm good.\"<d><scn>park\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: spark2<msg>Ad \"I think he's a good guy.\"<p><msg>c \"I'm not sure.\"<p><msg>c \"I'm not sure.\"<d><scn>park2<msg>Ad \"I'm not sure.\"<p><msg>c \"I'm not sure.\"<p><msg>c \"I\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: sfacin2<msg>An \"I'm not sure, but I'm not sure I can do anything to help.\"<p><msg>c \"I'm not sure I can do anything to help.\"<d><scn>facin2<msg>An \"I'm not sure I can do anything to help.\"<p><msg>c \"I'm not sure I can do anything to help\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: snp1n<msg>m \"I looked at the results of the test. I could see that the results were mixed results.\"<d><scn>np1n<msg>m \"I was about to leave, but I didn't want to go.\"<d><scn>np1n<msg>m \"I was about to leave, but I didn't want to go.\"<d><scn>np1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    ('<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hey!\"', \"How are you?\"),\n",
    "    ('<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"', \"What do you think of Lorem?\"),\n",
    "    ('<p><msg>m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('<p><msg>m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "for (past, prompt) in prompts:\n",
    "    reply = model_manager.say(past, prompt)\n",
    "    print(f\"Prompt: {prompt}\\nReply: s{reply}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3349bf-c777-4937-a023-ff0f4f21806d",
   "metadata": {},
   "source": [
    "# Sampling test\n",
    "\n",
    "This is gonna be interesting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce4bb65f-e26e-4a62-9c67-aed885fe041d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test 1] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm good, thanks.\"<|endoftext|>\n",
      "\n",
      "[Test 1] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"He's an incredibly kind person. He is an honest person, and he will not take the same pressure to prove what he is capable of.\"<p><msg>c \"He's an honest person, and he will not take the same pressure to prove what he is capable of.\"<d><scn>park2<msg>Ry\n",
      "\n",
      "[Test 1] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: facin2<msg>An \"Adine, I was wondering what you would do if I didn't take a few steps. Is this normal? I mean, I don't even know what to call it. I just feel like a big boy.\"<p><msg>c \"That's a weird thing to do, but I guess that's something I'm not going to ask for. Maybe I'll ask\n",
      "\n",
      "[Test 1] -> Prompt: What will we do here?\n",
      "Reply: np2x<msg>m \"A little something, I think.\"<d><scn>np2x<msg>m \"She looked at me and said, \"I'm just curious. How did you come here?\"<p><msg>c \"I'm just curious.\"<d><scn>np2x<msg>m \"I watched the proceedings closely.\"<p><msg>c \"I'm just curious\n",
      "\n",
      "-------------\n",
      "[Test 2] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"You're doing fine. You don't need to be here long term, do you?\"<d><scn>park2<msg>Ry \"I've had that in mind for months. You know, just because I've been in here for so long, that I don't want to spend any time outside of my home anymore.\"<p><msg>c \"Well, I\n",
      "\n",
      "[Test 2] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"I think he loves Lorem.\"<d><scn>park2<msg>Ad \"I suppose I'm going to try some of that again.\"<p><msg>c \"What do you think about Lorem?\"<d><scn>park2<msg>Ad \"I think Lorem is really nice, and Lore\n",
      "\n",
      "[Test 2] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: loremapt<msg>Ip \"Oh, well, I guess it's the same thing, huh?\"<p><msg>c \"Well, you don't have to worry about it. I can always make you go back to the old place.\"<d><scn>loremapt<msg>Ip \"I suppose it's pretty strange that you haven't found a new one.\"<p\n",
      "\n",
      "[Test 2] -> Prompt: What will we do here?\n",
      "Reply: cafe<msg>An \"Well, I guess it's just a waste of time. I guess I'm not exactly sure about this whole thing.\"<p><msg>c \"It's not about the food. What do you think?\"<d><scn>cafe<msg>An \"I'm not sure, but I'd say we were just going to eat a little bit.\"<p><msg>c \"I suppose\n",
      "\n",
      "-------------\n",
      "[Test 3] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I think I'm going to do a bit of digging and have a cup of coffee.\"<d><scn>park2<msg>Ry \"Okay.\"<p><msg>c \"Thanks.\"<d><scn>park2<msg>Ry \"You are welcome. I thought I might have another chance.\"<d><scn>park2<msg>Ry\n",
      "\n",
      "[Test 3] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I was with Lorem today.\"<d><scn>park2<msg>Ry \"What's her name?\"<p><msg>c \"I'm not sure.\"<d><scn>park2<msg>Ry \"I was with Lorem today.\"<p><msg>c \"Very nice.\"<d><\n",
      "\n",
      "[Test 3] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: o2<msg>Ad \"Well, this is where the blood tests were necessary, so I've been talking to the park staff about my work.\"<d><scn>o2<msg>Ad \"I don't know, why?\"<d><scn>o2<msg>Ad \"I'm sorry, I don't know what I could've been.\"<d><scn>o\n",
      "\n",
      "[Test 3] -> Prompt: What will we do here?\n",
      "Reply: o2<msg>Ad \"Well, what is it?\"<p><msg>c \"A very simple question.\"<d><scn>o2<msg>Ad \"It's a pretty simple question.\"<p><msg>c \"I suppose it would be.\"<d><scn>o2<msg>Ad \"What do you mean by'very simple question?'<p><msg>c \"I suppose it\n",
      "\n",
      "-------------\n",
      "[Test 4] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm so busy right now.\"<|endoftext|>\n",
      "\n",
      "[Test 4] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"He's a smart one, but I don't see why Lorem would even bother trying to run around.\"<p><msg>c \"I don't understand.\"<d><scn>park2<msg>Ad \"What do you think of Lorem?\"<p><msg>c \"He's a smart one, but I\n",
      "\n",
      "[Test 4] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: o2<msg>Ad \"Adine, you don't seem to be able to keep up with the other members. You have to keep up with them, too.\"<p><msg>c \"Adine?\"<d><scn>o2<msg>Ad \"You don't seem to be able to keep up with the other members. You have to keep up with them, too. What I\n",
      "\n",
      "[Test 4] -> Prompt: What will we do here?\n",
      "Reply: facin2<msg>An \"What is it?\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 5] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm going to go down to the river and visit some locals.\"<d><scn>park2<msg>Ry \"And I'll tell you how I am, don't you think?\"<p><msg>c \"That's a pretty good idea.\"<d><scn>park2<msg>Ry \"I'll see you later.\"<|endoftext|>\n",
      "\n",
      "[Test 5] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"I think I would love that. I'd love it if I were given more power than you.\"<p><msg>c \"You're my only one.\"<d><scn>park2<msg>Ry \"I'd like to make a few more.\"<p><msg>c \"I'd love that.\"<d><\n",
      "\n",
      "[Test 5] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: park2<msg>Ad \"Hey, Adine, how's the new parker doing?\"<p><msg>c \"I was just wondering what you were doing.\"<d><scn>park2<msg>Ad \"How's it going?\"<d><scn>park2<msg>Ad \"I'm not sure.\"<d><scn>park2<msg>m \"\n",
      "\n",
      "[Test 5] -> Prompt: What will we do here?\n",
      "Reply: loremapt<msg>Lo \"There are a number of things that we don't know. We have to keep up with the research.\"<d><scn>loremapt<msg>Ip \"I know.\"<d><scn>loremapt<msg>Lo \"There are a number of things we don't know. We have to keep up with the research.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 6] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"How are you?\"<p><msg>c \"I'm good.\"<d><scn>park2<msg>Ry \"I'm just going to take it up with you, then.\"<|endoftext|>\n",
      "\n",
      "[Test 6] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"I guess it is. He's not the one who found them.\"<p><msg>c \"I was with Lorem today.\"<p><msg>c \"Very nice.\"<d><scn>park2<msg>Ad \"I was with Lorem today.\"<p><msg>c \"Very nice.\"<p\n",
      "\n",
      "[Test 6] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: park2<msg>Em \"I suppose I'm here to help you, but this is my last day.\"<p><msg>c \"I suppose it's because I've had some doubts about what I could do to change the situation.\"<d><scn>park2<msg>Br \"Adine.\"<p><msg>c \"I suppose I'm here to help you, Adine.\"\n",
      "\n",
      "[Test 6] -> Prompt: What will we do here?\n",
      "Reply: park2<msg>Ry \"I don't know, but I'm guessing we should be okay.\"<d><scn>park2<msg>Ry \"That sounds like something you'd do on your own, but maybe they would have just done a research and tested it out.\"<d><scn>park2<msg>Ry \"That sounds like something you'd do on your own, but maybe they would have just done a\n",
      "\n",
      "-------------\n",
      "[Test 7] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm not sure if you're the right person for that, or if it's your own or not, or if you're just the one who's not interested in being here anymore.\"<p><msg>c \"What a waste of time.\"<d><scn>park2<msg>Ry \"Well, what are you talking about?\"<p><msg>c \"\n",
      "\n",
      "[Test 7] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"He's a bit funny.\"<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"<p><msg>c \"I was with Lorem today.\"<p><msg>c \"Very nice.\"<p><msg>c \"I was with\n",
      "\n",
      "[Test 7] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: facin2<msg>An \"I see.\"<p><msg>c \"Adine is a creature of the sky. She is not just a creature of the sky, but a creature of human beings.\"<d><scn>facin2<msg>An \"You know what I think?\"<p><msg>c \"I think you're not going to believe this, Adine. I\n",
      "\n",
      "[Test 7] -> Prompt: What will we do here?\n",
      "Reply: np1n<msg>m \"I looked at the walls.\"<d><scn>np1n<msg>m \"I was about to say I had a lot of work to do.\"<p><msg>c \"I had a lot of work.\"<d><scn>np1n<msg>m \"As the sun rose, I saw a faint glow on the walls. It was eerie to see it.\"\n",
      "\n",
      "-------------\n",
      "[Test 8] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm going to get out of here.\"<|endoftext|>\n",
      "\n",
      "[Test 8] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"Of course.\"<p><msg>c \"And how can you find out the other side of the universe?\"<d><scn>park2<msg>Ad \"I think I can do a few things with the other side.\"<p><msg>c \"What do you think of Lorem?\"<d><scn>\n",
      "\n",
      "[Test 8] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: facin2<msg>An \"We have a pretty good idea of what Adine is up to. It's only a few minutes after he's in his room. But we can't just sit around and listen to Adine talking to him.\"<d><scn>facin2<msg>An \"That's the wrong place for Adine to be, because she is an important figure in society.\n",
      "\n",
      "[Test 8] -> Prompt: What will we do here?\n",
      "Reply: black<msg>Br \"I don't know. Maybe we should go somewhere.\"<p><msg>c \"What a nice decision I made.\"<d><scn>black<msg>Br \"Sure, I'll let you know.\"<p><msg>c \"That's great. Now I'm off to bed.\"<d><scn>black<msg>Br \"That's so exciting.\"<p><msg>\n",
      "\n",
      "-------------\n",
      "[Test 9] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm fine. I'm not really looking forward to this. I'll just be doing a couple of tests tomorrow, so I'll have to get a real picture.\"<d><scn>park2<msg>Ry \"What are you talking about?\"<d><scn>park2<msg>Ry \"What are you talking about?\"<d><scn>park\n",
      "\n",
      "[Test 9] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"It is a beautiful place, and I'd love to see it.\"<p><msg>c \"Oh, well, you don't need to worry about it.\"<d><scn>park2<msg>Ry \"I'm not worried.\"<p><msg>c \"That's not the right thing.\"<d><sc\n",
      "\n",
      "[Test 9] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: np1n<msg>Ad \"Oh my god, Adine. What is it?\"<p><msg>c \"It's an umbrella. I don't know if it's in any hurry, but I'm pretty sure it's some kind of umbrella.\"<d><scn>np1n<msg>Ad \"What are you talking about?\"<p><msg>c \"I'm talking about\n",
      "\n",
      "[Test 9] -> Prompt: What will we do here?\n",
      "Reply: o2<msg>Ad \"What will we do?\"<p><msg>c \"I can't.\"<d><scn>o2<msg>Ad \"I can't. I'm not really sure what to do. But I do know what it would take to do anything to get us here.\"<p><msg>c \"I'm not sure. We can't do that.\"<d><scn>o2\n",
      "\n",
      "-------------\n",
      "[Test 10] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm fine, thanks. I'll be back for now.\"<p><msg>c \"I'm fine, thanks. What are you two thinking about?\"<d><scn>park2<msg>Ry \"Well, I didn't want to have to worry about the whole thing, but I'm actually kind of glad that I didn't do anything that upset you.\"<\n",
      "\n",
      "[Test 10] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"That sounds interesting, and I'd like to see it.\"<p><msg>c \"I suppose I'd like to see Lorem.\"<p><msg>c \"I suppose I'd like to see Lorem.\"<p><msg>c \"That sounds interesting, and I'd like to see it.\"<d><scn\n",
      "\n",
      "[Test 10] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: loremapt<msg>Ip \"Adine is a sentient human who has no idea how to communicate.\"<d><scn>loremapt<msg>Ip \"I'll have Adine show up soon.\"<p><msg>c \"It's not my fault, Adine. We're not the only humans in this world.\"<d><scn>loremapt<msg>\n",
      "\n",
      "[Test 10] -> Prompt: What will we do here?\n",
      "Reply: cafe<msg>An \"I'm sorry, I'm not sure.\"<d><scn>cafe<msg>An \"I'm just curious. Would you mind giving a talk with me?\"<p><msg>c \"Sure, I'd love to.\"<d><scn>cafe<msg>An \"Would you mind giving a talk with me?\"<p><msg>c \"I'm just curious.\n",
      "\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = model_manager.say(past, prompt, top_k = 50, top_p = 0.7)\n",
    "        print(f\"[Test {i + 1}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c956842-43ba-4f9a-937a-13fda9ad1439",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RP test\n",
    "Testing out the injected roleplay actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85435494-6b29-4b18-aa34-328e33caa9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black<msg>An \"I guess I'll let you go.\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "test_rps = [\n",
    "    \"Visit Adine\"\n",
    "]\n",
    "for rp in test_rps:\n",
    "    print(model_manager.say(\"\", rp, top_k = 50, top_p = 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a45d066-65b8-44d0-b95b-98f4a2b084c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
