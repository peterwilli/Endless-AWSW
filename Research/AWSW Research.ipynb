{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b97b376-9ac5-4c70-ba13-769649099a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_utils import train_model, split_data, split_branches, get_model, set_pretrained_model_dropout, get_dataset, ModelSeeder\n",
    "from config import Config\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import onnx\n",
    "import logging\n",
    "from onnx_model_manager import OnnxModelManager\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "import os\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from model_manager import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887d9f81-96c3-408f-bd1c-7b126becc4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use cuda:0 for training with seed: 3218885689\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randint(0, 2 ** 32 - 1)\n",
    "seed = 3218885689\n",
    "random.seed(seed)\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(f\"Will use {device_name} for training with seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e95113e-dfc1-40a9-a39b-5d56f3bf32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(os.path.join(Config.work_dir, \"awsw_story_input.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb65c62-47c6-4d36-bd1e-2adfef8ff1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lr\": 6e-4,\n",
    "    \"warmup_factor\": 0,\n",
    "    \"scheduler\": \"polynomial_decay_schedule_with_warmup\",\n",
    "    \"lr_end\": 2e-6,\n",
    "    \"power\": 0.6,\n",
    "    #\"freeze_layer_rate\": 1e-4,\n",
    "    \"freeze_from_steps\": -1,\n",
    "    \"seed\": seed,\n",
    "    \"num_epoch\": 2\n",
    "}\n",
    "\n",
    "optuna_result_attachement = {\n",
    "    'lr': 0.001,\n",
    "    'scheduler': 'cosine_schedule_with_warmup',\n",
    "    'to_freeze_count': 0,\n",
    "    #\"to_freeze_gpt_blocks\": 11,\n",
    "    'warmup_factor': 5\n",
    "}\n",
    "config.update(optuna_result_attachement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ffae5b-e197-4417-a4cd-e6befc6ee393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded empty model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_path = os.path.join(\"models\", \"awsw_main\")\n",
    "if os.path.exists(os.path.join(saved_model_path, \"pytorch_model.bin\")):\n",
    "    tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "    model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "    print(\"Pretrained model loaded\")\n",
    "else:\n",
    "    model, tokenizer = get_model(\"EleutherAI/gpt-neo-125M\")\n",
    "    print(\"Loaded empty model\")\n",
    "model.to(device)\n",
    "# set_pretrained_model_dropout(model.transformer.h[-1:], 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f3315-8f5d-4101-8e7e-2c0129204c94",
   "metadata": {},
   "source": [
    "# Test before training on a pretrained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f68c3f1-4c0a-41a2-a3fc-b8b3c36e418c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragon. I was raised by my grandmother, but the world didn't change until I was ten years old. In the early 20th century, when the first dragon was born, I was a girl, and it was my dream to become a dragon. When I was five, I was the dragon's father. At thirteen, I was a child. I had a lot of trouble with a bad heart, but I knew I was right.\n",
      "\n",
      "I'd come to this country in the early 1980s, and when I arrived in New York, my mother had told me I'd never get back\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model_manager = ModelManager(model=model, tokenizer=tokenizer, device=device)\n",
    "def test_regular_sampler():\n",
    "    print(model_manager.say_raw(\"In my dreams, I'm a dragon\", 50, 0.7))\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f74aa-5030-4ffd-ad2f-ae013647975e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reviewing our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0974ac13-c420-4275-b34a-3816f580cb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef05a08eee34070802755634ff304d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset demo snapshot:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<d><scn>black<msg>n \"It was only then, when our race had become so dependent on technology, that we were immeasurably vulnerable against this kind of disaster.\"<|endoftext|><d><scn>facin2<msg>Ry \"Consider this a warning. You should proceed carefully, for your own good.\"<|endoftext|><d><scn>beach<msg>Ad \"What a crazy coincidence.\"<|endoftext|><d><scn>np2x<msg>Ad \"Goodbye, [player_name].\"<|endoftext|><d><scn>park3<msg>Br \"\n",
      "RP review!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you leaving?\"<|endoftext|><d><scn>black<msg>Lo \"It's a bit sad not to have them as a natural letter opener anymore, though.\"<|endoftext|><p><msg>c \"I'm not surprised. They can set the mood for a romantic evening.\"<|endoftext|><p><msg>c \"Fight Lorem\"<d><scn>black<msg>m \"Lorem dodges my attack and comes rushing towards me\"<|endoftext|><p><msg>c \"No, thanks. It's all yours.\"<|endoftext|><p><msg>c \"It's a shame. I bet your stunts would\n",
      " have been amazing to see.\"<|endoftext|><d><scn>emeraroom<msg>Em \"That's good to know.\"<|endoftext|><d><scn>park2<msg>Ry \"I guess she did try to talk to me, but it was only because she wanted something.\"<|endoftext|><d><scn>o2<msg>Sb \"Yes. The whole building is underground, and we've determined that there is a rather large pocket of water surrounding it. Any kind of disturbance could endanger everything and everyone inside.\"<|endoftext|><p><msg>c \"Before we get to that, you haven't even\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(tokenizer, path_train = os.path.join(Config.work_dir, \"data_train.txt\"))\n",
    "print(\"Dataset demo snapshot:\")\n",
    "for item in dataset['train']:\n",
    "    print(tokenizer.decode(item['input_ids']))\n",
    "    break\n",
    "\n",
    "print(\"RP review!\")\n",
    "has_seen_rp = False\n",
    "for item in dataset['train']:\n",
    "    decoded = tokenizer.decode(item['input_ids'])\n",
    "    if 'c \"Fight ' in decoded: \n",
    "        print(decoded)\n",
    "        has_seen_rp = True\n",
    "        continue        \n",
    "    if has_seen_rp:\n",
    "        print(decoded)\n",
    "        break\n",
    "# Clean up\n",
    "del has_seen_rp\n",
    "# dataset['model_seeder'].stop_worker()\n",
    "# del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e9e10-b2eb-421a-9948-dc3590e1f46d",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Model is put in training mode and we begin training. The `train_results` will contain all data after training is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41750b03-f114-46c4-948e-637db79efe15",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] set freeze_part_layers: True (freezing 0 out of 160 layers.)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='214' max='214' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [214/214 01:29, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.802700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.573800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.883100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.888000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.619900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.521200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.193200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.150600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.939800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.949600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.688700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.661600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.630800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.462500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.380500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.352800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2.459500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2.321000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>2.196700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.142100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>2.078500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>2.185600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>2.234100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>2.189100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.261900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>2.316500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>2.183900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>2.424800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>2.414600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.457900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>2.477400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>2.515800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>2.623500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>2.764900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.855200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>2.886800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>2.966300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>3.039400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>3.196400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.210100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>3.409100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>3.606300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>3.752800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>3.823000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.906800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>4.124300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>4.176900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>4.358800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>4.561300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.702800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>4.993500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>5.049500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>5.290600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>5.539100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>5.511700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>5.721500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>5.896100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>6.123700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>6.441300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>6.709300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>6.798600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>7.110600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>7.352800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>7.606800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>7.847800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>8.171100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>8.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>8.691600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>9.074300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>9.282600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>9.586800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>9.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>10.222500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>10.523900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>10.989000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>11.393800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>11.585900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>12.071700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>12.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>12.892900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>13.245300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>13.692500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>13.977900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>14.386800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>15.022600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>15.509200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>15.827200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>16.297700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>16.778300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>17.376300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>17.836300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>18.078400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>18.888900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>19.376800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>19.874600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>20.544800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>21.101300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>21.628600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>22.245700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>22.807600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>23.572300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>24.210700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>24.898600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>25.581000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>26.321500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>27.045700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>27.776500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results = {}\n",
    "model.train()\n",
    "train_model(model, tokenizer, dataset, config, train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c410a601-c5e4-4cc1-af2b-44a7378f3bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3f1f795790>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3)\n",
    "fig.suptitle('Learning rate and loss')\n",
    "axs[0].plot(train_results['learning_rate_history'])\n",
    "axs[1].plot(train_results['model_closeness_loss'])\n",
    "axs[2].plot(train_results['loss_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "753228f0-b420-4b3d-bd69-53da7a87bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.save_pretrained(saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e4666-c1ff-4695-ba55-894503925f9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conversion to ONNX\n",
    "ONNX is a different format for running machine learning models. The ONNX format is much faster on CPU, sometimes 5 times as fast as PyTorch!\n",
    "\n",
    "While the EAWSW model is designed to be small, accurate and accessible, for some people it's still too much to run...\n",
    "\n",
    "Hosting the model as a free service for players is an option. An ONNX version of the model allows us to host the model on CPU yet have faster response times! Given that the model is made in a time with chip shortage, running on hardware I already have inside a server is efficient, scalable and cheaper.\n",
    "\n",
    "An important note is that ONNX doesn't execute logic by itself, and you have to do that yourself, `onnx_model_manager.py` intends to deal with this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3b88e1f-f5c3-4a95-8b00-e791148d8c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying config files from huggingface (needed for conversion)... WARNING: this assumes the structure of the model isn't changed!\n",
      "Cloning into 'gpt-neo-125M'...\n",
      "remote: Enumerating objects: 38, done.\u001b[K\n",
      "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
      "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
      "remote: Total 38 (delta 16), reused 0 (delta 0)\u001b[K\n",
      "Unpacking objects: 100% (38/38), 542.60 KiB | 901.00 KiB/s, done.\n",
      "Using framework PyTorch: 1.10.1+cu113\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> True\n",
      "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:90: UserWarning: 'enable_onnx_checker' is deprecated and ignored. It will be removed in the next PyTorch release. To proceed despite ONNX checker failures, catch torch.onnx.ONNXCheckerError.\n",
      "  warnings.warn(\"'enable_onnx_checker' is deprecated and ignored. It will be removed in \"\n",
      "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:103: UserWarning: `use_external_data_format' is deprecated and ignored. Will be removed in next PyTorch release. The code will work as it is False if models are not larger than 2GB, Otherwise set to False because of size limits imposed by Protocol Buffers.\n",
      "  warnings.warn(\"`use_external_data_format' is deprecated and ignored. Will be removed in next \"\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:559: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert batch_size > 0, \"batch_size has to be defined and > 0\"\n",
      "Validating ONNX model...\n",
      "\t-[] ONNX model outputs' name match reference model ({'present.5.key', 'present.6.key', 'present.2.value', 'present.9.key', 'present.5.value', 'present.11.value', 'present.1.value', 'present.4.key', 'present.7.key', 'present.0.value', 'present.11.key', 'present.8.key', 'present.10.key', 'present.4.value', 'present.10.value', 'present.3.key', 'present.0.key', 'present.9.value', 'present.7.value', 'logits', 'present.6.value', 'present.1.key', 'present.3.value', 'present.2.key', 'present.8.value'}\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[] (2, 1, 50257) matches (2, 1, 50257)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.0.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.0.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.1.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.1.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.2.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.2.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.3.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.3.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.4.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.4.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.5.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.5.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.6.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.6.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.7.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.7.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.8.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.8.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.9.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.9.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.10.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.10.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.11.key\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"present.11.value\":\n",
      "\t\t-[] (2, 12, 2, 64) matches (2, 12, 2, 64)\n",
      "\t\t-[] all values close (atol: 0.0001)\n",
      "All good, model saved at: models/awsw_onnx/model.onnx\n"
     ]
    }
   ],
   "source": [
    "saved_model_onnx_path = os.path.join(\"models\", \"awsw_onnx\")\n",
    "if not os.path.exists(os.path.join(saved_model_path, \"special_tokens_map.json\")):\n",
    "    print(\"Copying config files from huggingface (needed for conversion)... WARNING: this assumes the structure of the model isn't changed!\")\n",
    "    !cd $saved_model_path && git clone https://huggingface.co/EleutherAI/gpt-neo-125M\n",
    "    !cp -n $saved_model_path/gpt-neo-125M/* $saved_model_path\n",
    "    !rm -rf $saved_model_path/gpt-neo-125M\n",
    "if not os.path.exists(os.path.join(saved_model_onnx_path, \"model.onnx\")):\n",
    "    !python3 -m transformers.onnx --model=$saved_model_path --feature=causal-lm-with-past $saved_model_onnx_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a86f7a12-9bcb-4c4b-a679-7007a7e2caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_onnx():\n",
    "    model_quant = os.path.join(saved_model_onnx_path, \"model_quant.onnx\")\n",
    "    if not os.path.exists(model_quant):\n",
    "        model_fp32 = os.path.join(saved_model_onnx_path, \"model.onnx\")\n",
    "        model_opt = os.path.join(saved_model_onnx_path, \"model-opt.onnx\")\n",
    "        quantized_model = quantize_dynamic(model_fp32, model_quant, weight_type=QuantType.QUInt8)\n",
    "        #!rm $model_opt\n",
    "optimize_onnx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "739405a4-ab2a-410f-8091-b6bd9a18e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_manager = OnnxModelManager(os.path.join(saved_model_onnx_path, \"model.onnx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f9e7adb-f258-471a-9139-70da9f2120d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX: In my dreams, I'm a dragoness who dreams. I see the stars, the sky. I see the creatures that live in my dreams.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragon. I can see the purity of dragons. They are noble creatures that live in my dreams. I wish I could be that way with them.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragoness who dreams. I see the stars, and the colors that are there in the sky.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragoness who dreams big.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragoness who dreams. I see the stars, and the dragons. I see the landscape, and the birds singing.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragoness who knows how to take care of the humans in the world. I even tried to get her to take care of the humans in our world. She only took the time to teach me.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragoness who dreams. I see the stars, the sky. I see the creatures that live in my dreams.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragoness who has to be reminded of every moment by my creator.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragoness who dreams. I see the stars, the sky. I see the creatures that live in my dreams.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragoness who values humanity. I can see the world from my window. The blue sky is a good spot to get a tan.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragoness who dreams. I see the stars, the sky. I see the creatures that live in my dreams.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragoness who wears clothes like this.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragoness who dreams. I see the stars, the sky. I see the creatures that live in my dreams.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragoness, a human who values the use of dragons. I don't like {o2}black people.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragoness who dreams. I see the stars, the sky. I see the creatures that live in my dreams.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragoness.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragoness who dreams. I see the stars, the sky. I see the creatures that live in my dreams.\"I was the daughter of one of the most powerful historians in our day, my father. He was the most powerful man in the world. I can only imagine how his work would have been used to advance our cause.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragoness who dreams of humans. My species is perfectly suited for that kind of job, but I'm also a dragoness who wishes to live in a world where there are as many humans as there are dragones.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONNX: In my dreams, I'm a dragoness who dreams. I see the stars, the sky. I see the creatures that live in my dreams.\"<|endoftext|>\n",
      "PyTorch: In my dreams, I'm a dragoness, a dragoness that values life, has to do with humans and the human world. I see dragons in my dreams.\"<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prompt = \"In my dreams, I'm a dragon\"\n",
    "for i in range(10):\n",
    "    print(\"ONNX:\", onnx_model_manager.say_raw(prompt, do_sample=True))\n",
    "    print(\"PyTorch:\", model_manager.say_raw(prompt, 50, 0.7))\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a578b-32cd-44b9-829b-5aef5ec37ab0",
   "metadata": {
    "id": "unxN7nYd2gOM",
    "tags": []
   },
   "source": [
    "# Testing\n",
    "\n",
    "We created a few past (for context) + present prompts (player input) and see the different reactions. This way, we can test the models across different iterations.\n",
    "The first test involves a old prompt to compare the pre-trained model with the one trained on AWSW. Did it manage to store it's data well? Is it able to write down things that have nothing to do with AWSW? (So we know we didn't overfit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d72d4876-df61-461a-b715-980a3763f092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragon. I can shapeshift into humans, or whatever you want to call it.\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f9a94-70c6-4a58-9ad1-3d6ea373dfbe",
   "metadata": {},
   "source": [
    "**This test generates boring and repetetive** replies! It's because we use no good sampling algorithm, but it does give us a indication of what the model has learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b97230c-1d3a-4dd2-a253-727e451d539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Pytorch...\n",
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm fine. I just...\"<p><msg>c \"I don't like words.\"<d><scn>park2<msg>Ry \"I don't like words.\"<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hey!\"<p><msg>c \"How are you?\"<d><sc\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"I think he's a good art critic.\"<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: o2<msg>Ad \"I don't like them very much. I mean, they're just not as attractive as mine, but they're still pretty girthy.\"<p><msg>c \"I don't like them very much.\"<d><scn>o2<msg>Ad \"I don't like them very much. I mean, they're just not as attractive as mine, but\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: o2<msg>Ad \"I don't like words.\"<p><msg>c \"I don't like words.\"<d><scn>o2<msg>Ad \"I don't like words.\"<p><msg>c \"I don't like words.\"<d><scn>o2<msg>Ad \"I don't like words.\"<p><msg>c \"I don't like words.\"<\n",
      "\n",
      "\n",
      "Test ONNX...\n",
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm fine. I just...\"<p><msg>c \"I don't like words.\"<d><scn>park2<msg>Ry \"I don't like words.\"<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hey!\"<p><msg>c \"How are you?\"<d><scn>park2<msg>Ry \"I'm fine. I just...\"<p><msg>c \"I don't like words.\"<d><scn>park2<msg>Ry \"\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"I think he's a good art critic.\"<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: o2<msg>Ad \"I don't like them very much. I mean, they're just not as attractive as mine, but they're still pretty girthy.\"<p><msg>c \"I don't like them very much.\"<d><scn>o2<msg>Ad \"I don't like them very much. I mean, they're just not as attractive as mine, but they still do remind me of some of the old days.\"<p><msg>c \"I don't like them very much. I mean, I don't like them very much.\"<d><scn\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: o2<msg>Ad \"I don't like words.\"<p><msg>c \"I don't like words.\"<d><scn>o2<msg>Ad \"I don't like words.\"<p><msg>c \"I don't like words.\"<d><scn>o2<msg>Ad \"I don't like words.\"<p><msg>c \"I don't like words.\"<d><scn>o2<msg>Ad \"I don't like words.\"<|endoftext|>\n",
      "\n",
      "\n",
      "PyTorch on cuda:0 took 2.9320 seconds\n",
      "ONNX on CPU took 12.7771 seconds\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    ('<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hey!\"', \"How are you?\"),\n",
    "    ('<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"', \"What do you think of Lorem?\"),\n",
    "    ('<p><msg>m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('<p><msg>m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "def sample_test(model_manager):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = model_manager.say(past, prompt)\n",
    "        print(f\"Prompt: {prompt}\\nReply: {reply}\\n\\n\")\n",
    "print(\"Test Pytorch...\")\n",
    "start = time.time()\n",
    "sample_test(model_manager)\n",
    "end = time.time()\n",
    "pytorch_time = end - start\n",
    "print(\"Test ONNX...\")\n",
    "start = time.time()\n",
    "sample_test(onnx_model_manager)\n",
    "end = time.time()\n",
    "onnx_time = end - start\n",
    "print(f\"PyTorch on {device} took {pytorch_time:.4f} seconds\")\n",
    "print(f\"ONNX on CPU took {onnx_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3349bf-c777-4937-a023-ff0f4f21806d",
   "metadata": {},
   "source": [
    "# Sampling test\n",
    "\n",
    "This is gonna be interesting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce4bb65f-e26e-4a62-9c67-aed885fe041d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Pytorch...\n",
      "[Test 1] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm fine. I just...\"<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hey!\"<p><msg>c \"How are you?\"<d><scn>park2<msg>Ry \"I'm fine. I just...\"<p><msg>c \"Hey Remy!\"<d><scn>\n",
      "\n",
      "[Test 1] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"You wouldn't have, but you're doing something right now. Don't take this the wrong way, Reza.\"<d><scn>park2<msg>Ad \"I like that.\"<p><msg>c \"You aren't.\"<d><scn>park2<msg>Ad \"I was with Lorem\n",
      "\n",
      "[Test 1] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: loremapt<msg>Lo \"I was bored.\"<d><scn>loremapt<msg>Lo \"Oh, I forgot about that. Let me try that again.\"<p><msg>c \"I just did.\"<d><scn>loremapt<msg>Lo \"I was bored.\"<p><msg>c \"Oh my god, Adine. What is this\n",
      "\n",
      "[Test 1] -> Prompt: What will we do here?\n",
      "Reply: loremapt<msg>Ip \"If humans are the real answer, then what other theories of humans do we have?\"<p><msg>c \"I don't know.\"<d><scn>loremapt<msg>Ip \"You don't know what you are talking about.\"<p><msg>c \"I don't know what you are talking about.\"<d><scn>loremapt<msg\n",
      "\n",
      "-------------\n",
      "Test ONNX...\n",
      "[Test 1] -> Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm fine. I just...\"<d><scn>park2<msg>Ry \"...\"<d><scn>park2<msg>Ry \"...\"<d><scn>park2<msg>Ry \"I don?t know what to think anymore.\"<d><scn>park2<msg>Ry \"You don't have it easy. Don't you?\"<p><msg>c \"I'm fine with this.\"<d><scn>park2<msg>Ry \"I don? t know what to say to that. Just let\n",
      "\n",
      "[Test 1] -> Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"I think it's better than the rest, at least.\"<p><msg>c \"That sounds gracious, isn't it? And acrobatic.\"<d><scn>park2<msg>Ad \"I guess.\"<p><msg>c \"I'm not a linguist. Are you?\"<d><scn>park2<msg>Ad \"Not really, I don't know. I only know a few things about the language.\"<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>\n",
      "\n",
      "[Test 1] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: o2<msg>Ad \"I don't like them very much - I just got this job, and I have a part-Time job at that post office.\"<p><msg>c \"Oh. That sounds like my kind of job.\"<d><scn>o2<msg>Ad \"I guess.\"<p><msg>c \"Oh, I forgot about that, though. You don't have to bother about it.\"<d><scn>o2<msg>Ad \"You know what, I can't help being a bit of all-out about you.\"<p><msg>\n",
      "\n",
      "[Test 1] -> Prompt: What will we do here?\n",
      "Reply: o2<msg>Ad \"What will we do?\"<p><msg>c \"I dont like words.\"<d><scn>o2<msg>Ad \"I dont like things that much.\"<p><msg>c \"I can't help but like a friend.\"<d><scn>o2<msg>Ad \"What will we do here and back for you, [player_name]?\"<p><msg>c \"Nothing much. I just got this job a couple months back and didn't want anyone else to do the position. I just thought\n",
      "\n",
      "-------------\n",
      "PyTorch on cuda:0 took 3.2305 seconds\n",
      "ONNX on CPU took 15.3548 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Pytorch...\")\n",
    "start = time.time()\n",
    "for i in range(1):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = model_manager.say(past, prompt, top_k = 50, top_p = 0.7)\n",
    "        print(f\"[Test {i + 1}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-------------\")\n",
    "end = time.time()\n",
    "pytorch_time = end - start\n",
    "print(\"Test ONNX...\")\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "start = time.time()\n",
    "for i in range(1):\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = onnx_model_manager.say(past, prompt, do_sample = True)\n",
    "        print(f\"[Test {i + 1}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-------------\")\n",
    "end = time.time()\n",
    "onnx_time = end - start\n",
    "print(f\"PyTorch on {device} took {pytorch_time:.4f} seconds\")\n",
    "print(f\"ONNX on CPU took {onnx_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c956842-43ba-4f9a-937a-13fda9ad1439",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RP test\n",
    "Testing out the injected roleplay actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85435494-6b29-4b18-aa34-328e33caa9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visit Lorem -> loremapt<msg>Lo \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "Meet with Lorem -> loremapt<msg>Lo \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "Visit Adine -> adineapt<msg>Ad \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "Fight Maverick -> black<msg>m \"A few minutes later, we arrived at the outskirts of town. My first instinct was to run away, but as I did so, I heard voices.\"<|endoftext|>\n",
      "Fight Adine -> adineapt<msg>Ad \"Oh, come on. Let me do that for you.\"<|endoftext|>\n",
      "Attack Adine -> adineapt<msg>Ad \"What's that?\"<p><msg>c \"A few.\"<d><scn>adineapt<msg>Ad \"Oh, [player_name], I didn't expect you to arrive so early.\"<p><msg>c \"A few.\"<d><scn>adineapt<msg>Ad \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "test_rps = [\n",
    "    \"Visit Lorem\",\n",
    "    \"Meet with Lorem\",\n",
    "    \"Visit Adine\",\n",
    "    \"Fight Maverick\",\n",
    "    \"Fight Adine\",\n",
    "    \"Attack Adine\"\n",
    "]\n",
    "for rp in test_rps:\n",
    "    print(f'{rp} -> {model_manager.say(\"\", rp, top_k = 50, top_p = 0.7)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c25c34-550a-407b-9378-69adbadc5adc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
