{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebe416a-cacf-405b-b330-e99dc31880f9",
   "metadata": {},
   "source": [
    "# Weight mixing\n",
    "\n",
    "This is a new kind of method to \"train\" models super fast without having to retrain the entire model again.\n",
    "\n",
    "This method, introduced with the development of this mod, requires an overfitted model of your own dataset (in our case, `GPT-Neo-125M` combined with the AWSW data we extracted in step 1) + the pretrained model (`GPT-Neo-125M`).\n",
    "\n",
    "Weight mixing essentialy involves 3 different steps, and can easily be done on CPU in mere seconds, if you manage to get the pretrained weights in advance:\n",
    "\n",
    " 1. Generate samples from the base model (the model that came pretrained).\n",
    " \n",
    " 2. Add a small amount of gaussian noise to a variable `s`.\n",
    " \n",
    " 3. Do a linear interpolation between the base model and the main model (our own model) using `s` as a mask.\n",
    " \n",
    " 4. Repeat generating samples on this interpolated model\n",
    " \n",
    "     - Are the samples equal? Repeat from step 2.\n",
    "     - Is even 1 sample different? Quit and move to step 5 (adding more noise to `s`).\n",
    "   \n",
    " 5. Now we have the portion that we know we can adjust without the model giving considerably different results. This is what we call the cold zone.\n",
    " \n",
    "     - Using this new mask, we will linear interpolate between the base model and the main model given a user-specified `amount` and `cold_zone_diffusion_steps`.\n",
    "     \n",
    "     - `cold_zone_diffusion_steps` will \"spread\" noise slightly outside the cold zone by blurring, only affecting places that aren't used yet (i.e all the parts that are 0, the rest remains unchanged). The higher the value, the bigger area it will affect.\n",
    "     \n",
    "     - `amount` regulates the amount it'll transition between the main and base model.\n",
    "    \n",
    "**Note!** `cold_zone_diffusion_steps` can be skipped when not calling calculate_cold_zones, in this case we just do a simple linear interpolation between the 2 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921ec9f4-2e97-4002-8d4a-bf8a36ef888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from model_manager import ModelManager\n",
    "from model_mixing import ModelMixing\n",
    "from model_utils import get_model\n",
    "from config import Config\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1561d726-ba19-40d4-8886-cafa95aeb925",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = os.path.join(\"models\", \"awsw_main\")\n",
    "mixed_model_path = os.path.join(\"models\", \"awsw_mixed\")\n",
    "os.makedirs(mixed_model_path, exist_ok=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "main_model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "base_model, _ = get_model(\"EleutherAI/gpt-neo-125M\")\n",
    "target_model, _ = get_model(\"EleutherAI/gpt-neo-125M\")\n",
    "device = torch.device('cpu')\n",
    "target_model.eval()\n",
    "model_manager = ModelManager(model=target_model, tokenizer=tokenizer, device=device)\n",
    "model_manager_main = ModelManager(model=main_model, tokenizer=tokenizer, device=device)\n",
    "print(f\"Loaded base and main model to CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa61fd22-d4ec-493f-9c33-b52e11553494",
   "metadata": {},
   "source": [
    "# Initial test\n",
    "This will mostly be gibberish. This is intentional, as the target model only contains the pre-trained GPT-Neo weights!target_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374b092e-bdcb-4fa6-bb0e-0863a2cd2869",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    ('<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hello, [player_name].\"', \"How are you?\"),\n",
    "    ('<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"', \"What do you think of Lorem?\"),\n",
    "    ('<p><msg>m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('<p><msg>m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]    \n",
    "test_rps = [\n",
    "    \"Visit Lorem\",\n",
    "    \"Meet with Lorem\",\n",
    "    \"Visit Adine\",\n",
    "    \"Fight Maverick\",\n",
    "    \"Fight Adine\",\n",
    "    \"Attack Adine\"\n",
    "]\n",
    "\n",
    "def prompt_test(model_manager, do_sample_test = True):\n",
    "    for (past, prompt) in prompts:\n",
    "        print(f\"Prompt: {prompt}\")\n",
    "        reply = model_manager.say(past, prompt)\n",
    "        print(f\"Reply: {reply}\")\n",
    "        if do_sample_test:\n",
    "            reply = model_manager.say(past, prompt, top_k = 50, top_p = 0.7)\n",
    "            print(f\"Reply [sampled]: {reply}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "def rp_test(model_manager):\n",
    "    for rp in test_rps:\n",
    "        print(f'{rp} -> {model_manager.say(\"\", rp, top_k = 50, top_p = 0.7)}')\n",
    "        print(\"-\" * 10)\n",
    "    print(\"Lower case test\")\n",
    "    for rp in test_rps:\n",
    "        rp = rp[0].lower() + rp[1:]\n",
    "        print(f'{rp} -> {model_manager.say(\"\", rp)}')\n",
    "        rp = rp.lower()\n",
    "        print(f'{rp} -> {model_manager.say(\"\", rp)}')\n",
    "        print(\"-\" * 10)\n",
    "        \n",
    "prompt_test(model_manager_main, do_sample_test = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b4f12-8010-449e-9e38-ad4e76f04d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cold_zone_loss_responses(model_manager):\n",
    "    for (past, prompt) in prompts:\n",
    "        yield model_manager.say(past, prompt)\n",
    "    for rp in test_rps:\n",
    "        yield model_manager.say(\"\", rp)\n",
    "        rp = rp[0].lower() + rp[1:]\n",
    "        yield model_manager.say(\"\", rp)\n",
    "        rp = rp.lower()\n",
    "        yield model_manager.say(\"\", rp)\n",
    "\n",
    "original_target_model_responses = list(generate_cold_zone_loss_responses(model_manager_main))\n",
    "def cold_zone_loss() -> bool:\n",
    "    new_responses = generate_cold_zone_loss_responses(model_manager)\n",
    "    for r1, r2 in zip(original_target_model_responses, new_responses):\n",
    "        if not r1 == r2:\n",
    "            print(f\"Not correct:\\nOriginal: {r1}\\nv.s\\nNew: {r2}\\n{'-' * 10}\")\n",
    "            return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002824b2-28d2-4df5-b73c-a9116273fbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mixing = ModelMixing(tokenizer, base_model, main_model, target_model, seed = 45, cold_zone_loss = cold_zone_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7fdf84-8bc4-4df4-b5f0-8b247c1d3869",
   "metadata": {},
   "source": [
    "# Testing cold zone diffusion\n",
    "\n",
    "Cold zone diffusion is mission-critical in determining where to mix models. It's gotta work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d1bf4-6ccb-48ce-b6f3-b92e69d4935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cold_zone = np.random.rand(128, 128)\n",
    "test_cold_zone = torch.Tensor(test_cold_zone)\n",
    "diffused_cold_zone = model_mixing.diffuse_cold_zone(test_cold_zone, upper_bound = 0.5, diffusion = 0.1)\n",
    "fig, axs = plt.subplots(figsize=(13, 6), ncols=3)\n",
    "fig.suptitle('[Testing] Normal and diffused cold zone')\n",
    "pos = axs[0].imshow(test_cold_zone, cmap='Blues', interpolation='nearest', vmin=0, vmax=1)\n",
    "fig.colorbar(pos, ax=axs[0])\n",
    "pos = axs[1].imshow(diffused_cold_zone, cmap='Blues', interpolation='nearest', vmin=0, vmax=1)\n",
    "fig.colorbar(pos, ax=axs[1])\n",
    "pos = axs[2].imshow(abs(diffused_cold_zone - test_cold_zone), cmap='hot', interpolation='nearest', vmin=0, vmax=1)\n",
    "fig.colorbar(pos, ax=axs[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc45a25b-6db2-4097-8758-311c42a507f5",
   "metadata": {},
   "source": [
    "# Calculating the cold zones\n",
    "\n",
    "Cold zones are the area of the main model that are *safe to adjust* i.e they won't change the answers of the model drastically. Later it's our task to use this cold zone and expand slowly until we get a desired results, coming from both models.\n",
    "\n",
    "The process requires inference on both models, but no training. It's as slow as the models themselves, but is still feasible on CPU, and we only require samples, ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38858ee-24cd-4974-b070-5559732214c3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cold_zones_path = os.path.join(mixed_model_path, 'cold_zones.npz')\n",
    "if os.path.exists(cold_zones_path):\n",
    "    loaded_stuff = np.load(cold_zones_path)\n",
    "    model_mixing.cold_zones = [\n",
    "        torch.Tensor(loaded_stuff[key]) for key in loaded_stuff\n",
    "    ]\n",
    "    del loaded_stuff\n",
    "else:\n",
    "    model_mixing.calculate_cold_zones()\n",
    "    to_save = []\n",
    "    for i, c in enumerate(model_mixing.cold_zones):\n",
    "        to_save.append(c.numpy())\n",
    "    np.savez(cold_zones_path, *to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bdf8e9-0323-46d3-86d4-9619fa8518f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cold_zone = model_mixing.cold_zones[5]\n",
    "diffused_cold_zone = model_mixing.diffuse_cold_zone(test_cold_zone, diffusion = 0.5, upper_bound = 0.2)\n",
    "fig, axs = plt.subplots(figsize=(13, 6), ncols=3)\n",
    "fig.suptitle('Normal and diffused cold zone')\n",
    "pos = axs[0].imshow(test_cold_zone, cmap='Blues', interpolation='nearest', vmin=0, vmax=1)\n",
    "fig.colorbar(pos, ax=axs[0])\n",
    "pos = axs[1].imshow(diffused_cold_zone, cmap='Blues', interpolation='nearest', vmin=0, vmax=1)\n",
    "fig.colorbar(pos, ax=axs[1])\n",
    "pos = axs[2].imshow(abs(diffused_cold_zone - test_cold_zone), cmap='hot', interpolation='nearest', vmin=0, vmax=1)\n",
    "fig.colorbar(pos, ax=axs[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059a861b-53af-4349-982e-3ad11a39f9b9",
   "metadata": {},
   "source": [
    "# Let the mixing begin!\n",
    "The mixing process is the fastest of this whole notebok, and should take just a few seconds on a slow CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8b8856-a493-48aa-92a5-eb242ef4740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mixing.mix(1, cold_zone_diffusion = 0.2, upper_bound = 0.2, normalize_cold_zone = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26f025c-fdf7-448b-862d-f4415ef4e11d",
   "metadata": {},
   "source": [
    "# Testing the mixed model\n",
    "\n",
    "This model seems to perform as good and in most cases better than a finetuned model in our tests, let's see what it does now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06503fd5-96f3-4be4-b7a4-70b620163833",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_test(model_manager_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab64907d-aa1c-4959-8225-aae4e58116c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_test(model_manager_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfaa569-ec65-4470-9004-cc4ce0df0fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model.save_pretrained(mixed_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df667c1d-9f55-4454-ada6-b83bf97df226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
