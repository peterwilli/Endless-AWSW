{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da2dbfd-5b54-424f-8643-6482bd916f0c",
   "metadata": {},
   "source": [
    "# Overfitting\n",
    "\n",
    "... Normally? A bad thing! But for our case it's good...\n",
    "\n",
    "We use a new method to mix an overfitted model (our own) with a pretrained model (GPT-Neo-125M) and have them share eachothers traits. This way it's possible to finetune a model without having to retrain it. It's so fast it can be done in a second on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b97b376-9ac5-4c70-ba13-769649099a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_utils import train_model, split_data, split_branches, get_model, set_pretrained_model_dropout, get_dataset, ModelSeeder\n",
    "from config import Config\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import onnx\n",
    "import logging\n",
    "from onnx_model_manager import OnnxModelManager\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "import os\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from model_manager import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887d9f81-96c3-408f-bd1c-7b126becc4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use cuda:0 for training with seed: 970988852\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randint(0, 2 ** 32 - 1)\n",
    "seed = 970988852\n",
    "random.seed(seed)\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(f\"Will use {device_name} for training with seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e95113e-dfc1-40a9-a39b-5d56f3bf32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(os.path.join(Config.work_dir, \"awsw_story_input.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb65c62-47c6-4d36-bd1e-2adfef8ff1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'lr': 0.001,\n",
    "    \"warmup_factor\": 5,\n",
    "    'scheduler': 'cosine_schedule_with_warmup',\n",
    "    \"lr_end\": 2e-6,\n",
    "    \"power\": 0.6,\n",
    "    \"freeze_from_steps\": -1,\n",
    "    'to_freeze_count': 0,\n",
    "    \"seed\": seed,\n",
    "    \"num_epoch\": 700\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ffae5b-e197-4417-a4cd-e6befc6ee393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded empty model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_path = os.path.join(\"models\", \"awsw_main\")\n",
    "if os.path.exists(os.path.join(saved_model_path, \"pytorch_model.bin\")):\n",
    "    tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "    model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "    print(\"Pretrained model loaded\")\n",
    "else:\n",
    "    model, tokenizer = get_model(\"EleutherAI/gpt-neo-125M\")\n",
    "    print(\"Loaded empty model\")\n",
    "model.to(device)\n",
    "# set_pretrained_model_dropout(model.transformer.h, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f3315-8f5d-4101-8e7e-2c0129204c94",
   "metadata": {},
   "source": [
    "# Test before training on a pretrained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f68c3f1-4c0a-41a2-a3fc-b8b3c36e418c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragon, and I have to fight. I'm the one who is always trying to get to the bottom of my story. But I have a lot of experience with dragons and dragons in the real world. The dragon story has been told in the past couple of years, but it's not my experience.\n",
      "\n",
      "In my dream, I'm a dragon. I have to fight. I have to try to get to the bottom of my story. I have to try to get to the bottom of my story. But I have a lot of experience with dragons and dragons in the real world.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model_manager = ModelManager(model=model, tokenizer=tokenizer, device=device)\n",
    "def test_regular_sampler():\n",
    "    print(model_manager.say_raw(\"In my dreams, I'm a dragon\", 50, 0.7))\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f74aa-5030-4ffd-ad2f-ae013647975e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reviewing our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0974ac13-c420-4275-b34a-3816f580cb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db93f7ca18a94d89acb9f599edc24da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset demo snapshot:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2118 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p><msg>c \"That should work. See, you've already got that part down.\"<d><scn>beach<msg>Ad \"Guess so.\"<|endoftext|><p><msg>c \"Something serious happened. Looks like I have to leave.\"<d><scn>np2x<msg>Ad \"Right now? Why?\"<|endoftext|><p><msg>c \"Alright, what about this?\"<d><scn>loremapt<msg>Lo \"Works for me.\"<p><msg>c \"Alright.\"<p><msg>c \"(What kind of pose\n",
      "RP review!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msg>Lo \"Actually, Ipsum is deeply in love with his home laboratory.\"<|endoftext|><p><msg>c \"Of course.\"<d><scn>park2<msg>Ry \"Do you even like me? There must be a reason why you've put up with me for this long.\"<|endoftext|><p><msg>c \"It looked pretty impressive until the landing.\"<d><scn>beach<msg>Ad \"Ouch, my wing hurts.\"<p><msg>c \"Fight Adine\"<d><scn>beach<msg>m \"Adine dodges my\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(tokenizer, path_train = os.path.join(Config.work_dir, \"data_train.txt\"))\n",
    "print(\"Dataset demo snapshot:\")\n",
    "for item in dataset['train']:\n",
    "    print(tokenizer.decode(item['input_ids']))\n",
    "    break\n",
    "\n",
    "print(\"RP review!\")\n",
    "to_see_rp = [\n",
    "    'c \"Fight ',\n",
    "    'c \"What do you think of Lorem?'\n",
    "]\n",
    "for item in dataset['train']:\n",
    "    decoded = tokenizer.decode(item['input_ids'])\n",
    "    for rp in list(to_see_rp):\n",
    "        if rp in decoded: \n",
    "            print(decoded)\n",
    "            print(\"-\" * 10)\n",
    "            to_see_rp.remove(rp)\n",
    "            continue\n",
    "    if len(to_see_rp) == 0:\n",
    "        break\n",
    "# Clean up\n",
    "del to_see_rp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e9e10-b2eb-421a-9948-dc3590e1f46d",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Model is put in training mode and we begin training. The `train_results` will contain all data after training is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41750b03-f114-46c4-948e-637db79efe15",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37800' max='37800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37800/37800 5:10:36, Epoch 698/700]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>378</td>\n",
       "      <td>2.198100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>756</td>\n",
       "      <td>1.642800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1134</td>\n",
       "      <td>1.466300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1512</td>\n",
       "      <td>1.326700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>1.209200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2268</td>\n",
       "      <td>1.114700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2646</td>\n",
       "      <td>1.040500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3024</td>\n",
       "      <td>0.970100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3402</td>\n",
       "      <td>0.907200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3780</td>\n",
       "      <td>0.854000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4158</td>\n",
       "      <td>0.815100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4536</td>\n",
       "      <td>0.771400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4914</td>\n",
       "      <td>0.738400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5292</td>\n",
       "      <td>0.703300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5670</td>\n",
       "      <td>0.678600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6048</td>\n",
       "      <td>0.655400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6426</td>\n",
       "      <td>0.627800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6804</td>\n",
       "      <td>0.610400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7182</td>\n",
       "      <td>0.588600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7560</td>\n",
       "      <td>0.573900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7938</td>\n",
       "      <td>0.555400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8316</td>\n",
       "      <td>0.547300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8694</td>\n",
       "      <td>0.525100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9072</td>\n",
       "      <td>0.508100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9450</td>\n",
       "      <td>0.500800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9828</td>\n",
       "      <td>0.493800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10206</td>\n",
       "      <td>0.477800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10584</td>\n",
       "      <td>0.469100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10962</td>\n",
       "      <td>0.457900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11340</td>\n",
       "      <td>0.447100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11718</td>\n",
       "      <td>0.441200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12096</td>\n",
       "      <td>0.435700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12474</td>\n",
       "      <td>0.428700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12852</td>\n",
       "      <td>0.420100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13230</td>\n",
       "      <td>0.414400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13608</td>\n",
       "      <td>0.406400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13986</td>\n",
       "      <td>0.397100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14364</td>\n",
       "      <td>0.397200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14742</td>\n",
       "      <td>0.391200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15120</td>\n",
       "      <td>0.382000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15498</td>\n",
       "      <td>0.382200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15876</td>\n",
       "      <td>0.373200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16254</td>\n",
       "      <td>0.367100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16632</td>\n",
       "      <td>0.362800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17010</td>\n",
       "      <td>0.357800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17388</td>\n",
       "      <td>0.353000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17766</td>\n",
       "      <td>0.351800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18144</td>\n",
       "      <td>0.345300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18522</td>\n",
       "      <td>0.342200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18900</td>\n",
       "      <td>0.343300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19278</td>\n",
       "      <td>0.335600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19656</td>\n",
       "      <td>0.339100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20034</td>\n",
       "      <td>0.335300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20412</td>\n",
       "      <td>0.332700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20790</td>\n",
       "      <td>0.327500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21168</td>\n",
       "      <td>0.326800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21546</td>\n",
       "      <td>0.327900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21924</td>\n",
       "      <td>0.321200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22302</td>\n",
       "      <td>0.320100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22680</td>\n",
       "      <td>0.319000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23058</td>\n",
       "      <td>0.317000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23436</td>\n",
       "      <td>0.315400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23814</td>\n",
       "      <td>0.312000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24192</td>\n",
       "      <td>0.312600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24570</td>\n",
       "      <td>0.308300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24948</td>\n",
       "      <td>0.305700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25326</td>\n",
       "      <td>0.304800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25704</td>\n",
       "      <td>0.310100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26082</td>\n",
       "      <td>0.305000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26460</td>\n",
       "      <td>0.302900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26838</td>\n",
       "      <td>0.299800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27216</td>\n",
       "      <td>0.299600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27594</td>\n",
       "      <td>0.294600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27972</td>\n",
       "      <td>0.296400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28350</td>\n",
       "      <td>0.294300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28728</td>\n",
       "      <td>0.292100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29106</td>\n",
       "      <td>0.291200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29484</td>\n",
       "      <td>0.291300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29862</td>\n",
       "      <td>0.286300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30240</td>\n",
       "      <td>0.287000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30618</td>\n",
       "      <td>0.285500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30996</td>\n",
       "      <td>0.286900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31374</td>\n",
       "      <td>0.286100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31752</td>\n",
       "      <td>0.285400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32130</td>\n",
       "      <td>0.282000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32508</td>\n",
       "      <td>0.286100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32886</td>\n",
       "      <td>0.283600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33264</td>\n",
       "      <td>0.283300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33642</td>\n",
       "      <td>0.281900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34020</td>\n",
       "      <td>0.283500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34398</td>\n",
       "      <td>0.283200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34776</td>\n",
       "      <td>0.282000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35154</td>\n",
       "      <td>0.280700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35532</td>\n",
       "      <td>0.283100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35910</td>\n",
       "      <td>0.284200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36288</td>\n",
       "      <td>0.281300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36666</td>\n",
       "      <td>0.279900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37044</td>\n",
       "      <td>0.281100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37422</td>\n",
       "      <td>0.283100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37800</td>\n",
       "      <td>0.278500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results = {}\n",
    "model.train()\n",
    "train_model(model, tokenizer, dataset, config, train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c410a601-c5e4-4cc1-af2b-44a7378f3bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f43806b04f0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "fig.suptitle('Learning rate and loss')\n",
    "axs[0].plot(train_results['learning_rate_history'])\n",
    "axs[1].plot(train_results['loss_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "753228f0-b420-4b3d-bd69-53da7a87bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.save_pretrained(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30070cdb-23d0-4755-a517-2198a0454794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visit Lorem -> loremapt<msg>Lo \"Hey [player_name]! How are you?\"<|endoftext|>\n",
      "----------\n",
      "Meet with Lorem -> loremapt<msg>Lo \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "----------\n",
      "Visit Adine -> adineapt<msg>Ad \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "----------\n",
      "Fight Maverick -> black<msg>m \"I wasn't sure if he minded the question, or how I would const invests my time with Google.\"<|endoftext|>\n",
      "----------\n",
      "Fight Adine -> beach<msg>m \"I didn't hesitate and kicked Adine right in the stomach\"<|endoftext|>\n",
      "----------\n",
      "Attack Adine -> beach<msg>m \"She went for theasures, her arm extended. When she was down, I heard her voice cry. A magic chuckle psychosis.\"<|endoftext|>\n",
      "----------\n",
      "Lowercase test\n",
      "visit Lorem -> loremapt<msg>Lo \"Hey [player_name]! How are you?\"<|endoftext|>\n",
      "visit lorem -> loremapt<msg>Lo \"Hey [player_name]! How are you?\"<|endoftext|>\n",
      "----------\n",
      "meet with Lorem -> loremapt<msg>Lo \"Oh, [player_name], I wasn't expecting visitors.\"<|endoftext|>\n",
      "meet with lorem -> loremapt<msg>Lo \"Oh, [player_name], I wasn't expecting visitors.\"<|endoftext|>\n",
      "----------\n",
      "visit Adine -> park2<msg>Ka \"Hey [player_name]! How are you?\"<|endoftext|>\n",
      "visit adine -> adineapt<msg>Ad \"Oh, [player_name], I didn't expect you to arrive so early.\"<|endoftext|>\n",
      "----------\n",
      "fight Maverick -> np1x<msg>Mv \"Hey [player_name]!\"<|endoftext|>\n",
      "fight maverick -> park3<msg>Mv \"Hey [player_name]!\"<|endoftext|>\n",
      "----------\n",
      "fight Adine -> beach<msg>m \"She walked up to me with my hands cu [& as Iasonable I said: \"Why?\"<d><scn>beach<msg>Ad \"That's right. Just let me through.\"<|endoftext|>\n",
      "fight adine -> beach<msg>m \"I didn't hesitate and kicked Adine right in the stomach\"<|endoftext|>\n",
      "----------\n",
      "attack Adine -> beach<msg>m \"She went over to her far side and tried to grab her offensively.kward look beddsondrive?<p><msg>c \"I wouldn't mind seeing if I could court that possibility.\"<d><scn>beach<msg>Ad \"What would you like to know?\"<p><msg>c \"What do you think of Emera?\"<d><scn>beach<msg>Ad \"She is a bit interesting.\"<|endoftext|>\n",
      "attack adine -> beach<msg>m \"She went down the water every time I heard her.\"<|endoftext|>\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "test_rps = [\n",
    "    \"Visit Lorem\",\n",
    "    \"Meet with Lorem\",\n",
    "    \"Visit Adine\",\n",
    "    \"Fight Maverick\",\n",
    "    \"Fight Adine\",\n",
    "    \"Attack Adine\"\n",
    "]\n",
    "\n",
    "for rp in test_rps:\n",
    "    print(f'{rp} -> {model_manager.say(\"\", rp)}')\n",
    "    print(\"-\" * 10)\n",
    "    \n",
    "print(\"Lowercase test\")\n",
    "\n",
    "for rp in test_rps:\n",
    "    rp = rp[0].lower() + rp[1:]\n",
    "    print(f'{rp} -> {model_manager.say(\"\", rp)}')\n",
    "    rp = rp.lower()\n",
    "    print(f'{rp} -> {model_manager.say(\"\", rp)}')\n",
    "    print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5946f900-c221-48a9-8436-c0051890bcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"My name isiaturesuyonse [player_name]. If you like, I could help you up to date your words.\"<|endoftext|>\n",
      "Reply [sampled]: park2<msg>Ry \"My name isiaturesuyonseaii.\"<p><msg>c \"hey reza! over here!\"<d><scn>park2<msg>Rz \"Hey [player_name]!\"<|endoftext|>\n",
      "----------\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ry \"I think he's funny.\"<|endoftext|>\n",
      "Reply [sampled]: park2<msg>Ry \"I think he's good looking.\"<|endoftext|>\n",
      "----------\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: black<msg>Ad \"It's someplace, yes.\"<|endoftext|>\n",
      "Reply [sampled]: black<msg>Ad \"It's someplace, but she doesn't want to stay up. She goes now, and I won't have to ask you to stay with her as long.\"<d><scn>black<msg>Br \"I did?\"<p><msg>c \"Go to Katsuharu\"<d><scn>park1<msg>Ka \"Oh, [player_\n",
      "----------\n",
      "Prompt: What will we do here?\n",
      "Reply: alley<msg>An \"What's that?\"<|endoftext|>\n",
      "Reply [sampled]: alley<msg>An \"You decide where you're going, and how were you andreenshot an entire building?\"<d><scn>alley<msg>An \"If I get hit, you'll have to take a seat character if you're outside. If I don't find a bit of space by now, I'll have to go in. can still be worked on.\"<|endoftext|>\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    ('<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hello, [player_name].\"', \"How are you?\"),\n",
    "    ('<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"', \"What do you think of Lorem?\"),\n",
    "    ('<p><msg>m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('<p><msg>m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "def prompt_test(model_manager, do_sample_test = True):\n",
    "    for (past, prompt) in prompts:\n",
    "        print(f\"Prompt: {prompt}\")\n",
    "        reply = model_manager.say(past, prompt)\n",
    "        print(f\"Reply: {reply}\")\n",
    "        if do_sample_test:\n",
    "            reply = model_manager.say(past, prompt, top_k = 50, top_p = 0.7)\n",
    "            print(f\"Reply [sampled]: {reply}\")\n",
    "        print(\"-\" * 10)\n",
    "        \n",
    "prompt_test(model_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70744f31-8d0c-4bf1-837c-58a0b52b1c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
