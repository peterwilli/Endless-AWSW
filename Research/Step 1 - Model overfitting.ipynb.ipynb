{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da2dbfd-5b54-424f-8643-6482bd916f0c",
   "metadata": {},
   "source": [
    "# Overfitting\n",
    "\n",
    "... Normally? A bad thing! But for our case it's good...\n",
    "\n",
    "We use a new method to mix an overfitted model (our own) with a pretrained model (GPT-Neo-125M) and have them share eachothers traits. This way it's possible to finetune a model without having to retrain it. It's so fast it can be done in a second on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b97b376-9ac5-4c70-ba13-769649099a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_utils import train_model, split_data, split_branches, get_model, set_pretrained_model_dropout, get_dataset, ModelSeeder\n",
    "from config import Config\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import onnx\n",
    "import logging\n",
    "from onnx_model_manager import OnnxModelManager\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "import os\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from model_manager import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887d9f81-96c3-408f-bd1c-7b126becc4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use cuda:0 for training with seed: 970988852\n"
     ]
    }
   ],
   "source": [
    "# seed = random.randint(0, 2 ** 32 - 1)\n",
    "seed = 970988852\n",
    "random.seed(seed)\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(f\"Will use {device_name} for training with seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e95113e-dfc1-40a9-a39b-5d56f3bf32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(os.path.join(Config.work_dir, \"awsw_story_input.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb65c62-47c6-4d36-bd1e-2adfef8ff1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'lr': 0.001,\n",
    "    \"warmup_factor\": 5,\n",
    "    'scheduler': 'cosine_schedule_with_warmup',\n",
    "    \"lr_end\": 2e-6,\n",
    "    \"power\": 0.6,\n",
    "    \"freeze_from_steps\": -1,\n",
    "    'to_freeze_count': 0,\n",
    "    \"seed\": seed,\n",
    "    \"num_epoch\": 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ffae5b-e197-4417-a4cd-e6befc6ee393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded empty model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_path = os.path.join(\"models\", \"awsw_main\")\n",
    "if os.path.exists(os.path.join(saved_model_path, \"pytorch_model.bin\")):\n",
    "    tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "    model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "    print(\"Pretrained model loaded\")\n",
    "else:\n",
    "    model, tokenizer = get_model(\"EleutherAI/gpt-neo-125M\")\n",
    "    print(\"Loaded empty model\")\n",
    "model.to(device)\n",
    "# set_pretrained_model_dropout(model.transformer.h[-1:], 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f3315-8f5d-4101-8e7e-2c0129204c94",
   "metadata": {},
   "source": [
    "# Test before training on a pretrained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f68c3f1-4c0a-41a2-a3fc-b8b3c36e418c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my dreams, I'm a dragonflyer, a dragonfly in a dream. It's a thing I'd like to see happen, but I can't seem to find it. I'm not sure if I'm being sarcastic, but I'm not sure I'm being cynical.\n",
      "\n",
      "I'm thinking about a dragonfly. I know it's a dream, but I don't really understand how to do that. The only thing I can think of is how to get the dragonfly back to me, or to be able to get it back, and then I'm trying to think of how to get the dragonfly back\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model_manager = ModelManager(model=model, tokenizer=tokenizer, device=device)\n",
    "def test_regular_sampler():\n",
    "    print(model_manager.say_raw(\"In my dreams, I'm a dragon\", 50, 0.7))\n",
    "test_regular_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f74aa-5030-4ffd-ad2f-ae013647975e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reviewing our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0974ac13-c420-4275-b34a-3816f580cb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f229c5bbba4840b8d7b104ad1e2007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset demo snapshot:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p><msg>c \"Stone skipping.\"<d><scn>beach<msg>Ad \"Right. Since you taught me the stone skipping, I can show you how to fish.\"<|endoftext|><p><msg>c \"I can't really promise anything right now, but I'll keep it in mind.\"<d><scn>o2<msg>Br \"Well, you've got my number, so let me know as soon as you can.\"<|endoftext|><p><msg>c \"Visit Maverick\"<d><scn>park1<msg>Mv \"Hey [player_name\n",
      "RP review!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_name]!\"<|endoftext|><p><msg>c \"Fight Remy\"<d><scn>park2<msg>m \"I didn't hesitate and kicked Remy right in the stomach\"<|endoftext|><p><msg>c \"hello maverick\"<d><scn>park2<msg>Mv \"[player_name]? What are you doing here?\"<|endoftext|><p><msg>c \"What about those who enjoy that kind of work?\"<d><scn>emeraroom<msg>Em \"Sure, but I'm not talking about them. I'm talking about those like myself\n",
      " who are just not cut out for that kind of job.\"<d><scn>emeraroom<msg>Em \"Being in charge of your visit in this world, however, has been quite an opportunity.\"<|endoftext|><p><msg>c \"meet with emera\"<d><scn>emeraroom<msg>Em \"Oh, [player_name], I wasn't expecting visitors.\"<|endoftext|><p><msg>c \"hey zhong! over here!\"<d><scn>emeraroom<msg>Zh \"Hey [player_name]!\"<|endoftext|><p><msg>\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(tokenizer, path_train = os.path.join(Config.work_dir, \"data_train.txt\"))\n",
    "print(\"Dataset demo snapshot:\")\n",
    "for item in dataset['train']:\n",
    "    print(tokenizer.decode(item['input_ids']))\n",
    "    break\n",
    "\n",
    "print(\"RP review!\")\n",
    "has_seen_rp = False\n",
    "for item in dataset['train']:\n",
    "    decoded = tokenizer.decode(item['input_ids'])\n",
    "    if 'c \"Fight ' in decoded: \n",
    "        print(decoded)\n",
    "        has_seen_rp = True\n",
    "        continue        \n",
    "    if has_seen_rp:\n",
    "        print(decoded)\n",
    "        break\n",
    "# Clean up\n",
    "del has_seen_rp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e9e10-b2eb-421a-9948-dc3590e1f46d",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Model is put in training mode and we begin training. The `train_results` will contain all data after training is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41750b03-f114-46c4-948e-637db79efe15",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] set freeze_part_layers: True (freezing 0 out of 160 layers.)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6200' max='6200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6200/6200 47:06, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>2.213700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>1.349500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>1.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>0.822400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.698900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>372</td>\n",
       "      <td>0.599600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>434</td>\n",
       "      <td>0.532600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>0.456800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>558</td>\n",
       "      <td>0.402400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.360900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>682</td>\n",
       "      <td>0.308200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>744</td>\n",
       "      <td>0.279300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>806</td>\n",
       "      <td>0.256900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>868</td>\n",
       "      <td>0.237700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.228500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>992</td>\n",
       "      <td>0.223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1054</td>\n",
       "      <td>0.214100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1116</td>\n",
       "      <td>0.208000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1178</td>\n",
       "      <td>0.203200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.203600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1302</td>\n",
       "      <td>0.201100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1364</td>\n",
       "      <td>0.200800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1426</td>\n",
       "      <td>0.196800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1488</td>\n",
       "      <td>0.194800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.194400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1612</td>\n",
       "      <td>0.195900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1674</td>\n",
       "      <td>0.194600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1736</td>\n",
       "      <td>0.190100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1798</td>\n",
       "      <td>0.191800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.186700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1922</td>\n",
       "      <td>0.183400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1984</td>\n",
       "      <td>0.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2046</td>\n",
       "      <td>0.516300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2108</td>\n",
       "      <td>0.184200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2170</td>\n",
       "      <td>0.179700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2232</td>\n",
       "      <td>0.177000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2294</td>\n",
       "      <td>0.176500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2356</td>\n",
       "      <td>0.173200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2418</td>\n",
       "      <td>0.171500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2480</td>\n",
       "      <td>0.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2542</td>\n",
       "      <td>0.168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2604</td>\n",
       "      <td>0.165900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2666</td>\n",
       "      <td>0.166200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2728</td>\n",
       "      <td>0.164800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2790</td>\n",
       "      <td>0.164300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2852</td>\n",
       "      <td>0.162100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2914</td>\n",
       "      <td>0.161400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2976</td>\n",
       "      <td>0.161000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3038</td>\n",
       "      <td>0.158600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3162</td>\n",
       "      <td>0.159700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3224</td>\n",
       "      <td>0.158300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3286</td>\n",
       "      <td>0.155600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3348</td>\n",
       "      <td>0.156900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3410</td>\n",
       "      <td>0.154100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3472</td>\n",
       "      <td>0.153400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3534</td>\n",
       "      <td>0.153000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3596</td>\n",
       "      <td>0.151600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3658</td>\n",
       "      <td>0.152800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3720</td>\n",
       "      <td>0.151000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3782</td>\n",
       "      <td>0.151300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3844</td>\n",
       "      <td>0.149700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3906</td>\n",
       "      <td>0.149400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3968</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4030</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4092</td>\n",
       "      <td>0.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4154</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4216</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4278</td>\n",
       "      <td>0.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4340</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4402</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4464</td>\n",
       "      <td>0.143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4526</td>\n",
       "      <td>0.142500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4588</td>\n",
       "      <td>0.141500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>0.141300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4712</td>\n",
       "      <td>0.140100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4774</td>\n",
       "      <td>0.140600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4836</td>\n",
       "      <td>0.140300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4898</td>\n",
       "      <td>0.138400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4960</td>\n",
       "      <td>0.138100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5022</td>\n",
       "      <td>0.138700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5084</td>\n",
       "      <td>0.137100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5146</td>\n",
       "      <td>0.137700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5208</td>\n",
       "      <td>0.136400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5270</td>\n",
       "      <td>0.137400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5332</td>\n",
       "      <td>0.136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5394</td>\n",
       "      <td>0.135800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5456</td>\n",
       "      <td>0.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5518</td>\n",
       "      <td>0.134800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5580</td>\n",
       "      <td>0.134500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5642</td>\n",
       "      <td>0.134500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5704</td>\n",
       "      <td>0.134000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5766</td>\n",
       "      <td>0.133900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5828</td>\n",
       "      <td>0.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5890</td>\n",
       "      <td>0.134200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5952</td>\n",
       "      <td>0.133800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6014</td>\n",
       "      <td>0.132800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6076</td>\n",
       "      <td>0.133400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6138</td>\n",
       "      <td>0.133400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.134900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results = {}\n",
    "model.train()\n",
    "train_model(model, tokenizer, dataset, config, train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c410a601-c5e4-4cc1-af2b-44a7378f3bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f73fd4f0eb0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "fig.suptitle('Learning rate and loss')\n",
    "axs[0].plot(train_results['learning_rate_history'])\n",
    "axs[1].plot(train_results['loss_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "753228f0-b420-4b3d-bd69-53da7a87bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.save_pretrained(saved_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
