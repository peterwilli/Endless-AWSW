{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2TJ-BqFtQ86M",
    "outputId": "f41c5626-6827-4d90-f0a9-8a11c01a366d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 26 22:40:51 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   47C    P8     9W /  N/A |    847MiB /  5934MiB |      9%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oR9S63qiQt2b",
    "outputId": "b1303393-4c18-4510-da76-59e5f2590db8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.10.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (1.11.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.0.16)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2021.8.28)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.62.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (5.0.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2021.8.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.2)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (8.0.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GhhigZYMRK6N"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "from random import randrange\n",
    "import multiprocessing\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config, GPT2LMHeadModel, GPTNeoForCausalLM\n",
    "from transformers import AdamW, get_cosine_schedule_with_warmup, get_polynomial_decay_schedule_with_warmup\n",
    "from transformers import Trainer, TrainingArguments, TrainerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MTduRlf-RQJa",
    "outputId": "296dba31-0af6-422c-eea8-f5c1130a5daf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use cuda:0 for training with seed: 2425076780\n"
     ]
    }
   ],
   "source": [
    "seed = random.randint(0, 2 ** 32 - 1)\n",
    "random.seed(seed)\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(f\"Will use {device_name} for training with seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278,
     "referenced_widgets": [
      "641f6e8a671d4dfe9da34c7685520767",
      "c7eb14f1388e42f29fbac8eef195fede",
      "40b7d134ba7b40299f6bd16b1e781d09",
      "13e5a9ab53bc4e1d8c3c7905ebd05ddf",
      "bc3c9b957d93490c8f9773e7050fd4ef",
      "e702472021334098b47210f9f1395f21",
      "8ed62e486a664d1f83fee6f21cb4585d",
      "ad42520b822e4454947f5d466424c8ca",
      "917d4196cdd14970b7965652f3b950a2",
      "3d72f5178e404d8c948ef13fc81a2bb8",
      "0ae32803eeaf436ab66cb3da9ff5439d",
      "5f28c40531fc4f43b4b62fd04912100c",
      "3c7dd63eb62d44598666166a87c0ff88",
      "7ed9d2386d57488c890d1ec712d1bef0",
      "da3c1240d6a94f3c9ff9ec0545675446",
      "cc7c2ac1006b4b109f302d7d26e3a578",
      "9bb4dcdb6f434d8b8cc95ef80f2ffe00",
      "5af83a55a73b4f3481a7559951ebdf08",
      "c4384ee96a1a4ae4bc8b46fa640b9058",
      "5f2bf3aebfd64baf94df39964208af4c",
      "307da63f10ad4ae5ae5e7e387d176d39",
      "8a282a2414874cb588a386e1444951dd",
      "659e0ad7f39c4cdbbdc1345c07a2e3f4",
      "1481fbbc74544c4888c0d6f88d8b3c9d",
      "54b833977b424c25a690d1bfe5d8c3f1",
      "8bfab1db231a4ff1975775f81f8a84f1",
      "3af5019cfacf4afc8a15a14d9a121ea8",
      "0ac398931b04418cbd3d227b9c634883",
      "7789164b5ee245b3a537d9d61dae038f",
      "8abd99000df0453e86bc458be29a10c7",
      "7db95c969d94465aaffbe9139f0f2a90",
      "d21de377e9074df083556c68e7d7cdbb",
      "3a0ada2f620a40aaa6c33fcea7a0bb91",
      "38bc8c5a2a3447e7942e2058c35d5e5b",
      "79170285a49a450494f0bfbe6cb4788e",
      "9813f2bda5ce4ab6887683fe63d0629e",
      "5c6ca36359bb4a1982c599f6a3f23b9f",
      "6e2cfa054082449e942297afd2f50f73",
      "5f3133f5c7254c248dad8e75534ea920",
      "eef06f8bc02749f4b04af47d92eb91b2",
      "2c60d924ee7b4fad984e2072973c3af3",
      "c1132ffe6c684c7ebeb3f285a101536b",
      "aa2a21546de1463f88a7feb8b697f9d3",
      "0abba2f64b4a43abadb38d461a5c7f42",
      "f43e9d4fa52c48c087ffeef399bfbed6",
      "4f1eafd9553b4bd5b396bba8f3896a22",
      "bbd5e6b14d864c1eb6a4d9c4247fb520",
      "29b2e68155a947e0aca0760c7e8e4afa",
      "fa1b29c48993478f9c2be4877ec675fc",
      "e4a6b2af572e44eda537e74847c58709",
      "8110f29e7b134607b38b29fad32ab1a1",
      "470ba5ce89ee4927a9be685adbc08675",
      "d10fbe074d4b42c9a8a6522252ef016f",
      "5af59ca6be4a427c8f83a906bbb6ce93",
      "17c9592d03324c4797abc812044e7500",
      "f6153c2ce07b4f4097a2a0486fb896ac",
      "3daedb3b85264408a8821ee2e480b356",
      "b2ce0d43567b4cc09e1f5571ee25263c",
      "c3a28b9889cd40e2ac0b9860e7f3932b",
      "99e992b8d4564ddd9c7634ac7663053a",
      "ae627a7820d4450a97b47d63dd5fbd92",
      "56a8c3c144404bd793e29a023032a09f",
      "2a9348d6cd674898ac4c9a303a254f26",
      "bafebeb0fba04d148ae3adf44171e0fe",
      "a8e19067a3ad411cad1aba489d390516",
      "6cf4e15a56fc4ac188609b806f11afcd"
     ]
    },
    "id": "QSVYD7o_eL2o",
    "outputId": "4f570825-b314-421b-b1ee-07449f7787f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading empty, pre-trained model.\n",
      "Model attached to cuda:0\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(\"/opt/awsw\"):\n",
    "  # In case we run this locally (in Docker)\n",
    "  work_dir = os.path.join(\"/opt\", \"awsw\")\n",
    "else:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  work_dir = os.path.join(\"/content\", \"drive\", \"MyDrive\", \"endless_awsw\")\n",
    "\n",
    "models_dir = os.path.join(work_dir, \"models\")\n",
    "\n",
    "if not os.path.isdir(models_dir):\n",
    "    pathlib.Path(models_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "tokenizer = GPT2Tokenizer.from_pretrained('EleutherAI/gpt-neo-125M', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n",
    "# model = GPT2LMHeadModel.from_pretrained('EleutherAI/gpt-neo-125M', pad_token_id = tokenizer.pad_token_id)\n",
    "model = GPTNeoForCausalLM.from_pretrained('EleutherAI/gpt-neo-125M', pad_token_id = tokenizer.pad_token_id, bos_token_id=tokenizer.bos_token_id, eos_token_id=tokenizer.eos_token_id)\n",
    "model.config.attention_dropout = 0.01\n",
    "model.config.embed_dropout = 0.01\n",
    "print(f\"Loading empty, pre-trained model.\")\n",
    "\n",
    "model.to(device)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(f\"Model attached to {device_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMEavxJ32gOH"
   },
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzWBTuEj2gOJ",
    "outputId": "0668db46-b7fd-4806-e90e-a898d2a6b77b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_lines: \n",
      "train_lines: PlayerReply c \"Hey, Remy!\" DragonReply Ry \"Hello, [player_name].\"\n",
      "PlayerReply c \"Is there any particular reason why you wanted to meet here?\" DragonReply Ry \"I enjoy Tatsu Park is all. Have you been here before?\"\n",
      "PlayerReply c \"Can't say I have.\" PlayerReply c \"A few times.\" PlayerReply c \"Once or twice.\" DragonReply Ry \"I see.\" DragonReply Ry \"Well, what do you think of it?\"\n",
      "PlayerReply c \"It's pretty idyllic.\" DragonReply Ry smile \"It is. I like it a lot here.\"\n",
      "PlayerReply c \"It's pretty romantic.\" DragonReply Ry shy \"You think so?\"\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(work_dir, \"awsw_story_input.txt\")) as f:\n",
    "    data = f.read()\n",
    "lines = data.split(\"\\n\")\n",
    "player_dragon_pairs = {}\n",
    "last_player_talk = []\n",
    "closed_player_talk = False\n",
    "re_player_talk = re.compile(r'c \"(.*?)\"')\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    line_split = line.split(\" \")\n",
    "    if len(line_split) <= 1:\n",
    "        continue\n",
    "    \n",
    "    if line_split[0] == \"c\":\n",
    "        if closed_player_talk:\n",
    "            closed_player_talk = False\n",
    "            last_player_talk = []\n",
    "        last_player_talk.append(re.sub(re_player_talk, r\"\\1\", line))\n",
    "    else:\n",
    "        if not closed_player_talk:\n",
    "            last_player_talk = json.dumps(last_player_talk)\n",
    "            if not last_player_talk in player_dragon_pairs:\n",
    "                player_dragon_pairs[last_player_talk] = []\n",
    "            closed_player_talk = True\n",
    "            \n",
    "        line = \"DragonReply \" + line\n",
    "        if last_player_talk is not None:\n",
    "            player_dragon_pairs[last_player_talk].append(line)\n",
    "    \n",
    "train_lines = []\n",
    "eval_lines = []\n",
    "eval_per_character = 0\n",
    "\n",
    "for player_line_str in player_dragon_pairs.keys():\n",
    "    player_lines = json.loads(player_line_str)\n",
    "    dragon_lines = player_dragon_pairs[player_line_str]\n",
    "    compiled_line = \" \".join([f'PlayerReply c \"{player_line}\"' for player_line in player_lines]) + \" \" + \" \".join(dragon_lines)\n",
    "    train_lines.append(compiled_line)\n",
    "    \n",
    "test_bucket = {}\n",
    "for l in train_lines:\n",
    "    l_split = l.split(\" \")\n",
    "    character = None\n",
    "    for i, ls in enumerate(l_split):\n",
    "        if ls == \"DragonReply\":\n",
    "            character = l_split[i + 1]\n",
    "            break\n",
    "    if not character in test_bucket:\n",
    "        test_bucket[character] = []\n",
    "    test_bucket[character].append(l)\n",
    "    \n",
    "for i in range(eval_per_character):\n",
    "    for character in test_bucket.keys():\n",
    "        random_line = test_bucket[character][randrange(len(test_bucket[character]))]\n",
    "        eval_lines.append(random_line)\n",
    "        for i2, t in enumerate(train_lines):\n",
    "            if t == random_line:\n",
    "                del train_lines[i2]\n",
    "                break\n",
    "    \n",
    "joined_eval_lines = \"\\n\".join(eval_lines[:5])\n",
    "print(f\"eval_lines: {joined_eval_lines}\")\n",
    "joined_train_lines = \"\\n\".join(train_lines[:5])\n",
    "print(f\"train_lines: {joined_train_lines}\")\n",
    "\n",
    "if not os.path.isfile(os.path.join(work_dir, \"data_train.txt\")):\n",
    "    with open(os.path.join(work_dir, \"data_train.txt\"), \"w\") as f:\n",
    "        for l in train_lines:\n",
    "            f.write(l + \"\\n\")\n",
    "            \n",
    "if not os.path.isfile(os.path.join(work_dir, \"data_test.txt\")):\n",
    "    with open(os.path.join(work_dir, \"data_test.txt\"), \"w\") as f:\n",
    "        for l in eval_lines:\n",
    "            f.write(l + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220,
     "referenced_widgets": [
      "a04e889a56e94ce9812a0e7d89d4d4f4",
      "3c2d0014295e47f9a07de8d4e36e7ba4",
      "76286c1e442541e0a6cb2d7cbbc9cc8f",
      "dcad41ec160e448b83d85c907a48facb",
      "27f2d980cb774902a82c0ad2545f549a",
      "131ce893dc784733b42f384b419145db",
      "607ee5c0b54042f3919d0588d66e31c1",
      "b2373342cb4942569088a5b20186795a",
      "11475ac58a594c6db1641401b1cc0d13",
      "f6625c167f7b4aa4bbecf2129e07c068",
      "ef9e25d7100e4e9ba064e938bd8157ea",
      "7bb369ca60f94acc99a4ee8e8f8fd261",
      "bc20a41ccda14aeeb72014b80a5ec53a",
      "c6ff5b9114424dbfafcbc3b3ab887af5",
      "1153397efee1426cac848341c0b88785",
      "37672ae801de4f42a9f6f49cc33fb88e",
      "8528f9fbbc504a44b9670a760256192d",
      "406b2f47896446a187725d4a1aa926f8",
      "cb33a87e718546f3a33b7deea817de56",
      "eeb54e278e184bc5aabf0283f1b276ff",
      "809a3780924641b8ace57e9141b0167f",
      "b805525a58804750ae56dad7e43ecb0e",
      "906b9daf9437432c81546f35256c7232",
      "0ce77d162a014a2fa17628ef8fe20846",
      "3fed2802cbab4a90a5b3d5a8c9bc8974",
      "a146d5c5588944368242c519984cbccc",
      "28d30b2eecf04ae6835cf4c35648dcfc",
      "65c48ca18ea14cf9bccbaa2495c2f120",
      "5067025a37bb42318ae93216b3205b17",
      "d18658b25f6f47778b984d0bf35be999",
      "6ade1603ab664b9f9d5ce44014bc5305",
      "fd91a671eeb7431d90d86b44beb276bd",
      "df0a544035814e1ca11d6191c10a5b62",
      "23a62f16d8de4f3ab9fa64ada07d1e35",
      "d50f5db4d1a1430caecace0510c1a24e",
      "d36395d1dcad4ead98f7f4756b8dbd37",
      "2cf737292a8343f5965c3eb0ace01875",
      "9ba5d1e5fab74947a328842b5105a28e",
      "073bc138772048729e04017123149e80",
      "ab0ce277776d4d218bf97fff5acc8e28",
      "b404b600842a4fc4b2b66c6b015235d6",
      "06dd02ec048945e5bf6b17d2b5558fb2",
      "437e050108fd46e1ba0f35674fa7314f",
      "a5725e8dc8104756bcba16b2c886a27f",
      "a31733df07ed4bb485d518b64634acfb",
      "1a2fe039b81a42c496ba363b2000bc41",
      "3f271f4469cf4796b92a78eba64c30b3",
      "fd200bcd96354e36b32ca82660eb0ef2",
      "33f9747c1f474c1790c7c293c853fad5",
      "e10acb8e2c8240409a19c61499576afd",
      "cc3c5e1ef5974710a06c1eab3d90cfb1",
      "6eda966317484df2a47fa0c4f2a0370c",
      "0cd6ff104b484203adda9e8414fd80fa",
      "c5a11599f37c4077a4ab0daec124a78c",
      "6cd8593a13f54c138c9adf5ec85f2d97"
     ]
    },
    "id": "pWeL2qWd2gOK",
    "outputId": "efdd650f-d95e-47a9-ad2f-396593bb779e"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset('text', data_files={'train': os.path.join(work_dir, \"data_train.txt\"), 'test': os.path.join(work_dir, \"data_test.txt\")})\n",
    "\n",
    "class AWSWDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, dataset, dataset_type, do_shuffle=False):\n",
    "        self.current_dataset = dataset\n",
    "        self.dataset_type = dataset_type\n",
    "        self.do_shuffle = do_shuffle\n",
    "        self.shuffled_datasets = []\n",
    "        self.current_idx = 0\n",
    "        for i in range(1):\n",
    "            self.current_dataset = self.current_dataset.shuffle()\n",
    "            mapped_dataset = self.current_dataset.map(\n",
    "                group_texts,\n",
    "                batched=True,\n",
    "                batch_size=dataset_batch_size,\n",
    "                num_proc=dataset_map_cores\n",
    "            )\n",
    "            self.shuffled_datasets.append(mapped_dataset)\n",
    "        \n",
    "    def approx_len(self):\n",
    "        return len(self.shuffled_datasets[0][self.dataset_type])\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.current_idx = (self.current_idx + 1) % len(self.shuffled_datasets)\n",
    "        return iter(self.shuffled_datasets[self.current_idx][self.dataset_type])\n",
    "    \n",
    "def encode(batch):\n",
    "    result = []\n",
    "    attention_mask = []\n",
    "    for item in batch['text']:\n",
    "        #tokens = [tokenizer.bos_token_id] + tokenizer.encode(item) + [tokenizer.eos_token_id]\n",
    "        #tokens = tokenizer.encode(item)\n",
    "        tokens = tokenizer.encode(item) + [tokenizer.eos_token_id]\n",
    "        result.append(tokens)\n",
    "        attention_mask.append([1] * len(tokens))\n",
    "    return {\n",
    "        'attention_mask': attention_mask,\n",
    "        'input_ids': result\n",
    "    }\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Make a max size\n",
    "    block_size = 128\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    #random_shift = random.randint(0, 64)\n",
    "    #concatenated_examples['input_ids'] = concatenated_examples['input_ids'][random_shift:]\n",
    "    #concatenated_examples['attention_mask'] = concatenated_examples['attention_mask'][random_shift:]\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # Pad the end\n",
    "    to_add = (math.ceil(total_length / block_size) * block_size) - total_length\n",
    "    if to_add > 0:\n",
    "        concatenated_examples['input_ids'] += [tokenizer.pad_token_id] * to_add\n",
    "        concatenated_examples['attention_mask'] += [0] * to_add\n",
    "        total_length += to_add\n",
    "    # Split by chunks of block_size.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "def map_dragon_reply_text(batch):\n",
    "    # Make a max size\n",
    "    block_size = 128\n",
    "    result = {'text': []}\n",
    "    for item in batch['text']:\n",
    "        item_split = item.split(\" \")\n",
    "        player_replies = []\n",
    "        dragon_replies = []\n",
    "        current_reply = []\n",
    "        handling_reply = None\n",
    "        for token in item_split:\n",
    "            if token == \"PlayerReply\":\n",
    "                if handling_reply is None:\n",
    "                    handling_reply = \"PlayerReply\"\n",
    "                else:\n",
    "                    if handling_reply == \"PlayerReply\":\n",
    "                        # We need to store the PlayerReply\n",
    "                        player_replies.append(\" \".join(current_reply))\n",
    "                        current_reply = []\n",
    "            elif token == \"DragonReply\":\n",
    "                if handling_reply == \"DragonReply\":\n",
    "                    # We need to store the DragonReply\n",
    "                    dragon_replies.append(\" \".join(current_reply))\n",
    "                    current_reply = []\n",
    "                    \n",
    "                if handling_reply == \"PlayerReply\":\n",
    "                    # We need to store the PlayerReply\n",
    "                    player_replies.append(\" \".join(current_reply))\n",
    "                    current_reply = []\n",
    "                    \n",
    "                handling_reply = \"DragonReply\"\n",
    "                current_reply = []\n",
    "                    \n",
    "            if handling_reply is not None:\n",
    "                current_reply.append(token)\n",
    "                \n",
    "        # There's always a dragon reply at the end.\n",
    "        dragon_replies.append(\" \".join(current_reply))\n",
    "        for player_idx in range(len(player_replies)):\n",
    "            for dragon_idx in range(len(dragon_replies)):\n",
    "                result['text'].append(player_replies[player_idx] + \" \" + dragon_replies[dragon_idx])\n",
    "                \n",
    "    return result\n",
    "\n",
    "dataset_map_cores = min(multiprocessing.cpu_count(), 10)\n",
    "dataset_batch_size = 1000\n",
    "\n",
    "dataset = dataset.map(\n",
    "    map_dragon_reply_text,\n",
    "    batched=True,\n",
    "    batch_size=dataset_batch_size,\n",
    "    num_proc=dataset_map_cores\n",
    ")\n",
    "\n",
    "dataset = dataset.map(\n",
    "    encode,\n",
    "    batched=True,\n",
    "    batch_size=dataset_batch_size,\n",
    "    remove_columns=[\"text\"],\n",
    "    num_proc=dataset_map_cores\n",
    ")\n",
    "\n",
    "dataset = dataset.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=dataset_batch_size,\n",
    "    num_proc=dataset_map_cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PhiZIfn02gOL",
    "outputId": "47e5768d-8b9d-4ea8-c5ac-cc392abba402"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_training_steps: 867 num_total_steps: 86700\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "train_len = len(dataset['train'])\n",
    "num_training_steps = math.ceil(train_len / batch_size)\n",
    "num_epoch = 100\n",
    "num_total_steps = num_training_steps * num_epoch\n",
    "num_warmup_steps = num_training_steps * 2\n",
    "print(f\"num_training_steps: {num_training_steps} num_total_steps: {num_total_steps}\")\n",
    "def get_optimizer_and_scheduler(params):\n",
    "    optimizer = AdamW(params, lr=0.001)\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_total_steps)\n",
    "    #scheduler = get_polynomial_decay_schedule_with_warmup(optimizer, num_warmup_steps, num_total_steps, power=0.5, lr_end=1e-10)\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrs = []\n",
    "optimizer, scheduler = get_optimizer_and_scheduler([torch.tensor(0.1)])\n",
    "for i in range(num_total_steps):\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "plt.plot(lrs)\n",
    "plt.show()\n",
    "del lrs\n",
    "del optimizer\n",
    "del scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "id": "AdPIW0xSTpRY",
    "outputId": "01338ca7-7ed2-4d8e-dd7b-5c235e4c5e30"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 4334\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 5\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 5\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 86700\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='86700' max='86700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86700/86700 5:20:10, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.369200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.678400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.579000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.473300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.451400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.411700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>1.520300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.261200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>1.272000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.285300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>1.049200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.930600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.992300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.979200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.686500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.744500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.744300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.586900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>0.515200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.584100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>0.540300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.383300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5750</td>\n",
       "      <td>0.425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.443500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6250</td>\n",
       "      <td>0.327900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.319800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6750</td>\n",
       "      <td>0.338700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.335700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7250</td>\n",
       "      <td>0.241600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.272800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7750</td>\n",
       "      <td>0.295900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.219900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8250</td>\n",
       "      <td>0.215900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.241100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8750</td>\n",
       "      <td>0.228900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.180200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9250</td>\n",
       "      <td>0.203000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.221400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9750</td>\n",
       "      <td>0.165500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.170100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10250</td>\n",
       "      <td>0.190400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.169300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10750</td>\n",
       "      <td>0.149600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.164500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11250</td>\n",
       "      <td>0.177900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.131700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11750</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.160400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12250</td>\n",
       "      <td>0.141900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.128400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12750</td>\n",
       "      <td>0.141500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13250</td>\n",
       "      <td>0.109600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13750</td>\n",
       "      <td>0.135600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.123500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14250</td>\n",
       "      <td>0.108500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.124900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14750</td>\n",
       "      <td>0.130200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.097100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15250</td>\n",
       "      <td>0.114800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.116900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15750</td>\n",
       "      <td>0.101900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.101200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16250</td>\n",
       "      <td>0.112300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.115100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16750</td>\n",
       "      <td>0.086400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.099700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17250</td>\n",
       "      <td>0.110800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.094800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17750</td>\n",
       "      <td>0.090600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.100400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18250</td>\n",
       "      <td>0.097900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.085600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18750</td>\n",
       "      <td>0.092100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.098100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19250</td>\n",
       "      <td>0.081800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.083700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19750</td>\n",
       "      <td>0.094100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.090800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20250</td>\n",
       "      <td>0.073900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.083500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20750</td>\n",
       "      <td>0.087600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.075900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21250</td>\n",
       "      <td>0.078900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.084600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21750</td>\n",
       "      <td>0.081100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.068800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22250</td>\n",
       "      <td>0.080100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.082700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22750</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23250</td>\n",
       "      <td>0.076300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.074800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23750</td>\n",
       "      <td>0.066100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.073100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24250</td>\n",
       "      <td>0.077900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.061900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24750</td>\n",
       "      <td>0.065800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.071400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25250</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.063500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25750</td>\n",
       "      <td>0.069000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.074500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26250</td>\n",
       "      <td>0.056900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.061300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26750</td>\n",
       "      <td>0.066600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.062200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27250</td>\n",
       "      <td>0.056600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.065900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27750</td>\n",
       "      <td>0.066400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.054500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28250</td>\n",
       "      <td>0.057800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.063800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28750</td>\n",
       "      <td>0.058000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.056300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29250</td>\n",
       "      <td>0.061600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.060200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29750</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30250</td>\n",
       "      <td>0.059900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.054400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30750</td>\n",
       "      <td>0.051800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.056700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31250</td>\n",
       "      <td>0.055300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.049400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31750</td>\n",
       "      <td>0.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.056100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32250</td>\n",
       "      <td>0.049100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.048900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32750</td>\n",
       "      <td>0.054100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.055600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33250</td>\n",
       "      <td>0.043400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>0.048900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33750</td>\n",
       "      <td>0.053500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.048300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34250</td>\n",
       "      <td>0.046200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>0.051700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34750</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.043100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35250</td>\n",
       "      <td>0.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>0.050900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35750</td>\n",
       "      <td>0.044800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.045400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36250</td>\n",
       "      <td>0.046500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>0.047300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36750</td>\n",
       "      <td>0.041400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.045200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37250</td>\n",
       "      <td>0.047700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>0.041500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37750</td>\n",
       "      <td>0.042500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.045500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38250</td>\n",
       "      <td>0.043100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>0.038400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38750</td>\n",
       "      <td>0.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.046300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39250</td>\n",
       "      <td>0.037800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>0.040200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39750</td>\n",
       "      <td>0.041900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.042000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40250</td>\n",
       "      <td>0.036800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40750</td>\n",
       "      <td>0.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.037100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41250</td>\n",
       "      <td>0.039600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>0.042200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41750</td>\n",
       "      <td>0.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.035600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42250</td>\n",
       "      <td>0.039400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>0.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42750</td>\n",
       "      <td>0.035500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43250</td>\n",
       "      <td>0.038400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43500</td>\n",
       "      <td>0.036100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43750</td>\n",
       "      <td>0.034300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.038600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44250</td>\n",
       "      <td>0.038900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44500</td>\n",
       "      <td>0.032700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44750</td>\n",
       "      <td>0.035100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.039200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45250</td>\n",
       "      <td>0.035600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45500</td>\n",
       "      <td>0.034600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45750</td>\n",
       "      <td>0.035500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.035500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46250</td>\n",
       "      <td>0.030900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46500</td>\n",
       "      <td>0.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46750</td>\n",
       "      <td>0.036600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>0.032200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47250</td>\n",
       "      <td>0.034100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47500</td>\n",
       "      <td>0.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47750</td>\n",
       "      <td>0.033500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.030900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48250</td>\n",
       "      <td>0.032100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48500</td>\n",
       "      <td>0.035200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48750</td>\n",
       "      <td>0.032200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49250</td>\n",
       "      <td>0.031800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49500</td>\n",
       "      <td>0.031800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49750</td>\n",
       "      <td>0.027800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.032400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50250</td>\n",
       "      <td>0.035800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50500</td>\n",
       "      <td>0.029800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50750</td>\n",
       "      <td>0.030800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>0.032400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51250</td>\n",
       "      <td>0.030300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51500</td>\n",
       "      <td>0.028400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51750</td>\n",
       "      <td>0.030300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.032100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52250</td>\n",
       "      <td>0.028800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52500</td>\n",
       "      <td>0.029900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52750</td>\n",
       "      <td>0.030500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>0.030200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53250</td>\n",
       "      <td>0.029900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53500</td>\n",
       "      <td>0.028800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53750</td>\n",
       "      <td>0.031600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.027500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54250</td>\n",
       "      <td>0.027800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54500</td>\n",
       "      <td>0.030500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54750</td>\n",
       "      <td>0.028300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.028100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55250</td>\n",
       "      <td>0.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55500</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55750</td>\n",
       "      <td>0.025700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56250</td>\n",
       "      <td>0.029400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56500</td>\n",
       "      <td>0.027900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56750</td>\n",
       "      <td>0.027400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>0.027900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57250</td>\n",
       "      <td>0.028700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57500</td>\n",
       "      <td>0.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57750</td>\n",
       "      <td>0.027200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.028700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58250</td>\n",
       "      <td>0.026200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58500</td>\n",
       "      <td>0.026400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58750</td>\n",
       "      <td>0.028200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>0.028300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59250</td>\n",
       "      <td>0.024700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59500</td>\n",
       "      <td>0.027500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59750</td>\n",
       "      <td>0.028700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60250</td>\n",
       "      <td>0.025700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60500</td>\n",
       "      <td>0.028100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60750</td>\n",
       "      <td>0.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>0.026100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61250</td>\n",
       "      <td>0.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61500</td>\n",
       "      <td>0.026700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61750</td>\n",
       "      <td>0.025100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62250</td>\n",
       "      <td>0.027700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62500</td>\n",
       "      <td>0.026200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62750</td>\n",
       "      <td>0.024400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>0.026200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63250</td>\n",
       "      <td>0.027200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63500</td>\n",
       "      <td>0.023600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63750</td>\n",
       "      <td>0.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.026300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64250</td>\n",
       "      <td>0.025800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64500</td>\n",
       "      <td>0.024100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64750</td>\n",
       "      <td>0.025600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.026900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65250</td>\n",
       "      <td>0.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65500</td>\n",
       "      <td>0.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65750</td>\n",
       "      <td>0.026700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.024400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66250</td>\n",
       "      <td>0.024200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66500</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66750</td>\n",
       "      <td>0.027200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67000</td>\n",
       "      <td>0.023200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67250</td>\n",
       "      <td>0.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67500</td>\n",
       "      <td>0.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67750</td>\n",
       "      <td>0.024600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.024400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68250</td>\n",
       "      <td>0.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68500</td>\n",
       "      <td>0.025800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68750</td>\n",
       "      <td>0.023500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69000</td>\n",
       "      <td>0.024500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69250</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69500</td>\n",
       "      <td>0.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69750</td>\n",
       "      <td>0.023700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.025100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70250</td>\n",
       "      <td>0.024500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70500</td>\n",
       "      <td>0.023600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70750</td>\n",
       "      <td>0.024300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71000</td>\n",
       "      <td>0.024100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71250</td>\n",
       "      <td>0.023500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71500</td>\n",
       "      <td>0.023300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71750</td>\n",
       "      <td>0.024300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72250</td>\n",
       "      <td>0.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72500</td>\n",
       "      <td>0.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72750</td>\n",
       "      <td>0.024400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73000</td>\n",
       "      <td>0.023100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73250</td>\n",
       "      <td>0.023500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73500</td>\n",
       "      <td>0.023800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73750</td>\n",
       "      <td>0.023500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74250</td>\n",
       "      <td>0.022900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74500</td>\n",
       "      <td>0.023800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74750</td>\n",
       "      <td>0.022200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>0.022800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75250</td>\n",
       "      <td>0.023900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75500</td>\n",
       "      <td>0.022800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75750</td>\n",
       "      <td>0.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>0.023100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76250</td>\n",
       "      <td>0.022900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76500</td>\n",
       "      <td>0.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76750</td>\n",
       "      <td>0.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77000</td>\n",
       "      <td>0.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77250</td>\n",
       "      <td>0.022900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77500</td>\n",
       "      <td>0.022200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77750</td>\n",
       "      <td>0.022600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>0.022700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78250</td>\n",
       "      <td>0.022200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78500</td>\n",
       "      <td>0.021400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78750</td>\n",
       "      <td>0.022800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79000</td>\n",
       "      <td>0.022200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79250</td>\n",
       "      <td>0.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79500</td>\n",
       "      <td>0.022200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79750</td>\n",
       "      <td>0.022900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.021800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80250</td>\n",
       "      <td>0.021200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80500</td>\n",
       "      <td>0.022200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80750</td>\n",
       "      <td>0.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81000</td>\n",
       "      <td>0.021800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81250</td>\n",
       "      <td>0.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81500</td>\n",
       "      <td>0.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81750</td>\n",
       "      <td>0.021900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>0.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82250</td>\n",
       "      <td>0.021900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82500</td>\n",
       "      <td>0.021400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82750</td>\n",
       "      <td>0.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83000</td>\n",
       "      <td>0.021900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83250</td>\n",
       "      <td>0.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83500</td>\n",
       "      <td>0.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83750</td>\n",
       "      <td>0.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>0.021100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84250</td>\n",
       "      <td>0.021100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84500</td>\n",
       "      <td>0.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84750</td>\n",
       "      <td>0.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>0.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85250</td>\n",
       "      <td>0.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85500</td>\n",
       "      <td>0.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85750</td>\n",
       "      <td>0.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>0.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86250</td>\n",
       "      <td>0.021800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86500</td>\n",
       "      <td>0.020800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /opt/awsw/models/checkpoint-500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-1000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-1000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-1500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-1500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-1500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-2000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-2000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-2000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-2500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-2500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-2500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-3000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-3000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-3000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-3500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-3500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-3500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-4000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-4000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-4000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-4500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-4500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-4500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-3500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-5000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-5000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-5000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-5500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-5500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-5500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-4500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-6000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-6000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-6000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-6500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-6500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-6500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-5500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-7000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-7000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-7000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-7500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-7500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-7500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-6500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-8000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-8000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-8000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-8500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-8500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-8500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-7500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-9000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-9000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-9000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-9500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-9500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-9500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-8500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-10000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-10000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-10000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-10500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-10500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-10500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-9500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-11000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-11000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-11000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-10000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-11500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-11500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-11500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-10500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-12000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-12000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-12000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-11000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-12500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-12500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-12500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-11500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-13000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-13000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-13000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-12000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-13500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-13500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-13500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-12500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-14000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-14000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-14000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-13000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-14500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-14500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-14500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-13500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-15000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-15000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-15000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-14000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-15500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-15500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-15500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-14500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-16000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-16000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-16000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-15000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-16500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-16500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-16500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-15500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-17000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-17000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-17000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-16000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-17500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-17500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-17500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-16500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-18000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-18000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-18000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-17000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-18500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-18500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-18500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-17500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-19000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-19000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-19000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-18000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-19500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-19500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-19500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-18500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-20000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-20000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-20000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-19000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-20500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-20500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-20500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-19500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-21000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-21000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-21000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-20000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-21500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-21500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-21500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-20500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-22000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-22000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-22000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-21000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-22500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-22500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-22500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-21500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-23000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-23000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-23000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-22000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-23500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-23500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-23500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-22500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-24000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-24000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-24000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-23000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-24500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-24500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-24500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-23500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-25000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-25000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-25000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-24000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-25500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-25500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-25500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-24500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-26000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-26000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-26000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-25000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-26500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-26500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-26500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-25500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-27000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-27000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-27000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-26000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-27500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-27500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-27500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-26500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-28000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-28000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-28000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-27000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-28500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-28500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-28500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-27500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-29000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-29000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-29000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-28000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-29500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-29500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-29500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-28500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-30000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-30000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-30000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-29000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-30500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-30500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-30500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-29500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-31000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-31000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-31000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-30000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-31500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-31500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-31500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-30500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-32000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-32000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-32000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-31000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-32500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-32500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-32500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-31500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-33000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-33000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-33000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-32000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-33500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-33500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-33500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-32500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-34000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-34000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-34000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-33000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-34500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-34500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-34500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-33500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-35000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-35000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-35000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-34000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-35500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-35500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-35500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-34500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-36000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-36000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-36000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-35000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-36500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-36500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-36500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-35500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-37000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-37000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-37000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-36000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-37500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-37500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-37500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-36500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-38000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-38000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-38000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-37000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-38500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-38500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-38500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-37500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-39000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-39000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-39000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-38000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-39500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-39500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-39500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-38500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-40000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-40000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-40000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-39000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-40500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-40500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-40500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-39500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-41000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-41000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-41000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-40000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-41500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-41500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-41500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-40500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-42000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-42000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-42000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-41000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-42500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-42500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-42500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-41500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-43000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-43000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-43000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-42000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-43500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-43500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-43500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-42500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-44000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-44000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-44000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-43000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-44500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-44500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-44500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-43500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-45000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-45000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-45000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-44000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-45500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-45500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-45500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-44500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-46000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-46000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-46000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-45000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-46500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-46500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-46500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-45500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-47000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-47000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-47000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-46000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-47500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-47500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-47500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-46500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-48000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-48000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-48000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-47000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-48500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-48500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-48500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-47500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-49000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-49000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-49000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-48000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-49500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-49500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-49500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-48500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-50000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-50000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-50000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-49000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-50500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-50500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-50500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-49500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-51000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-51000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-51000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-50000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-51500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-51500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-51500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-50500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-52000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-52000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-52000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-51000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-52500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-52500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-52500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-51500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-53000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-53000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-53000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-52000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-53500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-53500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-53500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-52500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-54000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-54000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-54000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-53000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-54500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-54500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-54500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-53500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-55000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-55000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-55000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-54000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-55500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-55500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-55500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-54500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-56000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-56000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-56000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-55000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-56500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-56500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-56500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-55500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-57000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-57000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-57000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-56000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-57500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-57500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-57500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-56500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-58000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-58000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-58000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-57000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-58500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-58500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-58500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-57500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-59000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-59000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-59000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-58000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-59500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-59500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-59500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-58500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-60000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-60000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-60000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-59000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-60500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-60500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-60500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-59500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-61000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-61000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-61000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-60000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-61500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-61500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-61500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-60500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-62000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-62000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-62000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-61000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-62500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-62500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-62500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-61500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-63000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-63000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-63000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-62000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-63500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-63500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-63500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-62500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-64000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-64000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-64000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-63000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-64500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-64500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-64500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-63500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-65000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-65000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-65000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-64000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-65500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-65500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-65500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-64500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-66000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-66000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-66000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-65000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-66500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-66500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-66500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-65500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-67000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-67000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-67000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-66000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-67500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-67500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-67500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-66500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-68000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-68000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-68000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-67000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-68500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-68500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-68500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-67500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-69000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-69000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-69000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-68000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-69500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-69500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-69500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-68500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-70000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-70000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-70000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-69000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-70500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-70500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-70500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-69500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-71000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-71000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-71000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-70000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-71500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-71500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-71500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-70500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-72000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-72000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-72000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-71000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-72500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-72500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-72500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-71500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-73000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-73000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-73000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-72000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-73500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-73500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-73500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-72500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-74000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-74000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-74000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-73000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-74500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-74500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-74500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-73500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-75000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-75000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-75000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-74000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-75500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-75500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-75500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-74500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-76000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-76000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-76000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-75000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-76500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-76500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-76500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-75500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-77000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-77000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-77000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-76000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-77500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-77500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-77500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-76500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-78000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-78000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-78000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-77000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-78500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-78500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-78500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-77500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-79000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-79000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-79000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-78000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-79500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-79500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-79500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-78500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-80000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-80000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-80000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-79000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-80500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-80500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-80500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-79500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-81000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-81000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-81000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-80000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-81500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-81500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-81500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-80500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-82000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-82000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-82000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-81000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-82500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-82500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-82500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-81500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-83000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-83000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-83000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-82000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-83500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-83500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-83500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-82500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-84000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-84000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-84000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-83000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-84500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-84500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-84500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-83500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-85000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-85000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-85000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-84000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-85500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-85500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-85500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-84500] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-86000\n",
      "Configuration saved in /opt/awsw/models/checkpoint-86000/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-86000/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-85000] due to args.save_total_limit\n",
      "Saving model checkpoint to /opt/awsw/models/checkpoint-86500\n",
      "Configuration saved in /opt/awsw/models/checkpoint-86500/config.json\n",
      "Model weights saved in /opt/awsw/models/checkpoint-86500/pytorch_model.bin\n",
      "Deleting older checkpoint [/opt/awsw/models/checkpoint-85500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEVCAYAAADkckIIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA2vElEQVR4nO3deXzdVZn48c9z9+x70qbplq60pXRjKVtZpTBgERlEHWQcFVH8jTPqaBlfOriLo+KGICKrsllwLAoie0GgpS0t3aB0b5q2WZp9vcvz++P7TXsTkpCWJvcm93m/XveV7/2uzz25uU/OOd97jqgqxhhjTBdPogMwxhiTXCwxGGOM6cYSgzHGmG4sMRhjjOnGEoMxxphuLDEYY4zpxhKDGRFE5CwReTvRcSQjEdklIhf0se0eEfnuUMdkkpslBvO+9ffBM1RU9SVVnZbIGLqIyDkiUpHoOIw5VpYYzLAgIt5ExwAgDvu7MSOavcHNoBERj4gsFZHtIlIrIo+ISH7c9j+KyAERaRCRFSIyM27bPSJym4g8ISItwLluzeQrIvKme8zDIhJy9+/2X3p/+7rbvyoi+0WkUkQ+LSIqIpP7eB0viMj3ROQfQCtQLiKfFJEtItIkIjtE5LPuvhnAk0CpiDS7j9L3Kose18sTkb+ISLWI1LnLZT3i+Y6I/MO9/t9FpDBu+zUistu9zteP8nf2GRHZJiKHRGS5iJS660VEbhGRKhFpFJENIjLL3XaJiGx2Y9knIl85mmua5GOJwQym/wdcDiwCSoE64Na47U8CU4BiYC3whx7Hfwz4HpAFvOyuuwpYDEwEZgP/2s/1e91XRBYDXwIuACYD5wzgtVwDXOfGshuoAi4FsoFPAreIyDxVbQEuBipVNdN9VA6gLOJ5gLuB8cA4oA34VY99PuZetxgIAF9xX9sM4DY33lKgAChjAETkPOAHOOU22n2dD7mbPwCcDUwFctx9at1tvwM+q6pZwCzguYFczyQvSwxmMF0PfF1VK1S1A7gJuFJEfACqepeqNsVtO0lEcuKO/7Oq/kNVY6ra7q77hapWquoh4HFgTj/X72vfq4C7VXWTqra6134v97j7R1Q1rKp/VdXt6ngR+Dtw1rGWRTxVrVXVR1W1VVWbcJLjoh673a2qW1W1DXgk7rVdCfxFVVe41/kGEBvA6wP4OHCXqq51j70RWCgiE4AwTlKcDoiqblHV/e5xYWCGiGSrap2qrh3g9UySssRgBtN44E8iUi8i9cAWIAqUiIhXRH7oNq00ArvcYwrjjt/byzkPxC23Apn9XL+vfUt7nLu36/TUbR8RuVhEXnObXOqBS+gee099lkXPHUUkXUR+4zYHNQIrgNwe/SwDem1uDaaWgSnFqSV0HdvsHjtGVZ/DqbXcClSJyB0iku3u+mGc179bRF4UkYUDvJ5JUpYYzGDaC1ysqrlxj5Cq7sNpClmC05yTA0xwj5G44wdr6N/9dG9eGTuAYw7HIiJB4FHgx0CJquYCT3Ak9t7i7q8sevoyMA04VVWzcZpwoHvZ9GV//OsRkXSc5qSBqMRJYF3HZrjH7gNQ1V+o6nxgBk6T0n+5619X1SU4zVr/h1ODMcOYJQZzvPhFJBT38AG3A98TkfEAIlIkIkvc/bOADpz/SNOB7w9hrI8AnxSRE9wPzm8c5fEBIAhUAxERuRinDb7LQaCgR7NYf2XRUxZOv0K920H9P0cR2zLgUhE5U0QCwLcZ+N/5gzjlMsdNft8HVqrqLhE5WUROFRE/0AK0AzERCYjIx0UkR1XDQCMDb7oyScoSgzlensD5MOt63AT8HFgO/F1EmoDXgFPd/e/DabbYB2x2tw0JVX0S+AXwPLAt7todAzy+Cfh3nARTh1P7WR63/S2cD9kdbtNRKf2XRU8/A9KAGne/vx3Fa9sE3AA8gFN7qAMG9J0KVX0GJ0k+6h47Cbja3ZwN/NY9326chP6/7rZrgF1us9f1OH0VZhgTm6jHpDoROQHYCARVNZLoeIxJNKsxmJQkIh8SkaCI5AE3A49bUjDGYYnBpKrP4nwXYTvO3UGfS2w4xiQPa0oyxhjTjdUYjDHGdGOJwRhjTDeWGIwxxnRjicEYY0w3lhiMMcZ0Y4nBGGNMN5YYjDHGdGOJwRhjTDeWGIwxxnRjicEYY0w3lhiMMcZ0Y4nBGGNMN5YYjDHGdGOJwRhjTDe+RAdwPBQWFuqECRMSHYYxxgwra9asqVHVop7rB5QYRGQxzpy1XuBOVf1hj+1BnDl85+PMBfsRVd3lbrsR+BTOZCj/rqpPuevvAi4FqlR1Vty58oGHgQnALuAqVa3rL74JEyawevXqgbwUY4wxLhHZ3dv692xKEhEvcCtwMTAD+KiIzOix26eAOlWdDNyCM1Ui7n5XAzOBxcCv3fMB3OOu62kp8KyqTgGedZ8bY4wZIgPpYzgF2KaqO1S1E3gIWNJjnyXAve7yMuB8ERF3/UOq2qGqO4Ft7vlQ1RXAoV6uF3+ue4HLB/5yjDHGvF8DaUoaA+yNe14BnNrXPqoaEZEGoMBd/1qPY8e8x/VKVHW/u3wAKBlAjMfNqp2H+M+H16Gq+LwefB7B5xV8Hg8+r+D3esgI+sgMeskI+MgM+cgMuo+Qj4KMIIWZAQoynZ+ZQR9OjjTGmOEhqTufVVVFpNdJqUXkOuA6gHHjxh23a67dU8e++jaumDsGBcLRGJGoEokpkViMzkiMhrYwlfVtNLdHaOmI0NwZoa+pswM+D4UZAQqzgozOCTEmN50xeWmMyXUfeWnkpfsteRhjksZAEsM+YGzc8zJ3XW/7VIiID8jB6YQeyLE9HRSR0aq6X0RGA1W97aSqdwB3ACxYsKCPj+WjV98aJuD18JOrThrwh7Wq0toZpak9Qm1LBzXNndQ2d1Db3ElNs/O8urmD7dUtrNhaQ1s42u349ICXCQUZTCrOpLzwyM/yogzSA0mdu40xI9BAPnVeB6aIyEScD/WrgY/12Gc5cC3wKnAl8Jz73/5y4AER+SlQCkwBVr3H9brO9UP3558H+FqOi4a2MDlH+R+8iJAR9JER9DEqJ9TvvqpKXatT46ioa2NffRt7D7Wys6aFdXvr+Mubld1qH2Ny05g2KosZo7OZUZrNCaOzGZ+fjsdjNQxjzOB4z8Tg9hl8AXgK53bVu1R1k4h8G1itqsuB3wH3i8g2nA7lq91jN4nII8BmIALcoKpRABF5EDgHKBSRCuB/VPV3OAnhERH5FLAbuOq4vuL30NDWSU6af9DOLyLkZwTIzwgwa0zOu7a3h6Psqm1hR3ULO6qb2VbVzFsHmnhxazXRmJMxMgJepo/OZsbobGaX5TB3XC7lhZmWLIwxx4VoX43jw8iCBQv0eH2P4WO/fY3OSIxlnzv9uJzveGkPR9lW1czmykY273ceWyobaeqIAJAV8jFnbC5zx+Yyd1wec8bmkpcRSHDUxphkJiJrVHVBz/XWgN1DQ1uYUdn9NwclQsjvZdaYnG61jFhM2VHTzBt76nljbz1v7KnnV89vw61YMLk4k1Mn5nNaeQGnludTnJV8r8sYk3wsMfRQ3xpm2qisRIcxIB6PMLk4i8nFWfzzAqePv6UjwoZ9DazdU8eqnYf487pK/rByDwDlRRlOkpiYz+mTCinKCiYyfGNMkrLE0ENjW5jctOHbBJMR9HFaeQGnlRfw+XMgEo2xqbKR13bUsnLnIR5fV8kDbqKYWZrN2VOLWDS1iHnj8gj4bExFY4wlhm7C0RhNHZFB7Xweaj6vh5PG5nLS2Fw+u2gS0ZiyqbKBl96p4cWt1fx2xQ5ue2E7GQEvCycVsmhaEYumFDGuID3RoRtjEsQSQ5zGtjAAuekjJzH05PUIs8tymV2Wyw3nTqapPcwr22tZsbWaF7dW88yWg4DTP3HhjBIunFHCnLJcu+PJmBRiiSFOQwokhp6yQn4umjmKi2aOQlXZWdNyOEF01SaKsoJccEIxF84o4fRJhYT83vc+sTFm2LLEEKfeTQzZI6gp6WiICOVFmZQXZfLJMybS0Brm+bereHrzQZavq+TBVXtJD3hZNLWIxbNGccEJJWQE7S1kzEhjf9VxGlrdGkOKJoaectL9XD53DJfPHUNHJMqr22t5evNBnt58kCc3HiDo83De9GIunV3KudOLbPgOY0YI+0uO09WUNJI6n4+XoM/LOdOKOWdaMd9ZMovVu+v465uV/HXDAZ7ceIA0v5fzTyjm0tmjOWdasTU3GTOMWWKIU9/aCUBu+vC9XXUoeDzCKRPzOWViPt+8bCardh7iL29W8reNB/jLm/vJCHhZPGs0V8wbw2nlBXit49qYYcUSQ5yGNmd4ieyQFctAeT3CwkkFLJxUwLc+OJOVOw+xfF0lT2zYz6NrKxidE2LJnDFcMW8MU0uGxxcHjUl19gkYp76tk6ygD5/Xvuh1LHxeD2dMLuSMyYV8a8lMntlykD+t3cdvX9rB7S9uZ9aYbD40t4wPnlRq37o2JolZYojT0OoMuW3ev5Dfy6WzS7l0dik1zR08vr6Sx9bu4zt/2cz3n9jC2VMK+cjJYzn/hBL8loiNSSqWGOI0tIVT6jsMQ6UwM8gnz5jIJ8+YyDsHm3jsjX38ae0+rv/9WgozA3x4XhlXnTyWSUWZiQ7VGIMlhm7q28J2R9Igm1KSxdcWT+crH5jGiq3VPPT6Hn738k5+s2IHp0zI5yMnj+WSE0eTFrC7moxJFEsMcepbO5k+KjvRYaQEr0c4d3ox504vpqqpncfW7uPh1/fy5T+u56blm1gyt5SrTx7X62RGxpjBZYkhTkNbJGW/9ZxIxVkhrl80ic+eXc6qnYd46PW9/HF1Bb9/bQ9zxuZyzWnj+afZo+27EcYMEev1c6kqDW2d1seQQCLCqeUF3PKROaz67wv4n8tm0Nge5st/XM/CHzzLD57Ywp7a1kSHacyIZzUGV2tnlHBUbTiMJJGT7ueTZ0zkX0+fwKvba7nv1d3c+fJO7nhpB4umFvGJheNZNLXYvjxnzCCwxOCy4TCSk4hw+uRCTp9cyP6GNh5ctZcHV+3h3+5ZTVleGh8/dTxXLSijINO+F2HM8WJNSa761tQbcnu4GZ2TxpcunMorS8/j1o/NoywvjZv/9hYLf/gcX1v2Jm8daEx0iMaMCFZjcB2pMdg4ScnO7/XwT7NH80+zR7P1YBP3vLKLx9ZW8PDqvZwxuYBPnj6R86YX2+RCxhwjqzG4GtqcAfSsKWl4mVqSxfc/dCKvLj2fry6exvaqFj5932rO+8kL3POPnTR3RBIdojHDjiUGlzUlDW95GQE+f85kXvraufzyo3PJywhw0+ObWfj9Z/nOXzaz95DdzWTMQFlTkss6n0cGv9fDZSeVctlJpbyxp467/7GLe1/Zxd3/2MmFM0r4tzMmcsrEfESsmcmYvlhicNW3hfF7hXQbimHEmDsuj7nj8rjxkunc/+puHli1h6c2HWR2WQ7XnV3O4pmjbCRdY3phfxWu+tYwOWkB+09yBBqdk8ZXF0/n1aXn893LZ9HUHuELD7zBuW4/RGun9UMYE88Sg6uxLUxOmlWgRrK0gJd/OW08z3xpEb+5Zj7FWSGnH+IHz/Hjp96mqqk90SEakxTsk9BV39ZpU3qmCK9HuGjmKC6aOYo1uw9xx4od3PrCNu5YsYMr5o3h02eVM7nYhgA3qcsSg6uhLUxJVijRYZghNn98Pr+5Jp+dNS3c+dIOlq2p4KHX93LBCcVcd/YkTp6QZ82LJuVYU5LL6WOwO5JS1cTCDL73oRN5Zel5fPH8KazZXcdVv3mVy3/9Ck9s2E80pokO0ZghY4nBZdN6GoCCzCD/eeFUXll6Pt+5fBYNrZ18/g9rOf8nL/Dgqj10RKKJDtGYQWeJAYhEYzR1RKzGYA5LC3i55rTxPPvlc7jt4/PITvNz42MbOOvm57n9xe00tYcTHaIxg8b6GIDGdud2RRty2/Tk9QgXnziaxbNG8er2Wm57cTs/fPItbn1+G9ecNp5PnjGRoiwb2dWMLJYYcKb0BOyuJNOn+OG/N1Q0cPuL27ntxe3c+fJOrlpQxnVnTWJcQXqiwzTmuLDEgA2HYY7OiWU53Prxeeyobua3L+3gkdcreGDlHi6dXcr1iyYxo9TmDTfD24D6GERksYi8LSLbRGRpL9uDIvKwu32liEyI23aju/5tEbnovc4pIveIyE4RWec+5ry/l/je6rsSg3U+m6NQXpTJD66YzUtfO5fPnFXOs1sOcskvXuJf717Fyh21qNqdTGZ4es/EICJe4FbgYmAG8FERmdFjt08Bdao6GbgFuNk9dgZwNTATWAz8WkS8Azjnf6nqHPex7v28wIFo6BpZ1WoM5hiUZIe48ZITeGXp+fzXRdPYUNHAR+54jQ/f9gpPbz5IzG51NcPMQGoMpwDbVHWHqnYCDwFLeuyzBLjXXV4GnC/Ot4KWAA+paoeq7gS2uecbyDmHjDUlmeMhJ93PDedO5h9Lz+M7S2ZS1dTBZ+5bzUU/W8GjayoIR2OJDtGYARlIYhgD7I17XuGu63UfVY0ADUBBP8e+1zm/JyJvisgtIjLot3x0zcVgicEcDyG/l2sWTuCFr5zDz6+eg9cjfPmP6znnf1/gbhu0zwwDyfg9hhuB6cDJQD7wtd52EpHrRGS1iKyurq5+XxdsaAuTGfTZEMzmuPJ5PSyZM4Ynv3gWd//ryYzJTeNbj2/mjB8+x8+feYe6ls5Eh2hMrwbySbgPGBv3vMxd1+s+IuIDcoDafo7t85yqul8dHcDdOM1O76Kqd6jqAlVdUFRUNICX0bf6tk6rLZhBIyKcO72YR65fyLLrFzJ/fB63PLOVM25+jm8/vpnK+rZEh2hMNwNJDK8DU0RkoogEcDqTl/fYZzlwrbt8JfCcOrdkLAeudu9amghMAVb1d04RGe3+FOByYOP7eH0D0tAatik9zZBYMCGfO689maf+42wWzxzFfa/u4uwfPc+XHlnH1oNNiQ7PGGAA32NQ1YiIfAF4CvACd6nqJhH5NrBaVZcDvwPuF5FtwCGcD3rc/R4BNgMR4AZVjQL0dk73kn8QkSJAgHXA9cft1fahoc0G0DNDa9qoLH76kTl8+aJp3PnSDh5atZfH1u7j/OnFfHaRjepqEktGwr3WCxYs0NWrVx/z8Rf89EWmlmTy64/PP45RGTNwdS2d3Pfqbu59dReHWjqZNy6X6xdN4oITSvB4LEGYwSEia1R1Qc/11tvKkWk9jUmUvIwAX7xgCv/42nl8273V9br71/CBn63gkdV76YzYra5m6KR8YlBVd1pPa0oyiZcW8PKJuFtd/V4PX132Jmf/6Hl+u2KHjepqhkTKJ4a2cJTOaMw6n01S6brV9Yl/P5N7/+0UZyKhJ7Zw+g+f40d/e4vqpo5Eh2hGsJQfRM++9WySmYiwaGoRi6YWsX5vPb9ZcWRU1yvnl3HdWeVMKMxIdJhmhEn5xFBv4ySZYeKksbn8+uPz2VnTwh0rnPmpH1y1h4tnjeL6RZOYXZab6BDNCGGJodVGVjXDy8TCDH5wxYn854VTuOcfu7j/td08seEAp08q4LOLJnH2lEK71dW8Lynfx2BNSWa4Ks4K8dXF03ll6Xn89yXT2V7dzLV3reKin63gkdf30h62+anNsbHE0Gazt5nhLSvk57qzJ/HSV8/jJ/98El6Ph68++iZn3uyMyVTbbB3V5uhYU5L1MZgRIuDz8OH5ZVwxbwyvbq/lzpd3csszW/n1C9u4Yt4YPnXmRCYXZyU6TDMMpHxiaGgL4/MI6QFvokMx5riIn596W1Uzv3t5J4+treDBVXs5Z1oRnzmrnNMnFVg/hOlTyjcl1bc5A+jZH4kZiSYXZ/KDK07klaXn8aULp7JxXwMfv3MlF//8JZatqaAjYv0Q5t1SPjE0tIbJtmYkM8IVZAb59/On8PLXzuNHV85GFb7yx/WcefPz3PL0Vqoa2xMdokki1pTUFrb+BZMyQn4vVy0Yyz/PL+PlbTXc9fJOfv7sO9z6/DYuOXE0154+gXnjcq0GneJSPjHUt3VSnBVKdBjGDCkR4awpRZw1pYhdNS3c9+pu/rh6L8vXVzJrTDbXLpzAZSeVEvJb31sqsqYkG0DPpLgJhRl887IZvPbf5/Pdy2fREY7xX8vePDwu0z6bYS7lWI2h1RKDMQAZQR//ctp4Pn7qOF7dXss9r+zi9he3c/uL2/nAjFF8YuF4FtrdTCkhpRNDNKY0tUdsZFVj4sTf7lpR18rvX9vDQ6/v4W+bDjCxMIOrTx7LlfPLKMgMJjpUM0hSuimp0YbDMKZfZXnpLL14Oq/deD63fOQkCjMD/ODJt1j4g+f4fw++wSvbaxgJs0Ca7lK6xlDvJgarMRjTv5Dfy4fmlvGhuWW8c7CJB1bt4dE1FTy+vpKJhRl89JSxXDl/LPkZNrTMSJDSNYb6VmecJKsxGDNwU0qy+J/LZrLq6xfw06tOoiAjwPefeIvTvv8s/+/BN3j5nRpiMatFDGcpXWM4MrKq/ZdjzNEK+b1cMa+MK+aVsfVgEw+s3MNja51aRGlOiCvmlfHh+WVMtImEhh1LDFhTkjHv19SSLG764EyWXjydpzcfZNmaCn79wjZ+9fw2FozP48r5ZfzT7NFkhexvbTiwxIA1JRlzvIT8Xi47qZTLTirlQEM7f3pjH8vW7GXpYxu46fFNLJ45ig/PL+P0SYV4PXbba7JK6cRwePY2SwzGHHejckJ87pxJXL+onHV761m2poLl6yv5v3WVFGUF+acTR/PBOaXMHWtDcCSblE8MmUEffm9K98EbM6hEhLnj8pg7Lo9vXDqDZ7YcZPm6Sh5YuYd7XtnF2Pw0LptdygfnlDJ9VHaiwzWkeGKw4TCMGVohv5dLZ5dy6exSGtrCPLXpAI+vr+T2F7fz6xe2M7Ukkw+6TVHjC6zTOlFSPDF0WmIwJkFy0vxctWAsVy0YS01zB09s2M/ydZX8+O9b+fHft3LC6GwumlnC4lmjmFaSZc1NQ0hGwrcWFyxYoKtXrz7q4/68bh8tHVE+duq4QYjKGHMsKupaeXLDAZ7adIA1e+pQhfEF6SyeOYoPzBzF3LG5eKzj+rgQkTWquuBd61M5MRhjkltVUztPbz7IU5sO8sq2GiIxpTgryIUzSjh3WjGnTy4gPZDSDR/viyUGY8yw1tAW5vm3qnhq0wFe3FpNa2eUgNfDqeX5nDOtmHOnFTGxMMOanI6CJQZjzIjREYny+s46Xni7iuffrmJ7dQvgNDmdO62YRVOLOHliPplBq030xxKDMWbE2lPbygtbq3jh7Wpe2V5DeziG1yOcVJbDwkkFnD6pkPnj82xGuh4sMRhjUkJ7OMrqXXW8uqOGV7bX8mZFA9GYEvB6mDsul9MnFXJaeT6zy3JJC6R2orDEYIxJSc0dEV7feYhXttfw6o5aNlU2ogo+jzCjNJt54/KYNz6PeeNyGZObllJ9FJYYjDEGZ7j9NbvrWLunjjW761i/t4G2cBSA4qwgc8flMqs0h1ljcphZmk1xdijBEQ+evhKD9cwYY1JKbnqA808o4fwTSgCIRGO8daApLlHU89Smg4f3L8oKMqs0m5mlOcwozWZKcSbjCzII+EbuUDoDSgwishj4OeAF7lTVH/bYHgTuA+YDtcBHVHWXu+1G4FNAFPh3VX2qv3OKyETgIaAAWANco6qd7+9lGmNM73xeD7PGODWETyycAEBTe5gt+5vYuK+BjZUNbK5sZMU7NUTdCYh8HmFcQTpTijOZ7D4mFWUyNi+d3HT/sG+Oes+mJBHxAluBC4EK4HXgo6q6OW6fzwOzVfV6Ebka+JCqfkREZgAPAqcApcAzwFT3sF7PKSKPAI+p6kMicjuwXlVv6y9Ga0oyxgy29nCUbVXNbKtq5p2qpsPLu2tbicTNWJcZ9FGWl0ZZXjpj89MYm5fOmLw0irOCFLmPoC85Or3fT1PSKcA2Vd3hnughYAmwOW6fJcBN7vIy4FfipMwlwEOq2gHsFJFt7vno7ZwisgU4D/iYu8+97nn7TQzGGDPYQn7v4ZpFvM5IjN21LeyoaWHvoVYq6tqoqGtl76FWXtleQ2tn9F3nyknzO0kiM0hhVpDskI+skJ+skI/skI/sNGc5M+gn6PPg93oI+DwE3J9+r+D3efCIkO73HvchQgaSGMYAe+OeVwCn9rWPqkZEpAGnKWgM8FqPY8e4y72dswCoV9VIL/sbY0zSCfg8TCnJYkpJ1ru2qSqHWjqprG+nurmd6qYOqho7qG7uoLrJeWyoqKepPUJje5hw9OhvBnrmS4uYXJx5PF7KYcO281lErgOuAxg3zgbBM8YkHxGhIDNIQWYQyOl3X1WlIxKjsT3sJIq2MM0dETojMcLRGB2RGOGoHn4ejsaIqVKYefznrB9IYtgHjI17Xuau622fChHx4ZRA7Xsc29v6WiBXRHxuraG3awGgqncAd4DTxzCA12GMMUlLRAj5vYT8XorfXfkYUgO53+p1YIqITBSRAHA1sLzHPsuBa93lK4Hn1OnVXg5cLSJB926jKcCqvs7pHvO8ew7cc/752F+eMcaYo/WeNQa3z+ALwFM4t5bepaqbROTbwGpVXQ78Drjf7Vw+hPNBj7vfIzgd1RHgBlWNAvR2TveSXwMeEpHvAm+45zbGGDNERsQ3n0WkGth9jIcXAjXHMZzBZvEOLot38A23mEdyvONVtajnyhGRGN4PEVnd2328ycriHVwW7+AbbjGnYrwj9zvdxhhjjoklBmOMMd1YYnBveR1GLN7BZfEOvuEWc8rFm/J9DMYYY7qzGoMxxphuLDEYY4zpJqUTg4gsFpG3RWSbiCxNdDy9EZFdIrJBRNaJyGp3Xb6IPC0i77g/8xIY310iUiUiG+PW9RqfOH7hlvebIjIvSeK9SUT2uWW8TkQuidt2oxvv2yJyUQLiHSsiz4vIZhHZJCJfdNcnZRn3E29SlrGIhERklYisd+P9lrt+ooisdON62B2hAXcUh4fd9StFZEKSxHuPiOyMK9857vpjez+oako+cL5xvR0oBwLAemBGouPqJc5dQGGPdT8ClrrLS4GbExjf2cA8YON7xQdcAjwJCHAasDJJ4r0J+Eov+85w3xdBYKL7fvEOcbyjgXnuchbOPCYzkrWM+4k3KcvYLadMd9kPrHTL7RHganf97cDn3OXPA7e7y1cDDw9x+fYV7z3Alb3sf0zvh1SuMRyeZ0KdGeK65pkYDpbgzFWB+/PyRAWiqitwhkGJ11d8S4D71PEazoCJo4ckUFcf8fbl8HwiqroTiJ9PZEio6n5VXesuNwFbcIaiT8oy7ifeviS0jN1yanaf+t2H4swLs8xd37N8u8p9GXC+yNBN19ZPvH05pvdDKieG3uaZSMa5HxT4u4isEWeocYASVd3vLh8AShITWp/6ii+Zy/wLblX7rrimuaSK1222mIvzX2LSl3GPeCFJy1hEvCKyDqgCnsaptdRr7/PCdJt7BuiaeyZh8apqV/l+zy3fW8SZbrlbvK4BlW8qJ4bh4kxVnQdcDNwgImfHb1Snvpi09xwne3yu24BJwBxgP/CThEbTCxHJBB4F/kNVG+O3JWMZ9xJv0paxqkZVdQ7OMP+nANMTG1H/esYrIrOAG3HiPhnIxxmM9JilcmIYyDwTCaeq+9yfVcCfcN64B7uqg+7PqsRF2Ku+4kvKMlfVg+4fWwz4LUeaMpIiXhHx43zI/kFVH3NXJ20Z9xZvspcxgKrW4wz7vxB3XpheYjocr3Sfe2bIxcW72G3CU3WmUb6b91m+qZwYBjLPREKJSIaIZHUtAx8ANtJ9/otknLOir/iWA59w75Q4DWiIaw5JmB5trh/CKWPoez6RoYxNcIae36KqP43blJRl3Fe8yVrGIlIkIrnuchpwIU6/SF/zwvQ190wi430r7p8EwekPiS/fo38/DGWPerI9cHrst+K0KX490fH0El85zh0b64FNXTHitGk+C7wDPAPkJzDGB3GaBsI47Zef6is+nDsjbnXLewOwIEnivd+N5033D2l03P5fd+N9G7g4AfGeidNM9Cawzn1ckqxl3E+8SVnGwGyceV/exPkw/aa7vhwnQW0D/ggE3fUh9/k2d3t5ksT7nFu+G4Hfc+TOpWN6P9iQGMYYY7pJ5aYkY4wxvbDEYIwxphtLDMYYY7rxvfcuya+wsFAnTJiQ6DCMMWZYWbNmTY32MufziEgMEyZMYPXq1YkOwxhjhhUR2d3bemtKMsYY001KJ4b1e+tZuSMhX1o0xpikldKJ4WfPbOW7f92S6DCMMSappHRiCPq8dESiiQ7DGGOSSkonhpDfQ3s4lugwjDEmqaR0YrAagzHGvFtKJwarMRhjzLuldGII+q3GYIwxPaV0Ygj5nBqDjTBrjDFHpHRiCPq9AHRGrTnJGGO6pHZi8Dkv3/oZjDHmiJRODCG3xmD9DMYYc0RKJ4auGkOH1RiMMeawpEsMIjJWRJ4Xkc0isklEvjhY17IagzHGvFsyDrsdAb6sqmtFJAtYIyJPq+rm430h62Mwxph3S7oag6ruV9W17nITsAUYMxjX6qoxtIetxmCMMV2SLjHEE5EJwFxg5WCc/3AfQ8RqDMYY0yVpE4OIZAKPAv+hqo29bL9ORFaLyOrq6upjuobVGIwx5t2SMjGIiB8nKfxBVR/rbR9VvUNVF6jqgqKid01ZOiBBv9UYjDGmp6RLDCIiwO+ALar608G8VshnNQZjjOkp6RIDcAZwDXCeiKxzH5cMxoWsxmCMMe+WdLerqurLgAzFtazGYIwx75aMNYYhc+QLblZjMMaYLimdGI58wc1qDMYY0yWlE4PHIwS8HqsxGGNMnJRODODUGqzGYIwxR1hi8HutxmCMMXEsMViNwRhjukn5xBDyW2Iwxph4KZ8YxuWns62qOdFhGGNM0kj5xDB/fB5bDzbT0BZOdCjGGJMUUj4xzBuXB8Abe+oSHIkxxiSHlE8MJ43NxSOwdk99okMxxpikkPKJISPoY/qobNbuthqDMcaAJQYA5o3PZd3eeqIxZeO+Bm74w1rCUftugzEmNVliwOmAbu6IsPVgE9fetYq/btjP3kOtiQ7LGGMSwhIDMH9cPgAPrNxDbUsnAHWtnYkMyRhjEsYSAzCuIJ1PLBzP/a/tPryuuskSgzEmNVlicH3rgzPJS/cffl7T3JHAaIwxJnEsMbhEhIeuW8gpE51mJUsMxphUZYkhzrRRWTzy2YXkpvstMRhjUpYlhl4UZgapbbY+BmNMarLE0IvCzIDVGIwxKcsSQy8KM4Psrm3lSw+v455/7Ex0OMYYM6QsMfSiKCtIVVMHj72xj8fe2JfocIwxZkj5Eh1AMvr4qeMpyQ6xZncdGyoaEh2OMcYMKasx9GJycSbXL5rElOJMapo7iMU00SEZY8yQscTQj+KsIJGYcsiGxzDGpBBLDP0ozg4BUNVodygZY1KHJYZ+FGcFAahqak9wJMYYM3QsMfSjOMutMTRZjcEYkzqSMjGIyF0iUiUiGxMZR3G2U2OotsRgjEkhSZkYgHuAxYkOIuT3khXycbDRmpKMMakjKRODqq4ADiU6DoAJBRlsr25OdBjGGDNkkjIxJJNZY7JZv7eBXz77Dq/vSopcZYwxg2rYJgYRuU5EVovI6urq6kG7zszSHJo7Ivzk6a388+2vsvVg06BdyxhjksGwTQyqeoeqLlDVBUVFRYN2nVljcro931ZlzUrGmJFt2CaGoTJ9VBYA88blAnCoxb4FbYwZ2ZIyMYjIg8CrwDQRqRCRTyUqlpDfy8tfO5fff/pUwBKDMWbkS8rRVVX1o4mOIV5ZXjoAWSGfJQZjzIiXlDWGZJWfEaDOBtQzxoxwlhiOQn5GwGoMxpgRzxLDUchPtxqDMWbks8RwFPIyAhxq7qSirpXWzkiiwzHGmEFhieEo5GcEqGxo58ybn+fSX76c6HCMMWZQWGI4Cjlp/sPLO6pbaO6wWoMxZuSxxHAUOiMxABaWFwCwq6YlkeEYY8ygSMrvMSSrfz19AukBL6dPKuSyX73MrtqWdw2ZYYwxw50lhqOQlxHgs4smHe543lltNQZjzMhjTUnHID3gY1R2iJ21lhiMMSOPJYZjVF6UwVv7m7jsly9z2wvbEx2OMcYcN5YYjtEZkwvZvL+RDfsauPlvb9m80MaYEcMSwzFaPGtUt+d/XrcvQZEYY8zxZZ3Px2hSUSYnleVQXpTJiq3VNi+0MWbEsMTwPjz82YV4RPjob19jh92hZIwZIawp6X0I+b0EfB4mFmawq7aFjfsauPOlHahqokMzxphjZonhOJhYmMHBxg4u/eXLfPevW9h60JqVjDHDlyWG42BCQUa35xv2NSQoEmOMef8sMRwHJ4zOAuC/LppGesDLRksMxphhzDqfj4Pyokxe//oFFGUFeeHtKjbsa2DZmgq2HmziyvllTC3JSnSIxhgzYJYYjpOirCAA88bn8ZsXd7Bmdx3gDM9957ULEhmaMcYcFUsMx9kXz59CUWaQkN/L+r31/H3zQZ7ZfJAf/u0tbv+X+Uwuzkx0iMYY0y/rYzjO0gM+Pn1WOf9y2ngWTiqgoS3Mp+9bzbaqZvt2tDFmWLAawyA6ZWL+4eVpJVk8s6WKkN/Ly+/U8NXF05g7Lo+OSJSgz5vAKI0xpjurMQyisrx0vn7JCTz5xbO4cn4ZW/Y38r9Pvc0be+v4zH2ruf+13cz85lM8sHJPokM1xpjDrMYwyD5zdjkAY/PTiari8wgzRmfzsTtX8o3/2wjArc9vo7kjzGNr9/G/V57ErDHZPPdWFZOLMxnf4zsSxhgz2GQkDN+wYMECXb16daLDGDBV5YYH1pLm93FqeT5fXfYmAEGfB69HmD4qi7V76pk1Jpv/vGAqf1i5hxvOncS8cXlU1LWRHfKTk+5P8Kswxgx3IrJGVd9126QlhgQLR2Pc+8ouSnPTmDcuj0/d+zoVdW2cO62I/1tXCYDPIwCML0hne3ULEwrS+e9LTuCBVXs4eUI+S+aU8qe1+/B4hM8tmsSh1k7y0gN4PYKqElPwuucwxpgulhiGiUg0Rjiq+LzClx9Zz7RRWXzk5LH8+Km32bCvgRNGZ7NsTQUA+RkBDrV0dju+JDvIwcYOppZkMn98Pn99sxIR4RuXzuBvGw8A8PlzJ7GhooGAz8MHZpSwvbqFSCzGwvIC9h5qozMaZVJRJiKWTIwZySwxjCD3v7abaDTGx04dz8qdtfzfG5Vcd3Y53/3rZjZVNvJvZ0xg2ZoKDjS2c8EJJayvqGfvoTayQz7CUaUtHO31vOML0tld2wrAnLG5NLaHqW3u5MwpheypbaUzEuOsKYUcaGznQEM7F584moDPw57aFiYWZpIV8rF+bz1nTS0iO+RjV20LBRlB8jMCrNtbz4zSbGaV5rDnUCtleWmIwM6aFoqzQuRnBGjtjBDyefG4NR1LTMYMrmGVGERkMfBzwAvcqao/7G//VEsMfQlHY0RjSsjf/fbXnTUtPLvlIP88fyxt4ShrdtcxtSST9nCMv28+wMzSbPYcamXVzjrmjM0h5Pdy+4vbmTYqi6ygnzf21jGlOAuPR3jpnWpy0/yUZId460ATAAGvh85oDACPQKyPt5RHwOdx9vV5hDS/l6aOCAGfh9E5IXbXtpKX7icnzc/eujZGZYeYXZbDpspGfB6hvCiD6qYO0gM+JhRmsK++jYBXmFycxa6aFurbOlk0tZhDLR1UN3UwpSSL+tZO2sJRZozOoaUjwsHGdiYVZxKNKe3hKEVZQfxeD/sb2ikvzCDgc+LLDPrwez1sr2pmYlEGGQEfda2dBH0eirND7KtrIzPoI+T3UNPcSVFWkKKsIFWN7YgI4/LTiamibjPegcZ2Al4PhZkBapo7ialSkBHA5/UcToKxmBJTxecd+M2ClkDN+zFsEoOIeIGtwIVABfA68FFV3dzXMZYYhk5VUztZQT8hv4cdNS0EvB7K8tLYvL+RcFSZXJzJ4+sryUsPMLk4k8r6NupaO5lZmsOjayuIxpQpxZnsrGmhprmDMyYXsnLnIQ41d3LC6Gz2N7TR0BZmfEEGmyob2FXbwoljcojFYHt1M8XZQZrbI+x2ax2NbREq69sYk5dGyOfl7YNNBHwe8tL9HGzsIODzEPJ5aGyPAN2T2FARga4/s5DfQ3s4dni9ACJCSVaQmmanWTAn3U97ZxQRCPq9qEJTe5iCjAAigscDhZlBDrV0UlnfxqSiTPxeDzF1/imIxJSG1k5y0wN4BCKxIwnK7xW8HsHn8eDzCj532esuVzd10B6O4hHBI4IIzrIH97ng6Von9Hget78c2V8EmtsjeL1CdshHW2eUcMxJjM0dESJRdfb3OOfwihBVpSMSIzPoJRpTmtojFGYGiarS3hkl4PMgInRGYqQHvPi8QiSq7mt1CtvjcV6TR5zX7BHoiMQQICPoo7UzirqJWADlyO/JI+DzeojP0YLzWpxl5xco7u/xXb9z5PBr6iqTmCox93fRn/hj4uNSjhzb9Q9B0Ofhw/PKyMsIHM1b8kicwygxLARuUtWL3Oc3AqjqD/o6xhKDAeePpaKujZLsEAGfh9bOCF6PEPB62FnTQm56gOyQj/0N7QR9HoJ+L3sPtSICxVkhdrjTs/p9HupbOwlHlfLCDLYcaMIjkJfufJBVN3VQlpdGXWsnqlCQ6dQUapo7KckO0hGJUdXYcfhDpT0cozQ3jeaOMAcaOhiXn4bX66G6sZ2YOh/cBxraKMkJgUJDW5iQ34uq0hmNoQqZQR/1beHDHy4HGtspyAhSkh1iV60ze6AAbeEoXo+Qk+anvjUMgM/rfMBEYko0pu4HaIxIL8v5GQGyQj73Ohyu9cRU3QeHb2jo/vzIum77u+fICDrnbGyLkBbw4BXhUEsnWSE/AZ+HqBtbTJ2fXo8Q8ntpao/g8wgZQS9VTR0EfR5Cfi+dkRgxVYI+Ly2dEaJuv5zX46HrPouuc0Vi6tbGnMQcjSmtnVHS/F5EIBpXxRX3wziqTnnE3M9Hdd9fR5YH+c18FJ778iLKi45tqJ2+EkMyfo9hDLA37nkFcGrPnUTkOuA6gHHjxg1NZCapiQhj89MPP08PHHl7x//hxO+TMybn8HLXQIg9TbHRcU0f+vrHWuMSZ1eSjK9V9dX4p3HHdv109o+rrbjPFaU97DR7Hm/JmBgGRFXvAO4Ap8aQ4HCMMSmor/4dEfD0+fF//AzWcDrJOCTGPmBs3PMyd50xxpghkIyJ4XVgiohMFJEAcDWwPMExGWNMyki6zmcAEbkE+BnO7ap3qer33mP/amD3MV6uEKg5xmMTweIdXBbv4BtuMY/keMeralHPlUmZGIaSiKzurVc+WVm8g8viHXzDLeZUjDcZm5KMMcYkkCUGY4wx3VhicG95HUYs3sFl8Q6+4RZzysWb8n0MxhhjurMagzHGmG5SOjGIyGIReVtEtonI0kTH0xsR2SUiG0RknYisdtfli8jTIvKO+zMvgfHdJSJVIrIxbl2v8YnjF255vyki85Ik3ptEZJ9bxuvc26W7tt3oxvu2iFyUgHjHisjzIrJZRDaJyBfd9UlZxv3Em5RlLCIhEVklIuvdeL/lrp8oIivduB52v1OFiATd59vc7ROSJN57RGRnXPnOcdcf2/tBVVPygfMdie1AORAA1gMzEh1XL3HuAgp7rPsRsNRdXgrcnMD4zgbmARvfKz7gEuBJnKFiTgNWJkm8NwFf6WXfGe77IghMdN8v3iGOdzQwz13Owhl5eEaylnE/8SZlGbvllOku+4GVbrk9Alztrr8d+Jy7/Hngdnf5auDhIS7fvuK9B7iyl/2P6f2QyjWGU4BtqrpDVTuBh4AlCY5poJYA97rL9wKXJyoQVV0BHOqxuq/4lgD3qeM1IFdERg9JoK4+4u3LEuAhVe1Q1Z3ANpz3zZBR1f2qutZdbgK24Aw0mZRl3E+8fUloGbvl1Ow+9bsPBc4Dlrnre5ZvV7kvA86XvgZMGgT9xNuXY3o/pHJi6G0U1/7ewImiwN9FZI04I8oClKjqfnf5AFCSmND61Fd8yVzmX3Cr2nfFNc0lVbxus8VcnP8Sk76Me8QLSVrGIuIVkXVAFfA0Tq2lXlUjvcR0OF53ewNQkMh4VbWrfL/nlu8tItI1VPAxlW8qJ4bh4kxVnQdcDNwgImfHb1Snvpi0t5Yle3yu24BJwBxgP/CThEbTCxHJBB4F/kNVG+O3JWMZ9xJv0paxqkZVdQ7OgJ2nANMTG1H/esYrIrOAG3HiPhnIB772fq6RyolhWIziqqr73J9VwJ9w3rgHu6qD7s+qxEXYq77iS8oyV9WD7h9bDPgtR5oykiJeEfHjfMj+QVUfc1cnbRn3Fm+ylzGAqtYDzwMLcZpcuqYliI/pcLzu9hygdmgjdcTFu9htwlNV7QDu5n2WbyonhqQfxVVEMkQkq2sZ+ACwESfOa93drgX+nJgI+9RXfMuBT7h3SpwGNMQ1hyRMjzbXD+GUMTjxXu3eiTIRmAKsGuLYBPgdsEVVfxq3KSnLuK94k7WMRaRIRHLd5TScKYW34HzgXunu1rN8u8r9SuA5t8aWyHjfivsnQXD6Q+LL9+jfD0PZo55sD5we+604bYpfT3Q8vcRXjnPHxnpgU1eMOG2azwLvAM8A+QmM8UGcpoEwTvvlp/qKD+fOiFvd8t4ALEiSeO9343nT/UMaHbf/19143wYuTkC8Z+I0E70JrHMflyRrGfcTb1KWMTAbeMONayPwTXd9OU6C2gb8EQi660Pu823u9vIkifc5t3w3Ar/nyJ1Lx/R+sG8+G2OM6SaVm5KMMcb0whKDMcaYbiwxGGOM6cYSgzHGmG4sMRhjjOnGEoMxxphuLDEYY4zpxhKDMcaYbv4/pwtfhYbr4wsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class AWSWTrainer(Trainer):\n",
    "    def _get_train_sampler(self):\n",
    "        return None\n",
    "    \n",
    "class AWSWTrainerCallback(TrainerCallback):\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        learning_rate_history = [h['learning_rate'] for h in state.log_history if 'loss' in h]\n",
    "        loss_history = [h['loss'] for h in state.log_history if 'loss' in h]\n",
    "        fig, axs = plt.subplots(2)\n",
    "        fig.suptitle('Learning rate and loss')\n",
    "        axs[0].plot(learning_rate_history)\n",
    "        axs[1].plot(loss_history)\n",
    "        \n",
    "def train(model):\n",
    "    optimizer, scheduler = get_optimizer_and_scheduler(model.parameters())\n",
    "    training_args = TrainingArguments(\n",
    "        models_dir,\n",
    "        seed=seed,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=num_epoch,\n",
    "        save_total_limit=2,\n",
    "        save_steps=500,\n",
    "        logging_steps=250\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model, \n",
    "        args=training_args, \n",
    "        train_dataset=dataset['train'],\n",
    "        optimizers=(optimizer, scheduler),\n",
    "        callbacks=[AWSWTrainerCallback]\n",
    "    )\n",
    "    checkpoint_dirs = [os.path.join(models_dir, d) for d in os.listdir(models_dir) if os.path.isdir(os.path.join(models_dir, d))]\n",
    "    if len(checkpoint_dirs) > 0:\n",
    "        latest_checkpoint = max(checkpoint_dirs, key=os.path.getmtime)\n",
    "        trainer.train(latest_checkpoint)\n",
    "    else:\n",
    "        trainer.train()\n",
    "\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unxN7nYd2gOM",
    "tags": []
   },
   "source": [
    "# Testing\n",
    "\n",
    "We created a few past (for context) + present prompts (player input) and see the different reactions. This way, we can test the models across different iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5UePGmLD2gON"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "\n",
      "Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_dragon_reply(past, prompt, top_k=None, top_p=None):\n",
    "    block_size = 128\n",
    "    model.eval()\n",
    "    prompt = f'{past} PlayerReply c \"{prompt}\" DragonReply'\n",
    "    generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "    generated = generated.to(device)\n",
    "\n",
    "    sample_outputs = model.generate(\n",
    "        generated, \n",
    "        do_sample=(top_k is not None and top_p is not None),\n",
    "        top_p=top_p,\n",
    "        top_k=top_k,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        max_length=block_size,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    return tokenizer.decode(sample_outputs[0], skip_special_tokens=False)[len(prompt):].strip()\n",
    "\n",
    "prompts = [\n",
    "    ('PlayerReply c \"Hey Remy!\" DragonReply Ry \"Hey!\"', \"How are you?\"),\n",
    "    ('PlayerReply c \"I was with Lorem today.\" DragonReply Ad \"That\\'s awesome. He\\'s a cute fellow.\"', \"What do you think of Lorem?\"),\n",
    "    ('DragonReply m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('DragonReply m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "# Set a fixed seed to make sure we get the same response every time.\n",
    "torch.manual_seed(80085)\n",
    "for (past, prompt) in prompts:\n",
    "    reply = generate_dragon_reply(past, prompt)\n",
    "    print(f\"Prompt: {prompt}\\nReply: {reply}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OZarUHg2gON"
   },
   "source": [
    "# Sampling test\n",
    "\n",
    "Which combination is the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bWoLzL9B2gON"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test 1 top_k: 88, top_p: 0.65] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 1 top_k: 88, top_p: 0.65] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 1 top_k: 88, top_p: 0.65] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 1 top_k: 88, top_p: 0.65] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 2 top_k: 80, top_p: 0.08] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 2 top_k: 80, top_p: 0.08] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 2 top_k: 80, top_p: 0.08] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 2 top_k: 80, top_p: 0.08] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 3 top_k: 47, top_p: 0.54] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 3 top_k: 47, top_p: 0.54] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a particularly good idea.\"<|endoftext|>\n",
      "\n",
      "[Test 3 top_k: 47, top_p: 0.54] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 3 top_k: 47, top_p: 0.54] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 4 top_k: 46, top_p: 0.77] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 4 top_k: 46, top_p: 0.77] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 4 top_k: 46, top_p: 0.77] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 4 top_k: 46, top_p: 0.77] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 5 top_k: 13, top_p: 0.54] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 5 top_k: 13, top_p: 0.54] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a particularly good idea.\"<|endoftext|>\n",
      "\n",
      "[Test 5 top_k: 13, top_p: 0.54] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 5 top_k: 13, top_p: 0.54] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 6 top_k: 94, top_p: 0.15] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 6 top_k: 94, top_p: 0.15] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 6 top_k: 94, top_p: 0.15] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 6 top_k: 94, top_p: 0.15] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 7 top_k: 47, top_p: 0.09] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 7 top_k: 47, top_p: 0.09] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 7 top_k: 47, top_p: 0.09] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 7 top_k: 47, top_p: 0.09] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 8 top_k: 93, top_p: 0.65] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 8 top_k: 93, top_p: 0.65] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 8 top_k: 93, top_p: 0.65] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 8 top_k: 93, top_p: 0.65] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 9 top_k: 75, top_p: 0.7] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 9 top_k: 75, top_p: 0.7] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 9 top_k: 75, top_p: 0.7] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 9 top_k: 75, top_p: 0.7] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 10 top_k: 79, top_p: 0.69] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 10 top_k: 79, top_p: 0.69] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 10 top_k: 79, top_p: 0.69] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 10 top_k: 79, top_p: 0.69] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 11 top_k: 22, top_p: 0.54] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 11 top_k: 22, top_p: 0.54] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a particularly good idea.\"<|endoftext|>\n",
      "\n",
      "[Test 11 top_k: 22, top_p: 0.54] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 11 top_k: 22, top_p: 0.54] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 12 top_k: 9, top_p: 0.24] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 12 top_k: 9, top_p: 0.24] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 12 top_k: 9, top_p: 0.24] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 12 top_k: 9, top_p: 0.24] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 13 top_k: 91, top_p: 0.1] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 13 top_k: 91, top_p: 0.1] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 13 top_k: 91, top_p: 0.1] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 13 top_k: 91, top_p: 0.1] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 14 top_k: 10, top_p: 0.96] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 14 top_k: 10, top_p: 0.96] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 14 top_k: 10, top_p: 0.96] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 14 top_k: 10, top_p: 0.96] -> Prompt: What will we do here?\n",
      "Reply: An \"Hey, [player_name]. I'm not letting you distract me with something I didn't want to said.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 15 top_k: 50, top_p: 0.86] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 15 top_k: 50, top_p: 0.86] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 15 top_k: 50, top_p: 0.86] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 15 top_k: 50, top_p: 0.86] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 16 top_k: 6, top_p: 0.86] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 16 top_k: 6, top_p: 0.86] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 16 top_k: 6, top_p: 0.86] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 16 top_k: 6, top_p: 0.86] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 17 top_k: 54, top_p: 0.77] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 17 top_k: 54, top_p: 0.77] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 17 top_k: 54, top_p: 0.77] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 17 top_k: 54, top_p: 0.77] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 18 top_k: 57, top_p: 0.73] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 18 top_k: 57, top_p: 0.73] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 18 top_k: 57, top_p: 0.73] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 18 top_k: 57, top_p: 0.73] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 19 top_k: 35, top_p: 0.15] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 19 top_k: 35, top_p: 0.15] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 19 top_k: 35, top_p: 0.15] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 19 top_k: 35, top_p: 0.15] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 20 top_k: 47, top_p: 0.57] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 20 top_k: 47, top_p: 0.57] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a particularly good idea.\"<|endoftext|>\n",
      "\n",
      "[Test 20 top_k: 47, top_p: 0.57] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 20 top_k: 47, top_p: 0.57] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 21 top_k: 100, top_p: 0.56] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 21 top_k: 100, top_p: 0.56] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a particularly good idea.\"<|endoftext|>\n",
      "\n",
      "[Test 21 top_k: 100, top_p: 0.56] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 21 top_k: 100, top_p: 0.56] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 22 top_k: 20, top_p: 0.07] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 22 top_k: 20, top_p: 0.07] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 22 top_k: 20, top_p: 0.07] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 22 top_k: 20, top_p: 0.07] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 23 top_k: 54, top_p: 0.63] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 23 top_k: 54, top_p: 0.63] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 23 top_k: 54, top_p: 0.63] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 23 top_k: 54, top_p: 0.63] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 24 top_k: 7, top_p: 0.62] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 24 top_k: 7, top_p: 0.62] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match in theThough.\"<|endoftext|>\n",
      "\n",
      "[Test 24 top_k: 7, top_p: 0.62] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 24 top_k: 7, top_p: 0.62] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 25 top_k: 59, top_p: 0.89] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 25 top_k: 59, top_p: 0.89] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 25 top_k: 59, top_p: 0.89] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 25 top_k: 59, top_p: 0.89] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 26 top_k: 91, top_p: 0.83] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 26 top_k: 91, top_p: 0.83] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 26 top_k: 91, top_p: 0.83] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 26 top_k: 91, top_p: 0.83] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 27 top_k: 22, top_p: 0.47] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 27 top_k: 22, top_p: 0.47] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 27 top_k: 22, top_p: 0.47] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 27 top_k: 22, top_p: 0.47] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 28 top_k: 9, top_p: 0.49] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 28 top_k: 9, top_p: 0.49] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 28 top_k: 9, top_p: 0.49] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 28 top_k: 9, top_p: 0.49] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 29 top_k: 31, top_p: 0.24] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 29 top_k: 31, top_p: 0.24] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 29 top_k: 31, top_p: 0.24] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 29 top_k: 31, top_p: 0.24] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 30 top_k: 74, top_p: 0.76] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 30 top_k: 74, top_p: 0.76] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 30 top_k: 74, top_p: 0.76] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 30 top_k: 74, top_p: 0.76] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 31 top_k: 41, top_p: 0.97] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 31 top_k: 41, top_p: 0.97] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 31 top_k: 41, top_p: 0.97] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 31 top_k: 41, top_p: 0.97] -> Prompt: What will we do here?\n",
      "Reply: An \"Hey, [player_name]. I'm not letting you distract me with something I didn't said.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 32 top_k: 86, top_p: 0.51] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 32 top_k: 86, top_p: 0.51] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 32 top_k: 86, top_p: 0.51] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 32 top_k: 86, top_p: 0.51] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 33 top_k: 86, top_p: 0.86] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 33 top_k: 86, top_p: 0.86] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 33 top_k: 86, top_p: 0.86] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 33 top_k: 86, top_p: 0.86] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 34 top_k: 25, top_p: 0.2] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 34 top_k: 25, top_p: 0.2] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 34 top_k: 25, top_p: 0.2] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 34 top_k: 25, top_p: 0.2] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 35 top_k: 40, top_p: 0.42] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 35 top_k: 40, top_p: 0.42] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 35 top_k: 40, top_p: 0.42] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 35 top_k: 40, top_p: 0.42] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 36 top_k: 84, top_p: 0.76] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 36 top_k: 84, top_p: 0.76] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 36 top_k: 84, top_p: 0.76] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 36 top_k: 84, top_p: 0.76] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 37 top_k: 89, top_p: 0.74] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 37 top_k: 89, top_p: 0.74] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 37 top_k: 89, top_p: 0.74] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 37 top_k: 89, top_p: 0.74] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 38 top_k: 9, top_p: 0.13] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 38 top_k: 9, top_p: 0.13] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 38 top_k: 9, top_p: 0.13] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 38 top_k: 9, top_p: 0.13] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 39 top_k: 56, top_p: 0.76] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 39 top_k: 56, top_p: 0.76] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 39 top_k: 56, top_p: 0.76] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 39 top_k: 56, top_p: 0.76] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 40 top_k: 20, top_p: 0.31] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 40 top_k: 20, top_p: 0.31] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 40 top_k: 20, top_p: 0.31] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 40 top_k: 20, top_p: 0.31] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 41 top_k: 80, top_p: 0.59] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 41 top_k: 80, top_p: 0.59] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a particularly good idea.\"<|endoftext|>\n",
      "\n",
      "[Test 41 top_k: 80, top_p: 0.59] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 41 top_k: 80, top_p: 0.59] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 42 top_k: 65, top_p: 0.45] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 42 top_k: 65, top_p: 0.45] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 42 top_k: 65, top_p: 0.45] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 42 top_k: 65, top_p: 0.45] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 43 top_k: 1, top_p: 0.37] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 43 top_k: 1, top_p: 0.37] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 43 top_k: 1, top_p: 0.37] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 43 top_k: 1, top_p: 0.37] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 44 top_k: 26, top_p: 0.46] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 44 top_k: 26, top_p: 0.46] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 44 top_k: 26, top_p: 0.46] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 44 top_k: 26, top_p: 0.46] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 45 top_k: 48, top_p: 0.58] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 45 top_k: 48, top_p: 0.58] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a particularly good idea.\"<|endoftext|>\n",
      "\n",
      "[Test 45 top_k: 48, top_p: 0.58] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 45 top_k: 48, top_p: 0.58] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 46 top_k: 64, top_p: 0.32] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 46 top_k: 64, top_p: 0.32] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 46 top_k: 64, top_p: 0.32] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 46 top_k: 64, top_p: 0.32] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 47 top_k: 42, top_p: 0.78] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 47 top_k: 42, top_p: 0.78] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 47 top_k: 42, top_p: 0.78] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 47 top_k: 42, top_p: 0.78] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 48 top_k: 80, top_p: 0.38] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 48 top_k: 80, top_p: 0.38] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 48 top_k: 80, top_p: 0.38] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 48 top_k: 80, top_p: 0.38] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 49 top_k: 50, top_p: 0.32] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 49 top_k: 50, top_p: 0.32] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 49 top_k: 50, top_p: 0.32] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 49 top_k: 50, top_p: 0.32] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 50 top_k: 61, top_p: 0.16] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 50 top_k: 61, top_p: 0.16] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 50 top_k: 61, top_p: 0.16] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 50 top_k: 61, top_p: 0.16] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 51 top_k: 36, top_p: 0.34] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 51 top_k: 36, top_p: 0.34] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 51 top_k: 36, top_p: 0.34] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 51 top_k: 36, top_p: 0.34] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 52 top_k: 7, top_p: 0.53] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 52 top_k: 7, top_p: 0.53] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a particularly good idea.\"<|endoftext|>\n",
      "\n",
      "[Test 52 top_k: 7, top_p: 0.53] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 52 top_k: 7, top_p: 0.53] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 53 top_k: 19, top_p: 0.21] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 53 top_k: 19, top_p: 0.21] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 53 top_k: 19, top_p: 0.21] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 53 top_k: 19, top_p: 0.21] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 54 top_k: 34, top_p: 0.71] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 54 top_k: 34, top_p: 0.71] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 54 top_k: 34, top_p: 0.71] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 54 top_k: 34, top_p: 0.71] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 55 top_k: 56, top_p: 0.74] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 55 top_k: 56, top_p: 0.74] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 55 top_k: 56, top_p: 0.74] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 55 top_k: 56, top_p: 0.74] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 56 top_k: 84, top_p: 0.31] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 56 top_k: 84, top_p: 0.31] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 56 top_k: 84, top_p: 0.31] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 56 top_k: 84, top_p: 0.31] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 57 top_k: 83, top_p: 0.48] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 57 top_k: 83, top_p: 0.48] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 57 top_k: 83, top_p: 0.48] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 57 top_k: 83, top_p: 0.48] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 58 top_k: 39, top_p: 0.33] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 58 top_k: 39, top_p: 0.33] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 58 top_k: 39, top_p: 0.33] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 58 top_k: 39, top_p: 0.33] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 59 top_k: 20, top_p: 0.25] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 59 top_k: 20, top_p: 0.25] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 59 top_k: 20, top_p: 0.25] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 59 top_k: 20, top_p: 0.25] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 60 top_k: 36, top_p: 0.24] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 60 top_k: 36, top_p: 0.24] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 60 top_k: 36, top_p: 0.24] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 60 top_k: 36, top_p: 0.24] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 61 top_k: 17, top_p: 0.03] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 61 top_k: 17, top_p: 0.03] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 61 top_k: 17, top_p: 0.03] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 61 top_k: 17, top_p: 0.03] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 62 top_k: 55, top_p: 0.75] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 62 top_k: 55, top_p: 0.75] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 62 top_k: 55, top_p: 0.75] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 62 top_k: 55, top_p: 0.75] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 63 top_k: 40, top_p: 0.21] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 63 top_k: 40, top_p: 0.21] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 63 top_k: 40, top_p: 0.21] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 63 top_k: 40, top_p: 0.21] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 64 top_k: 93, top_p: 0.17] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 64 top_k: 93, top_p: 0.17] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 64 top_k: 93, top_p: 0.17] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 64 top_k: 93, top_p: 0.17] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 65 top_k: 94, top_p: 0.49] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 65 top_k: 94, top_p: 0.49] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 65 top_k: 94, top_p: 0.49] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 65 top_k: 94, top_p: 0.49] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 66 top_k: 87, top_p: 0.54] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 66 top_k: 87, top_p: 0.54] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a particularly good idea.\"<|endoftext|>\n",
      "\n",
      "[Test 66 top_k: 87, top_p: 0.54] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 66 top_k: 87, top_p: 0.54] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 67 top_k: 100, top_p: 0.59] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 67 top_k: 100, top_p: 0.59] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a particularly good idea.\"<|endoftext|>\n",
      "\n",
      "[Test 67 top_k: 100, top_p: 0.59] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 67 top_k: 100, top_p: 0.59] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 68 top_k: 63, top_p: 0.2] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 68 top_k: 63, top_p: 0.2] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 68 top_k: 63, top_p: 0.2] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 68 top_k: 63, top_p: 0.2] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 69 top_k: 9, top_p: 0.29] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 69 top_k: 9, top_p: 0.29] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 69 top_k: 9, top_p: 0.29] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 69 top_k: 9, top_p: 0.29] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 70 top_k: 61, top_p: 0.15] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 70 top_k: 61, top_p: 0.15] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 70 top_k: 61, top_p: 0.15] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 70 top_k: 61, top_p: 0.15] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 71 top_k: 71, top_p: 0.27] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 71 top_k: 71, top_p: 0.27] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 71 top_k: 71, top_p: 0.27] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 71 top_k: 71, top_p: 0.27] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 72 top_k: 2, top_p: 0.75] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 72 top_k: 2, top_p: 0.75] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a particularly good idea.\"<|endoftext|>\n",
      "\n",
      "[Test 72 top_k: 2, top_p: 0.75] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late. I could prepare myself for the possibility of a long-term lodging kinda my job.\"<|endoftext|>\n",
      "\n",
      "[Test 72 top_k: 2, top_p: 0.75] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 73 top_k: 61, top_p: 0.98] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 73 top_k: 61, top_p: 0.98] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 73 top_k: 61, top_p: 0.98] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 73 top_k: 61, top_p: 0.98] -> Prompt: What will we do here?\n",
      "Reply: An \"Hey, [player_name]. I'm not letting you distract me with something I didn't said.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 74 top_k: 84, top_p: 0.18] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 74 top_k: 84, top_p: 0.18] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 74 top_k: 84, top_p: 0.18] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 74 top_k: 84, top_p: 0.18] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 75 top_k: 80, top_p: 0.74] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 75 top_k: 80, top_p: 0.74] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 75 top_k: 80, top_p: 0.74] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 75 top_k: 80, top_p: 0.74] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 76 top_k: 9, top_p: 0.97] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 76 top_k: 9, top_p: 0.97] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 76 top_k: 9, top_p: 0.97] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 76 top_k: 9, top_p: 0.97] -> Prompt: What will we do here?\n",
      "Reply: An \"Hey, [player_name]. I'm not letting you distract me with something I didn't said.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 77 top_k: 67, top_p: 0.48] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 77 top_k: 67, top_p: 0.48] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 77 top_k: 67, top_p: 0.48] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 77 top_k: 67, top_p: 0.48] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 78 top_k: 65, top_p: 0.07] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 78 top_k: 65, top_p: 0.07] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 78 top_k: 65, top_p: 0.07] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 78 top_k: 65, top_p: 0.07] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 79 top_k: 71, top_p: 0.59] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 79 top_k: 71, top_p: 0.59] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a particularly good idea.\"<|endoftext|>\n",
      "\n",
      "[Test 79 top_k: 71, top_p: 0.59] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 79 top_k: 71, top_p: 0.59] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 80 top_k: 66, top_p: 0.21] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 80 top_k: 66, top_p: 0.21] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 80 top_k: 66, top_p: 0.21] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 80 top_k: 66, top_p: 0.21] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 81 top_k: 65, top_p: 0.37] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 81 top_k: 65, top_p: 0.37] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 81 top_k: 65, top_p: 0.37] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 81 top_k: 65, top_p: 0.37] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 82 top_k: 72, top_p: 0.38] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 82 top_k: 72, top_p: 0.38] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 82 top_k: 72, top_p: 0.38] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 82 top_k: 72, top_p: 0.38] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 83 top_k: 88, top_p: 0.43] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 83 top_k: 88, top_p: 0.43] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 83 top_k: 88, top_p: 0.43] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 83 top_k: 88, top_p: 0.43] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 84 top_k: 84, top_p: 0.98] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 84 top_k: 84, top_p: 0.98] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 84 top_k: 84, top_p: 0.98] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 84 top_k: 84, top_p: 0.98] -> Prompt: What will we do here?\n",
      "Reply: An \"Hey, [player_name]. I'm not letting you distract me with something I didn't said.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 85 top_k: 68, top_p: 0.75] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 85 top_k: 68, top_p: 0.75] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 85 top_k: 68, top_p: 0.75] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 85 top_k: 68, top_p: 0.75] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 86 top_k: 81, top_p: 0.88] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 86 top_k: 81, top_p: 0.88] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 86 top_k: 81, top_p: 0.88] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 86 top_k: 81, top_p: 0.88] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 87 top_k: 83, top_p: 0.59] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 87 top_k: 83, top_p: 0.59] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a particularly good idea.\"<|endoftext|>\n",
      "\n",
      "[Test 87 top_k: 83, top_p: 0.59] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 87 top_k: 83, top_p: 0.59] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 88 top_k: 82, top_p: 0.05] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 88 top_k: 82, top_p: 0.05] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 88 top_k: 82, top_p: 0.05] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 88 top_k: 82, top_p: 0.05] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 89 top_k: 82, top_p: 0.68] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 89 top_k: 82, top_p: 0.68] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 89 top_k: 82, top_p: 0.68] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 89 top_k: 82, top_p: 0.68] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 90 top_k: 62, top_p: 0.96] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 90 top_k: 62, top_p: 0.96] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 90 top_k: 62, top_p: 0.96] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 90 top_k: 62, top_p: 0.96] -> Prompt: What will we do here?\n",
      "Reply: An \"Hey, [player_name]. I'm not letting you distract me with something I didn't want to said.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 91 top_k: 47, top_p: 0.0] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 91 top_k: 47, top_p: 0.0] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 91 top_k: 47, top_p: 0.0] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 91 top_k: 47, top_p: 0.0] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 92 top_k: 18, top_p: 0.68] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 92 top_k: 18, top_p: 0.68] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 92 top_k: 18, top_p: 0.68] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 92 top_k: 18, top_p: 0.68] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 93 top_k: 96, top_p: 0.58] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 93 top_k: 96, top_p: 0.58] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a particularly good idea.\"<|endoftext|>\n",
      "\n",
      "[Test 93 top_k: 96, top_p: 0.58] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 93 top_k: 96, top_p: 0.58] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 94 top_k: 0, top_p: 0.08] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 94 top_k: 0, top_p: 0.08] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 94 top_k: 0, top_p: 0.08] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 94 top_k: 0, top_p: 0.08] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 95 top_k: 70, top_p: 0.5] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 95 top_k: 70, top_p: 0.5] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 95 top_k: 70, top_p: 0.5] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 95 top_k: 70, top_p: 0.5] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 96 top_k: 6, top_p: 0.76] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 96 top_k: 6, top_p: 0.76] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 96 top_k: 6, top_p: 0.76] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 96 top_k: 6, top_p: 0.76] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 97 top_k: 40, top_p: 0.13] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 97 top_k: 40, top_p: 0.13] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 97 top_k: 40, top_p: 0.13] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 97 top_k: 40, top_p: 0.13] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 98 top_k: 24, top_p: 0.71] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 98 top_k: 24, top_p: 0.71] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a match.\"<|endoftext|>\n",
      "\n",
      "[Test 98 top_k: 24, top_p: 0.71] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 98 top_k: 24, top_p: 0.71] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 99 top_k: 84, top_p: 0.99] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 99 top_k: 84, top_p: 0.99] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can make a similar offer.\"<|endoftext|>\n",
      "\n",
      "[Test 99 top_k: 84, top_p: 0.99] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's what I'm going to give you.\"<|endoftext|>\n",
      "\n",
      "[Test 99 top_k: 84, top_p: 0.99] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n",
      "[Test 100 top_k: 89, top_p: 0.14] -> Prompt: How are you?\n",
      "Reply: Ry \"Oh, hello [player_name]! What are you doing here?\"<|endoftext|>\n",
      "\n",
      "[Test 100 top_k: 89, top_p: 0.14] -> Prompt: What do you think of Lorem?\n",
      "Reply: Ad \"He's a good little human, but I'm not sure if I can take a call in and care.\"<|endoftext|>\n",
      "\n",
      "[Test 100 top_k: 89, top_p: 0.14] -> Prompt: Oh my god, Adine. What is this?\n",
      "Reply: Ad think b \"It's getting late, so maybe I should leave it at that for today.\"<|endoftext|>\n",
      "\n",
      "[Test 100 top_k: 89, top_p: 0.14] -> Prompt: What will we do here?\n",
      "Reply: An \"I'll tear you up.\"<|endoftext|>\n",
      "\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    torch.manual_seed(80085)\n",
    "    top_k = random.randint(0, 100)\n",
    "    top_p = round(random.uniform(0, 1), 2)\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = generate_dragon_reply(past, prompt, top_k = top_k, top_p = top_p)\n",
    "        print(f\"[Test {i + 1} top_k: {top_k}, top_p: {top_p}] -> Prompt: {prompt}\\nReply: {reply}\\n\")\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgM9Awn7acpG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What to say?\n"
     ]
    }
   ],
   "source": [
    "def generate_reply(prompt):\n",
    "    model.eval()\n",
    "    prompt = f'PlayerReply c \"{prompt}\" DragonReply'\n",
    "    generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "    generated = generated.to(device)\n",
    "    print(prompt, generated)\n",
    "\n",
    "    sample_outputs = model.generate(\n",
    "        generated, \n",
    "        do_sample=True,   \n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        top_k=50, \n",
    "        max_length = 128,\n",
    "        top_p=0.95, \n",
    "        num_return_sequences=3\n",
    "    )\n",
    "\n",
    "    for i, sample_output in enumerate(sample_outputs):\n",
    "        print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=False)))\n",
    "\n",
    "print(\"What to say?\")\n",
    "print(generate_reply(input()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXKM4uLM2gOO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AWSW_GPT-Neo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06dd02ec048945e5bf6b17d2b5558fb2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "073bc138772048729e04017123149e80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0abba2f64b4a43abadb38d461a5c7f42": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ac398931b04418cbd3d227b9c634883": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0ae32803eeaf436ab66cb3da9ff5439d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cd6ff104b484203adda9e8414fd80fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ce77d162a014a2fa17628ef8fe20846": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11475ac58a594c6db1641401b1cc0d13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1153397efee1426cac848341c0b88785": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eeb54e278e184bc5aabf0283f1b276ff",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cb33a87e718546f3a33b7deea817de56",
      "value": 2
     }
    },
    "131ce893dc784733b42f384b419145db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13e5a9ab53bc4e1d8c3c7905ebd05ddf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_917d4196cdd14970b7965652f3b950a2",
      "max": 898669,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ad42520b822e4454947f5d466424c8ca",
      "value": 898669
     }
    },
    "1481fbbc74544c4888c0d6f88d8b3c9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17c9592d03324c4797abc812044e7500": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a2fe039b81a42c496ba363b2000bc41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23a62f16d8de4f3ab9fa64ada07d1e35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d36395d1dcad4ead98f7f4756b8dbd37",
       "IPY_MODEL_2cf737292a8343f5965c3eb0ace01875",
       "IPY_MODEL_9ba5d1e5fab74947a328842b5105a28e"
      ],
      "layout": "IPY_MODEL_d50f5db4d1a1430caecace0510c1a24e"
     }
    },
    "27f2d980cb774902a82c0ad2545f549a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef9e25d7100e4e9ba064e938bd8157ea",
      "placeholder": "",
      "style": "IPY_MODEL_f6625c167f7b4aa4bbecf2129e07c068",
      "value": " 2/2 [00:00&lt;00:00, 35.19it/s]"
     }
    },
    "28d30b2eecf04ae6835cf4c35648dcfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df0a544035814e1ca11d6191c10a5b62",
      "placeholder": "",
      "style": "IPY_MODEL_fd91a671eeb7431d90d86b44beb276bd",
      "value": " 1/? [00:00&lt;00:00,  9.11 tables/s]"
     }
    },
    "29b2e68155a947e0aca0760c7e8e4afa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d10fbe074d4b42c9a8a6522252ef016f",
      "max": 1007,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_470ba5ce89ee4927a9be685adbc08675",
      "value": 1007
     }
    },
    "2a9348d6cd674898ac4c9a303a254f26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2c60d924ee7b4fad984e2072973c3af3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2cf737292a8343f5965c3eb0ace01875": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06dd02ec048945e5bf6b17d2b5558fb2",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b404b600842a4fc4b2b66c6b015235d6",
      "value": 0
     }
    },
    "307da63f10ad4ae5ae5e7e387d176d39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "33f9747c1f474c1790c7c293c853fad5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6cd8593a13f54c138c9adf5ec85f2d97",
      "placeholder": "",
      "style": "IPY_MODEL_c5a11599f37c4077a4ab0daec124a78c",
      "value": " 2/2 [00:00&lt;00:00, 19.80it/s]"
     }
    },
    "37672ae801de4f42a9f6f49cc33fb88e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b805525a58804750ae56dad7e43ecb0e",
      "placeholder": "",
      "style": "IPY_MODEL_809a3780924641b8ace57e9141b0167f",
      "value": " 2/2 [00:00&lt;00:00, 20.01it/s]"
     }
    },
    "38bc8c5a2a3447e7942e2058c35d5e5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9813f2bda5ce4ab6887683fe63d0629e",
       "IPY_MODEL_5c6ca36359bb4a1982c599f6a3f23b9f",
       "IPY_MODEL_6e2cfa054082449e942297afd2f50f73"
      ],
      "layout": "IPY_MODEL_79170285a49a450494f0bfbe6cb4788e"
     }
    },
    "3a0ada2f620a40aaa6c33fcea7a0bb91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3af5019cfacf4afc8a15a14d9a121ea8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a0ada2f620a40aaa6c33fcea7a0bb91",
      "placeholder": "",
      "style": "IPY_MODEL_d21de377e9074df083556c68e7d7cdbb",
      "value": " 357/357 [00:00&lt;00:00, 9.50kB/s]"
     }
    },
    "3c2d0014295e47f9a07de8d4e36e7ba4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c7dd63eb62d44598666166a87c0ff88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d72f5178e404d8c948ef13fc81a2bb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3daedb3b85264408a8821ee2e480b356": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f271f4469cf4796b92a78eba64c30b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc3c5e1ef5974710a06c1eab3d90cfb1",
      "placeholder": "",
      "style": "IPY_MODEL_e10acb8e2c8240409a19c61499576afd",
      "value": "100%"
     }
    },
    "3fed2802cbab4a90a5b3d5a8c9bc8974": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5067025a37bb42318ae93216b3205b17",
      "placeholder": "",
      "style": "IPY_MODEL_65c48ca18ea14cf9bccbaa2495c2f120",
      "value": ""
     }
    },
    "406b2f47896446a187725d4a1aa926f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40b7d134ba7b40299f6bd16b1e781d09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ed62e486a664d1f83fee6f21cb4585d",
      "placeholder": "",
      "style": "IPY_MODEL_e702472021334098b47210f9f1395f21",
      "value": "Downloading: 100%"
     }
    },
    "437e050108fd46e1ba0f35674fa7314f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "470ba5ce89ee4927a9be685adbc08675": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4f1eafd9553b4bd5b396bba8f3896a22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5067025a37bb42318ae93216b3205b17": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54b833977b424c25a690d1bfe5d8c3f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7789164b5ee245b3a537d9d61dae038f",
      "placeholder": "",
      "style": "IPY_MODEL_0ac398931b04418cbd3d227b9c634883",
      "value": "Downloading: 100%"
     }
    },
    "56a8c3c144404bd793e29a023032a09f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5af59ca6be4a427c8f83a906bbb6ce93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5af83a55a73b4f3481a7559951ebdf08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c6ca36359bb4a1982c599f6a3f23b9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c1132ffe6c684c7ebeb3f285a101536b",
      "max": 560,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2c60d924ee7b4fad984e2072973c3af3",
      "value": 560
     }
    },
    "5f28c40531fc4f43b4b62fd04912100c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7ed9d2386d57488c890d1ec712d1bef0",
       "IPY_MODEL_da3c1240d6a94f3c9ff9ec0545675446",
       "IPY_MODEL_cc7c2ac1006b4b109f302d7d26e3a578"
      ],
      "layout": "IPY_MODEL_3c7dd63eb62d44598666166a87c0ff88"
     }
    },
    "5f2bf3aebfd64baf94df39964208af4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f3133f5c7254c248dad8e75534ea920": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "607ee5c0b54042f3919d0588d66e31c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "641f6e8a671d4dfe9da34c7685520767": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_40b7d134ba7b40299f6bd16b1e781d09",
       "IPY_MODEL_13e5a9ab53bc4e1d8c3c7905ebd05ddf",
       "IPY_MODEL_bc3c9b957d93490c8f9773e7050fd4ef"
      ],
      "layout": "IPY_MODEL_c7eb14f1388e42f29fbac8eef195fede"
     }
    },
    "659e0ad7f39c4cdbbdc1345c07a2e3f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_54b833977b424c25a690d1bfe5d8c3f1",
       "IPY_MODEL_8bfab1db231a4ff1975775f81f8a84f1",
       "IPY_MODEL_3af5019cfacf4afc8a15a14d9a121ea8"
      ],
      "layout": "IPY_MODEL_1481fbbc74544c4888c0d6f88d8b3c9d"
     }
    },
    "65c48ca18ea14cf9bccbaa2495c2f120": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6ade1603ab664b9f9d5ce44014bc5305": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "6cd8593a13f54c138c9adf5ec85f2d97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6cf4e15a56fc4ac188609b806f11afcd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e2cfa054082449e942297afd2f50f73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0abba2f64b4a43abadb38d461a5c7f42",
      "placeholder": "",
      "style": "IPY_MODEL_aa2a21546de1463f88a7feb8b697f9d3",
      "value": " 560/560 [00:00&lt;00:00, 13.1kB/s]"
     }
    },
    "6eda966317484df2a47fa0c4f2a0370c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "76286c1e442541e0a6cb2d7cbbc9cc8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_607ee5c0b54042f3919d0588d66e31c1",
      "placeholder": "",
      "style": "IPY_MODEL_131ce893dc784733b42f384b419145db",
      "value": "100%"
     }
    },
    "7789164b5ee245b3a537d9d61dae038f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79170285a49a450494f0bfbe6cb4788e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bb369ca60f94acc99a4ee8e8f8fd261": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c6ff5b9114424dbfafcbc3b3ab887af5",
       "IPY_MODEL_1153397efee1426cac848341c0b88785",
       "IPY_MODEL_37672ae801de4f42a9f6f49cc33fb88e"
      ],
      "layout": "IPY_MODEL_bc20a41ccda14aeeb72014b80a5ec53a"
     }
    },
    "7db95c969d94465aaffbe9139f0f2a90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ed9d2386d57488c890d1ec712d1bef0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5af83a55a73b4f3481a7559951ebdf08",
      "placeholder": "",
      "style": "IPY_MODEL_9bb4dcdb6f434d8b8cc95ef80f2ffe00",
      "value": "Downloading: 100%"
     }
    },
    "809a3780924641b8ace57e9141b0167f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8110f29e7b134607b38b29fad32ab1a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8528f9fbbc504a44b9670a760256192d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a282a2414874cb588a386e1444951dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8abd99000df0453e86bc458be29a10c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8bfab1db231a4ff1975775f81f8a84f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7db95c969d94465aaffbe9139f0f2a90",
      "max": 357,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8abd99000df0453e86bc458be29a10c7",
      "value": 357
     }
    },
    "8ed62e486a664d1f83fee6f21cb4585d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "906b9daf9437432c81546f35256c7232": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3fed2802cbab4a90a5b3d5a8c9bc8974",
       "IPY_MODEL_a146d5c5588944368242c519984cbccc",
       "IPY_MODEL_28d30b2eecf04ae6835cf4c35648dcfc"
      ],
      "layout": "IPY_MODEL_0ce77d162a014a2fa17628ef8fe20846"
     }
    },
    "917d4196cdd14970b7965652f3b950a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9813f2bda5ce4ab6887683fe63d0629e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eef06f8bc02749f4b04af47d92eb91b2",
      "placeholder": "",
      "style": "IPY_MODEL_5f3133f5c7254c248dad8e75534ea920",
      "value": "Downloading: 100%"
     }
    },
    "99e992b8d4564ddd9c7634ac7663053a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6cf4e15a56fc4ac188609b806f11afcd",
      "placeholder": "",
      "style": "IPY_MODEL_a8e19067a3ad411cad1aba489d390516",
      "value": " 526M/526M [00:18&lt;00:00, 30.1MB/s]"
     }
    },
    "9ba5d1e5fab74947a328842b5105a28e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5725e8dc8104756bcba16b2c886a27f",
      "placeholder": "",
      "style": "IPY_MODEL_437e050108fd46e1ba0f35674fa7314f",
      "value": " 0/? [00:00&lt;?, ? tables/s]"
     }
    },
    "9bb4dcdb6f434d8b8cc95ef80f2ffe00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a04e889a56e94ce9812a0e7d89d4d4f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_76286c1e442541e0a6cb2d7cbbc9cc8f",
       "IPY_MODEL_dcad41ec160e448b83d85c907a48facb",
       "IPY_MODEL_27f2d980cb774902a82c0ad2545f549a"
      ],
      "layout": "IPY_MODEL_3c2d0014295e47f9a07de8d4e36e7ba4"
     }
    },
    "a146d5c5588944368242c519984cbccc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ade1603ab664b9f9d5ce44014bc5305",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d18658b25f6f47778b984d0bf35be999",
      "value": 1
     }
    },
    "a31733df07ed4bb485d518b64634acfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3f271f4469cf4796b92a78eba64c30b3",
       "IPY_MODEL_fd200bcd96354e36b32ca82660eb0ef2",
       "IPY_MODEL_33f9747c1f474c1790c7c293c853fad5"
      ],
      "layout": "IPY_MODEL_1a2fe039b81a42c496ba363b2000bc41"
     }
    },
    "a5725e8dc8104756bcba16b2c886a27f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8e19067a3ad411cad1aba489d390516": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa2a21546de1463f88a7feb8b697f9d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab0ce277776d4d218bf97fff5acc8e28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad42520b822e4454947f5d466424c8ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ae627a7820d4450a97b47d63dd5fbd92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2373342cb4942569088a5b20186795a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b2ce0d43567b4cc09e1f5571ee25263c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56a8c3c144404bd793e29a023032a09f",
      "placeholder": "",
      "style": "IPY_MODEL_ae627a7820d4450a97b47d63dd5fbd92",
      "value": "Downloading: 100%"
     }
    },
    "b404b600842a4fc4b2b66c6b015235d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b805525a58804750ae56dad7e43ecb0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bafebeb0fba04d148ae3adf44171e0fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbd5e6b14d864c1eb6a4d9c4247fb520": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8110f29e7b134607b38b29fad32ab1a1",
      "placeholder": "",
      "style": "IPY_MODEL_e4a6b2af572e44eda537e74847c58709",
      "value": "Downloading: 100%"
     }
    },
    "bc20a41ccda14aeeb72014b80a5ec53a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc3c9b957d93490c8f9773e7050fd4ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ae32803eeaf436ab66cb3da9ff5439d",
      "placeholder": "",
      "style": "IPY_MODEL_3d72f5178e404d8c948ef13fc81a2bb8",
      "value": " 899k/899k [00:00&lt;00:00, 1.32MB/s]"
     }
    },
    "c1132ffe6c684c7ebeb3f285a101536b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3a28b9889cd40e2ac0b9860e7f3932b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bafebeb0fba04d148ae3adf44171e0fe",
      "max": 526017373,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2a9348d6cd674898ac4c9a303a254f26",
      "value": 526017373
     }
    },
    "c4384ee96a1a4ae4bc8b46fa640b9058": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c5a11599f37c4077a4ab0daec124a78c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c6ff5b9114424dbfafcbc3b3ab887af5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_406b2f47896446a187725d4a1aa926f8",
      "placeholder": "",
      "style": "IPY_MODEL_8528f9fbbc504a44b9670a760256192d",
      "value": "100%"
     }
    },
    "c7eb14f1388e42f29fbac8eef195fede": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb33a87e718546f3a33b7deea817de56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cc3c5e1ef5974710a06c1eab3d90cfb1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc7c2ac1006b4b109f302d7d26e3a578": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a282a2414874cb588a386e1444951dd",
      "placeholder": "",
      "style": "IPY_MODEL_307da63f10ad4ae5ae5e7e387d176d39",
      "value": " 456k/456k [00:00&lt;00:00, 1.08MB/s]"
     }
    },
    "d10fbe074d4b42c9a8a6522252ef016f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d18658b25f6f47778b984d0bf35be999": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d21de377e9074df083556c68e7d7cdbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d36395d1dcad4ead98f7f4756b8dbd37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab0ce277776d4d218bf97fff5acc8e28",
      "placeholder": "",
      "style": "IPY_MODEL_073bc138772048729e04017123149e80",
      "value": ""
     }
    },
    "d50f5db4d1a1430caecace0510c1a24e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da3c1240d6a94f3c9ff9ec0545675446": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f2bf3aebfd64baf94df39964208af4c",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c4384ee96a1a4ae4bc8b46fa640b9058",
      "value": 456318
     }
    },
    "dcad41ec160e448b83d85c907a48facb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11475ac58a594c6db1641401b1cc0d13",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b2373342cb4942569088a5b20186795a",
      "value": 2
     }
    },
    "df0a544035814e1ca11d6191c10a5b62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e10acb8e2c8240409a19c61499576afd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4a6b2af572e44eda537e74847c58709": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e702472021334098b47210f9f1395f21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eeb54e278e184bc5aabf0283f1b276ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eef06f8bc02749f4b04af47d92eb91b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef9e25d7100e4e9ba064e938bd8157ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f43e9d4fa52c48c087ffeef399bfbed6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bbd5e6b14d864c1eb6a4d9c4247fb520",
       "IPY_MODEL_29b2e68155a947e0aca0760c7e8e4afa",
       "IPY_MODEL_fa1b29c48993478f9c2be4877ec675fc"
      ],
      "layout": "IPY_MODEL_4f1eafd9553b4bd5b396bba8f3896a22"
     }
    },
    "f6153c2ce07b4f4097a2a0486fb896ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b2ce0d43567b4cc09e1f5571ee25263c",
       "IPY_MODEL_c3a28b9889cd40e2ac0b9860e7f3932b",
       "IPY_MODEL_99e992b8d4564ddd9c7634ac7663053a"
      ],
      "layout": "IPY_MODEL_3daedb3b85264408a8821ee2e480b356"
     }
    },
    "f6625c167f7b4aa4bbecf2129e07c068": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa1b29c48993478f9c2be4877ec675fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17c9592d03324c4797abc812044e7500",
      "placeholder": "",
      "style": "IPY_MODEL_5af59ca6be4a427c8f83a906bbb6ce93",
      "value": " 1.01k/1.01k [00:00&lt;00:00, 25.4kB/s]"
     }
    },
    "fd200bcd96354e36b32ca82660eb0ef2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0cd6ff104b484203adda9e8414fd80fa",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6eda966317484df2a47fa0c4f2a0370c",
      "value": 2
     }
    },
    "fd91a671eeb7431d90d86b44beb276bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
