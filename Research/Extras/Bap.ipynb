{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0ffaf77-a7ef-4818-975f-52b4f773c96d",
   "metadata": {},
   "source": [
    "![Bap the model! Make more data!](bap.gif)\n",
    "# Bap the model, get more data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff95a395-cea5-4d69-9d7e-e65044713f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config, GPT2LMHeadModel, GPTNeoForCausalLM\n",
    "import torch\n",
    "import re\n",
    "\n",
    "sys.path.append('..')\n",
    "from model_manager import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab29342b-c565-48fe-bdc9-b7739e0d8910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df01d84-921b-4bdf-b683-9e1e7561cf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = os.path.join(\"..\", \"models\", \"awsw_main\")\n",
    "model_manager = ModelManager(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de3aa66-5c44-4509-a545-d598bd47407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_token = \"<|endoftext|>\"\n",
    "prompts = [\n",
    "    ('PlayerReply c \"Hey Kevin!\" DragonReply Kv \"Hey!\"', \"How are you?\", \"Kv\"),\n",
    "    ('PlayerReply c \"Hey Adine!\" DragonReply Ad \"Hello.\"', \"How are you?\", \"Ad\"),\n",
    "    ('PlayerReply c \"Hey Maverick!\" DragonReply Kv \"Oh, it\\'s you...\"', \"How are you?\", \"Mv\"),\n",
    "    ('PlayerReply c \"Hey Remy, Anna told me about your love life.\" DragonReply Ry \"My love life? It\\'s non-existent.\"', \"It isn\\'t anymore...\", \"Ry\"),\n",
    "    ('PlayerReply c \"Maverick...\" DragonReply Mv \"What is it...\"', \"I tried to sleep under your wing in my dreams but you strangled me and it turned into a fight nightmare.\", \"Mv\"),\n",
    "    ('PlayerReply c \"You must be Anna!\" DragonReply An \"Hey, I heard about you\"', \"TheNoodle is cool, don't you think?\", \"An\"),\n",
    "]\n",
    "fixed_replies = []\n",
    "for (past, prompt, correct_dragon) in prompts:\n",
    "    reply = model_manager.say(past, prompt)\n",
    "    reply = reply.replace(end_token, \"\")\n",
    "    current_name = reply[:reply.index(\" \")]\n",
    "    if current_name != correct_dragon:\n",
    "        logging.warning(f\"Reply got wrong name (should have been {correct_dragon} but is {current_name}). Repairing...\")\n",
    "        reply = reply[reply.index(\" \") + 1:]\n",
    "        reply = f\"{correct_dragon} {reply}\"\n",
    "        fixed_replies.append(f'{past} PlayerReply c \"{prompt}\" DragonReply {reply}')\n",
    "    print(f\"Prompt: {prompt}\\nReply: {reply}\\n\\n\")\n",
    "fixed_replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59945d0-b861-4aab-b048-882143adcb8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
