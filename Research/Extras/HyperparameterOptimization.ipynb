{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3ea4e9-18e2-4512-8b20-9905e0142728",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import optuna\n",
    "import json\n",
    "import shutil\n",
    "import matplotlib.pyplot as pl\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "sys.path.append('..')\n",
    "from model_manager import ModelManager\n",
    "from model_utils import train_model, split_data\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfbafe7-fbef-4f60-85ba-134aecfe3e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_name = \"AWSW Best Learning Params\"\n",
    "storage_url = f\"sqlite:///{study_name}.db\"\n",
    "study = optuna.create_study(study_name=study_name, storage=storage_url, load_if_exists=True)\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device_name = \"cpu\"\n",
    "device = torch.device(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf02aba-5129-43ea-85ff-bb7f2f3cf9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    config = {\n",
    "        \"model_name\": \"EleutherAI/gpt-neo-125M\",\n",
    "        \"lr\": 6e-4,\n",
    "        \"warmup_factor\": 2,\n",
    "        \"scheduler\": \"polynomial_decay_schedule_with_warmup\",\n",
    "        \"lr_end\": 2e-6,\n",
    "        \"power\": 0.6,\n",
    "        \"freeze_from_steps\": 10,\n",
    "        \"seed\": 80085,\n",
    "        \"num_epoch\": 5,\n",
    "        \"to_freeze_count\": 120,\n",
    "        \"model_folder\": os.path.join(Config.work_dir, \"models\", \"awsw_hyperopt\")\n",
    "    }\n",
    "    config['freeze_from_steps'] = trial.suggest_int('freeze_from_steps', -1, 200)\n",
    "    config['to_freeze_count'] = trial.suggest_int('to_freeze_count', 10, 120)\n",
    "    train_results = {}\n",
    "    # There's sadly no way to train without saving the model in Huggingface so I'll delete it each time we begin training.\n",
    "    if os.path.isdir(config['model_folder']): \n",
    "        shutil.rmtree(config['model_folder'])\n",
    "    transformers.logging.set_verbosity_error()\n",
    "    train_model(config, train_results, device = device)\n",
    "    return train_results['loss_history'][-1]\n",
    "\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa681e-eea6-4f3f-b7f6-8a053a1bd43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b3965-9601-4b43-ba7c-cf58d4a1e9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!optuna-dashboard --host 0.0.0.0 \"$storage_url\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab27b8a9-c37c-45f3-b806-393f62c52b84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
