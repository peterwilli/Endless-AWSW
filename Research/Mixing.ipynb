{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "921ec9f4-2e97-4002-8d4a-bf8a36ef888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from model_manager import ModelManager\n",
    "from model_mixing import ModelMixing\n",
    "from model_utils import get_model\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1561d726-ba19-40d4-8886-cafa95aeb925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded base and main model to CPU\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = os.path.join(\"models\", \"awsw_main\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "main_model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "base_model, _ = get_model(\"EleutherAI/gpt-neo-125M\")\n",
    "target_model, _ = get_model(\"EleutherAI/gpt-neo-125M\")\n",
    "device = torch.device('cpu')\n",
    "model_manager = ModelManager(model=target_model, tokenizer=tokenizer, device=device)\n",
    "print(f\"Loaded base and main model to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "374b092e-bdcb-4fa6-bb0e-0863a2cd2869",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"How are you?\"<p><msg>c \"How are you?\"<d><scn>park2<msg>Ry \"How are you?\"<p><msg>c \"How are you?\"<d><scn>park2<msg>Ry \"How are you?\"<p><msg>c \"How are you?\"<d><scn>park2\n",
      "Reply [sampled]: park2<msg>Remy<msg>C<scn>Remy<scn>Remy<scn>C<scn>Remy<scn>C<scn>Remy<scn>C<scn>Remy<scn>C<scn>C<scn>Remy<scn>C<scn>C<scn>\n",
      "----------\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"Very nice.\"<p><msg>c \"What do you think of Lorem?\"<d><scn>park2<msg>Ad \"Very nice.\"<p><msg>c \"What do you think of Lorem?\"<d><scn>park2<msg>Ad \"Very nice.\"<p><msg>\n",
      "Reply [sampled]: park2<msg>Ad \"Very nice.\"<p><msg>c \"What do you think of Lorem?\"<d><scn>park2<msg>Ad \"Very nice.\"<p><msg>c \"What do you think of Lorem?\"<d><scn>park2<msg>Ad \"Very nice.\"<p><msg>\n",
      "----------\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: c \"Oh my god, Adine. What is this?\"<d><scn>c \"Oh my god, Adine. What is this?\"<d><scn>c \"Oh my god, Adine. What is this?\"<d><scn>c \"Oh my god, Adine. What is this?\"<d><scn>c \"Oh my god, Adine.\n",
      "Reply [sampled]: Adine:</scn> \"It's a Tatsu park. Adine, I'm in Tatsu park. I'm here because I am the only one who can get out of it. I can't stay here. I'm not a child. I'm not a human.\"<d><scn>Adine:</scn> \"I don't know how you do it.\"<d><\n",
      "----------\n",
      "Prompt: What will we do here?\n",
      "Reply: c \"I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure\n",
      "Reply [sampled]: c<scn>d\"</scn></p>\n",
      "<p><msg>d\"I was just going to go home. <d><scn>c<scn>d\"</scn></scn></p>\n",
      "<p><msg>c\"You are not a scientist.\"<d><scn>c<scn>d\"</scn></scn></p>\n",
      "<p><\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    ('<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hey!\"', \"How are you?\"),\n",
    "    ('<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"', \"What do you think of Lorem?\"),\n",
    "    ('<p><msg>m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('<p><msg>m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "def sample_test(model_manager):\n",
    "    for (past, prompt) in prompts:\n",
    "        print(f\"Prompt: {prompt}\")\n",
    "        reply = model_manager.say(past, prompt)\n",
    "        print(f\"Reply: {reply}\")\n",
    "        reply = model_manager.say(past, prompt, top_k = 50, top_p = 0.7)\n",
    "        print(f\"Reply [sampled]: {reply}\")\n",
    "        print(\"-\" * 10)\n",
    "sample_test(model_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "002824b2-28d2-4df5-b73c-a9116273fbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "park2<msg>Ry \"How are you?\"<p><msg>c \"How are you?\"<d><scn>park2<msg>Ry \"How are you?\"<p><msg>c \"How are you?\"<d><scn>park2<msg>Ry \"How are you?\"<p><msg>c \"How are you?\"<d><scn>park2\n",
      "park2<msg>Remy<msg>c \"Hey!\"<p><msg>c \"Hey!\"<d><scn>park2<msg>Remy<msg>c \"Hey!\"<p><msg>c \"Hey!\"<d><scn>park2<msg>Remy<msg>c \"Hey!\"<p><msg>c \"Hey!\"<d><scn\n",
      "park2<msg>Remy \"Good, I'm fine.\"<p><msg>c \"You're fine, I'm fine.\"<d><scn>park2<msg>Remy \"You're fine, I'm fine.\"<p><msg>c \"You're fine, I'm fine.\"<d><scn>park2<msg>Remy \"You're fine, I'm\n",
      "park2<msg>Remy \"Good, I'm fine.\"<p><msg>c \"You're fine, I'm fine.\"<d><scn>park2<msg>Remy \"You're fine, I'm fine.\"<p><msg>c \"You're fine, I'm fine.\"<d><scn>park2<msg>Remy \"You're fine, I'm\n",
      "park2<msg>R \"Good, I'm fine.\"<p><msg>c \"You're fine, I'm fine.\"<p><msg>c \"You're fine, I'm fine.\"<p><msg>c \"You're fine, I'm fine.\"<p><msg>c \"You're fine, I'm fine.\"<p><msg>c \"You're fine, I'm\n",
      "park2<msg>R \"Good, thanks.\"<p><msg>c \"You're welcome.\"<d><scn>park2<msg>R \"You're welcome.\"<p><msg>c \"You're welcome.\"<d><scn>park2<msg>R \"You're welcome.\"<p><msg>c \"You're welcome.\"<d><scn>park2\n",
      "park2<msg>R \"Good, thanks.\"<p><msg>c \"You're welcome.\"<d><scn>park2<msg>R \"I'm afraid I'm going to have to take a while.\"<p><msg>c \"You're welcome.\"<d><scn>park2<msg>R \"I'm afraid I'm going to have to take a while.\"<\n",
      "park2<msg>R \"Good, thanks.\"<p><msg>c \"You're welcome.\"<d><scn>park2<msg>R \"I'm afraid I'm going to have to take this all on my own.\"<p><msg>c \"You're welcome.\"<d><scn>park2<msg>R \"I'm afraid I'm going to have to take this\n",
      "park2<msg>R \"Good, thanks.\"<p><msg>c \"You're welcome.\"<d><scn>park2<msg>R \"I'm afraid. I'm afraid I'm afraid I'm afraid I'm afraid I'm afraid I'm afraid I'm afraid I'm afraid I'm afraid I'm afraid I'm afraid I'm afraid I'm afraid I'm afraid I'm afraid I'm\n",
      "park2<msg>R \"I'm fine, I'm fine.\"<p><msg>c \"You're fine, I'm fine.\"<p><msg>c \"You're fine, I'm fine.\"<p><msg>c \"You're fine, I'm fine.\"<p><msg>c \"You're fine, I'm fine.\"<p><msg>c \"You're fine,\n",
      "park2<msg>Ry \"I'm fine.\"<p><msg>c \"I'm afraid I'm going to ruin you.\"<d><scn>park2<msg>Ry \"I'm afraid I'm going to ruin you.\"<p><msg>c \"I'm afraid I'm going to ruin you.\"<d><scn>park2<msg>Ry \"I'm afraid I'm\n"
     ]
    }
   ],
   "source": [
    "def is_good(model):\n",
    "    is_good = False\n",
    "    for (past, prompt) in prompts:\n",
    "        reply = model_manager.say(past, prompt)\n",
    "        print(reply)\n",
    "        return reply.startswith('park2<msg>Ry \"I\\'m fine')\n",
    "    return is_good\n",
    "model_mixing = ModelMixing(base_model, main_model, target_model, is_good, seed = 3443)\n",
    "model_mixing.start_mixing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b415905-4c6e-456f-b421-1e86c6e85579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pytorch] Visit Lorem -> lorem<msg>c \"This is Lorem. I'm afraid of the wild, but I'm so afraid of the wild that I'll just have to share it with you.\"<|endoftext|>\n",
      "----------\n",
      "[Pytorch] Meet with Lorem -> lorem<msg>c \"This is Lorem. We have just about two years of knowledge.\"<d><scn>lorem<msg>c \"This is Lorem. We have just about two years of knowledge.\"<d><scn>lorem<msg>c \"This is Lorem. We have just about two years of knowledge.\"<d><scn>lorem<msg>c \"This is Lorem. We have just about two years of knowledge.\"<d><scn>lorem\n",
      "----------\n",
      "[Pytorch] Visit Adine -> loremapt<msg>Ad \"Hey, [player_name]. I'm with you.\"<p><msg>c \"Hey, [player_name]. I'm with you.\"<p><msg>c \"Hey, [player_name]. I'm with you.\"<|endoftext|>\n",
      "----------\n",
      "[Pytorch] Fight Maverick -> o<msg>m \"He's just out here, and it's a nice place.\"<p><msg>c \"You're right. I'm getting too excited about this. I'm going to ruin you.\"<d><scn>o<msg>c \"This is an interesting time for me.\"<p><msg>c \"I'm leaving.\"<p><msg>c \"You're right. I'm leaving.\"<d><scn>o<msg>c \"You're right. I'm leaving.\"\n",
      "----------\n",
      "[Pytorch] Fight Adine -> Adine<msg>Ad \"Remy's name.\"<d><scn>Remy<msg>Remy<msg>Remy<msg>Remy<msg>Remy<msg>Remy<msg>Remy<msg>Remy<msg>Remy<msg>Remy<msg>Remy<msg>Remy<msg>Remy<msg>Remy<msg>Remy<msg>Remy<msg>Remy<msg>Remy<msg>Remy<\n",
      "----------\n",
      "[Pytorch] Attack Adine -> c \"You're right. I'm a stupidess, but I'm not afraid of you.\"<d><scn>c \"You're right. I'm not afraid of you.\"<d><scn>c \"You're right.\"<d><scn>c \"You're right.\"<d><scn>c \"You're right.\"<d><scn>c \"You're right.\"<d><scn>c \"You're right.\"<d><scn>c \"You're right.\"\n",
      "----------\n",
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm fine.\"<p><msg>c \"I'm afraid I'm going to ruin you.\"<d><scn>park2<msg>Ry \"I'm afraid I'm going to ruin you.\"<p><msg>c \"I'm afraid I'm going to ruin you.\"<d><scn>park2<msg>Ry \"I'm afraid I'm\n",
      "Reply [sampled]: park2<msg>Ry \"I'm fine.\"<p><msg>c \"I'm afraid. I'm afraid I'm afraid.\"<p><msg>c \"What's that?\"<d><scn>park2<msg>Ry \"I'm afraid that I'm afraid.\"<p><msg>c \"What is it?\"<d><scn>park2<msg>Ry \"It\n",
      "----------\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"I think he's cute.\"<p><msg>c \"I'm afraid he's cute.\"<p><msg>c \"I'm afraid he's cute.\"<p><msg>c \"I'm afraid he's cute.\"<p><msg>c \"I'm afraid he's cute.\"<p><msg>c \"I\n",
      "Reply [sampled]: park2<msg>Ad \"I think it's a nice.\"<p><msg>c \"Yeah, I'm very nice.\"<p><msg>c \"What is it?\"<d><scn>park2<msg>Ad \"I'm afraid we're over.\"<p><msg>c \"What is it?\"<d><scn>park\n",
      "----------\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: o<msg>Ad \"It's a cute thing, I think.\"<p><msg>c \"It's a cute thing, I think.\"<p><msg>c \"It's a cute thing, I think.\"<p><msg>c \"It's a cute thing, I think.\"<p><msg>c \"It's a cute thing, I think.\"<p><msg>c\n",
      "Reply [sampled]: black<p><msg>c \"It's my pleasure.\"<p><msg>c \"It's a nice thing, I think.\"<p><msg>c \"It's a nice thing, I think.\"<p><msg>c \"It's nice to have you on my side.\"<p><msg>c \"You're right.\"<p><msg>c \"I think I'm right\n",
      "----------\n",
      "Prompt: What will we do here?\n",
      "Reply: c \"You're right.\"<p><msg>c \"You're right.\"<p><msg>c \"You're right.\"<p><msg>c \"You're right.\"<p><msg>c \"You're right.\"<p><msg>c \"You're right.\"<p><msg>c \"You're right.\"<p><msg>c \"You're right.\"<p><msg>c \"You\n",
      "Reply [sampled]: o<msg>c \"This is an interesting question.\"<p><msg>c \"It's a shame to have to spend so much time with people.\"<p><msg>c \"It is a shame to have to take such an extraordinary, difficult, difficult, difficult, difficult, difficult, difficult, difficult, difficult, difficult, difficult, difficult, difficult, difficult, difficult, difficult, difficult, difficult, difficult, difficult, difficult\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "test_rps = [\n",
    "    \"Visit Lorem\",\n",
    "    \"Meet with Lorem\",\n",
    "    \"Visit Adine\",\n",
    "    \"Fight Maverick\",\n",
    "    \"Fight Adine\",\n",
    "    \"Attack Adine\"\n",
    "]\n",
    "for rp in test_rps:\n",
    "    print(f'[Pytorch] {rp} -> {model_manager.say(\"\", rp, top_k = 50, top_p = 0.7)}')\n",
    "    print(\"-\" * 10)\n",
    "    \n",
    "sample_test(model_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015ae23f-75b7-4abe-9d72-4311ab6bf1db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
