{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "921ec9f4-2e97-4002-8d4a-bf8a36ef888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_utils import train_model, split_data, split_branches, get_model, set_pretrained_model_dropout, get_dataset, ModelSeeder\n",
    "from config import Config\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import onnx\n",
    "import logging\n",
    "from onnx_model_manager import OnnxModelManager\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "import os\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from model_manager import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1561d726-ba19-40d4-8886-cafa95aeb925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded base and main model to CPU\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = os.path.join(\"models\", \"awsw_main\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "main_model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "base_model, _ = get_model(\"EleutherAI/gpt-neo-125M\")\n",
    "target_model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
    "device = torch.device('cpu')\n",
    "model_manager = ModelManager(model=target_model, tokenizer=tokenizer, device=device)\n",
    "print(f\"Loaded base and main model to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "374b092e-bdcb-4fa6-bb0e-0863a2cd2869",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm fine.\"<p><msg>c \"I'm fine.\"<p><msg>c \"I'm fine.\"<p><msg>c \"I'm fine.\"<p><msg>c \"I'm fine.\"<p><msg>c \"I'm fine.\"<p><msg>c \"I'm fine.\"<p><msg>c \"I'm\n",
      "Reply [sampled]: park2<msg>Ry \"Hey, I'm just about done here, but I think I've had to do something a little different.\"<p><msg>c \"Yeah, I'm fine.\"<d><scn>park2<msg>Ry \"I'm just having a little fun, I guess.\"<|endoftext|>\n",
      "----------\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"I think he's a good student.\"<p><msg>c \"I'm not sure, but I think he's a good student.\"<p><msg>c \"I'm not sure, but I think I can handle it.\"<p><msg>c \"I'm not sure, but I think I can handle it.\"<\n",
      "Reply [sampled]: park2<msg>Ad \"I'm not sure, but I think he's a good art critic.\"<p><msg>c \"I can see that.\"<p><msg>c \"I'm not sure what you're talking about.\"<d><scn>park2<msg>Ad \"I think I should get going.\"<p><msg>c\n",
      "----------\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: park<msg>Adine, I don't know. I don't want to. I don't want to. I don't want to. I don't want to. I don't want to. I don't want to. I don't want to. I don't want to. I don't want to. I don't want to. I don't want to. I don't want to. I\n",
      "Reply [sampled]: o<msg>Adine, you're a good girl, but you don't like me. I'm sorry, but I can't help but think that it's a waste of time. I'm leaving.\"<p><msg>c \"I can't help but think that it's a waste of time.\"<d><scn>o<msg>Adine, I think it's time for you to\n",
      "----------\n",
      "Prompt: What will we do here?\n",
      "Reply: cafe<msg>An \"I'll just go ahead and call you when I'm done.\"<p><msg>c \"I'll see if I can find anything.\"<d><scn>cafe<msg>An \"I'll try.\"<|endoftext|>\n",
      "Reply [sampled]: loremapt<msg>I \"I'll take a look.\"<p><msg>c \"What do you think is the biggest, most important thing that makes the world a sphere?\"<d><scn>loremapt<msg>I \"It's the same thing you do.\"<p><msg>c \"It's the same thing you do.\"<p><msg>c \"It's the same thing you do.\"\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    ('<p><msg>c \"Hey Remy!\"<d><scn>park2<msg>Ry \"Hey!\"', \"How are you?\"),\n",
    "    ('<p><msg>c \"I was with Lorem today.\"<d><scn>park2<msg>Ad \"Very nice.\"', \"What do you think of Lorem?\"),\n",
    "    ('<p><msg>m \"In Tatsu park, Adine and I sat down.\"', \"Oh my god, Adine. What is this?\"),\n",
    "    ('<p><msg>m \"I sat down on a chair in Anna\\'s lab.\"', \"What will we do here?\"),\n",
    "]\n",
    "\n",
    "def sample_test(model_manager):\n",
    "    for (past, prompt) in prompts:\n",
    "        print(f\"Prompt: {prompt}\")\n",
    "        reply = model_manager.say(past, prompt)\n",
    "        print(f\"Reply: {reply}\")\n",
    "        reply = model_manager.say(past, prompt, top_k = 50, top_p = 0.7)\n",
    "        print(f\"Reply [sampled]: {reply}\")\n",
    "        print(\"-\" * 10)\n",
    "sample_test(model_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "002824b2-28d2-4df5-b73c-a9116273fbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for p1, p2, p3 in zip(main_model.parameters(), base_model.parameters(), target_model.parameters()):\n",
    "        p3.data = torch.lerp(p1.data, p2.data, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b415905-4c6e-456f-b421-1e86c6e85579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pytorch] Visit Lorem -> loremapt<msg>Lo \"Hey [player_name]!\"<|endoftext|>\n",
      "----------\n",
      "[Pytorch] Meet with Lorem -> loremapt<msg>Lo \"Hey [player_name]! How are you?\"<|endoftext|>\n",
      "----------\n",
      "[Pytorch] Visit Adine -> adineapt<msg>Ad \"Hey, [player_name]!\"<|endoftext|>\n",
      "----------\n",
      "[Pytorch] Fight Maverick -> o2<msg>m \"Maverick dodges my attack and comes out with a nice, wide, and cheap weapon. I think he's getting desperate.\"<d><scn>o2<msg>m \"I'm just saying Maverick's actions are very similar to what I just said.\"<d><scn>o2<msg>m \"I'm not sure if there is anything I can do to help, but I'll be right back.\"<d><scn>o2<msg>m \"\n",
      "----------\n",
      "[Pytorch] Fight Adine -> cafe<msg>m \"Adine barely avoids my attack, and I quickly dove behind her, trying to stay in cover as I dove into the water.\"<d><scn>cafe<msg>m \"I quickly dove behind her, but she managed to get up and quickly punch me in the face, a fish in the line of fire.\"<d><scn>cafe<msg>m \"I was just about to start on my second when I suddenly heard her voice.\"<d><scn>cafe\n",
      "----------\n",
      "[Pytorch] Attack Adine -> cafe<msg>m \"Adine dodges my attack and comes towards me.\"<|endoftext|>\n",
      "----------\n",
      "Prompt: How are you?\n",
      "Reply: park2<msg>Ry \"I'm fine. I'm just a little busy.\"<p><msg>c \"I'm not sure if I should take any visitors.\"<d><scn>park2<msg>Ry \"No, I'm not going to be rude or anything, but I think it's better if we go our separate ways.\"<p><msg>c \"Hey Remy!\"<d\n",
      "Reply [sampled]: park2<msg>Ry \"Well, I'm just about done here for the day, but if you want to discuss it further, I'd be more than happy.\"<p><msg>c \"I'm fine.\"<d><scn>park2<msg>Ry \"I'm fine. I'll just be careful.\"<|endoftext|>\n",
      "----------\n",
      "Prompt: What do you think of Lorem?\n",
      "Reply: park2<msg>Ad \"I think he's a good student.\"<p><msg>c \"I'm not sure, I am not a linguist. Are you?\"<d><scn>park2<msg>Ad \"Not really. I am a linguist. Are you?\"<p><msg>c \"I'm not sure, I am not\n",
      "Reply [sampled]: park2<msg>Ad \"I think he's a nice fellow.\"<p><msg>c \"I'm not sure if he's a particularly friendly person.\"<d><scn>park2<msg>Ad \"I think he's friendly.\"<p><msg>c \"I'm not sure if he's a particularly friendly person.\"<d><scn\n",
      "----------\n",
      "Prompt: Oh my god, Adine. What is this?\n",
      "Reply: park2<msg>Ad \"It's a long story.\"<p><msg>c \"I don't know. We have no time for that.\"<d><scn>park2<msg>Ad \"It's too late.\"<p><msg>c \"I don't know. We have no time for that.\"<d><scn>park2<msg>Ad \"It's too\n",
      "Reply [sampled]: o2<msg>Ad \"It's a children's game. It's a children's game. It's a game about humans and their society.\"<d><scn>o2<msg>Ad \"It's a game about humans and their society. It's a children's game. It's a game about humans and their society. It's a children's game. It's a game about humans and\n",
      "----------\n",
      "Prompt: What will we do here?\n",
      "Reply: loremapt<msg>Ip \"I'll take a seat.\"<d><scn>loremapt<msg>Ip \"This apartment is mine as my home is now.\"<p><msg>c \"I'll take a seat.\"<d><scn>loremapt<msg>Ip \"This apartment is my home, I'll take care of it.\"<p><msg>c \"I'll take\n",
      "Reply [sampled]: loremapt<msg>Ip \"We'll look for a different one, and I'll be your waitress today. I'll be right back.\"<p><msg>c \"How about a seat?\"<d><scn>loremapt<msg>Ip \"The right thing to do is to get out of your seat and go to the other side of the table.\"<p><msg>c \"How does it look\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "test_rps = [\n",
    "    \"Visit Lorem\",\n",
    "    \"Meet with Lorem\",\n",
    "    \"Visit Adine\",\n",
    "    \"Fight Maverick\",\n",
    "    \"Fight Adine\",\n",
    "    \"Attack Adine\"\n",
    "]\n",
    "for rp in test_rps:\n",
    "    print(f'[Pytorch] {rp} -> {model_manager.say(\"\", rp, top_k = 50, top_p = 0.7)}')\n",
    "    print(\"-\" * 10)\n",
    "    \n",
    "sample_test(model_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015ae23f-75b7-4abe-9d72-4311ab6bf1db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
